{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61979795",
   "metadata": {},
   "source": [
    "# HOMO-LUMO Gap Predictions\n",
    "\n",
    "### Problem Statement & Motivation\n",
    "\n",
    "Accurately predicting quantum chemical properties like the HOMO–LUMO energy gap is essential for advancing materials science, drug discovery, and electronic design. The HOMO–LUMO gap is particularly informative for assessing molecular reactivity and stability. While Density Functional Theory (DFT) provides precise estimates, its high computational cost makes it impractical for large-scale screening of molecular libraries. This notebook explores machine learning alternatives that are fast, scalable, and interpretable, offering solutions that are accessible even on modest hardware.\n",
    "\n",
    "### Related Work & Key Gap\n",
    "\n",
    "Past work has shown that:\n",
    "\n",
    "* DFT is accurate but computationally intensive\n",
    "* ML models like kernel methods and GNNs show promise, but often require large models and expensive hardware\n",
    "\n",
    "Key Gap: A need for lightweight, high-performing models that can run locally and integrate with user-friendly tools for deployment in research or education.\n",
    "\n",
    "### Methodology & Evaluation\n",
    "\n",
    "This notebook:\n",
    "\n",
    "* Benchmarks a variety of 2D-based models using RDKit descriptors, Coulomb matrices, and graph neural networks (GNNs) on a 5k molecule subset\n",
    "* Progresses to a hybrid GNN architecture combining OGB-standard graphs with SMILES-derived cheminformatics features\n",
    "* Achieves **MAE = 0.159 eV**\n",
    "* Visualizes results using parity plots, error inspection, and predicted-vs-true comparisons\n",
    "* Evaluates both random and high-error cases to better understand model behavior\n",
    "\n",
    "| Metric   | Best Model (Hybrid GNN) |\n",
    "| -------- | ----------------------- |\n",
    "| **MAE**  | 0.159 eV                |\n",
    "| **RMSE** | 0.234 eV                |\n",
    "| **R²**   | 0.965                   |\n",
    "\n",
    "\n",
    "### Deployment & Accessibility\n",
    "\n",
    "To make the model practically useful, an **interactive web app** was developed:\n",
    "\n",
    "**Live App**: [HOMO–LUMO Gap Predictor on Hugging Face](https://huggingface.co/spaces/MooseML/homo-lumo-gap-predictor)\n",
    "\n",
    "Features:\n",
    "\n",
    "* **SMILES input** for any organic molecule\n",
    "* **Real-time prediction** of the HOMO–LUMO gap\n",
    "* **Molecular visualization**\n",
    "* Simple **CSV logging** for result tracking\n",
    "\n",
    "GitHub Repository: [MooseML/homo-lumo-gap-models](https://github.com/MooseML/homo-lumo-gap-models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a8192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ace_tools_open as tools\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import pickle\n",
    "import joblib\n",
    "import os \n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, Module, Sequential, Dropout\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# OGB dataset \n",
    "from ogb.lsc import PygPCQM4Mv2Dataset, PCQM4Mv2Dataset\n",
    "from ogb.utils import smiles2graph\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "# RDKit\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "\n",
    "# ChemML\n",
    "from chemml.chem import Molecule, RDKitFingerprint, CoulombMatrix, tensorise_molecules\n",
    "from chemml.models import MLP, NeuralGraphHidden, NeuralGraphOutput\n",
    "from chemml.utils import regression_metrics\n",
    "\n",
    "# SKlearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "589db70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Built with CUDA: True\n",
      "CUDA available: True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Device: /physical_device:GPU:0\n",
      "Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"CUDA available:\", tf.test.is_built_with_gpu_support())\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# list all GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# check compute capability if GPU available\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(f\"Device: {gpu.name}\")\n",
    "        print(f\"Compute Capability: {details.get('compute_capability')}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b585ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: data\n",
      "LMDB directory: data\\processed_chunks\n",
      "Train LMDB: data\\processed_chunks\\polymer_train3d_dist.lmdb\n",
      "Test LMDB: data\\processed_chunks\\polymer_test3d_dist.lmdb\n",
      "LMDBs already exist.\n"
     ]
    }
   ],
   "source": [
    "# Paths - Fixed for Kaggle environment\n",
    "if os.path.exists('/kaggle'):\n",
    "    DATA_ROOT = '/kaggle/input/neurips-open-polymer-prediction-2025'\n",
    "    CHUNK_DIR = '/kaggle/working/processed_chunks'  # Writable directory\n",
    "    BACKBONE_PATH = '/kaggle/input/polymer/best_gnn_transformer_hybrid.pt'\n",
    "else:\n",
    "    DATA_ROOT = 'data'\n",
    "    CHUNK_DIR = os.path.join(DATA_ROOT, 'processed_chunks')\n",
    "    BACKBONE_PATH = 'best_gnn_transformer_hybrid.pt'\n",
    "\n",
    "TRAIN_LMDB = os.path.join(CHUNK_DIR, 'polymer_train3d_dist.lmdb')\n",
    "TEST_LMDB = os.path.join(CHUNK_DIR, 'polymer_test3d_dist.lmdb')\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"LMDB directory: {CHUNK_DIR}\")\n",
    "print(f\"Train LMDB: {TRAIN_LMDB}\")\n",
    "print(f\"Test LMDB: {TEST_LMDB}\")\n",
    "\n",
    "# Create LMDBs if they don't exist\n",
    "if not os.path.exists(TRAIN_LMDB) or not os.path.exists(TEST_LMDB):\n",
    "    print('Building LMDBs...')\n",
    "    os.makedirs(CHUNK_DIR, exist_ok=True)\n",
    "    # Run the LMDB builders\n",
    "    !python build_polymer_lmdb_fixed.py train\n",
    "    !python build_polymer_lmdb_fixed.py test\n",
    "    print('LMDB creation complete.')\n",
    "else:\n",
    "    print('LMDBs already exist.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c34b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV with shape: (7973, 6)\n",
      "                                                 SMILES  Tg       FFV  \\\n",
      "7560  *C=Cc1ccc2c3ccc(*)cc3n(-c3ccc(OCCCCCCCCCC)c(OC... NaN  0.386695   \n",
      "1405                  *CC(=O)NCCCCCCNC(=O)Cc1ccc(O*)cc1 NaN  0.335504   \n",
      "5196                              *CC(*)c1ccccc1C(=O)NC NaN  0.355580   \n",
      "2087  *c1ccc2c(c1)C(=O)N(c1ccc(Oc3ccc(N4C(=O)c5ccc(-... NaN  0.401573   \n",
      "3337                    *CC(*)OC(=O)c1ccc(-c2ccccc2)cc1 NaN  0.353609   \n",
      "\n",
      "            Tc  Density  Rg  \n",
      "7560       NaN      NaN NaN  \n",
      "1405       NaN      NaN NaN  \n",
      "5196  0.183667      NaN NaN  \n",
      "2087       NaN      NaN NaN  \n",
      "3337       NaN      NaN NaN  \n"
     ]
    }
   ],
   "source": [
    "# /path/to/your_script.py\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_path = os.path.join(DATA_ROOT, 'train.csv')\n",
    "train_df   = pd.read_csv(train_path)\n",
    "\n",
    "#  Keep only the columns we care about \n",
    "target_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "train_df   = train_df[target_cols]        # drops id and any other columns\n",
    "\n",
    "#  Sample a subset (optional) \n",
    "n = len(train_df)\n",
    "subset_size = n                         # change to whatever you need\n",
    "subset_df   = train_df.sample(subset_size, random_state=42)\n",
    "\n",
    "#  Save the subset as a CSV \n",
    "subset_path = os.path.join(DATA_ROOT, 'train_subset.csv')\n",
    "subset_df.to_csv(subset_path, index=False)\n",
    "\n",
    "print(f\"Saved CSV with shape: {subset_df.shape}\")\n",
    "print(subset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f5f955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = Molecule(subset_df['SMILES'][0], input_type='smiles')\n",
    "mol.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f557b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7973 molecules.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(subset_path)\n",
    "print(f\"Loaded {len(df)} molecules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04007d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*C=Cc1ccc2c3ccc(*)cc3n(-c3ccc(OCCCCCCCCCC)c(OC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.386695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*CC(=O)NCCCCCCNC(=O)Cc1ccc(O*)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*CC(*)c1ccccc1C(=O)NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355580</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*c1ccc2c(c1)C(=O)N(c1ccc(Oc3ccc(N4C(=O)c5ccc(-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*CC(*)OC(=O)c1ccc(-c2ccccc2)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  Tg       FFV        Tc  \\\n",
       "0  *C=Cc1ccc2c3ccc(*)cc3n(-c3ccc(OCCCCCCCCCC)c(OC... NaN  0.386695       NaN   \n",
       "1                  *CC(=O)NCCCCCCNC(=O)Cc1ccc(O*)cc1 NaN  0.335504       NaN   \n",
       "2                              *CC(*)c1ccccc1C(=O)NC NaN  0.355580  0.183667   \n",
       "3  *c1ccc2c(c1)C(=O)N(c1ccc(Oc3ccc(N4C(=O)c5ccc(-... NaN  0.401573       NaN   \n",
       "4                    *CC(*)OC(=O)c1ccc(-c2ccccc2)cc1 NaN  0.353609       NaN   \n",
       "\n",
       "   Density  Rg  \n",
       "0      NaN NaN  \n",
       "1      NaN NaN  \n",
       "2      NaN NaN  \n",
       "3      NaN NaN  \n",
       "4      NaN NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1779d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values by Column:\n",
      "         Total Missing  Percent Missing\n",
      "SMILES               0         0.000000\n",
      "Tg                7462        93.590869\n",
      "FFV                943        11.827418\n",
      "Tc                7236        90.756303\n",
      "Density           7360        92.311551\n",
      "Rg                7359        92.299009\n",
      "\n",
      "Feature Statistics (Min, Max, Mean, etc.):\n",
      "               Tg          FFV          Tc     Density          Rg\n",
      "count  511.000000  7030.000000  737.000000  613.000000  614.000000\n",
      "mean    96.452314     0.367212    0.256334    0.985484   16.419787\n",
      "std    111.228279     0.029609    0.089538    0.146189    4.608640\n",
      "min   -148.029738     0.226992    0.046500    0.748691    9.728355\n",
      "25%     13.674509     0.349549    0.186000    0.890243   12.540328\n",
      "50%     74.040183     0.364264    0.236000    0.948193   15.052194\n",
      "75%    161.147595     0.380790    0.330500    1.062096   20.411067\n",
      "max    472.250000     0.777097    0.524000    1.840999   34.672906\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "total_rows = len(df)\n",
    "percent_missing = (missing_values / total_rows) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Total Missing': missing_values,\n",
    "    'Percent Missing': percent_missing\n",
    "})\n",
    "\n",
    "print(\"Missing Values by Column:\")\n",
    "print(missing_df)\n",
    "print(\"\\nFeature Statistics (Min, Max, Mean, etc.):\")\n",
    "print(df[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125f621",
   "metadata": {},
   "source": [
    "The only property that appears will succeed with a simple imputation strategy is FFV. All other properties contain very high percent missing. Therefore, I will impute median for FFV, train a model for FFV, and train separate models for other properties. I will attempt to filter out missing values for each property. If this yields uncessful, I may explore sampling techniques or use the trained model to impute values to train a secondaery model. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe69f3",
   "metadata": {},
   "source": [
    "# Tg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc711963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Tg DataFrame shape: (7973, 2)\n",
      "Initial Tg Missing Values:\n",
      "SMILES       0\n",
      "Tg        7462\n",
      "dtype: int64\n",
      "\n",
      "Cleaned Tg DataFrame shape: (511, 2)\n",
      "Cleaned Tg Missing Values:\n",
      "SMILES    0\n",
      "Tg        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a new DataFrame with only the SMILES and Tg columns\n",
    "df_tg = df[['SMILES', 'Tg']].copy()\n",
    "\n",
    "print(\"Initial Tg DataFrame shape:\", df_tg.shape)\n",
    "print(\"Initial Tg Missing Values:\")\n",
    "print(df_tg.isnull().sum())\n",
    "\n",
    "# 2. Drop all rows where the 'Tg' value is missing\n",
    "df_tg.dropna(subset=['Tg'], inplace=True)\n",
    "\n",
    "print(\"\\nCleaned Tg DataFrame shape:\", df_tg.shape)\n",
    "print(\"Cleaned Tg Missing Values:\")\n",
    "print(df_tg.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d169da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem, Descriptors, HybridizationType, SanitizeFlags\n",
    "def rdkit_ogb_agree(smi: str) -> bool:\n",
    "    m = Chem.MolFromSmiles(smi)\n",
    "    if m is None:\n",
    "        return False\n",
    "    return m.GetNumAtoms() == smiles2graph(smi)[\"num_nodes\"]\n",
    "\n",
    "def canonicalize_polymer_smiles(smiles: str, cap_atomic_num: int = 6) -> str:\n",
    "    \"\"\"\n",
    "    Turn every '*' (dummy atom) into a real atom (default C) in the RDKit graph,\n",
    "    preserving existing bond orders/stereo; sanitize, remove explicit Hs, and\n",
    "    return canonical isomeric SMILES.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"RDKit could not parse SMILES: {smiles}\")\n",
    "\n",
    "    rw = Chem.RWMol(mol)\n",
    "    for a in rw.GetAtoms():\n",
    "        if a.GetAtomicNum() == 0:   # '*'\n",
    "            a.SetAtomicNum(cap_atomic_num)  # 6 = carbon\n",
    "            a.SetFormalCharge(0)\n",
    "            a.SetIsAromatic(False)\n",
    "            a.SetNoImplicit(False)\n",
    "            a.SetNumExplicitHs(0)\n",
    "\n",
    "    mol2 = rw.GetMol()\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol2)\n",
    "    except Exception:\n",
    "        Chem.SanitizeMol(mol2, sanitizeOps=SanitizeFlags.SANITIZE_ALL ^ SanitizeFlags.SANITIZE_KEKULIZE)\n",
    "        Chem.Kekulize(mol2, clearAromaticFlags=True)\n",
    "\n",
    "    mol2 = Chem.RemoveHs(mol2)\n",
    "    return Chem.MolToSmiles(mol2, isomericSmiles=True, canonical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff48e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on *CC(*)(C)C(=O)OCCOC(=O)c1cc(OC(=O)c2ccc(N=Nc3ccc(OCCCCCCC)cc3)cc2)cc(OC(=O)c2ccc(N=Nc3ccc(OCCCCCCC)cc3)cc2)c1 | Reason: Bad Conformer Id\n",
      "Failed on *c1ccc(-c2cc(Oc3ccc(S(=O)(=O)O[Na])cc3)c(*)cc2Oc2ccc(S(=O)(=O)O[Na])cc2)cc1 | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *C#CC(Cn1c2ccc(CCCCCCCCCCCCCCCC)cc2c2cc(CCCCCCCCCCCCCCCC)ccc21)=C(*)Cn1c2ccc(CCCCCCCCCCCCCCCC)cc2c2cc(CCCCCCCCCCCCCCCC)ccc21 | Reason: Bad Conformer Id\n",
      "Failed on *C#Cc1cc(OC(COCCOCCOCCOC)COCCOCCOCCOC)c(C#Cc2cc(OCCOCCOCCOCCC(=O)O[Na])c(*)cc2OCCOCCOCCOCCC(=O)O[Na])cc1OC(COCCOCCOCCOC)COCCOCCOCCOC | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *Oc1ccc(C(c2ccc(Oc3ccc(C(=O)c4ccc(*)cc4)cc3)cc2)c2ccccc2C(=O)O[Na])cc1 | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *Nc1ccc(NC(=O)c2cc(C(*)=O)c(C(=O)O)cc2C(=O)O)cc1S(=O)(=O)O[Na] | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *c1ccc2c(c1)C(CCCCCCCC)(CCCCCCCC)c1cc(-c3ccc4c(c3)C(CCCCCCCCCCCC)(CCCCCCCCCCCC)c3cc(*)ccc3-4)ccc1-2 | Reason: Bad Conformer Id\n",
      "Kept 504 molecules after filtering.\n",
      "Kept 504 molecules after filtering.\n",
      "Saved cleaned Tg dataset to 'cleaned_tg_dataset.csv'.\n",
      "Target shape: (504,)\n",
      "RDKit FP shape: (504, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Build the molecule list\n",
    "valid_mol_objs = []\n",
    "valid_targets = []  # Now stores an array with one value per molecule\n",
    "\n",
    "for i, row in df_tg.iterrows():\n",
    "    smi = row['SMILES']\n",
    "    \n",
    "    # 2.a Clean the SMILES first\n",
    "    cleaned_smiles = canonicalize_polymer_smiles(smi)\n",
    "\n",
    "    try:\n",
    "        # 2.b Create your custom Molecule from the cleaned string\n",
    "        mol = Molecule(cleaned_smiles, input_type='smiles')\n",
    "        mol.hydrogens('add')\n",
    "        mol.to_xyz(optimizer='MMFF', maxIters=200)\n",
    "\n",
    "        # 2.c Only keep molecules that got a 3-D geometry\n",
    "        if mol.xyz is not None:\n",
    "            valid_mol_objs.append(mol)\n",
    "            \n",
    "            # Keep only the 'Tg' target column as a NumPy array\n",
    "            valid_targets.append(\n",
    "                row[['Tg']].values\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipped bc missing xyz: {smi}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on {smi} | Reason: {e}\")\n",
    "\n",
    "print(f\"Kept {len(valid_mol_objs)} molecules after filtering.\")\n",
    "\n",
    "df_clean = pd.DataFrame({\n",
    "    'SMILES': [m.smiles for m in valid_mol_objs],\n",
    "    'Tg':     [t[0] for t in valid_targets],\n",
    "})\n",
    "print(f\"Kept {len(df_clean)} molecules after filtering.\")\n",
    "df_clean.to_csv('cleaned_tg_dataset.csv', index=False)\n",
    "print(\"Saved cleaned Tg dataset to 'cleaned_tg_dataset.csv'.\")\n",
    "\n",
    "y = np.array([t[0] for t in valid_targets])\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# Your feature computation will now work correctly\n",
    "fp_featurizer = RDKitFingerprint(\n",
    "    fingerprint_type='morgan', vector='bit', n_bits=1024, radius=3\n",
    ")\n",
    "X_fp = fp_featurizer.represent(valid_mol_objs)\n",
    "\n",
    "print(\"RDKit FP shape:\", X_fp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff620911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Feature Splits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_5f403d4c_e3b8_4cfd_9fa8_074364eadeea\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>Split</th>\n",
       "      <th>Shape</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.3.0 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_5f403d4c_e3b8_4cfd_9fa8_074364eadeea:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"X_train_fp_scaled\", \"(403, 1024)\"], [\"X_test_fp_scaled\", \"(101, 1024)\"], [\"y_train_scaled\", \"(403, 1)\"], [\"y_test_scaled\", \"(101, 1)\"], [\"X_train_fp_unscaled\", \"(403, 1024)\"], [\"X_test_fp_unscaled\", \"(101, 1024)\"], [\"y_train_unscaled\", \"(403,)\"], [\"y_test_unscaled\", \"(101,)\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # 1. make separate train/test splits for both scaled and unscaled targets\n",
    "# # scaled targets (MLP, KRR, GNN)\n",
    "# X_train_fp_scaled, X_test_fp_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "#     X_fp, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "# # X_train_cm_scaled, X_test_cm_scaled, _, _ = train_test_split(\n",
    "# #     X_cm, y, test_size=0.2, random_state=42\n",
    "# # )\n",
    "\n",
    "# xscaler_fp = StandardScaler()\n",
    "# # xscaler_cm = StandardScaler()\n",
    "# yscaler = StandardScaler()\n",
    "\n",
    "# X_train_fp_scaled = xscaler_fp.fit_transform(X_train_fp_scaled)\n",
    "# X_test_fp_scaled  = xscaler_fp.transform(X_test_fp_scaled)\n",
    "\n",
    "# # X_train_cm_scaled = xscaler_cm.fit_transform(X_train_cm_scaled)\n",
    "# # X_test_cm_scaled  = xscaler_cm.transform(X_test_cm_scaled)\n",
    "\n",
    "# y_train_scaled = yscaler.fit_transform(y_train_scaled)\n",
    "# y_test_scaled  = yscaler.transform(y_test_scaled)\n",
    "\n",
    "# # b) unscaled targets (Random Forest)\n",
    "# y_unscaled = y              \n",
    "# X_train_fp_unscaled, X_test_fp_unscaled, y_train_unscaled, y_test_unscaled = train_test_split(\n",
    "#     X_fp, y_unscaled, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # 2. show shapes\n",
    "# tools.display_dataframe_to_user(\n",
    "#     name=\"Cleaned Feature Splits\",\n",
    "#     dataframe=pd.DataFrame({\n",
    "#         \"Split\": [\n",
    "#             \"X_train_fp_scaled\", \"X_test_fp_scaled\",\n",
    "#             # \"X_train_cm_scaled\", \"X_test_cm_scaled\",\n",
    "#             \"y_train_scaled\",   \"y_test_scaled\",\n",
    "#             \"X_train_fp_unscaled\", \"X_test_fp_unscaled\",\n",
    "#             \"y_train_unscaled\",   \"y_test_unscaled\"\n",
    "#         ],\n",
    "#         \"Shape\": [\n",
    "#             X_train_fp_scaled.shape, X_test_fp_scaled.shape,\n",
    "#             # X_train_cm_scaled.shape, X_test_cm_scaled.shape,\n",
    "#             y_train_scaled.shape,   y_test_scaled.shape,\n",
    "#             X_train_fp_unscaled.shape, X_test_fp_unscaled.shape,\n",
    "#             y_train_unscaled.shape,   y_test_unscaled.shape\n",
    "#         ]\n",
    "#     })\n",
    "# )\n",
    "\n",
    "# 1. make separate train/test splits for both scaled and unscaled targets\n",
    "# a) Scaled targets (for KRR)\n",
    "# Your y is now a 1D array of FFV values.\n",
    "X_train_fp, X_test_fp, y_train, y_test = train_test_split(\n",
    "    X_fp, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "xscaler_fp = StandardScaler()\n",
    "yscaler = StandardScaler()\n",
    "\n",
    "X_train_fp_scaled = xscaler_fp.fit_transform(X_train_fp)\n",
    "X_test_fp_scaled = xscaler_fp.transform(X_test_fp)\n",
    "\n",
    "# Reshape y arrays for the StandardScaler\n",
    "y_train_scaled = yscaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = yscaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# b) Unscaled targets (for models that don't need scaling, like Random Forest)\n",
    "# These are the original, unscaled splits. You can use the variables you already created.\n",
    "X_train_fp_unscaled = X_train_fp\n",
    "X_test_fp_unscaled = X_test_fp\n",
    "y_train_unscaled = y_train\n",
    "y_test_unscaled = y_test\n",
    "\n",
    "# 2. show shapes\n",
    "# The shape display now reflects the single target variable\n",
    "tools.display_dataframe_to_user(\n",
    "    name=\"Cleaned Feature Splits\",\n",
    "    dataframe=pd.DataFrame({\n",
    "        \"Split\": [\n",
    "            \"X_train_fp_scaled\", \"X_test_fp_scaled\",\n",
    "            \"y_train_scaled\", \"y_test_scaled\",\n",
    "            \"X_train_fp_unscaled\", \"X_test_fp_unscaled\",\n",
    "            \"y_train_unscaled\", \"y_test_unscaled\"\n",
    "        ],\n",
    "        \"Shape\": [\n",
    "            X_train_fp_scaled.shape, X_test_fp_scaled.shape,\n",
    "            y_train_scaled.shape, y_test_scaled.shape,\n",
    "            X_train_fp_unscaled.shape, X_test_fp_unscaled.shape,\n",
    "            y_train_unscaled.shape, y_test_unscaled.shape\n",
    "        ]\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dc183",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression baseline first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9778d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  63.695431  85.338681   0.415116\n"
     ]
    }
   ],
   "source": [
    "# Kernel Ridge on RDKit fingerprints\n",
    "krr = KernelRidge(kernel='rbf', alpha=1.0)\n",
    "krr.fit(X_train_fp_scaled, y_train_scaled)\n",
    "\n",
    "# predict on scaled test set\n",
    "y_pred_krr_scaled = krr.predict(X_test_fp_scaled)\n",
    "\n",
    "# Inverse transform predictions and test targets to compare with unscaled values\n",
    "# You must reshape y_pred_krr_scaled and y_test_scaled to 2D before inverse transforming\n",
    "y_pred_krr = yscaler.inverse_transform(y_pred_krr_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_krr = yscaler.inverse_transform(y_test_scaled).flatten()\n",
    "\n",
    "# Eval against true unscaled test target\n",
    "print(\"Kernel Ridge (RDKit FP)\")\n",
    "metrics_krr = regression_metrics(y_test_krr, y_pred_krr)\n",
    "print(metrics_krr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fedd",
   "metadata": {},
   "source": [
    "## Random Forest Regression baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3ea7be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.404863  73.313325   0.568338\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RDKit FP) \n",
    "rfr = RandomForestRegressor(n_estimators=100, max_depth=30, random_state=42)\n",
    "rfr.fit(X_train_fp_unscaled, y_train_unscaled)\n",
    "# predict\n",
    "y_pred_rfr = rfr.predict(X_test_fp_unscaled)\n",
    "# eval\n",
    "print(\"Random Forest (RDKit FP)\")\n",
    "metrics_rfr = regression_metrics(y_test_unscaled, y_pred_rfr)\n",
    "print(metrics_rfr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74973657",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron with Morgan Fingerprints baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70bbb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7492\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7733\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4898\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3715\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3138\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2750\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2553\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2350\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2241\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2168\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2126\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2080\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2059\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2042\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2030\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2015\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2009\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1998\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1983\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1974\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1971\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1962\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1956\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1945\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1937\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1926\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1920\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1915\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1909\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1904\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1898\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1893\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1888\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1882\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1877\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1872\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1866\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1861\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1856\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1851\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1846\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1841\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1835\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1830\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1825\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1820\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1815\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1810\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1805\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1800\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1795\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1790\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1785\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1780\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1775\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1770\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1765\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1761\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1756\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1751\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1746\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1741\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1736\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1731\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1727\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1722\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1717\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1712\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1708\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1703\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1698\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1694\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1689\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1684\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1679\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1675\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1670\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1666\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1661\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1657\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1652\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1647\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1643\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1634\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1629\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1625\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1620\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1616\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1611\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1607\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1602\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1598\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1593\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1589\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1585\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1580\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1576\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1572\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1567\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1563\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1559\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1554\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1550\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1546\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1541\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1537\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1533\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1529\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1525\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1520\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1516\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1512\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1508\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1504\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1500\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1495\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1491\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1487\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1483\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1479\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1475\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1471\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1467\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1463\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1459\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1455\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1451\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1447\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1443\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1439\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1435\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1431\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1427\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1423\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1419\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1415\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1411\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1407\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1403\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1399\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1392\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1388\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1384\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1380\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1376\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1373\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1369\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1365\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1357\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1354\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1350\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1346\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1343\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1339\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1335\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1332\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1328\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1324\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1321\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1317\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1313\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1310\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1303\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1299\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1292\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1288\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1285\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1281\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1278\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1274\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1271\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1267\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1264\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1260\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1257\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1253\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1250\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1246\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1243\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1240\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1236\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1233\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1229\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1226\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1223\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1219\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1216\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1213\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1209\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1206\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1203\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1199\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "MLP (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.560681  75.902175   0.537314\n"
     ]
    }
   ],
   "source": [
    "# MLP (Fingerprint)\n",
    "mlp_fp = MLP(\n",
    "    engine='tensorflow',\n",
    "    nfeatures=X_train_fp_scaled.shape[1],\n",
    "    nneurons=[64, 128], # These are the hidden layers\n",
    "    activations=['ReLU', 'ReLU'],\n",
    "    learning_rate=0.01,\n",
    "    alpha=0.001,\n",
    "    nepochs=200,\n",
    "    batch_size=64,\n",
    "    loss='mean_squared_error',\n",
    "    is_regression=True\n",
    ")\n",
    "\n",
    "mlp_fp.fit(X=X_train_fp_scaled, y=y_train_scaled.ravel()) # Use .ravel() to convert to 1D\n",
    "y_pred_fp_scaled = mlp_fp.predict(X_test_fp_scaled)\n",
    "# Reshape the output from predict() to 2D before inverse transforming\n",
    "y_pred_fp = yscaler.inverse_transform(y_pred_fp_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_fp = yscaler.inverse_transform(y_test_scaled).flatten()\n",
    "\n",
    "# Eval against true unscaled test target\n",
    "print(\"MLP (RDKit FP)\")\n",
    "metrics_mlp = regression_metrics(y_test, y_pred_fp)\n",
    "print(metrics_mlp[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abe3c7",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron with Coulomb Matrix representation baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64495ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP (Coulomb matrix)\n",
    "# mlp_cm = MLP(\n",
    "#     engine='tensorflow', \n",
    "#     nfeatures=X_train_cm_scaled.shape[1], \n",
    "#     nneurons=[64, 128], \n",
    "#     activations=['ReLU', 'ReLU'],\n",
    "#     learning_rate=0.0001, \n",
    "#     alpha=0.001, \n",
    "#     nepochs=100, \n",
    "#     batch_size=64, \n",
    "#     loss='mean_squared_error', \n",
    "#     is_regression=True\n",
    "#     )\n",
    "\n",
    "# mlp_cm.fit(X=X_train_cm_scaled, y=y_train_scaled)\n",
    "# y_pred_cm_scaled = mlp_cm.predict(X_test_cm_scaled)\n",
    "# y_pred_cm = yscaler.inverse_transform(y_pred_cm_scaled)\n",
    "# y_test_cm = yscaler.inverse_transform(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7101926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Comparison\n",
      "\n",
      "Kernel Ridge (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  63.695431  85.338681   0.415116\n",
      "\n",
      "Random Forest (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.404863  73.313325   0.568338\n",
      "\n",
      "MLP (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.560681  75.902175   0.537314\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "results = {\"Kernel Ridge (RDKit FP)\": regression_metrics(y_test_krr, y_pred_krr),\n",
    "           \"Random Forest (RDKit FP)\": regression_metrics(y_test_unscaled, y_pred_rfr),\n",
    "           \"MLP (RDKit FP)\": regression_metrics(y_test_fp, y_pred_fp),\n",
    "        #    \"MLP (Coulomb Matrix)\": regression_metrics(y_test_cm, y_pred_cm)\n",
    "        }\n",
    "\n",
    "# display\n",
    "print(\"Final Model Comparison\")\n",
    "for name, metrics_df in results.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(metrics_df[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e7366",
   "metadata": {},
   "source": [
    "## Parity Plots and Residuals Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ff8791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_regression_results(y_true, y_pred, title=\"Model Evaluation\", save_dir=\"plots\"):\n",
    "    residuals = y_true.flatten() - y_pred.flatten()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # parity plot\n",
    "    sns.scatterplot(ax=axes[0], x=y_true.flatten(), y=y_pred.flatten(), alpha=0.5)\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    axes[0].plot([min_val, max_val], [min_val, max_val], '--r')\n",
    "    axes[0].set_xlabel(\"Actual HOMO-LUMO Gap\")\n",
    "    axes[0].set_ylabel(\"Predicted HOMO-LUMO Gap\")\n",
    "    axes[0].set_title(\"Parity Plot\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].axis('equal')\n",
    "\n",
    "    # residuals histogram\n",
    "    sns.histplot(ax=axes[1], data=residuals, bins=30, kde=True)\n",
    "    axes[1].set_title(\"Residuals Histogram\")\n",
    "    axes[1].set_xlabel(\"Residual (Actual - Predicted)\")\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # overall title\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "\n",
    "    # save fig as pdf for best overleaf upload format \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = os.path.join(save_dir, f\"{title.lower().replace(' ', '_')}_plots.pdf\")\n",
    "    fig.savefig(filename, bbox_inches='tight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_regression_results(y_test_fp, y_pred_fp, title=\"MLP Untuned(RDKit FP)\")\n",
    "# plot_regression_results(y_test_cm, y_pred_cm, title=\"MLP Untuned (Coulomb Matrix)\")\n",
    "plot_regression_results(y_test_krr, y_pred_krr, title=\"Kernel Ridge Untuned (RDKit FP)\")\n",
    "plot_regression_results(y_test_unscaled, y_pred_rfr, title=\"Random Forest Untuned (RDKit FP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dce050",
   "metadata": {},
   "source": [
    "## Tune hyperparameters for baseline models with Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66717bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 18:07:31,274] A new study created in memory with name: no-name-2c5544dd-a13f-4e25-84e0-408d9fef1e39\n",
      "[I 2025-09-04 18:07:31,289] Trial 0 finished with value: 52.47805602991537 and parameters: {'alpha': 0.06586033910839106, 'kernel': 'poly'}. Best is trial 0 with value: 52.47805602991537.\n",
      "[I 2025-09-04 18:07:31,303] Trial 1 finished with value: 55.412910810865775 and parameters: {'alpha': 0.01189927541556288, 'kernel': 'rbf', 'gamma': 0.0001648963316314988}. Best is trial 0 with value: 52.47805602991537.\n",
      "[I 2025-09-04 18:07:31,316] Trial 2 finished with value: 52.14000842310857 and parameters: {'alpha': 0.26346624549357756, 'kernel': 'poly'}. Best is trial 2 with value: 52.14000842310857.\n",
      "[I 2025-09-04 18:07:31,328] Trial 3 finished with value: 52.09947380024483 and parameters: {'alpha': 0.7923779405719946, 'kernel': 'poly'}. Best is trial 3 with value: 52.09947380024483.\n",
      "[I 2025-09-04 18:07:31,340] Trial 4 finished with value: 52.32335741706265 and parameters: {'alpha': 0.14119986874068377, 'kernel': 'poly'}. Best is trial 3 with value: 52.09947380024483.\n",
      "[I 2025-09-04 18:07:31,354] Trial 5 finished with value: 55.31698809949579 and parameters: {'alpha': 0.2378916861968663, 'kernel': 'rbf', 'gamma': 6.471926225070463e-05}. Best is trial 3 with value: 52.09947380024483.\n",
      "[I 2025-09-04 18:07:31,367] Trial 6 finished with value: 51.968859362500964 and parameters: {'alpha': 0.42275121284674017, 'kernel': 'poly'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,379] Trial 7 finished with value: 58.82575559400796 and parameters: {'alpha': 0.18067640510655608, 'kernel': 'rbf', 'gamma': 2.201184790778948e-05}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,392] Trial 8 finished with value: 51.981828569578845 and parameters: {'alpha': 0.5468036981666496, 'kernel': 'poly'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,402] Trial 9 finished with value: 68.43826969386384 and parameters: {'alpha': 0.015893479145357808, 'kernel': 'linear'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,415] Trial 10 finished with value: 68.42449870540118 and parameters: {'alpha': 0.0526283971868109, 'kernel': 'linear'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,441] Trial 11 finished with value: 52.193471126620416 and parameters: {'alpha': 0.9733751803495119, 'kernel': 'poly'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,458] Trial 12 finished with value: 51.96500117248103 and parameters: {'alpha': 0.4920579525092092, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,476] Trial 13 finished with value: 51.97419864966313 and parameters: {'alpha': 0.4159966331024372, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,491] Trial 14 finished with value: 51.968444818788015 and parameters: {'alpha': 0.4232777190128455, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,504] Trial 15 finished with value: 68.41400583322502 and parameters: {'alpha': 0.080656110114022, 'kernel': 'linear'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,518] Trial 16 finished with value: 52.58128817556072 and parameters: {'alpha': 0.023234350205253104, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,532] Trial 17 finished with value: 52.05712524469121 and parameters: {'alpha': 0.32980900939145164, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,546] Trial 18 finished with value: 68.39458522328754 and parameters: {'alpha': 0.13261628224132208, 'kernel': 'linear'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,566] Trial 19 finished with value: 89.0327252770603 and parameters: {'alpha': 0.6298351352618616, 'kernel': 'rbf', 'gamma': 0.7952453489587329}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,580] Trial 20 finished with value: 52.54936018804663 and parameters: {'alpha': 0.03579894262103647, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,594] Trial 21 finished with value: 51.96687854001945 and parameters: {'alpha': 0.42526973300745385, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,609] Trial 22 finished with value: 51.97791306468501 and parameters: {'alpha': 0.5378915817154151, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,626] Trial 23 finished with value: 52.18061933920176 and parameters: {'alpha': 0.23348583667929712, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,641] Trial 24 finished with value: 52.054619899356105 and parameters: {'alpha': 0.3319257953086633, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,662] Trial 25 finished with value: 52.08681005398675 and parameters: {'alpha': 0.7702583560629688, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,682] Trial 26 finished with value: 52.361925368359316 and parameters: {'alpha': 0.12106605590677347, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,699] Trial 27 finished with value: 51.97560333104032 and parameters: {'alpha': 0.4142278627567089, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,715] Trial 28 finished with value: 68.37586103542857 and parameters: {'alpha': 0.1828183805648035, 'kernel': 'linear'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,730] Trial 29 finished with value: 89.032716443888 and parameters: {'alpha': 0.9587745065596295, 'kernel': 'rbf', 'gamma': 0.060706583409964786}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,745] Trial 30 finished with value: 52.42390156162841 and parameters: {'alpha': 0.090613119757921, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,762] Trial 31 finished with value: 51.96668406725522 and parameters: {'alpha': 0.42551736465255957, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,776] Trial 32 finished with value: 52.05722998098624 and parameters: {'alpha': 0.32972066238840725, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,793] Trial 33 finished with value: 52.01120905878846 and parameters: {'alpha': 0.6192240947377317, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,811] Trial 34 finished with value: 51.96342341968574 and parameters: {'alpha': 0.48527751803893, 'kernel': 'poly'}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,825] Trial 35 finished with value: 52.24775210076025 and parameters: {'alpha': 0.18738602991439993, 'kernel': 'poly'}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,845] Trial 36 finished with value: 52.13629371446523 and parameters: {'alpha': 0.2662897587982509, 'kernel': 'poly'}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,860] Trial 37 finished with value: 78.68633182165037 and parameters: {'alpha': 0.8110462590695258, 'kernel': 'rbf', 'gamma': 0.0031603499980466985}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,878] Trial 38 finished with value: 51.961542842093415 and parameters: {'alpha': 0.4774062604325275, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,893] Trial 39 finished with value: 51.971211985294644 and parameters: {'alpha': 0.5204914097923213, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,917] Trial 40 finished with value: 76.4026123709475 and parameters: {'alpha': 0.28634003080762305, 'kernel': 'rbf', 'gamma': 0.002922293105660872}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,936] Trial 41 finished with value: 52.04149605922797 and parameters: {'alpha': 0.6951343718689064, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,953] Trial 42 finished with value: 51.96157915011297 and parameters: {'alpha': 0.4588484548527643, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,968] Trial 43 finished with value: 51.974321170033235 and parameters: {'alpha': 0.5298554496223997, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,983] Trial 44 finished with value: 52.02247491555436 and parameters: {'alpha': 0.35968374719260787, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,998] Trial 45 finished with value: 52.17108459565094 and parameters: {'alpha': 0.2403799931808444, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,012] Trial 46 finished with value: 51.96810025203249 and parameters: {'alpha': 0.5058798993837317, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,025] Trial 47 finished with value: 68.13405255180737 and parameters: {'alpha': 0.8405293836136751, 'kernel': 'linear'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,042] Trial 48 finished with value: 52.02543304515025 and parameters: {'alpha': 0.6582593301255977, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,057] Trial 49 finished with value: 52.22933552237023 and parameters: {'alpha': 0.1996139831330201, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,073] Trial 50 finished with value: 52.29797265304777 and parameters: {'alpha': 0.1555967046976449, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,088] Trial 51 finished with value: 51.977345853661795 and parameters: {'alpha': 0.41203845820076174, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,104] Trial 52 finished with value: 52.61356305492147 and parameters: {'alpha': 0.011076118083251133, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,120] Trial 53 finished with value: 51.961558896907526 and parameters: {'alpha': 0.46538414726946603, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,137] Trial 54 finished with value: 51.962247498264475 and parameters: {'alpha': 0.4803295713899409, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,158] Trial 55 finished with value: 68.33332499049632 and parameters: {'alpha': 0.29724846377190656, 'kernel': 'linear'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,176] Trial 56 finished with value: 52.48466409351611 and parameters: {'alpha': 0.06295527488132921, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,196] Trial 57 finished with value: 89.03272380864796 and parameters: {'alpha': 0.4658868559955186, 'kernel': 'rbf', 'gamma': 0.07317555814354744}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,211] Trial 58 finished with value: 52.015786202609455 and parameters: {'alpha': 0.6314766599597024, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,227] Trial 59 finished with value: 52.039107593207625 and parameters: {'alpha': 0.34518175702344894, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,241] Trial 60 finished with value: 52.5507841610139 and parameters: {'alpha': 0.035226985876633615, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,257] Trial 61 finished with value: 51.96157589961576 and parameters: {'alpha': 0.4547793366561898, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,271] Trial 62 finished with value: 51.99436894744592 and parameters: {'alpha': 0.576467550067699, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,287] Trial 63 finished with value: 52.005197848010134 and parameters: {'alpha': 0.37775982614307163, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,301] Trial 64 finished with value: 52.05883787572597 and parameters: {'alpha': 0.723159624682569, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,322] Trial 65 finished with value: 51.96153145175183 and parameters: {'alpha': 0.4693673305699074, 'kernel': 'poly'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,337] Trial 66 finished with value: 52.19862488651819 and parameters: {'alpha': 0.9842115497070224, 'kernel': 'poly'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,353] Trial 67 finished with value: 68.35331501794829 and parameters: {'alpha': 0.24340474224991604, 'kernel': 'linear'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,367] Trial 68 finished with value: 52.0945185987686 and parameters: {'alpha': 0.2990014365740163, 'kernel': 'poly'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,382] Trial 69 finished with value: 51.961517736909315 and parameters: {'alpha': 0.4709166016409924, 'kernel': 'poly'}. Best is trial 69 with value: 51.961517736909315.\n",
      "[I 2025-09-04 18:07:32,395] Trial 70 finished with value: 52.21490670799681 and parameters: {'alpha': 0.20941321017733855, 'kernel': 'poly'}. Best is trial 69 with value: 51.961517736909315.\n",
      "[I 2025-09-04 18:07:32,409] Trial 71 finished with value: 51.961512376108054 and parameters: {'alpha': 0.4445432859238032, 'kernel': 'poly'}. Best is trial 71 with value: 51.961512376108054.\n",
      "[I 2025-09-04 18:07:32,424] Trial 72 finished with value: 52.00040401461049 and parameters: {'alpha': 0.3835639006267663, 'kernel': 'poly'}. Best is trial 71 with value: 51.961512376108054.\n",
      "[I 2025-09-04 18:07:32,446] Trial 73 finished with value: 51.961449192903274 and parameters: {'alpha': 0.476887750531236, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,464] Trial 74 finished with value: 51.98905721435983 and parameters: {'alpha': 0.5636885577207004, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,483] Trial 75 finished with value: 51.961577273556095 and parameters: {'alpha': 0.455444107021338, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,495] Trial 76 finished with value: 52.00246719864148 and parameters: {'alpha': 0.5965885006620995, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,512] Trial 77 finished with value: 54.80725498194603 and parameters: {'alpha': 0.31408515054659203, 'kernel': 'rbf', 'gamma': 0.0003052666520487559}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,527] Trial 78 finished with value: 52.136021803345564 and parameters: {'alpha': 0.8591320897872, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,540] Trial 79 finished with value: 52.052914508281354 and parameters: {'alpha': 0.7134881862837423, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,554] Trial 80 finished with value: 52.00139150853791 and parameters: {'alpha': 0.3823650481615241, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,567] Trial 81 finished with value: 51.96146634818446 and parameters: {'alpha': 0.44060780197168276, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,580] Trial 82 finished with value: 51.96980875856301 and parameters: {'alpha': 0.4215465270818391, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,594] Trial 83 finished with value: 51.96155272109186 and parameters: {'alpha': 0.44943196500625937, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,607] Trial 84 finished with value: 51.97289675915037 and parameters: {'alpha': 0.526704776800457, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,620] Trial 85 finished with value: 52.14035964147195 and parameters: {'alpha': 0.2631999996228438, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,634] Trial 86 finished with value: 68.31318799352148 and parameters: {'alpha': 0.3516080032551108, 'kernel': 'linear'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,647] Trial 87 finished with value: 51.99945516698461 and parameters: {'alpha': 0.5890123813299221, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,662] Trial 88 finished with value: 52.6061520239504 and parameters: {'alpha': 0.013820428616055626, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,679] Trial 89 finished with value: 89.0327252770603 and parameters: {'alpha': 0.7545636235829007, 'kernel': 'rbf', 'gamma': 0.9695442488758451}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,695] Trial 90 finished with value: 52.03014132278019 and parameters: {'alpha': 0.6718282587797618, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,710] Trial 91 finished with value: 51.96156467059265 and parameters: {'alpha': 0.46424226918900763, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,724] Trial 92 finished with value: 51.96157348002087 and parameters: {'alpha': 0.46192850723210205, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,741] Trial 93 finished with value: 51.99243753425823 and parameters: {'alpha': 0.39329733290288266, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,757] Trial 94 finished with value: 51.97465944157995 and parameters: {'alpha': 0.5306066705832921, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,770] Trial 95 finished with value: 52.05527511156812 and parameters: {'alpha': 0.33137155577371186, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,789] Trial 96 finished with value: 51.96572890404508 and parameters: {'alpha': 0.4952421772726629, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,803] Trial 97 finished with value: 52.122906625902914 and parameters: {'alpha': 0.27657979269019667, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,822] Trial 98 finished with value: 51.961370500165984 and parameters: {'alpha': 0.43450048547076636, 'kernel': 'poly'}. Best is trial 98 with value: 51.961370500165984.\n",
      "[I 2025-09-04 18:07:32,844] Trial 99 finished with value: 51.974254463201994 and parameters: {'alpha': 0.41592628731448095, 'kernel': 'poly'}. Best is trial 98 with value: 51.961370500165984.\n"
     ]
    }
   ],
   "source": [
    "def objective_krr(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 1.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly'])\n",
    "    gamma = trial.suggest_float('gamma', 1e-5, 1.0, log=True) if kernel == 'rbf' else None\n",
    "    model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma) if gamma else KernelRidge(alpha=alpha, kernel=kernel)\n",
    "    model.fit(X_train_fp_scaled, y_train_scaled)\n",
    "    preds_scaled = model.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "    preds = yscaler.inverse_transform(preds_scaled)\n",
    "    y_test_inv = yscaler.inverse_transform(y_test_scaled)\n",
    "    metrics = regression_metrics(y_test_inv, preds)\n",
    "    return metrics['MAE'][0]\n",
    "\n",
    "study_krr = optuna.create_study(direction='minimize')\n",
    "study_krr.optimize(objective_krr, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83942b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 18:07:36,340] A new study created in memory with name: no-name-571e3f03-3bb2-49d7-9e5b-88944aa83273\n",
      "[I 2025-09-04 18:07:36,695] Trial 0 finished with value: 54.611500266146024 and parameters: {'n_estimators': 100, 'max_depth': 60}. Best is trial 0 with value: 54.611500266146024.\n",
      "[I 2025-09-04 18:07:37,127] Trial 1 finished with value: 53.24178721398811 and parameters: {'n_estimators': 200, 'max_depth': 10}. Best is trial 1 with value: 53.24178721398811.\n",
      "[I 2025-09-04 18:07:37,730] Trial 2 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:38,343] Trial 3 finished with value: 54.05674128710554 and parameters: {'n_estimators': 200, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:38,560] Trial 4 finished with value: 54.704354298388026 and parameters: {'n_estimators': 50, 'max_depth': 80}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:39,190] Trial 5 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:39,914] Trial 6 finished with value: 53.47018274669734 and parameters: {'n_estimators': 250, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:40,493] Trial 7 finished with value: 53.79704749291141 and parameters: {'n_estimators': 200, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:40,937] Trial 8 finished with value: 53.54010401337062 and parameters: {'n_estimators': 150, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:41,261] Trial 9 finished with value: 54.21533823750181 and parameters: {'n_estimators': 100, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:42,099] Trial 10 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 90}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:42,933] Trial 11 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 50}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:43,552] Trial 12 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:44,280] Trial 13 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 70}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:45,066] Trial 14 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:45,682] Trial 15 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:46,397] Trial 16 finished with value: 53.57817243697484 and parameters: {'n_estimators': 250, 'max_depth': 100}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:46,878] Trial 17 finished with value: 53.94771543377596 and parameters: {'n_estimators': 150, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:47,709] Trial 18 finished with value: 53.42147900496652 and parameters: {'n_estimators': 300, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:48,440] Trial 19 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 60}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:49,306] Trial 20 finished with value: 53.42147900496652 and parameters: {'n_estimators': 300, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:49,948] Trial 21 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:50,509] Trial 22 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:51,345] Trial 23 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:51,972] Trial 24 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:52,670] Trial 25 finished with value: 53.47018274669734 and parameters: {'n_estimators': 250, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:53,244] Trial 26 finished with value: 53.79704749291141 and parameters: {'n_estimators': 200, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:53,865] Trial 27 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:54,601] Trial 28 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 50}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:54,833] Trial 29 finished with value: 54.36384490703731 and parameters: {'n_estimators': 50, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:55,173] Trial 30 finished with value: 54.611500266146024 and parameters: {'n_estimators': 100, 'max_depth': 60}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:55,793] Trial 31 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:56,440] Trial 32 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:57,046] Trial 33 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:57,740] Trial 34 finished with value: 53.531034696813975 and parameters: {'n_estimators': 250, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:58,325] Trial 35 finished with value: 53.92580128403864 and parameters: {'n_estimators': 200, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:58,959] Trial 36 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:59,859] Trial 37 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:00,448] Trial 38 finished with value: 54.05674128710554 and parameters: {'n_estimators': 200, 'max_depth': 70}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:00,917] Trial 39 finished with value: 53.54010401337062 and parameters: {'n_estimators': 150, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:01,630] Trial 40 finished with value: 53.47018274669734 and parameters: {'n_estimators': 250, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:02,249] Trial 41 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:02,868] Trial 42 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:03,691] Trial 43 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:04,343] Trial 44 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:05,054] Trial 45 finished with value: 53.531034696813975 and parameters: {'n_estimators': 250, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:05,672] Trial 46 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:06,397] Trial 47 finished with value: 53.531034696813975 and parameters: {'n_estimators': 250, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:07,122] Trial 48 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:07,338] Trial 49 finished with value: 54.57468448667023 and parameters: {'n_estimators': 50, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:08,077] Trial 50 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:08,706] Trial 51 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:09,340] Trial 52 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:10,162] Trial 53 finished with value: 53.38214016287373 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:10,782] Trial 54 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:11,123] Trial 55 finished with value: 54.21533823750181 and parameters: {'n_estimators': 100, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:11,959] Trial 56 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 90}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:12,501] Trial 57 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:13,323] Trial 58 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:13,864] Trial 59 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:14,327] Trial 60 finished with value: 53.805224367094354 and parameters: {'n_estimators': 150, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:14,950] Trial 61 finished with value: 52.84979616026848 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:15,783] Trial 62 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:16,403] Trial 63 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:17,021] Trial 64 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:17,895] Trial 65 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:18,532] Trial 66 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:19,274] Trial 67 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 70}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:20,105] Trial 68 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:20,740] Trial 69 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:21,549] Trial 70 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:22,183] Trial 71 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:22,807] Trial 72 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:23,422] Trial 73 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:24,255] Trial 74 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:24,891] Trial 75 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:25,604] Trial 76 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 50}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:26,224] Trial 77 finished with value: 52.84979616026848 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:26,845] Trial 78 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:27,568] Trial 79 finished with value: 53.57817243697484 and parameters: {'n_estimators': 250, 'max_depth': 100}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:28,432] Trial 80 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:29,047] Trial 81 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:29,673] Trial 82 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:30,318] Trial 83 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:30,919] Trial 84 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:31,754] Trial 85 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:32,372] Trial 86 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:33,197] Trial 87 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:33,751] Trial 88 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:34,214] Trial 89 finished with value: 53.2417872139881 and parameters: {'n_estimators': 200, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:35,077] Trial 90 finished with value: 53.42147900496652 and parameters: {'n_estimators': 300, 'max_depth': 30}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:35,684] Trial 91 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:36,304] Trial 92 finished with value: 52.84979616026848 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:36,939] Trial 93 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:37,758] Trial 94 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:38,624] Trial 95 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 80}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:39,244] Trial 96 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:39,791] Trial 97 finished with value: 52.91805619992672 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:40,580] Trial 98 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:41,217] Trial 99 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n"
     ]
    }
   ],
   "source": [
    "def objective_rfr(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 100, step=10)\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_fp_unscaled, y_train_unscaled)\n",
    "    preds = model.predict(X_test_fp_unscaled)\n",
    "    metrics = regression_metrics(y_test_unscaled, preds)\n",
    "    return metrics['MAE'][0]\n",
    "\n",
    "study_rfr = optuna.create_study(direction='minimize')\n",
    "study_rfr.optimize(objective_rfr, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b6bd272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:24,914] A new study created in memory with name: no-name-4ab51d06-e6c2-4787-94b5-1e523db9ae9a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 13.0463\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.5493\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0623\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7880\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.6493\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5376\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.4500\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.3826\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3276\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.2778\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2318\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1888\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.1488\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1109\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0754\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0411\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.0079\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9758\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.9449\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.9140\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8838\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8540\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8246\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7956\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7669\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7385\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7102\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6821\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6543\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6265\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5990\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5716\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5443\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5171\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4901\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4632\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4364\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4096\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3830\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3565\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3300\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3037\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2774\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2513\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2252\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1992\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1732\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1474\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1216\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0959\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0702\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0447\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0192\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9938\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9684\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9431\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9179\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8928\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8677\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8427\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8177\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.7929\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7681\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7433\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7186\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6940\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6695\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6450\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6206\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5962\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5719\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5477\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5235\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4994\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4753\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4513\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4274\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4036\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3798\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3560\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 9.3323\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3087\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2852\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2617\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2382\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2149\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1915\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.1683\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1451\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1219\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0989\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0758\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0529\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0300\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0071\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9844\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9616\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9390\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9163\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8938\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:32,502] Trial 0 finished with value: 65.97623144240474 and parameters: {'lr': 0.0006131707246017513, 'alpha': 0.014757403572832895, 'activation': 'relu', 'n1': 320, 'n2': 256}. Best is trial 0 with value: 65.97623144240474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0463\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2119\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9368\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7513\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6307\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5531\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5196\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4819\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4692\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4585\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4498\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4446\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4411\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4371\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4349\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4334\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4319\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4306\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4295\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4285\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4275\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4266\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4249\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4240\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4232\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4223\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4215\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4207\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4199\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4191\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4183\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4175\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4167\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4159\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4152\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4144\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4136\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4129\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4121\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4113\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4106\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4098\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4091\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4083\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4076\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4068\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4061\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4053\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4046\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4038\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4031\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4024\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4016\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4009\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4002\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3995\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3987\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3980\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3973\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3966\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3958\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3944\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3937\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3930\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3923\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3915\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3908\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3901\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3894\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3887\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3880\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3873\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3866\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3859\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3852\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3845\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3838\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3831\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3824\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3817\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3810\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3803\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3796\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3790\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3783\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3776\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3769\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3762\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3755\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3749\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3742\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3735\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3728\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3722\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3715\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3708\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3701\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3695\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:34,264] Trial 1 finished with value: 61.46685337652091 and parameters: {'lr': 0.007037316607790657, 'alpha': 0.0009259457413312761, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 1 with value: 61.46685337652091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4335\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8620\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5381\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3505\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2835\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2151\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1895\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1468\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1299\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1167\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1062\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0995\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0884\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0839\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0795\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0750\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0709\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0668\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0629\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0589\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0550\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0512\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0472\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0434\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0396\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0358\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0321\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0246\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0209\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0172\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0136\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0099\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0063\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0027\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9991\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9955\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9919\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9883\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9848\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9813\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9708\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9673\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9638\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9604\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9569\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9535\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9501\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9467\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9433\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9400\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9366\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9333\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9299\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9266\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9233\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9200\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9167\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9102\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9069\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9037\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9005\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8972\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8940\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8908\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8877\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8845\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8813\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8782\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8751\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8719\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8688\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8657\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8627\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8596\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8565\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8535\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8504\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8474\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8444\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8414\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8384\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8354\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8324\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8294\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8265\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8235\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8206\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8177\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8118\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8090\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8061\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8032\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8003\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7975\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:36,083] Trial 2 finished with value: 59.99714808365374 and parameters: {'lr': 0.007103555042896184, 'alpha': 0.001803930832367276, 'activation': 'gelu', 'n1': 256, 'n2': 192}. Best is trial 2 with value: 59.99714808365374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1853\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1944\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0524\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9098\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8578\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8153\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7964\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7762\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7648\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7566\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7523\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7489\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7449\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7418\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7366\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7342\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7320\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7298\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7276\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7255\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7234\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7214\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7193\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7173\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7152\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7132\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7112\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7092\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7072\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7052\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7033\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7013\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6973\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6954\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6935\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6915\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6896\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6876\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6857\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6838\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6819\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6781\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6762\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6743\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6724\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6705\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6686\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6667\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6649\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6630\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6612\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6593\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6575\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6557\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6538\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6520\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6502\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6484\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6465\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6429\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6411\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6393\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6376\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6358\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6340\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6322\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6305\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6287\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6269\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6252\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6234\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6217\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6200\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6182\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6165\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6148\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6131\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6097\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6079\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6062\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6046\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6028\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6012\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5995\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5978\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5962\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5945\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5928\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5912\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5895\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5879\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5862\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5846\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5830\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5813\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:37,651] Trial 3 finished with value: 59.55488712192801 and parameters: {'lr': 0.004657392505497789, 'alpha': 0.0021561184888452835, 'activation': 'relu', 'n1': 128, 'n2': 128}. Best is trial 3 with value: 59.55488712192801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8280\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1476\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9408\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8615\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8108\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7829\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7879\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7556\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7404\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7325\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7278\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7225\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7193\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7158\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7138\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7116\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7098\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7083\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7064\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7047\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7032\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7017\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7003\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6988\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6974\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6961\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6947\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6933\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6920\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6906\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6893\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6879\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6866\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6840\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6827\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6813\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6787\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6775\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6762\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6749\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6736\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6723\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6710\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6697\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6685\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6672\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6659\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6647\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6634\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6621\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6609\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6596\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6584\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6571\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6559\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6547\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6534\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6522\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6510\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6497\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6485\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6473\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6460\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6448\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6436\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6424\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6412\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6400\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6388\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6375\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6363\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6352\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6339\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6328\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6316\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6304\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6292\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6280\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6268\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6256\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6244\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6233\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6221\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6209\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6197\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6186\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6174\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6162\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6151\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6139\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6128\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6116\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6104\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6093\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6081\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6070\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6059\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6047\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:39,472] Trial 4 finished with value: 59.83959769023511 and parameters: {'lr': 0.005391205538210505, 'alpha': 0.001257192903748666, 'activation': 'gelu', 'n1': 192, 'n2': 384}. Best is trial 3 with value: 59.55488712192801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3738\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3670\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3664\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3614\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3317\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3240\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3112\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3013\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2926\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2734\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2624\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2540\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2342\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2285\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2071\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2319\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1770\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1549\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1386\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1257\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1111\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1032\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0695\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0531\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0428\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0290\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0381\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0089\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9717\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9640\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9746\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9392\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8966\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8834\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8678\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8693\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8350\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8205\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8112\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7929\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7808\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7697\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7573\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7480\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7488\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7247\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7222\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7181\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7142\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7077\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6871\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6776\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6711\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6717\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6545\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6542\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6482\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6391\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6288\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6233\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6175\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6132\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6073\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6032\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5993\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5948\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5909\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5835\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5802\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5773\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5717\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5656\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5653\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5600\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5551\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5509\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5473\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5440\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5410\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5393\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5367\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5297\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5264\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5236\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5208\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5175\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5179\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5192\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5116\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5078\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5062\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5026\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4983\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4985\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4928\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4912\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4914\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4867\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:41,049] Trial 5 finished with value: 57.95134360880324 and parameters: {'lr': 0.0010252295697744435, 'alpha': 0.000894687368799269, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 5 with value: 57.95134360880324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7150\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6512\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 17.5593\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4668\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3681\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2775\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1930\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1197\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.0473\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9818\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9202\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8640\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8077\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7571\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7075\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6619\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6141\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5708\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5285\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4878\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4477\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4096\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3727\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3366\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3015\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2675\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2326\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.2017\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1683\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1362\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1050\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0745\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0436\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0141\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9845\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9557\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9269\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8982\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.8700\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8418\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8142\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7869\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7602\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7335\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7071\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6806\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6550\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6289\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6031\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5775\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5523\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5272\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5021\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.4775\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4528\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4285\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4040\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3796\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.3557\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3318\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3080\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2844\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2609\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2374\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2141\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1910\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1679\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1449\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1218\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0991\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0763\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.0538\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0311\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0086\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9864\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9641\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9419\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9199\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8978\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8759\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8539\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.8321\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8103\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7887\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7670\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7455\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7240\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7026\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6813\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6598\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6387\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.6174\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5963\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5752\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5541\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5331\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5122\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4914\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4705\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4497\n",
      "4/4 [==============================] - 0s 834us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:42,714] Trial 6 finished with value: 72.7612765917017 and parameters: {'lr': 0.00011936108934714092, 'alpha': 0.04139892684630957, 'activation': 'relu', 'n1': 128, 'n2': 256}. Best is trial 5 with value: 57.95134360880324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2594\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9850\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7148\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5996\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4031\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.2582\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0912\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9319\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 19.7817\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6202\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4729\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3153\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1653\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0145\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8641\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7211\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5789\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4230\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2838\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1318\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9865\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8478\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7072\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5644\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4282\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2908\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1588\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.0245\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8845\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7466\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6156\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4930\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3518\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2315\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0988\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9690\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8407\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.7161\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.5911\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4646\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3415\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2190\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.0988\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9787\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8601\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7459\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6275\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5176\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3995\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2862\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1708\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0629\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9554\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 13.8442\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7333\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6263\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5216\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4112\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3109\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2050\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1008\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0030\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8985\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7992\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7011\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6024\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.5101\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4073\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3155\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2177\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1217\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0299\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9375\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8439\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.7615\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6654\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5777\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4856\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3980\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3108\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.2251\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1408\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0529\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9707\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.8838\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8016\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7191\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6373\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5582\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4788\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3950\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3184\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2366\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1614\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0808\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0082\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9292\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8545\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7796\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7059\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:44,394] Trial 7 finished with value: 57.49475406130353 and parameters: {'lr': 0.0007068994556534392, 'alpha': 0.03869731508263629, 'activation': 'sigmoid', 'n1': 192, 'n2': 192}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2655\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1104\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9899\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8382\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7176\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6132\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5277\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4574\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4002\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3516\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3067\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2706\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2370\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2086\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1838\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1605\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1396\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1214\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0890\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0745\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0613\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0488\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0378\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0277\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0181\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0093\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0008\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9932\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9848\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9782\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9715\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9648\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9589\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9530\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9477\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9427\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9376\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9333\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9287\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9246\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9206\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9168\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9130\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9098\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9062\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9037\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9004\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8972\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8945\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8916\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8891\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8866\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8842\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8820\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8797\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8777\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8757\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8737\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8720\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8700\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8683\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8666\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8649\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8633\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8618\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8604\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8589\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8574\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8561\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8548\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8534\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8522\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8510\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8499\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8488\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8477\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8466\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8455\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8445\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8436\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8426\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8417\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8408\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8399\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8391\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8382\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8375\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8368\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8358\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8351\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8343\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8335\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8328\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8321\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8314\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8307\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8300\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8294\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8288\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:45,990] Trial 8 finished with value: 78.30218485723917 and parameters: {'lr': 0.00012402581332656212, 'alpha': 0.003015430821816265, 'activation': 'relu', 'n1': 384, 'n2': 384}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2297\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0752\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8669\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.6755\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5013\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3621\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2509\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1622\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0873\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0249\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9719\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9249\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8852\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8500\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8186\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7919\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7638\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7411\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7200\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7006\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6822\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6659\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6502\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6355\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6211\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6084\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.5954\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5842\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5731\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5623\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5523\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5422\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5326\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5239\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5149\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5066\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4984\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4903\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4829\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4750\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4680\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4609\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4541\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4473\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4409\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4344\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4284\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4221\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4159\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4100\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4041\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3984\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3927\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3871\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3817\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3764\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3712\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3659\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3607\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3557\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3507\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3458\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3409\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3361\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3314\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3266\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3220\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3173\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3127\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3082\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3036\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2990\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2945\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2900\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2857\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2813\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2769\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2726\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2682\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2640\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.2598\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2555\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2513\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2470\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2428\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2386\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2345\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2304\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2263\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2221\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2180\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2139\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2099\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2058\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2018\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1978\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1937\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1897\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1857\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1818\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:47,652] Trial 9 finished with value: 83.68321030912738 and parameters: {'lr': 0.00014305628101450837, 'alpha': 0.013006000625615206, 'activation': 'relu', 'n1': 256, 'n2': 128}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1573\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1453\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1421\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1357\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1233\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1150\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1061\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1006\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0935\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0831\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0795\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0682\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0640\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0542\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0476\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0473\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0442\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0249\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0126\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0021\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9968\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9902\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9808\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9772\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9703\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9676\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9588\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9475\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9383\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9325\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9352\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9170\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9208\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9121\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9011\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8899\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8865\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8773\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8682\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8591\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8535\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8451\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8370\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8306\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8239\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8197\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8122\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8028\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7942\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7868\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7807\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7766\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7687\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7592\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7533\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7469\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7339\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7313\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7230\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7139\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7103\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6947\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6889\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6816\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6817\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6697\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6642\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6555\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6460\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6409\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6356\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6279\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6141\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6113\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6012\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5968\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5915\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5876\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5830\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5728\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5713\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5620\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5586\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5524\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5481\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5435\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5384\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5355\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5282\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5249\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5226\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5122\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5147\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5065\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5033\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5003\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4965\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:49,264] Trial 10 finished with value: 57.97517346034134 and parameters: {'lr': 0.00036853845956751074, 'alpha': 0.00015476639458539238, 'activation': 'sigmoid', 'n1': 320, 'n2': 320}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3986\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2354\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1900\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1557\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0989\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0824\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0562\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0351\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0155\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9839\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9570\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9367\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9058\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8849\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8589\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8359\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8376\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7906\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7499\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7232\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6992\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6792\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6645\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6417\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6115\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5944\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5807\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5751\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5744\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5484\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5416\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5630\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5429\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4934\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4834\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4706\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4716\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4578\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4480\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4403\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4356\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4258\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4207\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4142\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4107\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4111\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3930\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3847\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3799\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3792\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3806\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3673\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3583\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3524\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3535\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3418\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3382\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3369\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3290\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3255\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3213\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3137\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3102\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3064\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3034\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3003\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2993\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2962\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2922\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2888\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2887\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2781\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2755\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2734\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2708\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2691\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2671\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2650\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2630\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2594\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2558\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2546\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2525\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2514\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2497\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2482\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2462\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2446\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2439\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2415\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2405\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2376\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:50,859] Trial 11 finished with value: 57.14954265060914 and parameters: {'lr': 0.001519422226672702, 'alpha': 0.00034349596510678093, 'activation': 'sigmoid', 'n1': 192, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3800\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6918\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5007\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3052\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2524\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1969\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1562\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1365\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1178\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1070\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0975\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0906\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0788\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0766\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0746\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0731\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0695\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0686\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0682\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0673\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0671\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0670\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0668\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0667\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0664\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0664\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0663\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0658\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0657\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0657\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0656\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:52,487] Trial 12 finished with value: 70.68801466047385 and parameters: {'lr': 0.0016197931101672725, 'alpha': 0.00012750602782036794, 'activation': 'tanh', 'n1': 192, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1879\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1610\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1446\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1327\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0977\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0490\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0140\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9793\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9600\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9283\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8867\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8583\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8122\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7710\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7476\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7104\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6917\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6466\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6146\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5696\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5431\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5189\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5043\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4969\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4684\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4577\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4415\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4402\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4348\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4015\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4075\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4148\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3971\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3678\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3565\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3555\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3383\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3340\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3231\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3099\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3049\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3010\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2910\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2936\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2884\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2777\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2713\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2714\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2648\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2567\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2548\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2522\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2512\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2483\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2441\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2415\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2319\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2301\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2295\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2246\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2222\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2216\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2159\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2175\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2122\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2121\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2114\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2092\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2068\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2060\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2046\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2024\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2009\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2009\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2002\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1976\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1964\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1952\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1927\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1916\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1910\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1903\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1892\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1884\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1859\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1846\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1836\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1832\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1820\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1812\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1808\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:54,123] Trial 13 finished with value: 61.0425012665679 and parameters: {'lr': 0.002137765007936263, 'alpha': 0.00028448720470978487, 'activation': 'sigmoid', 'n1': 192, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1571\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7166\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2476\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9758\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7779\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5826\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4175\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2727\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1898\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0606\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9383\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8365\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7436\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6269\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5440\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4494\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3671\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2875\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2070\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1594\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0768\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0095\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9342\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.8735\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8064\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7489\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6906\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6363\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5847\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5334\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4885\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4376\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4045\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3504\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3057\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2691\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2254\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1839\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1448\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1109\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0772\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0438\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0147\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9453\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9156\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8906\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8660\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8321\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8059\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7841\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7661\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7384\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7414\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7253\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7015\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6656\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6417\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6161\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6149\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5905\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5666\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5526\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5303\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5131\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4980\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4917\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4755\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4648\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4475\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4266\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4111\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4026\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3875\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3760\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3647\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3624\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3614\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3481\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3396\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3577\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3617\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3679\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3795\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3597\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3155\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3456\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2919\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3051\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2775\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2709\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2473\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2381\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2509\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2651\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2317\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2473\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2396\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2309\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:55,778] Trial 14 finished with value: 63.52409774657985 and parameters: {'lr': 0.019547295308692616, 'alpha': 0.00597785411675189, 'activation': 'sigmoid', 'n1': 256, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8739\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4172\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3025\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2784\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2100\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1982\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1830\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1791\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1679\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1612\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1567\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1495\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1454\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1380\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1336\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1357\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1342\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1196\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1165\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1072\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0979\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0931\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0892\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0799\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0778\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0717\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0715\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0642\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0540\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0462\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0408\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0441\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0269\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0352\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0254\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0152\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0061\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0039\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9948\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9885\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9799\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9755\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9684\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9615\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9557\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9503\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9476\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9431\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9333\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9251\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9184\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9135\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9111\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9047\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8957\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8879\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8832\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8714\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8699\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8625\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8539\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8508\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8399\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8381\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8311\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8249\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8271\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8121\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8093\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8002\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7911\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7874\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7805\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7720\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7723\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7601\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7581\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7491\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7443\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7391\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7356\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7333\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7201\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7203\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7089\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7084\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7004\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6964\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6904\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6821\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6752\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6719\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6701\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6594\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6534\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6476\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6456\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6410\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:57,330] Trial 15 finished with value: 58.562715955041384 and parameters: {'lr': 0.00035676340184542766, 'alpha': 0.0003903578866662198, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 37.3357\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 35.7575\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 34.4924\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.3279\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.0825\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.9001\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.7407\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.6266\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5528\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5195\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.5254\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.5685\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6479\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7621\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9095\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0890\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2994\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5395\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8083\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1044\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4271\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7750\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1476\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5436\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9622\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4029\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8644\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3463\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8475\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3675\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9054\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4604\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0324\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6203\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2238\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8422\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4747\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1211\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.7812\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4535\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1381\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8346\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5425\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2609\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9904\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7298\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4793\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.2384\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.0060\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7823\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5671\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3599\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1607\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9688\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7843\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6068\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4355\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2707\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1122\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9600\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8132\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6717\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5357\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4045\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2786\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1571\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0404\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9283\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8202\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7162\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6157\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5197\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4267\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3368\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2508\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1679\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0114\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9377\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8664\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7981\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7328\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6694\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6081\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5490\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4925\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4382\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3868\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3361\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2874\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2405\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1953\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1521\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1101\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0701\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0314\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9941\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9587\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9239\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8912\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:58,960] Trial 16 finished with value: 65.87201327033065 and parameters: {'lr': 0.002699479695264986, 'alpha': 0.04927873066015183, 'activation': 'tanh', 'n1': 320, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2194\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2184\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2144\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2083\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1662\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1577\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1518\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1463\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1381\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1191\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1112\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1075\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0898\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0872\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0709\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0760\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1047\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0539\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0308\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0196\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0115\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0020\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0031\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9702\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9581\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9534\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9445\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9592\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9327\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8997\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8948\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9072\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8746\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8420\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8278\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8184\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8230\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7875\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7753\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7681\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7502\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7372\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7258\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7130\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7030\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7001\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6776\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6764\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6746\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6651\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6553\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6330\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6238\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6204\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6238\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5945\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5929\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5896\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5771\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5689\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5643\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5616\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5517\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5463\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5407\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5357\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5366\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5313\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5237\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5131\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5100\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5051\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4992\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4951\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4964\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4906\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4799\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4737\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4703\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4671\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4640\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4534\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4497\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4467\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4390\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4377\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4391\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4310\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4264\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4240\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4205\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4139\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4161\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4084\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4055\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4089\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4027\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:00,497] Trial 17 finished with value: 54.887397256505984 and parameters: {'lr': 0.0008268674952260534, 'alpha': 0.0004886784355305433, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3388\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2017\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2134\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1775\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1779\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1659\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1627\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1599\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1569\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1519\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1499\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1447\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1429\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1370\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1345\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1375\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1356\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1289\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1206\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1211\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1128\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1088\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1067\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0998\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0992\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0943\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0945\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0902\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0828\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0781\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0732\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0784\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0638\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0725\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0666\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0563\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0516\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0491\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0431\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0391\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0319\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0303\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0250\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0201\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0161\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0113\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0114\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0037\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0001\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9928\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9897\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9853\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9831\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9789\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9718\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9669\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9636\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9544\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9515\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9469\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9401\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9370\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9292\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9270\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9221\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9167\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9198\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9068\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9036\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8968\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8886\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8847\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8788\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8718\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8719\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8601\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8574\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8505\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8443\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8392\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8372\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8312\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8210\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8194\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8110\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8085\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8002\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7954\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7890\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7829\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7833\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7698\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7726\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7642\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7587\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7511\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7476\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7380\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7386\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7312\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:02,146] Trial 18 finished with value: 67.32759250313498 and parameters: {'lr': 0.0003127506277317366, 'alpha': 0.0004365005994739172, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2263\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2193\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2167\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2134\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1880\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1817\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1694\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1597\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1534\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1338\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1243\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1167\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0964\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0720\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0799\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0907\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0399\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0265\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0088\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9992\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9866\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9828\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9473\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9379\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9280\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9156\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9232\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8946\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8644\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8591\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8579\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8270\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8076\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7964\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7849\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7822\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7512\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7449\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7334\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7171\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7053\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6956\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6849\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6769\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6725\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6541\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6546\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6505\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6441\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6327\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6174\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6137\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6075\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6054\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5871\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5906\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5863\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5717\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5649\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5629\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5586\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5505\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5462\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5417\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5365\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5347\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5275\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5243\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5167\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5132\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5092\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5049\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5012\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4971\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4910\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4808\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4774\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4739\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4720\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4708\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4625\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4590\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4560\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4527\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4498\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4479\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4507\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4386\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4318\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4268\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4276\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4218\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4201\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4203\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4157\n",
      "4/4 [==============================] - 0s 838us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:03,805] Trial 19 finished with value: 57.10359805375634 and parameters: {'lr': 0.0008688529977470843, 'alpha': 0.000620431612666866, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 1.7689\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1850\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8495\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6139\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5447\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4978\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4623\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4338\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4118\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3914\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3746\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3589\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3454\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3336\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3236\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3140\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3055\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2986\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2926\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2818\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2779\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2740\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2709\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2678\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2627\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2605\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2585\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2550\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2535\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2521\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2509\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2499\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2488\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2478\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2470\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2462\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2455\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2448\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2441\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2436\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2431\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2426\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2422\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2418\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2407\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2401\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2399\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2396\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2395\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2392\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2390\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2387\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2385\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2384\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2382\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2381\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2380\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2378\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2377\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2376\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2375\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2374\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2373\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2373\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2372\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2371\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2370\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2369\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2369\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2368\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2366\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2366\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2365\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2365\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2364\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2362\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2362\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2360\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2360\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2359\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2359\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2358\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2358\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2357\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2357\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:06,036] Trial 20 finished with value: 73.66704382072314 and parameters: {'lr': 0.0008042694329300243, 'alpha': 0.0005797064995685693, 'activation': 'tanh', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1884\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1026\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0988\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0897\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0430\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0291\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0180\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0056\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9991\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9463\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9314\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9088\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8942\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8747\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8559\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8706\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8255\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7844\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7626\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7369\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7187\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7100\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6836\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6440\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6096\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6103\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5994\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5636\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5541\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5788\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5651\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4980\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4815\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4650\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4492\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4383\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4274\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4175\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4120\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3987\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3940\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3868\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3805\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3838\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3641\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3534\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3527\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3433\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3462\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3372\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3286\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3186\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3050\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3004\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2974\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2900\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2861\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2812\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2785\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2733\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2736\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2643\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2594\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2571\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2501\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2457\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2422\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2397\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2376\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2294\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2273\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2238\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2204\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2178\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2151\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2125\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2109\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2110\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2059\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2030\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2019\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2021\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1977\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1972\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1923\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1899\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1876\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1848\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1834\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1809\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1786\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1773\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:07,773] Trial 21 finished with value: 58.82215589005639 and parameters: {'lr': 0.001293822559519647, 'alpha': 0.00024436757942165546, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3108\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3166\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2347\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2158\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2174\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1865\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1839\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0888\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0550\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0148\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9777\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8926\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8762\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8743\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8609\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8196\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7355\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6553\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6004\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5779\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5654\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5495\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5451\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5209\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5082\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4949\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4786\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4739\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4602\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4548\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4433\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4461\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4230\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4161\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4148\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3874\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3808\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3820\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3696\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3669\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3604\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3543\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3527\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3504\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3544\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3408\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3345\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3299\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3291\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3227\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3238\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3236\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3154\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3253\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3080\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3043\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2992\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2985\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2990\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2969\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2956\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2936\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2892\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2856\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2838\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2798\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2766\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2728\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2721\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2712\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2707\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2727\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2700\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2700\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2644\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2648\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2621\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2618\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2606\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2589\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2585\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2567\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2586\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2561\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2546\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2532\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:09,500] Trial 22 finished with value: 64.36580875396851 and parameters: {'lr': 0.0027744557006031084, 'alpha': 0.0005827368166316126, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1227\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1163\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1142\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1092\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0922\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0885\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0737\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0690\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0630\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0481\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0467\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0334\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0255\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0200\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0065\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0090\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0083\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9812\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9840\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9621\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9515\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9474\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9385\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9246\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9193\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9104\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9076\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8994\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8822\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8688\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8607\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8625\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8403\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8406\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8291\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8034\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7958\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7854\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7714\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7604\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7493\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7284\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7181\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7105\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7010\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6940\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6815\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6710\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6593\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6524\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6471\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6354\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6262\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6155\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6107\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5944\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5899\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5807\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5710\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5660\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5553\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5484\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5435\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5358\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5317\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5224\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5171\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5074\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4952\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4905\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4824\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4824\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4718\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4694\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4613\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4568\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4525\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4504\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4486\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4390\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4378\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4298\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4268\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4226\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4183\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4184\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4141\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4069\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4058\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3991\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3986\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3917\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3933\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3874\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3853\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3810\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3798\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:11,192] Trial 23 finished with value: 57.49350968555152 and parameters: {'lr': 0.0005666118553888679, 'alpha': 0.0001988065057044844, 'activation': 'sigmoid', 'n1': 192, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3773\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3157\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3248\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3085\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3075\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3054\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3003\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2988\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2953\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2923\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2891\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2846\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2821\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2786\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2748\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2807\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2747\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2711\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2632\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2627\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2602\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2554\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2512\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2474\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2458\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2419\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2405\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2380\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2326\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2283\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2248\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2282\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2173\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2210\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2186\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2082\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2088\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2047\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2008\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1979\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1916\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1906\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1864\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1825\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1791\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1754\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1755\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1691\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1664\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1628\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1584\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1570\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1554\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1507\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1458\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1421\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1389\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1335\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1299\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1265\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1230\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1190\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1142\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1133\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1093\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1048\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1070\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0978\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0908\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0845\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0810\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0772\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0720\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0721\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0640\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0600\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0578\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0522\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0484\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0465\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0417\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0350\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0319\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0280\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0240\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0187\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0141\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0117\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0054\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0069\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9956\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9975\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9914\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9877\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9793\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9770\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9729\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9697\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9668\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:12,843] Trial 24 finished with value: 74.36739544316448 and parameters: {'lr': 0.00025402258047026735, 'alpha': 0.0007753327889135206, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2495\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2632\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1705\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1598\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1449\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1124\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0825\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0557\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0465\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0257\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9973\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9867\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9582\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9183\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8854\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8721\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8934\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8534\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8262\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7709\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7309\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6940\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6781\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6839\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6470\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6263\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6122\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5866\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5837\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5904\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5407\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5370\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5491\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5419\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5090\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4940\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4904\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4868\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4742\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4777\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4776\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4592\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4427\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4345\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4270\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4243\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4216\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4168\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4085\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3927\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3964\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3957\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3930\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3720\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3732\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3833\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3650\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3636\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3528\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3588\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3578\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3507\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3383\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3348\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3312\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3287\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3282\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3183\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3154\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3118\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3114\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3063\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3059\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3038\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3017\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2965\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2939\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2925\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2902\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2877\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2874\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2840\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2804\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2781\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2738\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2726\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2679\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2651\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2647\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2624\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2600\n",
      "4/4 [==============================] - 0s 668us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:14,554] Trial 25 finished with value: 56.17399134753914 and parameters: {'lr': 0.0014832161187332013, 'alpha': 0.0003380614603970123, 'activation': 'sigmoid', 'n1': 192, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0639\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0594\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0600\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0590\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0424\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0436\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0326\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0291\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0154\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0145\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0106\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9989\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0020\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9874\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0062\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0166\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9728\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9822\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9608\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9574\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9557\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9549\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9327\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9369\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9322\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9302\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9375\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9117\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8981\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8922\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8976\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8747\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8739\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8630\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8572\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8428\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8462\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8294\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8175\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8087\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8009\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7911\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7822\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7785\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7668\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7667\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7460\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7337\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7241\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7216\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7160\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7094\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6883\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6926\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6706\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6499\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6444\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6322\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6250\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6147\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6094\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6012\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5930\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5894\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5748\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5635\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5560\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5465\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5418\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5353\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5258\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5176\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5101\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5019\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4940\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4875\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4879\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4846\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4697\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4646\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4553\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4487\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4429\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4372\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4343\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4291\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4208\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4183\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4125\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4097\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4005\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4024\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3925\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3920\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3901\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3830\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:16,155] Trial 26 finished with value: 59.40491410688315 and parameters: {'lr': 0.0005225852011665604, 'alpha': 0.00010234367597197874, 'activation': 'sigmoid', 'n1': 128, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1172\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8391\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8782\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8105\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8106\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7910\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7895\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7833\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7771\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7728\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7697\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7649\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7623\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7584\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7547\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7610\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7555\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7518\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7425\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7430\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7371\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7323\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7298\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7245\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7232\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7192\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7182\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7153\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7088\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7048\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7006\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7052\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6926\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6986\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6951\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6843\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6829\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6793\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6753\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6718\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6656\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6642\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6599\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6560\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6528\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6488\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6497\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6428\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6402\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6349\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6320\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6298\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6283\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6242\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6184\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6148\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6127\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6058\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6028\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5998\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5954\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5923\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5867\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5862\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5826\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5779\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5809\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5712\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5684\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5648\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5580\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5551\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5515\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5458\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5469\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5378\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5352\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5323\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5264\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5229\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5229\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5182\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5100\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5081\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5033\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5009\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4947\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4910\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4875\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4819\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4858\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4721\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4772\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4693\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4677\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4577\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4579\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4504\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4514\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4472\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:17,827] Trial 27 finished with value: 71.64389253822792 and parameters: {'lr': 0.00021514221254018622, 'alpha': 0.0031128939043399, 'activation': 'sigmoid', 'n1': 192, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4629\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9092\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6181\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4800\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3813\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3246\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2872\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2563\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2338\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2171\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2028\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1915\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1828\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1749\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1685\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1591\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1554\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1521\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1496\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1473\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1452\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1436\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1422\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1411\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1399\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1389\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1381\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1374\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1367\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1355\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1351\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1346\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1343\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1339\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1336\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1333\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1331\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1328\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1326\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1324\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1323\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1321\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1320\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1318\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1317\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1316\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1315\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1313\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1313\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1312\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1311\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1311\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1309\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1308\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1308\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1308\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1307\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1307\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1307\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1305\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1305\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1304\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1304\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1303\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1303\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1303\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1301\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1301\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:19,511] Trial 28 finished with value: 75.46315048873812 and parameters: {'lr': 0.0009504018362641837, 'alpha': 0.00018772816978607088, 'activation': 'tanh', 'n1': 256, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7843\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4013\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0503\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8431\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7014\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6210\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5649\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5178\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4877\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4598\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4382\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4192\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4051\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3923\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3825\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3731\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3655\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3588\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3534\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3482\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3440\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3401\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3365\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3334\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3308\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3281\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3258\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3238\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3217\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3198\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3183\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3168\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3153\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3140\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3128\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3117\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3107\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3096\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3087\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3078\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3069\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3061\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3054\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3046\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3039\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3032\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3026\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3020\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3014\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3008\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3003\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2997\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2992\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2987\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2982\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2978\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2973\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2968\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2964\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2960\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2955\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2951\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2947\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2943\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2939\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2935\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2932\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2928\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2924\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2921\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2917\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2913\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2910\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2906\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2903\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2900\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2896\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2893\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2890\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2886\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2883\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2880\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2877\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2874\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2870\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2867\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2864\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2861\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2858\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2855\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2852\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2849\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2846\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2843\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2840\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2837\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2834\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2831\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2828\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2825\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:21,285] Trial 29 finished with value: 75.71937928748969 and parameters: {'lr': 0.0005303842432961027, 'alpha': 0.0013844633386373548, 'activation': 'gelu', 'n1': 384, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3925\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3866\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3192\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2998\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3019\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2609\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2246\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1668\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1574\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1118\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1015\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0686\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0354\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0336\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0133\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9780\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0091\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9101\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8866\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8309\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7606\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7264\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7012\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7041\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6739\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6155\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6111\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5921\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5801\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5643\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5389\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5355\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5375\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5388\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4968\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4788\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4718\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4591\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4495\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4414\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4490\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4497\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4210\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4110\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3982\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4047\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3999\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3933\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3773\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3731\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3725\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3729\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3753\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3628\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3561\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3477\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3500\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3480\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3474\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3375\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3331\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3365\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3330\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3291\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3210\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3174\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3148\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3143\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3091\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3118\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3095\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3066\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3060\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2998\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3022\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2961\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2956\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2940\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2922\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2931\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2908\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2888\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2850\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2837\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2828\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2830\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2814\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2825\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2789\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2773\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2764\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2754\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2739\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2788\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2745\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2729\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2706\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2690\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:22,790] Trial 30 finished with value: 58.70081934525798 and parameters: {'lr': 0.0023123022936027016, 'alpha': 0.000586292422524495, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4406\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2482\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2420\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2164\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1433\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1048\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0885\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0609\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0454\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0189\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9526\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9201\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8960\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8786\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8478\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8479\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7715\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7389\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7164\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6988\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6844\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6677\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6336\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6206\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6086\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6033\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5991\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5859\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5688\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5729\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5733\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5411\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5253\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5123\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5114\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4929\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4848\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4781\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4736\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4640\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4594\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4591\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4476\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4563\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4421\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4226\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4181\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4214\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4150\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4090\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3988\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4051\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3928\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3824\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3830\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3730\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3689\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3659\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3623\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3580\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3543\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3499\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3471\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3435\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3420\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3380\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3374\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3281\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3276\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3245\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3222\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3209\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3155\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3142\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3096\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3068\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3046\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3037\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3013\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2993\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2971\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2964\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2937\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2922\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2918\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2895\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2876\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2842\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2843\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2812\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2806\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2790\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2770\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2768\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:24,422] Trial 31 finished with value: 56.794680817555815 and parameters: {'lr': 0.0014571610387418346, 'alpha': 0.0003171968403787017, 'activation': 'sigmoid', 'n1': 256, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2442\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1869\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1735\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1582\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1157\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1004\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0806\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0644\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0472\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0173\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9942\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9784\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9521\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9368\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9127\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9165\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8639\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8244\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8041\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7835\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7650\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7289\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6992\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6703\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6714\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6610\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6288\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6211\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6338\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6186\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5650\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5519\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5403\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5403\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5251\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5144\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5077\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5010\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4898\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4780\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4733\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4574\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4522\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4502\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4509\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4470\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4332\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4192\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4212\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4080\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4051\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4026\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3957\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3924\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3876\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3858\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3787\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3746\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3710\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3670\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3648\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3643\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3593\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3552\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3513\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3538\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3486\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3429\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3361\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3335\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3304\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3275\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3256\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3220\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3194\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3175\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3178\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3144\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3099\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3074\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3048\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3026\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3025\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3026\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2991\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2962\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2940\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2921\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2913\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2884\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2878\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2832\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2818\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2798\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:25,988] Trial 32 finished with value: 58.5561709359424 and parameters: {'lr': 0.001095587620589835, 'alpha': 0.00026712732781587935, 'activation': 'sigmoid', 'n1': 256, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5063\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3945\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3300\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2198\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1490\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0795\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0829\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9526\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8738\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8330\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7997\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7218\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6829\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6603\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6876\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7259\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6227\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6182\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5617\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5432\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5209\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5158\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5035\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4862\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4843\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4717\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4563\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4351\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4312\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4234\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4162\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4090\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3991\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3946\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3912\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4019\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3794\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3764\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3719\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3719\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3639\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3637\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3577\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3541\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3534\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3537\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3503\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3463\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3430\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3415\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3385\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3389\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3389\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3346\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3412\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3336\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3284\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3272\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3274\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3276\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3260\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3272\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3254\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3218\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3204\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3195\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3188\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3185\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3158\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3141\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3122\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3115\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3117\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3107\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3097\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3109\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3095\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3085\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3057\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3047\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3047\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3034\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3035\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3032\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3023\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3012\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3012\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3005\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3002\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3008\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3004\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3005\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2994\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2987\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2984\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:27,679] Trial 33 finished with value: 62.33236491380777 and parameters: {'lr': 0.0034300013336170374, 'alpha': 0.0004402987574185776, 'activation': 'sigmoid', 'n1': 256, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4266\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6878\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4347\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3238\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2447\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1838\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1467\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1168\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1036\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0935\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0868\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0811\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0763\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0729\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0701\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0678\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0657\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0639\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0623\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0609\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0597\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0584\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0573\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0563\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0553\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0543\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0534\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0525\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0517\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0509\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0500\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0492\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0484\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0477\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0469\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0462\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0454\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0447\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0440\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0433\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0425\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0418\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0411\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0404\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0397\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0390\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0383\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0376\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0369\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0362\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0356\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0349\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0342\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0335\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0328\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0322\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0315\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0308\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0302\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0295\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0288\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0282\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0275\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0269\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0262\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0255\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0249\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0242\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0235\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0229\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0222\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0216\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0209\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0203\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0196\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0190\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0183\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0177\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0170\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0164\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0157\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0151\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0144\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0138\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0131\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0125\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0118\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0112\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0106\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0099\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0093\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0086\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0080\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0074\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0067\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0061\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0054\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0048\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0042\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0035\n",
      "4/4 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:29,496] Trial 34 finished with value: 65.05443481641218 and parameters: {'lr': 0.001715196401300293, 'alpha': 0.0013219123216076413, 'activation': 'gelu', 'n1': 320, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5447\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6048\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5959\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3133\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2508\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2523\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1808\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1575\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0340\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9694\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8834\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8457\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8065\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8054\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8488\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7668\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7109\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6909\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6838\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6505\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6405\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6261\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6058\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6036\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6003\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6047\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5739\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5552\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5502\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5530\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5479\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5391\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5445\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5401\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5243\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5268\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5345\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5209\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4990\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4945\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4900\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4879\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4845\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4851\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4764\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4733\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4743\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4685\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4667\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4649\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4620\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4639\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4616\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4569\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4583\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4588\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4545\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4519\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4523\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4522\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4464\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4475\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4452\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4415\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4410\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4452\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4432\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4433\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4371\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4353\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4339\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4327\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4320\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4316\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4302\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4301\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4285\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4278\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4274\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4268\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4256\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4250\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4253\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4236\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4230\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4232\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4229\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4216\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4210\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4193\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4198\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4209\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4193\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4177\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4175\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4160\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4153\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:31,102] Trial 35 finished with value: 64.18843170252426 and parameters: {'lr': 0.003637777667057363, 'alpha': 0.0007445754898470012, 'activation': 'sigmoid', 'n1': 192, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6763\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8767\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3659\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2203\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1269\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0628\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0219\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9953\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9736\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9600\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9483\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9394\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9316\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9259\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9211\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9170\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9106\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9083\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9061\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9043\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9026\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9012\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8999\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8989\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8978\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8970\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8961\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8953\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8945\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8939\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8933\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8927\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8921\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8916\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8911\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8907\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8902\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8899\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8894\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8890\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8887\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8883\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8880\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8876\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8873\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8867\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8864\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8861\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8858\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8855\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8852\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8849\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8847\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8844\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8841\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8839\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8836\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8833\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8831\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8826\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8823\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8820\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8818\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8815\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8813\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8810\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8808\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8805\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8803\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8801\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8798\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8796\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8793\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8791\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8789\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8786\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8784\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8782\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8779\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8777\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8775\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8772\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8770\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8767\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8765\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8763\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8760\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8758\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8756\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8754\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8751\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8749\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8747\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8744\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8742\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8740\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8738\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:32,954] Trial 36 finished with value: 76.06853375116097 and parameters: {'lr': 0.000781099390239808, 'alpha': 0.0011604181674921877, 'activation': 'gelu', 'n1': 320, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7803\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4847\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2502\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1572\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1039\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0207\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0013\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9800\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9742\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9433\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9062\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8878\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8645\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8265\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8147\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8269\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7753\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7360\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7150\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6898\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6699\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6607\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6317\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6004\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5833\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5677\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5697\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5736\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5277\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5168\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5398\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5261\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4639\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4466\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4326\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4295\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4166\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4066\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3904\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3812\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3764\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3700\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3653\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3702\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3495\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3412\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3371\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3294\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3292\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3248\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3076\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3066\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2950\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2943\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2946\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2830\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2760\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2666\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2611\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2533\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2433\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2353\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2354\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2322\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2267\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2237\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2206\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2167\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2143\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2108\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2081\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2032\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2033\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1989\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1956\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1912\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1871\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1867\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1834\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1821\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1789\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1779\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1778\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1744\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1727\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1707\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1694\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1675\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:34,555] Trial 37 finished with value: 58.24711478208619 and parameters: {'lr': 0.0012659580917846744, 'alpha': 0.00019105348920217408, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5300\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5876\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3921\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3307\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3053\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2785\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2508\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2260\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2198\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2071\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2065\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2046\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2033\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2029\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2013\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2011\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2007\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2007\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2007\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1999\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2001\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1997\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1992\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1990\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1989\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1987\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1984\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1982\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1980\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1978\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1977\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1973\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1972\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1970\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1968\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1966\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1965\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1962\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1960\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1959\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1957\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1955\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1954\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1952\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1950\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1949\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1947\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1946\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1944\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1943\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1941\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1938\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1936\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1935\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1932\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1930\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1929\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1927\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1925\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1924\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1922\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1921\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1919\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1918\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1914\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1913\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1911\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1910\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1908\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1907\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1905\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1903\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1902\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1901\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1898\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1896\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1894\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1893\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1891\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1888\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1887\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1885\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1882\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1880\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1879\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1877\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1876\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1874\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1873\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1871\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1870\n",
      "4/4 [==============================] - 0s 869us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:36,234] Trial 38 finished with value: 59.783804825071115 and parameters: {'lr': 0.008061907712918122, 'alpha': 0.0003608613311849593, 'activation': 'relu', 'n1': 192, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9989\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9940\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9925\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9871\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9691\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9663\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9510\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9440\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9417\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9242\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9209\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9131\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8987\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8976\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8811\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8918\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8941\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8577\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8629\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8390\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8297\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8275\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8194\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8016\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7978\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7914\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7865\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7859\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7653\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7501\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7429\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7463\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7257\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7228\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7149\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7021\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6919\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6843\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6800\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6619\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6516\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6408\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6320\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6219\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6128\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6049\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5972\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5951\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5826\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5744\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5600\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5536\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5517\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5429\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5344\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5180\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5175\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4988\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4921\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4828\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4745\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4660\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4592\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4492\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4452\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4375\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4331\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4282\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4176\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4058\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3895\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3874\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3804\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3753\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3686\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3629\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3534\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3485\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3427\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3426\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3419\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3257\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3244\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3148\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3101\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3055\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3007\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2960\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2935\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2860\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2834\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2774\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2762\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2662\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2704\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2607\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2600\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2583\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2526\n",
      "4/4 [==============================] - 0s 835us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:37,843] Trial 39 finished with value: 55.55557160710136 and parameters: {'lr': 0.0004500254115521539, 'alpha': 0.0027582362290749732, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1542\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6544\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1112\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8658\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7405\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6371\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5616\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5115\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4783\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4426\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4151\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3944\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3749\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3586\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3452\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3338\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3224\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3133\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3051\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2977\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2908\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2846\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2786\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2731\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2685\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2637\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2596\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2554\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2516\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2477\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2442\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2410\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2377\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2346\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2316\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2287\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2260\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2233\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2207\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2181\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2156\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2132\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2108\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2085\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2063\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2040\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2017\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1996\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1974\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1953\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1931\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1911\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1890\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1870\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1850\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1830\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1810\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1790\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1770\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1751\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1731\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1712\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1693\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1674\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1655\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1636\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1617\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1598\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1579\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1560\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1542\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1523\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1505\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1486\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1468\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1450\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1431\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1413\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1395\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1376\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1358\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1340\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1322\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1304\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1286\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1268\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1250\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1232\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1214\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1196\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1178\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1160\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1142\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1125\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1107\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1089\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1071\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1053\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1036\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1018\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:39,458] Trial 40 finished with value: 78.5477734197659 and parameters: {'lr': 0.000442128886129882, 'alpha': 0.004572804169783657, 'activation': 'relu', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5943\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5951\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5846\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5808\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5555\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5252\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5149\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4990\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4951\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4708\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4431\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4281\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4067\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3951\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3775\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3676\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3887\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3488\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3049\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2648\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2526\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2496\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2272\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1899\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1747\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1642\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1835\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1623\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1290\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1030\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1244\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1278\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0532\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0295\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0095\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0037\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9826\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9712\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9649\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9455\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9327\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9251\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9141\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9046\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9055\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8900\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8803\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8806\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8710\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8699\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8607\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8527\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8404\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8422\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8238\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8185\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8153\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8065\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8008\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7939\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7923\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7845\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7824\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7728\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7681\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7665\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7641\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7545\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7523\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7430\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7395\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7386\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7345\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7303\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7277\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7200\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7175\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7123\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7056\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7025\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7024\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6912\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6860\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6835\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6794\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6764\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6738\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6749\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6709\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6660\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6613\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6582\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6588\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6515\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6498\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6447\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6428\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6388\n",
      "4/4 [==============================] - 0s 878us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:41,003] Trial 41 finished with value: 57.85965679787283 and parameters: {'lr': 0.000924801486507968, 'alpha': 0.0022087628583511336, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9288\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9218\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8928\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8753\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8195\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7913\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7761\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7600\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7419\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7101\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6857\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6706\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6427\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6278\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6020\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5930\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6106\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5547\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5173\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4979\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4760\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4525\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4418\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4097\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3836\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3677\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3500\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3554\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3214\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2831\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2716\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2834\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2447\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1880\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1657\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1470\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1423\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1055\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0849\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0655\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0415\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0215\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0027\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9817\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9635\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9496\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9245\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9107\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9022\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8850\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8751\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8413\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8254\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8127\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8128\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7726\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7608\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7481\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7317\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7155\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7017\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6894\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6746\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6617\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6472\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6348\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6260\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6140\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6005\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5821\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5703\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5585\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5463\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5331\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5272\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5157\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4993\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4871\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4734\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.4618\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4509\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4397\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4341\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4160\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4033\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3936\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3832\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3705\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3646\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3562\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3412\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3295\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3206\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3091\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2968\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2886\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2736\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2621\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2588\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2430\n",
      "4/4 [==============================] - 0s 666us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:42,655] Trial 42 finished with value: 56.009657313499055 and parameters: {'lr': 0.000698821200582735, 'alpha': 0.008196610165303004, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6672\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6602\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6441\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6243\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5610\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5345\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5095\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4853\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4594\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4258\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4014\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3815\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3464\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3274\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2929\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2852\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2921\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2266\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.1929\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1659\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1402\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1129\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0965\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0567\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0307\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0085\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9880\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9866\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9478\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9029\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8869\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8792\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8352\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7948\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7699\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7483\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7392\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6896\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6695\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6476\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6160\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5921\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5681\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5435\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5208\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5014\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4720\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4552\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4395\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4202\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3976\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3646\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3506\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3319\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3222\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2773\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2627\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2474\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2211\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2009\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1843\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1655\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1458\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1280\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1105\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0930\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0767\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0577\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0416\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0212\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0048\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9896\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9725\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9544\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9400\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9229\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9051\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8892\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8722\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8560\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8420\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8292\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8168\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7920\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7768\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7608\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7458\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7306\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7161\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7054\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6874\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6715\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6579\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6421\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6240\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6131\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5937\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5801\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5693\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5516\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:44,296] Trial 43 finished with value: 55.42133869615102 and parameters: {'lr': 0.0006530219627934531, 'alpha': 0.010667358653405856, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8646\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8464\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8431\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8321\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8243\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8161\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8065\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7989\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7902\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7808\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7726\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7624\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7544\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7451\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7360\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7363\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7258\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7161\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7022\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6969\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6882\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6781\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6689\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6590\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6518\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6427\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6359\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6289\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6175\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6082\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5995\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5986\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5813\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5811\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5738\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5568\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5525\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5435\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.5336\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5264\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5147\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5088\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4993\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4904\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4822\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4737\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4684\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4575\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4503\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4411\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4327\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4260\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4194\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4101\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4003\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3919\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3844\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3739\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3661\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3581\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3500\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3416\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3317\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3273\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3186\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3093\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3076\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2935\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2852\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2779\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2670\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2589\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2514\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2416\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2381\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2256\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2167\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2112\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2007\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1932\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1873\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1787\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1670\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1602\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1519\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1438\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1344\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1259\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1187\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1089\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1079\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0908\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0905\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0793\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0726\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0593\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0534\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.0450\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0385\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0320\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:45,876] Trial 44 finished with value: 74.18297710794084 and parameters: {'lr': 0.0001801887393834703, 'alpha': 0.012333680001063628, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.9119\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8497\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7820\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7075\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6122\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5295\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4401\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3555\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2736\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1790\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0918\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0112\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.9181\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8388\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7477\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.6791\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6269\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5049\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4126\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.3285\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2484\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1653\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.0941\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.9943\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.9120\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8369\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7589\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7078\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6132\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5114\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.4419\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3855\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2850\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1877\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.1087\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0347\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9741\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8722\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.7970\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7245\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6431\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5679\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4924\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4173\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3435\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2764\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1955\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.1298\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.0592\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9897\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9200\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8399\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7721\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7047\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6458\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5576\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4973\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4298\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3584\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2907\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2267\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1638\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0953\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0298\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9657\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9025\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8412\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.7778\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.7129\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6467\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5848\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.5228\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.4609\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3997\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3429\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.2799\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2188\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1598\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0972\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0377\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9795\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9237\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8685\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8015\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7435\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.6857\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6286\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5713\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.5167\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4642\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4032\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3473\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.2929\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.2358\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1771\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.1254\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.0660\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.0138\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.9657\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.9074\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:47,462] Trial 45 finished with value: 54.434319211628384 and parameters: {'lr': 0.000648662551024776, 'alpha': 0.02260346133324402, 'activation': 'sigmoid', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3387\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.8465\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4531\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2060\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0383\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8949\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7618\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6426\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5361\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4308\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.3320\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2363\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1434\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0527\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9635\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8758\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7890\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7030\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6184\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5340\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4506\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3678\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2854\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1227\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0418\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9617\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8818\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.8024\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7234\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6449\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5666\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4887\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4113\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3342\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2574\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1811\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1050\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.0293\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9539\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8789\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8042\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7299\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6558\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5821\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5087\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4356\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3629\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2904\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2183\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1465\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0749\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0037\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.9328\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8622\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7919\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7219\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6521\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5827\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5136\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4448\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3762\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3080\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2400\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1723\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1049\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0378\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9710\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9044\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8382\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7722\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7065\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6410\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5759\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5110\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4464\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3820\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3180\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2542\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1906\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1274\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0644\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0016\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9391\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8769\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8150\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7533\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6919\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6307\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5698\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5091\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4487\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3885\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3286\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2690\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2096\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1504\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0915\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0329\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9744\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:49,265] Trial 46 finished with value: 69.39861457218095 and parameters: {'lr': 0.0006674482071770976, 'alpha': 0.022344366281202434, 'activation': 'gelu', 'n1': 384, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7258\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4953\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1855\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1632\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1495\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1068\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0929\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0763\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0583\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0388\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0265\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0091\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9906\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9800\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9577\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9609\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9529\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9112\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9099\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8782\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8611\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8512\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8353\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8119\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8007\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7857\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7764\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7662\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7390\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7184\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7036\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7003\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6729\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6635\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6505\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6290\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6125\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6002\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5843\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5634\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5471\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5306\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5150\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4992\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4835\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4726\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4539\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4479\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4293\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4133\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3946\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3826\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3728\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3568\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3425\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3227\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3146\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2933\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2811\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2656\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2527\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2377\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2255\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2106\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2001\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1882\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1757\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1635\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1492\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1343\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1208\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1082\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0990\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0863\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0768\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0649\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0521\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0384\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0281\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0167\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0074\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9995\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9828\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9751\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9602\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9512\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9405\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9299\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9227\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9132\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8984\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8918\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8791\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8715\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8575\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8546\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8393\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8339\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8254\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8140\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:50,839] Trial 47 finished with value: 57.86262325052492 and parameters: {'lr': 0.00042339336152147746, 'alpha': 0.008543526188068818, 'activation': 'sigmoid', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6998\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4304\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1473\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.9178\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7111\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22.5653\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.4352\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3336\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.2422\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.1612\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0852\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0151\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9486\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.8854\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.8268\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7690\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7127\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6589\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6066\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5553\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5042\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4548\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4059\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.3582\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.3110\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2644\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2175\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.1720\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.1262\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0809\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0364\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9922\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9474\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9036\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8598\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8165\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7731\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7300\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.6874\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.6446\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6022\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5599\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5178\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4758\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4340\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.3923\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.3507\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.3094\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.2680\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.2269\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1858\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1449\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.1041\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.0634\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.0228\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9824\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.9420\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.9017\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8615\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8215\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7815\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7416\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7018\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.6621\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 19.6226\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5831\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5437\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5044\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.4652\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.4260\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3870\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3480\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3091\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.2703\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2316\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1930\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.1545\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.1160\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.0776\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.0393\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0012\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9630\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9250\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.8870\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.8491\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8113\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7736\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.7359\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6984\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6608\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.6234\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5861\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5488\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5116\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4745\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4375\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4005\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3636\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3268\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2901\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:52,462] Trial 48 finished with value: 76.45138356723437 and parameters: {'lr': 0.0002693783264055018, 'alpha': 0.02658771263919912, 'activation': 'relu', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7953\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3826\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0338\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8243\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6738\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5535\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4559\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3734\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3054\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2410\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.1819\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1270\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0745\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.0246\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 14.9770\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9313\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8860\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8425\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.8005\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7592\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7189\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.6789\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.6397\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6008\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5629\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.5250\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4879\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.4509\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.4143\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3779\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3420\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3063\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.2708\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2355\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2004\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1656\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.1309\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0964\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0622\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0278\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.9939\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.9601\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.9263\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8927\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8593\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8260\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.7928\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7598\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7268\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6940\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.6612\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6286\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5960\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.5636\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.5313\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4990\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4669\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4348\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4029\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3710\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3392\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3075\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2759\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2444\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2129\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1816\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1503\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1191\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0880\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0570\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 13.0260\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9951\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9643\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9336\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9030\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8724\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8419\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8115\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7812\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.7509\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.7207\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6906\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6606\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6306\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6007\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5709\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5412\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5115\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4819\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4524\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4229\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.3935\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3642\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3350\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3058\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.2767\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.2477\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2187\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1898\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.1610\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:54,029] Trial 49 finished with value: 79.13577456217612 and parameters: {'lr': 0.0004616504188371658, 'alpha': 0.018294769482185606, 'activation': 'tanh', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9157\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8939\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8720\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8502\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.8136\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7884\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7569\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7299\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7066\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6699\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6453\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6214\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5841\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5661\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5285\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5265\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5220\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4527\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4275\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3934\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3704\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3434\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3230\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2778\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2563\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2355\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2113\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2041\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1610\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1192\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0996\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0858\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0414\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0156\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9898\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9625\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9441\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9053\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8856\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8604\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8290\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8046\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.7803\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7550\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7318\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.7106\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6833\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.6697\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6500\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.6305\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6022\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5721\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5565\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5371\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5264\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4821\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 8.4711\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4505\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4239\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.4033\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3864\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3671\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3463\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3273\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3090\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2906\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2743\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2547\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2360\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2143\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1973\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1809\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1629\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1434\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1288\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1132\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0933\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0756\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0567\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0397\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.0244\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0097\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9930\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9718\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9550\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9385\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9218\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9058\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8920\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8805\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8577\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8416\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8262\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8096\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7913\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7798\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7598\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7462\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7330\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7145\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:55,671] Trial 50 finished with value: 56.475750969483066 and parameters: {'lr': 0.0006453727281820407, 'alpha': 0.009790137385693147, 'activation': 'sigmoid', 'n1': 384, 'n2': 320}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4690\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3381\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0930\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0201\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0244\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9868\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9400\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9155\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8965\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8730\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8403\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8211\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7874\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7612\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7461\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7208\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7347\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6937\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6426\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6003\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5731\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5508\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5352\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5135\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4684\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4469\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4215\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4347\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4142\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3832\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3230\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3190\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3359\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2824\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2482\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2268\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2274\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1943\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1737\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1595\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1437\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1243\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1142\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0999\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0806\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0859\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0703\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0462\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0407\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0270\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0216\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0135\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9989\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9788\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9747\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9553\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9394\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9349\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9163\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9067\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8934\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8831\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8716\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8625\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8502\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8406\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8308\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8255\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8103\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8053\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7876\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7786\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7711\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7636\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7552\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7459\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7337\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7249\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7184\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7077\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7006\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6921\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6909\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.6763\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6639\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6559\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6466\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6388\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6335\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6249\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6171\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6078\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5983\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5908\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5851\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5747\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5675\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5592\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5539\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5439\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:57,236] Trial 51 finished with value: 55.88046729443471 and parameters: {'lr': 0.0010990602884344404, 'alpha': 0.005651126370097854, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5178\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4785\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4338\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3938\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3172\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2957\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2816\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2678\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2496\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2254\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2100\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2015\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1755\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1663\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1418\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1466\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1719\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1112\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0833\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0655\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0531\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0371\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0318\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9979\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9805\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9726\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9595\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9715\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9370\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9013\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8952\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8964\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8614\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8318\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8180\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8036\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8026\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7621\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7511\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7380\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7141\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6999\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6830\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6661\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6503\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6421\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6206\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6110\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6001\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5875\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5751\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5504\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5399\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5308\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5265\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4934\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4888\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4778\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4607\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4481\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4397\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4297\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4169\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4066\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3966\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3880\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3779\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3699\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3585\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3458\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3370\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3304\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3216\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3109\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3051\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2973\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2864\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2781\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2667\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2589\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2529\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2484\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2422\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2260\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2191\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2109\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2028\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1957\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1923\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1899\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1743\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1676\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1622\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1538\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.1426\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1415\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1280\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1234\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1197\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1090\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:58,918] Trial 52 finished with value: 57.723269285538926 and parameters: {'lr': 0.0006604875383176219, 'alpha': 0.006040681144711947, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5580\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5606\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5344\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5249\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5081\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4702\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4437\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4204\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4113\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3955\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3615\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3462\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3170\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2823\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2746\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2546\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2671\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2240\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1847\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1393\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1159\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0971\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0827\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0786\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0286\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0110\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9895\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0037\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9890\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9730\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9077\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8976\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9247\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8836\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8512\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8345\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8411\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8167\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8003\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7879\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7768\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7600\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7505\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7436\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7290\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7385\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7266\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7103\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7128\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6963\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7028\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6968\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6885\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6699\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6781\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6671\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6410\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6376\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6219\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6151\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6073\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5980\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5920\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5837\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5765\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5709\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5667\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5659\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5521\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5526\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5385\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5333\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5296\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5250\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5245\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5198\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5115\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5026\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4996\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4960\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4902\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4851\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4882\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4776\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4689\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4626\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4567\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4526\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4502\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4460\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4431\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4373\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4299\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4265\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4221\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4174\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4140\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4094\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4046\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4012\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:00,509] Trial 53 finished with value: 60.72872794413582 and parameters: {'lr': 0.001117578516471097, 'alpha': 0.003561639301935277, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1988\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7092\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3117\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3195\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2243\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1622\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1497\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1359\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1169\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0996\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0932\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0749\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0652\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0536\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0388\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0376\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0331\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0050\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9810\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9678\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9610\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9493\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9338\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9251\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9145\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9094\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8998\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8813\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8659\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8565\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8569\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8322\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8311\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8178\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.8027\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7884\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7821\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7697\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7537\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7415\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7297\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7182\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7065\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6945\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6872\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6737\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6680\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6529\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6411\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.6281\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6191\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6133\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6012\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5886\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5756\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5704\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5501\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5446\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5313\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5190\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5119\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4995\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4880\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4811\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4707\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4642\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4530\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4422\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4299\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4189\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4066\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4022\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3893\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3840\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3725\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3638\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3515\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3447\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3359\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3293\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3244\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3095\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3044\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2913\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2849\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2764\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2683\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2621\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2537\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2444\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2389\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2288\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2250\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2116\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2123\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2002\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1946\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1879\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1812\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:02,338] Trial 54 finished with value: 59.69757891514321 and parameters: {'lr': 0.0003889726320747716, 'alpha': 0.0072501034517637765, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1943\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8422\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6778\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6902\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6086\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6265\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5958\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5915\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5875\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5745\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5717\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5596\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5556\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5453\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5392\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5379\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5353\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5197\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5159\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5047\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4935\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4875\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4820\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4719\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4694\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4617\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4589\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4507\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4387\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4302\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4241\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4277\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4083\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4148\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4053\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3934\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3824\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3818\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3700\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3616\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3519\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3469\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3383\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3309\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3241\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3179\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3135\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3057\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2973\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2886\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2817\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2756\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2718\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2650\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2548\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2487\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2424\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2290\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2254\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2172\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2082\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2042\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1930\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1887\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1823\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1747\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1761\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1616\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1567\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1467\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1372\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1307\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1253\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1150\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1173\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1010\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0989\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0867\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0814\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0748\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0708\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0648\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0522\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0508\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0393\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0366\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0272\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0223\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0143\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0090\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0036\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9953\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9919\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9873\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9766\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9768\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9672\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9601\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9570\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9507\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:03,959] Trial 55 finished with value: 60.41195850551317 and parameters: {'lr': 0.0003051940280185812, 'alpha': 0.004336887877957567, 'activation': 'sigmoid', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.7395\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.5572\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1991\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.8287\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.4537\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0319\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 21.6169\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2083\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8271\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4383\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0526\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.6961\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3263\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9555\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5816\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2407\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.9356\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.5784\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2560\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9338\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.5940\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2873\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9876\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7137\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.4136\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.1271\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8564\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5823\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3319\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0810\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8056\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5661\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.3408\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1071\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8487\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6125\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3863\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1765\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9480\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.7373\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5463\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3338\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1157\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9167\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7210\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5434\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3585\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1792\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9816\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8005\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6290\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4623\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2992\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1330\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9633\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8071\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6680\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5007\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3582\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2023\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0601\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9251\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7860\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6375\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5019\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.3706\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2423\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1230\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9882\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8669\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7509\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.6295\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5190\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3985\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2903\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.1786\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0712\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9653\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8605\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7587\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6589\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5581\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4624\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3705\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2755\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1856\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0931\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0050\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.9235\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8354\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7515\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6678\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5877\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5078\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4357\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3553\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2784\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2045\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1337\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0613\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:05,534] Trial 56 finished with value: 52.81048543606694 and parameters: {'lr': 0.00194612835157685, 'alpha': 0.03280636474326703, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.5355\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2679\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.7919\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.4116\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.9927\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.5828\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1784\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7700\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3899\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0046\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6104\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2492\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8723\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 20.4881\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 20.1243\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7824\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4680\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1124\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7834\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4338\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.0980\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7609\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4529\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1668\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8571\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5643\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.2803\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9983\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7322\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4783\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1817\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9294\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6959\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4465\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1799\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9351\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7025\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4781\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2375\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0159\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8100\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5855\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3595\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1493\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9420\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7520\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5593\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3653\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1650\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9667\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7850\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6108\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4383\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2575\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0761\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9118\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7595\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5822\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4262\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2602\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1126\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9662\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8163\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6532\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5091\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3677\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2312\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1017\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9526\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.8251\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6950\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5662\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4440\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3158\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1975\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0795\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9581\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8411\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7262\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6161\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5064\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3977\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2946\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1927\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.0892\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.9881\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8898\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7914\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6980\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6026\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5116\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4190\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3299\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2411\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1628\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0717\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9874\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9054\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.8275\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.7469\n",
      "4/4 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:07,270] Trial 57 finished with value: 55.33884713276276 and parameters: {'lr': 0.0017224473897670786, 'alpha': 0.035158247086843245, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.0702\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.7136\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 25.4195\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0374\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.6779\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.2724\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.8658\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4719\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1093\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7363\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3624\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 22.0171\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6582\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 21.2881\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9296\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.5998\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2978\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9511\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6474\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3291\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 18.9924\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6787\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3871\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.1155\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.8199\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5372\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.2664\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.9861\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7340\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4928\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.2019\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.9521\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7194\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.4789\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.2220\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9836\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7536\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5349\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3018\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0854\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8831\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6638\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.4358\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2277\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0239\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8321\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6393\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4513\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2454\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.0504\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8691\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6935\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5221\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3397\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.1561\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9876\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8339\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6554\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.4965\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3299\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1777\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0263\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.8734\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7130\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5656\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4203\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2782\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1438\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9945\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8620\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7298\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5944\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4690\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3347\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2135\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0872\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.9630\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8421\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7208\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6047\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4899\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3758\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2656\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1594\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0498\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9444\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8366\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7332\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6354\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5334\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4359\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3375\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2428\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1477\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0626\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9667\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8748\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7860\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7011\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6136\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:08,900] Trial 58 finished with value: 56.920772943434145 and parameters: {'lr': 0.001785481306795398, 'alpha': 0.03079649038272542, 'activation': 'sigmoid', 'n1': 320, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.5054\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.8108\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.3308\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.7305\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1206\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5899\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1644\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8073\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5496\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3704\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2707\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2460\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2891\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3975\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.5666\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7904\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0675\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3925\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.7634\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1766\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6296\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1186\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.6427\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1983\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7846\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3983\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.0381\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7021\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3886\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0971\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8247\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5700\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3319\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1112\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9056\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7131\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5330\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3663\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2111\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0662\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9306\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8034\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6859\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5770\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4733\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3770\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2887\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2057\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1285\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0551\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9885\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9268\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8670\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8101\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7577\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6676\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6284\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5873\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5526\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5196\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4905\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4600\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4346\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4029\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3936\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4110\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3906\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3578\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3266\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2958\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3127\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2678\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2328\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2158\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2070\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1902\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1792\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1698\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1601\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1522\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1436\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1353\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1238\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1316\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1179\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1279\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1178\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1146\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1082\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1074\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0999\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1006\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0918\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0960\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0822\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:10,469] Trial 59 finished with value: 62.95734778948861 and parameters: {'lr': 0.00578184151227972, 'alpha': 0.04098935941014275, 'activation': 'tanh', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6384\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5813\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3928\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2103\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0376\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8439\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6762\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4114\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2090\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0161\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8349\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6436\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4526\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2981\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1637\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0337\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8401\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6654\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4491\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3034\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1548\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0113\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8699\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7306\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6092\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4636\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3248\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1921\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0655\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9476\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8189\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6949\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5664\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4542\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3267\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.2057\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0972\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9980\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8627\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7509\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6402\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5318\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4235\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3171\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2120\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1128\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0105\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9084\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8103\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7080\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6079\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5156\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4181\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3296\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2407\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1439\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0694\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9659\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8676\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7796\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6956\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6162\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5298\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4490\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3619\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2798\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1982\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1172\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0427\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9631\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8867\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8088\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7346\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.6581\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5827\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5103\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4403\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3706\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3002\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2345\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1624\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0961\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.0267\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.9614\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8930\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8279\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7627\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6993\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6386\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5764\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5132\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4538\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3932\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3347\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2797\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2208\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1631\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1054\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0504\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.9975\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:12,140] Trial 60 finished with value: 56.696271028300565 and parameters: {'lr': 0.002461490694915656, 'alpha': 0.016151784191946968, 'activation': 'sigmoid', 'n1': 384, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2478\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0172\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.6292\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.2039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.7728\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.3084\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.8436\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3769\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9510\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5081\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 21.0783\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6730\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2592\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.8499\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4320\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0481\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6989\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3091\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9580\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6014\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2231\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.8920\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5531\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2490\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9205\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6053\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.3089\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0067\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7212\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4522\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.1495\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8841\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6490\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.3864\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1056\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8469\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5968\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.3651\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1179\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8887\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.6739\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.4503\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2182\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.0039\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.7934\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.5994\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.4027\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.2104\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9972\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8044\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6219\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4424\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2737\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0920\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9109\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7417\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5883\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4166\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2637\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1012\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9518\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8136\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6649\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5098\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3653\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2266\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0918\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9671\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8269\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6995\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5804\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4534\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3391\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2123\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9820\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8728\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7635\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6549\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5502\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4465\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3437\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2454\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1503\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0538\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9608\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8668\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7769\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6940\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6044\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5187\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4336\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3521\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2715\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1994\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1182\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0408\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9671\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8970\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8212\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:13,780] Trial 61 finished with value: 55.08044581208695 and parameters: {'lr': 0.001958106556908009, 'alpha': 0.034984303463819054, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.1616\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.8200\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 23.3166\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.5923\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9211\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2497\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6290\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9602\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3305\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.7055\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1374\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.5334\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9948\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4749\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0187\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.6430\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0196\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5227\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1054\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6449\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2282\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8081\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4130\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.0409\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6900\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3353\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9895\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.6440\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.3227\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0134\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7192\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4242\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1348\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8700\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5989\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3371\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0833\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8722\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6281\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3893\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1829\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9542\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7497\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5408\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.3532\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1742\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9881\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.8000\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6372\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4599\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3010\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1454\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.9931\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8493\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7130\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.5751\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4320\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3073\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1854\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0577\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9407\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8351\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7157\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6192\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5076\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4024\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3008\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2059\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1179\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0288\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9471\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8564\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7717\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6930\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6192\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5423\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4703\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4005\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3333\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2672\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2050\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1429\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0834\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0296\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9697\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9163\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8602\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8107\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7635\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7197\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6685\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6220\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5758\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5334\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5064\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4586\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4205\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3779\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3390\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3063\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:15,332] Trial 62 finished with value: 56.70197451274833 and parameters: {'lr': 0.0032422305194448643, 'alpha': 0.033385227441928095, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 35.5160\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 34.3798\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.6214\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.6235\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 31.7705\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.9054\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.0474\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.1749\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.3661\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5506\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.7811\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.0299\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2903\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.5957\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.8805\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1947\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.5677\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.3039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6944\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0781\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5192\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9696\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4595\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9319\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4112\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9346\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4585\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0081\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5727\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1206\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7054\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3259\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9270\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5151\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1325\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7661\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4188\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0672\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7358\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4311\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1060\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7900\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4932\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1997\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9326\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6632\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4134\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1290\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8790\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6411\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4108\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1858\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9562\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7343\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5226\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3316\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1192\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.9337\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7368\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5554\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3880\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2159\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0419\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8745\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7164\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5636\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4230\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2688\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1260\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9938\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.8572\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7343\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6011\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4822\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3608\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2470\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1350\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0261\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9217\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8167\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7158\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6204\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5284\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4354\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3468\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2549\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1717\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0973\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0157\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9349\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8583\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7845\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7133\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6468\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5783\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5118\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4479\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3937\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3272\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:17,022] Trial 63 finished with value: 54.66146450273181 and parameters: {'lr': 0.0020581756490388532, 'alpha': 0.048516082802718796, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 34.6021\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 34.1687\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.4120\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.6096\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 31.7844\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.9139\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.0611\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.2258\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.4434\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.6504\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.8943\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.1686\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 25.4433\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 24.7524\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.0413\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 23.3722\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7612\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 22.1110\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5098\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9059\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.3075\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7573\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2190\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7160\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1892\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.6712\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.1981\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7271\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2841\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.8458\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3960\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9847\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6097\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.2137\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7998\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4169\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0548\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.7119\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3567\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0249\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7224\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3986\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0784\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7808\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4864\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.2155\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9448\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6860\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4078\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1555\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9162\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6821\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4546\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2253\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0016\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7891\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5986\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3800\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1930\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9933\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8093\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6413\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4648\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2850\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1154\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9547\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7994\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6567\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.4985\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3526\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2182\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0788\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9538\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8164\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6947\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5714\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4541\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3396\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2275\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1181\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0113\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9062\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8084\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7137\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6171\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5262\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4321\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3456\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2682\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1824\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0999\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0209\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9448\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8710\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8013\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7304\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6607\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5940\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5358\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4681\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:18,657] Trial 64 finished with value: 54.59184485389007 and parameters: {'lr': 0.0020123123607267567, 'alpha': 0.048452573091974704, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5493\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5576\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.0548\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.3595\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.7560\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.1291\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4954\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.8784\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3208\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7350\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.1715\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.6448\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1106\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5858\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0550\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5618\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1229\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6370\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 17.1931\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.7342\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2791\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8568\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4476\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.0693\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6671\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2961\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9328\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5763\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2396\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9134\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5688\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2570\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9681\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6738\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3576\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0689\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7909\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5300\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.2573\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0032\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7707\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5217\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2678\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0362\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8104\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6043\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3949\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1938\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9723\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7673\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5779\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3963\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2203\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0371\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8551\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6880\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5372\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3651\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2149\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0558\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9112\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7734\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6345\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4828\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3489\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2181\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0930\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9783\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8463\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7303\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6224\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5061\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4050\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2906\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1928\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0914\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9918\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8953\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7996\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7092\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6211\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5331\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4517\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3739\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2924\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2148\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1377\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0622\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9961\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9228\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8548\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7856\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7216\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6570\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6046\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5380\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4768\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4195\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3676\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3096\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:20,374] Trial 65 finished with value: 54.29691622536134 and parameters: {'lr': 0.001974353041603855, 'alpha': 0.045875023609623755, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.6103\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.7891\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2425\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.5463\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.9425\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.3232\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7147\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0731\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4991\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9076\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.3549\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8116\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2689\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7630\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2523\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7569\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3161\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8142\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3748\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9231\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4516\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0392\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2672\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8680\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4797\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1282\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.7742\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.4415\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1264\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7837\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4790\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2093\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9169\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5941\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3072\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0337\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7713\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5052\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2577\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0347\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7950\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5468\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3234\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1009\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9034\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7005\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5082\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2907\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1002\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9200\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7445\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5756\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4010\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2297\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0681\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9251\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7592\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6166\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4649\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3267\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1989\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0673\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9294\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8004\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6783\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5602\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4533\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3308\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2192\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1177\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0109\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9167\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8098\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7172\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6224\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5330\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4447\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3590\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2761\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1933\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1123\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0370\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9642\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8903\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8210\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7476\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6808\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6218\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5558\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4919\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4306\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3711\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3136\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2613\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2053\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1505\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0992\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0543\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0004\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:22,067] Trial 66 finished with value: 54.65766232421647 and parameters: {'lr': 0.00214220020753589, 'alpha': 0.04442101481643664, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5023\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.9981\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.3848\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.7039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0389\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.3509\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6681\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.9667\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3211\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6706\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0593\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4583\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8630\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3119\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7624\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2142\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7322\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1760\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6914\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.1976\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7013\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2532\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8156\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4082\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9979\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5761\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1997\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8255\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.4710\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1248\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7704\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4484\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1480\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8343\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5018\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1997\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.9175\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6427\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3640\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1013\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8697\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6106\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3618\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1292\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8940\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6858\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4764\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2816\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0579\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8637\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6812\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4997\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3278\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1476\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9738\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8074\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6653\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4921\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3490\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1956\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0550\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9277\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7939\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6585\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5269\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4042\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2862\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1791\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0586\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9471\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8459\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7414\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6485\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5429\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4517\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3571\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2706\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1838\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1010\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0212\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9389\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8619\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7892\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7196\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6463\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5796\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5074\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4438\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3874\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3247\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2622\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2041\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1480\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0931\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0418\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9895\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9386\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8895\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8488\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7983\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:23,734] Trial 67 finished with value: 54.38580421337003 and parameters: {'lr': 0.0021726256722235855, 'alpha': 0.04672479114420974, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.3087\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.8229\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.2061\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5029\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.8105\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0884\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.3734\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6497\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.9900\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3084\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6713\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0465\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4307\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8535\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2676\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.7047\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2144\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6409\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1382\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6230\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.1007\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6329\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1822\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7630\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3300\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8970\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5017\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1079\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7377\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3847\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0078\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6742\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3759\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0563\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7115\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3952\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1006\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8232\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5324\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2617\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0251\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7621\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4987\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2582\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.0203\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8072\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5930\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3935\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1601\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9589\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7691\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5844\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.4074\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2236\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0440\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8751\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7283\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5527\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4057\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2479\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1055\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9748\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8379\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6971\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5648\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4400\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3200\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2119\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0863\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9745\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8722\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7642\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6710\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5628\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4705\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3745\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2855\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1978\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1128\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0307\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9483\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8690\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7955\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7249\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6516\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5840\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5116\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4472\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3911\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3269\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2647\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2047\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1480\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0933\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0424\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9891\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9368\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8877\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8468\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7942\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:25,411] Trial 68 finished with value: 53.91736794297466 and parameters: {'lr': 0.0021248397770244963, 'alpha': 0.048452239153924805, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9031\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8734\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0875\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6943\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3314\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0074\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7043\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4272\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1568\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8977\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6449\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4002\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1608\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9279\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7001\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.4772\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2592\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0459\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8370\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6325\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4323\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2365\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0446\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8568\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6729\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4929\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3166\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1440\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9751\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8096\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6477\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4891\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3338\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1816\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0327\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8869\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7442\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6044\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4676\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3336\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2024\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0739\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9481\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.8249\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7044\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5863\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4706\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3574\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2466\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1380\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0317\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9276\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8258\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7260\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6282\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5326\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4389\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3472\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2574\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1694\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0833\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9990\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9164\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8356\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7564\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6789\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6030\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5287\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4559\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3847\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3149\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2465\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1796\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1141\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0499\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9871\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9256\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8653\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8063\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7485\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6920\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6366\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5824\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5292\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4772\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4263\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3764\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3276\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2798\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2330\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1871\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1422\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0982\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0552\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0130\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9718\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9313\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8917\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8530\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8150\n",
      "4/4 [==============================] - 0s 666us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:27,057] Trial 69 finished with value: 57.01057855341436 and parameters: {'lr': 0.002957590254938874, 'alpha': 0.02509315814409954, 'activation': 'relu', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.3545\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7899\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7643\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7079\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6886\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6936\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7475\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8459\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9941\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1884\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4264\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7061\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0252\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3812\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7723\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1963\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6515\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1362\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6489\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1879\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7518\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3392\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9490\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5798\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2305\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9002\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5875\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2918\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0120\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7472\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4970\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2599\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0355\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8235\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6227\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4328\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2532\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0830\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9224\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7700\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6260\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4898\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3608\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2387\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1234\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0140\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9108\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8133\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7207\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6331\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5502\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4717\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3975\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3272\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2608\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1982\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1385\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0822\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0289\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9785\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9309\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8855\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8428\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8022\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7640\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7276\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6933\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6609\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6301\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6015\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5739\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5474\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5228\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4991\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4769\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4558\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4170\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3992\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3823\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3663\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3512\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3371\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3230\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3103\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2978\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2755\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2552\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2281\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2200\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2126\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1985\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1920\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1859\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1802\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:28,835] Trial 70 finished with value: 54.224988136544084 and parameters: {'lr': 0.0041223405551542875, 'alpha': 0.046427939714433056, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0043\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4276\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.1737\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9376\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7125\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5382\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4376\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3893\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4064\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4842\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6185\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8052\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0412\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3239\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6498\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0162\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4209\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8616\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3359\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8417\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3775\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9408\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5307\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1449\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7823\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4416\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1212\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8201\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5370\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2709\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0209\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7857\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5646\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3568\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1614\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9779\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8052\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6429\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4906\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3470\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2122\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0855\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9663\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8542\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7491\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6499\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5569\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4697\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3875\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3101\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2374\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1689\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1046\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0441\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9872\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9341\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8837\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8365\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7919\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7501\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7109\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6737\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6390\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6061\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5755\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5464\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5192\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4937\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4696\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4475\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4260\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4058\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3869\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3686\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3520\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3360\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3212\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2938\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2696\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2587\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2487\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2384\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2293\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2203\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2122\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2047\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1906\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1838\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1776\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1716\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1660\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1611\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1562\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1514\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1470\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1429\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1394\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:30,657] Trial 71 finished with value: 54.6606564701801 and parameters: {'lr': 0.004286202090680954, 'alpha': 0.04966097050391106, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2335\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8185\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8566\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9104\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9524\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0168\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.1403\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3042\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5138\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7733\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0739\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4131\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7896\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2005\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6443\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1187\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6222\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1531\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7100\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2911\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8955\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5216\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1682\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8343\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5187\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2205\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9387\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6724\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4207\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1829\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9582\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7456\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5447\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3550\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1756\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0061\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8459\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6944\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5515\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4160\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2882\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1674\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0531\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9451\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8432\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7466\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6555\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5697\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4882\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4112\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3384\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2696\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2046\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1431\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0850\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0304\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9783\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9293\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8390\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7977\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7583\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7213\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6861\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6531\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6217\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5920\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5642\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5377\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5131\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4893\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4456\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4252\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4063\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3882\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3713\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3550\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3398\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3254\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3118\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2991\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2752\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2643\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2537\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2440\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2350\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2263\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2178\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1881\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1820\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1759\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1701\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1646\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1595\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1549\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:32,452] Trial 72 finished with value: 54.31076159649843 and parameters: {'lr': 0.00463546788420104, 'alpha': 0.042097378084847925, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3571\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3923\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7418\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1521\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6424\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1813\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7388\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3208\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9304\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5679\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2221\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8977\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.5911\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2996\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0245\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7639\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5175\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2835\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0621\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8523\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6536\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4653\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2868\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1177\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9573\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8055\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6615\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5251\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3957\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2732\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1570\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0468\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9424\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8435\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7497\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6609\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5766\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4967\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4212\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3493\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2813\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2168\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1557\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0977\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0429\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9907\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9415\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8948\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8509\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8085\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7693\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7308\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6953\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6613\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6295\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5991\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5706\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5427\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5165\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4923\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4687\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4465\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4056\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3869\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3688\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3520\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3357\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3209\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3061\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2927\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2668\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2553\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2443\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2336\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2236\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2138\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2050\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1809\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1734\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1666\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1598\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1536\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1491\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1429\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1384\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1327\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1231\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1183\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1142\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1100\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1065\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1030\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0998\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0975\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0959\n",
      "4/4 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:34,296] Trial 73 finished with value: 54.453783915730945 and parameters: {'lr': 0.008804173964550322, 'alpha': 0.0210942773834046, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1602\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3501\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8385\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0344\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5121\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0055\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5523\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1098\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7050\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3242\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.9643\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6289\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3124\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0145\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7338\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4690\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2197\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9840\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7619\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5526\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3552\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1691\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9928\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8268\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6701\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5225\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3845\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2517\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1285\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0106\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9021\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7957\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6980\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6043\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5163\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4337\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3553\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2820\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2129\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1474\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0856\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0278\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9717\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9192\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8703\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8234\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7795\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7386\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6999\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6626\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6286\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5951\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5642\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5351\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5077\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4820\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4586\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4345\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3925\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3730\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3538\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3367\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3197\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3055\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2911\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2634\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2588\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2465\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2241\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2130\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2013\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1897\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1839\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1715\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1557\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1479\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1421\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1252\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1204\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1160\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1119\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1076\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1036\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0997\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0962\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0929\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0900\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0869\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0793\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0849\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:36,065] Trial 74 finished with value: 54.531885326614606 and parameters: {'lr': 0.009520095859857844, 'alpha': 0.021031807479581142, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3046\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9278\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1760\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5194\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8814\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3370\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8032\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2895\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8090\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3519\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9165\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5046\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1112\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7373\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3808\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0412\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7177\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1150\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8345\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5672\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3122\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0692\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8374\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6163\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4056\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2045\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0129\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8300\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6556\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4894\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3307\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1793\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0351\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8973\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7661\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6408\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5214\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4076\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2988\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1952\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0964\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0021\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9121\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8264\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7445\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6665\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5923\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5214\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4536\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3891\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3274\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2688\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1594\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1085\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0599\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0135\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9693\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9271\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8485\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8120\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7770\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7438\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7120\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6816\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6529\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6255\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5993\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5740\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5502\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5274\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5053\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4847\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4648\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4458\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4277\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4104\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3940\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3783\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3635\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3493\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3355\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3224\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3100\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2982\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2763\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2659\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2559\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2466\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2375\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2289\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2209\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2055\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1984\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1853\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:37,882] Trial 75 finished with value: 53.330981826575204 and parameters: {'lr': 0.005745559099222646, 'alpha': 0.028691482524501436, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0167\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7525\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0323\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4488\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7890\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1962\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6028\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0486\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5240\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0268\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5543\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1043\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6763\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2695\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8819\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5130\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1616\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8268\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5080\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2042\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9147\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6391\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3764\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1261\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8877\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6605\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4440\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2378\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0412\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8540\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6755\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5054\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3433\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1889\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0417\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9016\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7679\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6405\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5194\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4036\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2934\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1884\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0883\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9929\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9021\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8154\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7330\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6546\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5797\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5082\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4403\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3753\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3135\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2546\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1986\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1453\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0943\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0457\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9994\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9554\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8732\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8351\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7987\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7641\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7310\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6995\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6696\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6412\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6141\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5880\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5632\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5397\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5168\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4956\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4555\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4368\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4190\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4021\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3860\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3708\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3563\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3421\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3287\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3159\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3040\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2925\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2816\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2710\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2608\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2512\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2419\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2332\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2251\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2171\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2094\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1954\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:39,708] Trial 76 finished with value: 54.142874385042184 and parameters: {'lr': 0.00542159070491758, 'alpha': 0.030944388344594388, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7769\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5807\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8940\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2812\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6773\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0996\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5574\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0287\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5273\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0544\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6076\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1826\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7799\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3974\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0344\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6891\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3617\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0500\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7539\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4729\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2054\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9519\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7100\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4802\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2619\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0546\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8573\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6699\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4918\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3224\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1615\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0083\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8627\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7244\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5929\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4679\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3489\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2359\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1287\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0264\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9292\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8370\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7492\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6657\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5865\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5109\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4393\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3713\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3067\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2449\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1865\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1306\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0776\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0273\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9795\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9342\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8909\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8106\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7735\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7382\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7044\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6726\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6421\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6133\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5857\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5597\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5351\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5117\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4893\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4676\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4476\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4288\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4095\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3929\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3766\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3600\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3449\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3305\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3037\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2912\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2685\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2578\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2477\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2382\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2291\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2205\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2120\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2038\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1891\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1823\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1760\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1697\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1581\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1528\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1479\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:41,473] Trial 77 finished with value: 54.22571804367231 and parameters: {'lr': 0.006210474656590668, 'alpha': 0.028307470595575146, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1699\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7354\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8764\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4395\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4069\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4765\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5810\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7839\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0600\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4057\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8138\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2756\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7905\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3496\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9503\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5883\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2600\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9622\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6926\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4478\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2264\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0250\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8422\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6767\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5264\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3905\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2698\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1556\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0579\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9625\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8875\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8038\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7382\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6728\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6152\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5642\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5176\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4759\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4406\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4072\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3768\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3542\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3271\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3266\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3006\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2457\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2316\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2136\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1950\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1848\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1710\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1607\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1500\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1413\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1326\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1253\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1174\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1111\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1061\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0961\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0925\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0890\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0783\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0765\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0790\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0979\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0915\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0805\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0788\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0669\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0605\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0582\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0552\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0548\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0525\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0495\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0557\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0495\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0540\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:43,311] Trial 78 finished with value: 56.19758879906386 and parameters: {'lr': 0.011394619525542356, 'alpha': 0.02876680619016224, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5619\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1673\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0264\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9782\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9261\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9291\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9906\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1082\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2878\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5235\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8132\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1507\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5332\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9585\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4233\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9247\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4600\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0269\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6231\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2469\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8964\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5694\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2648\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9808\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7160\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4693\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2392\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0249\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8251\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6389\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4653\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3033\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1523\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0117\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8806\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7584\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6445\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5381\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4396\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3469\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2608\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1806\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1058\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0358\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9708\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9099\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8535\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8011\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7524\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7060\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6637\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6232\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5860\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5513\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5190\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4890\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4606\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4343\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4096\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3868\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3655\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3452\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3268\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3093\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2932\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2507\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2272\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2163\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2065\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1973\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1877\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1801\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1725\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1650\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1580\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1515\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1454\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1398\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1347\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1254\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1209\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1170\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1136\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1101\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1070\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1039\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1003\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0976\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0950\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0924\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0861\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0844\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0829\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0813\n",
      "4/4 [==============================] - 0s 864us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:45,139] Trial 79 finished with value: 54.92387933984133 and parameters: {'lr': 0.006219573309194602, 'alpha': 0.03869730855519753, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5796\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6544\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2432\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0026\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7814\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5707\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3843\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1970\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0254\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8595\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6986\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5422\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3903\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2422\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0976\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9566\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8190\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6846\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5535\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4254\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3003\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1781\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0589\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9424\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8286\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7176\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6090\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5031\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3995\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2985\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1998\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1034\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0092\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9172\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8273\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7396\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6539\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5702\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4884\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4085\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3305\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2542\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1798\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1070\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0360\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9666\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8988\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8327\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7680\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7048\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6431\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5828\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5239\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4664\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4102\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3554\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3017\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2493\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1982\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1482\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0994\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0516\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0051\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9595\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9151\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8716\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8292\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7878\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7473\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7078\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6692\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6314\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5945\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5584\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5233\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4889\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4553\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4225\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3904\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3591\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3286\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2987\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2696\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2410\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2132\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1859\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1594\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1335\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1082\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0834\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0591\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0355\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0123\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9898\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9677\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9252\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9046\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8845\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8650\n",
      "4/4 [==============================] - 0s 873us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:46,953] Trial 80 finished with value: 55.47997905097739 and parameters: {'lr': 0.004761660891407249, 'alpha': 0.017383691919961128, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4726\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1791\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6582\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2170\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7532\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3150\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9053\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5091\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1267\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7606\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4082\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0673\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7379\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4202\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1130\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8161\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5289\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2513\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9828\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7232\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4722\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2295\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9948\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7678\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5483\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3360\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1307\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9321\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7401\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5543\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3748\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2010\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0329\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8704\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7131\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5610\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4139\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2716\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1340\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0008\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8720\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7474\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6269\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5102\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3975\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2884\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1829\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0809\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9822\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8867\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7942\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7049\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6184\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5348\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4539\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3757\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2268\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1559\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0875\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0212\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9570\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8951\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8350\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7770\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7209\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6666\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6141\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5633\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5143\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4668\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4206\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3762\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3331\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2914\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2511\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2122\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1745\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1380\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1028\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0686\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0356\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0039\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9728\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9430\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9140\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8861\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8591\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8330\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8076\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7830\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7593\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7363\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7141\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6927\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6720\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6518\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6136\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5955\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:48,734] Trial 81 finished with value: 55.27014748184249 and parameters: {'lr': 0.003966510983459755, 'alpha': 0.029436816394541963, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0846\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4511\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4634\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5710\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6677\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8086\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9886\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2101\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4768\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7873\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1367\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5225\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9428\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3959\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8794\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3919\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9314\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4966\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0861\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6983\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3322\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9861\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6595\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3509\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0593\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7839\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5236\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2779\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0457\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8264\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6193\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4235\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2384\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0638\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8987\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7428\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5955\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4562\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3250\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2006\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0832\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9724\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8676\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7685\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6751\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5867\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5033\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4247\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3504\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2798\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2134\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1504\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0910\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0349\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9820\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9321\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8847\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8400\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7977\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7578\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7201\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6843\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6507\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6187\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5888\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5602\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5333\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5080\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4842\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4617\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4400\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4197\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4007\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3820\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3651\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3488\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3334\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3186\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3049\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2919\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2680\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2466\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2366\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2272\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2185\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2103\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2025\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1876\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1808\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1743\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1683\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1627\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1573\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1520\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1472\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1427\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1386\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:50,522] Trial 82 finished with value: 54.747110517986215 and parameters: {'lr': 0.005044296075894868, 'alpha': 0.03898893704105874, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1712\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1082\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.4294\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.8799\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3212\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7576\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2468\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7421\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2772\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8353\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4160\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0178\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6383\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2779\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9349\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6084\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2976\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0013\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7195\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4511\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1955\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9518\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7199\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4988\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2883\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0878\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8968\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7149\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5416\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3765\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2193\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0694\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9266\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7907\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6611\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5378\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4201\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3081\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2016\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0998\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0029\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9107\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8228\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7390\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6592\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5831\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5108\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4420\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3765\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3137\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2542\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1972\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1430\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0915\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0424\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9957\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9511\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9086\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8680\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8295\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7929\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7577\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7245\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6926\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6624\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6335\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6060\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5799\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5552\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5314\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5086\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4873\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4468\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4105\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3933\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3770\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3616\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3468\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3328\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3195\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2947\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2830\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2719\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2615\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2421\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2240\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2158\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2078\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2002\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1797\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1736\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1677\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1621\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:52,644] Trial 83 finished with value: 54.60401935582229 and parameters: {'lr': 0.006680939529286577, 'alpha': 0.025221417860610478, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2609\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9057\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6846\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5373\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4546\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4352\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5014\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6267\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.8254\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.0821\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3972\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7652\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1815\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6420\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1440\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6839\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2589\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8658\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5027\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1671\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8570\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5704\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3053\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0603\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8338\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6249\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4321\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2528\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0881\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9352\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7950\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6636\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5434\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4316\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3287\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2337\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1457\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0643\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9897\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9199\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8557\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7963\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7415\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6905\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6438\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5601\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5233\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4900\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4572\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4294\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4004\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3757\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3523\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3312\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3115\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2935\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2757\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2594\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2317\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2189\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2074\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1964\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1866\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1771\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1685\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1603\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1535\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1462\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1403\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1341\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1230\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1183\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1139\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1098\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1056\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1023\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0988\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0957\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0934\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0816\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0804\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0792\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0735\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0692\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0684\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0674\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0672\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "4/4 [==============================] - 0s 880us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:54,447] Trial 84 finished with value: 55.2301306889337 and parameters: {'lr': 0.007559863856886031, 'alpha': 0.035507594224455964, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.1100\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1282\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9910\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5752\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4630\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6171\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0027\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5823\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3675\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3295\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4319\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6669\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0115\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4496\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9694\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5566\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2040\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9016\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6435\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4219\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2336\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0700\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9296\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8102\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7074\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6206\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5467\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4799\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4301\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3792\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3486\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3031\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2762\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2487\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2239\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2043\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1880\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1727\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1646\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1545\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1412\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1347\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1250\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1228\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1173\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1091\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1098\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1159\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1102\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1043\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1030\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1029\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0896\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0867\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0843\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0810\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0778\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0814\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0814\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0762\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0767\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0760\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0874\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0870\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0971\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1064\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0853\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0758\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0745\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0772\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0722\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0704\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0749\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0787\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0839\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0849\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1027\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0900\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0831\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0969\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0823\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:56,307] Trial 85 finished with value: 54.38135509720895 and parameters: {'lr': 0.011372490571262574, 'alpha': 0.043753669347685945, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3589\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0197\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6719\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0422\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6142\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3706\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2413\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2324\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3587\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5845\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9082\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3142\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7937\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3381\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9447\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6032\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3103\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0204\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7861\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5805\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3984\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2483\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1024\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8574\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7596\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6055\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5384\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4819\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4316\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3872\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3475\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3132\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2835\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2172\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2091\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2003\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1912\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1772\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1918\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1687\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1528\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1397\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1463\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1509\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1276\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1186\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1130\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1029\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0979\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0884\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0799\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0772\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0745\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0737\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0726\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0699\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0687\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0717\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0786\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0762\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0748\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0651\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0631\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0617\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0589\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0592\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0586\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0593\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0712\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0704\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0811\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0744\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0681\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0692\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "4/4 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:58,113] Trial 86 finished with value: 55.949863005042836 and parameters: {'lr': 0.013245679779290231, 'alpha': 0.032390335022136216, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5125\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4318\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3427\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2672\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4022\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7736\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3242\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0855\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0264\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1226\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3576\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7072\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1564\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6891\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2947\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9671\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6818\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4363\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2311\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0589\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9188\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7897\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6806\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5941\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5149\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4484\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3465\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3091\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2763\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2506\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2287\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2051\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1889\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1734\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1640\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1635\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1512\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1648\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1896\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1761\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1670\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1491\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1304\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1216\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1078\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1128\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1242\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1140\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1057\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0964\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0892\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0844\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0861\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0941\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0869\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0844\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0860\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0908\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0771\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0850\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0799\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0831\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0753\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0733\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0669\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0665\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0736\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0683\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1117\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1214\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1252\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1069\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1125\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1125\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1083\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0958\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0869\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0824\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0761\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0697\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0820\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0758\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:59,979] Trial 87 finished with value: 57.13412939449313 and parameters: {'lr': 0.013753092965148251, 'alpha': 0.038327108731713286, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5395\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3995\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7529\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2619\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7653\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2932\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8385\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4261\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0254\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6424\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2763\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9265\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5900\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2672\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9569\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6584\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3714\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0953\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8297\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5741\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3283\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0918\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8643\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6454\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4346\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2320\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0369\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8493\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6686\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4949\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3277\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1667\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0118\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8628\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7193\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5813\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4485\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.3206\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1977\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0792\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9653\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8557\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7502\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6486\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5509\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4568\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3663\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2794\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1956\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1149\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0372\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9625\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8907\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8215\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7549\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6909\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6292\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5699\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5128\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4579\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4050\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3540\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3051\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2579\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2126\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1689\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1269\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0865\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0476\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0104\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9395\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9062\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8739\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8430\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8132\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7846\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7304\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7049\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6803\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6567\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6341\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6120\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5909\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5705\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5511\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5324\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5143\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4968\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4799\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4638\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4481\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4331\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4188\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4049\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3915\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3786\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3663\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3545\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:01,777] Trial 88 finished with value: 54.13674064855176 and parameters: {'lr': 0.005266479996662898, 'alpha': 0.02548226942571884, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1876\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3958\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1493\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0015\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8501\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7229\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6050\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4999\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3984\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3023\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2086\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1187\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0304\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9447\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8610\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7794\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6998\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6216\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5453\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4707\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3977\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3264\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2563\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1879\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1209\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0556\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9914\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9286\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8672\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8071\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7483\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6907\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6344\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5793\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5253\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4725\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4208\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3701\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3206\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2721\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2247\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1782\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1328\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0447\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0020\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9602\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9195\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8795\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8403\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8020\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7644\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7278\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6918\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6566\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6222\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5885\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5555\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5232\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4916\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4606\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4303\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4007\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3716\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3432\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3154\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2881\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2615\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2354\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2099\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1849\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1604\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1365\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1130\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0901\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0676\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0456\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0241\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0030\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9824\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9622\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9424\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9232\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9042\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8856\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8674\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8323\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8153\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7987\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7823\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7664\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7507\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7354\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7205\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7058\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6914\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6774\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6637\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6503\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:03,621] Trial 89 finished with value: 51.87719012805435 and parameters: {'lr': 0.005659908689217048, 'alpha': 0.013367428810420565, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0343\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0685\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7975\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5824\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4653\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3267\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2184\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1173\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0260\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9389\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8531\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7715\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6921\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6150\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5390\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4649\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3920\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3205\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2503\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1814\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1137\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0470\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9816\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9172\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8540\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7917\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7305\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6703\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6111\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5529\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4956\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4393\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3838\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3293\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2757\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2230\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1711\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1201\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0699\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0205\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9719\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9241\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8771\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8309\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7854\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7406\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6966\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6534\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6108\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5688\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5276\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4870\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4472\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4079\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3693\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3313\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2940\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2572\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1855\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1505\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1161\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0822\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0489\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0161\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9839\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9521\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9209\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8902\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8601\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8304\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8011\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7724\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7441\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7163\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6889\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6620\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6354\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6094\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5838\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5585\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5337\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5093\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4853\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4617\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4384\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4156\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3931\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3710\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3492\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3278\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3067\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2860\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2656\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2455\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2258\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2064\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1873\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1685\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1500\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:05,502] Trial 90 finished with value: 58.129531107344214 and parameters: {'lr': 0.003931747065517547, 'alpha': 0.014788267825545398, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6282\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7252\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3552\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1177\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8124\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5910\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3921\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1991\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0099\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8331\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6654\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5047\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3497\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1995\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0537\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9123\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7751\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6417\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5123\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3865\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2643\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1456\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9181\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8091\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7033\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6004\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5005\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4033\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3089\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2172\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1280\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0413\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9571\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8752\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7956\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7182\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6431\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5701\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4990\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4300\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3629\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2977\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2343\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1727\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1128\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0546\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9981\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9432\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8897\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8378\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7873\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7382\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6905\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6442\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5992\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5554\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5129\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4715\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4313\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3923\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3542\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3174\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2814\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2466\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1798\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1478\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1167\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0865\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0571\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0285\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0008\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9737\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9475\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9220\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8972\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8731\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8270\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8049\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7834\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7626\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7422\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7225\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7032\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6846\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6666\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6490\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6318\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6152\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5990\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5832\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5679\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5531\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5387\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5246\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5110\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4977\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4849\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:07,384] Trial 91 finished with value: 56.448921305401946 and parameters: {'lr': 0.005212677116400229, 'alpha': 0.019241661342297642, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6721\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1908\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4788\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8803\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2981\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7365\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1883\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6943\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2248\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7745\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3465\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9400\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5508\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1794\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8246\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4854\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1613\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8513\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5549\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2716\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0007\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7416\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4939\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2569\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0303\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8137\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6064\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4083\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2186\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0374\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8641\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6982\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5395\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3879\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2427\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1040\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9713\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8442\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7230\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6067\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4957\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3895\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2878\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1906\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0977\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0087\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9237\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8426\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7648\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6903\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6192\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5511\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4860\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4237\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3642\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3074\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2529\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2008\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1509\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1033\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0578\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0141\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9725\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9325\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8944\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8578\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8230\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7897\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7578\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7274\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6981\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6701\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6434\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6176\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5933\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5698\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5473\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5258\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5053\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4669\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4491\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4320\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4154\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3996\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3845\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3702\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3565\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3434\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3307\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3185\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2957\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2851\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2751\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2654\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2560\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2471\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2386\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2306\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:09,177] Trial 92 finished with value: 53.66051793603558 and parameters: {'lr': 0.005706785231232192, 'alpha': 0.02717730570168838, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4230\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2813\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6719\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1149\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5863\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0802\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5963\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1262\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6824\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2603\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8572\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4732\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1066\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7566\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4221\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1021\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7961\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5035\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2236\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9560\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7002\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4552\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2211\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9970\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7827\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5778\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3817\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1942\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0147\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8431\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6790\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5218\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3715\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2278\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0903\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9587\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8328\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7123\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5973\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4869\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3815\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2807\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1842\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0918\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0035\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9189\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8381\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7610\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6871\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6162\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5486\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4836\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4217\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3624\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3058\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2516\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1996\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1500\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1024\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0570\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0136\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9718\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9321\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8940\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8576\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8227\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7893\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7575\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7272\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6980\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6699\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6433\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6177\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5930\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5697\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5472\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5257\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5051\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4854\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4666\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4486\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4315\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4151\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3993\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3841\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3695\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3559\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3427\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3179\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3061\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2950\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2843\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2741\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2645\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2551\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2461\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2376\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2294\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2217\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:11,006] Trial 93 finished with value: 55.13825186992917 and parameters: {'lr': 0.006023648939669022, 'alpha': 0.025608930381952826, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2661\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4897\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1263\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9051\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7195\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5040\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3225\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1144\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9333\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7622\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5967\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4283\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2716\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1175\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9713\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8287\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6909\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5566\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4268\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3011\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1788\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0608\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9451\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8328\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7239\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6183\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5160\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4164\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3197\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2257\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1345\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0459\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9598\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8761\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7949\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7160\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6393\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5649\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4926\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4223\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3540\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2878\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2233\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1607\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0999\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0408\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9834\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9277\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8736\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8209\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7699\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7202\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6720\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6251\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5796\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5354\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4925\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4507\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4102\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3708\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3326\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2954\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2593\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2242\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1901\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1570\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1249\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0634\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0339\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0052\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9774\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9504\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9240\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8986\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8738\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8262\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8035\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7814\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7600\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7392\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7190\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6801\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6436\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6261\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6091\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5926\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5765\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5609\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5457\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5310\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5167\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5028\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4892\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4761\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4634\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4511\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:12,831] Trial 94 finished with value: 55.18334923023347 and parameters: {'lr': 0.007249996136264344, 'alpha': 0.014062824067704701, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0250\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3852\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9268\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5371\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2529\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9803\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7584\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5522\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3441\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1443\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9548\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7715\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5909\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4159\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2455\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0787\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9156\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7560\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5998\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4470\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2973\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1506\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0071\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8665\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7288\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5939\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4618\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3323\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2055\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0813\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9597\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8404\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7236\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6092\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4971\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3873\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2797\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1742\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0710\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9697\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8705\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7734\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6782\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5849\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4936\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4041\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3163\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2305\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1462\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0637\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9829\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9036\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8260\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7500\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6755\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6025\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5310\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4609\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3922\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3249\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2590\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1944\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1311\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0690\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0083\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9488\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8904\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8333\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7772\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7224\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6687\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6159\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5643\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5137\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4641\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4156\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3680\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3213\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2757\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2309\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1871\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1441\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1020\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0607\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0203\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9806\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9418\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9038\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8301\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7943\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7592\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7249\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6912\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6582\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6259\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5943\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5632\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5328\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5031\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:14,712] Trial 95 finished with value: 54.400481701617174 and parameters: {'lr': 0.0025573425263952228, 'alpha': 0.028210335093461072, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7481\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6631\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.2909\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.9439\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6741\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3850\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1206\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8751\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6384\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4115\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1906\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9758\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7659\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5610\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3607\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1650\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9736\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7862\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6029\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4235\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2480\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0761\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9079\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7432\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5821\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4244\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2699\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1188\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9707\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8259\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6841\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5453\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4093\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2762\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1459\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0184\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8935\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7712\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6516\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5344\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4197\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3073\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1974\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0897\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9843\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8811\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7801\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6812\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5843\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4895\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3967\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3057\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2168\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1296\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0443\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9608\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8790\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7990\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7206\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6438\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5687\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4951\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4231\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3525\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2835\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2159\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1497\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0849\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0214\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9594\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8986\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8389\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7806\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7235\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6676\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6128\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5592\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5067\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4554\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4051\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3558\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3076\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2605\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2142\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1689\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1246\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0812\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0388\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9972\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9565\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9166\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8775\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8393\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8018\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7652\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7294\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6942\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6598\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6261\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5932\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:16,571] Trial 96 finished with value: 55.179252811348114 and parameters: {'lr': 0.003132280531967108, 'alpha': 0.023861343794290158, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9706\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1561\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9325\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7667\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6790\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5910\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5139\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4429\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.3787\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3190\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2604\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2037\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1484\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0944\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0413\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9889\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9375\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8869\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8370\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7879\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7394\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6917\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6445\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5978\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5519\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5065\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4618\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4176\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3740\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3310\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2886\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2467\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2053\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1644\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1242\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0844\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0451\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0064\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9681\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9303\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8931\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8563\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8200\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7841\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7487\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7138\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6793\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6453\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6117\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5785\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5457\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5134\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4815\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4500\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4189\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3883\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3580\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3281\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2985\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2694\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2406\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2122\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1842\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1565\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1292\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1023\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0756\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0494\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0234\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9978\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9725\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9476\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9229\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8986\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8746\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8509\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8275\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8044\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7816\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7591\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7369\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7149\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6933\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6719\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6508\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6300\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6094\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5891\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5691\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5493\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5298\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5105\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4915\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4727\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4541\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4358\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4177\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3999\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3823\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3649\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:18,389] Trial 97 finished with value: 67.3344204733916 and parameters: {'lr': 0.003667060694435729, 'alpha': 0.01251252893772502, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3530\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0170\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2973\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6584\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9925\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3343\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7154\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1308\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5841\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.0634\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.5696\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1012\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6568\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2342\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8328\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4514\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0889\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7441\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4165\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1051\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8090\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5274\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2597\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0052\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7630\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5329\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3140\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1059\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9080\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7198\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5408\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3705\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2086\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0547\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9082\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7690\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6365\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5105\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3909\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2768\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1685\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0655\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9675\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8741\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7855\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7011\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6210\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5450\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4726\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4034\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3380\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2754\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2161\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1597\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1060\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0552\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0065\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9603\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9164\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8746\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8350\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7971\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7612\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7269\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6945\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6635\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6341\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6062\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5798\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5545\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5303\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5075\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4646\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4450\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4262\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4082\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3910\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3748\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3594\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3447\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3309\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3178\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3050\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2928\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2705\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2603\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2504\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2318\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2233\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2150\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2072\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1930\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1861\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1798\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1738\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1682\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:20,253] Trial 98 finished with value: 55.53417099862192 and parameters: {'lr': 0.005553259285402389, 'alpha': 0.031422762431068584, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7737\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7919\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3475\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8931\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4857\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1215\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7553\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4123\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0940\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7823\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4852\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2009\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9271\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6646\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.4121\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.1692\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9357\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.7114\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4954\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2877\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0879\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8956\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7108\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5328\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3617\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1971\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0386\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8863\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7397\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5988\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4631\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3326\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2069\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0863\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9700\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8582\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7505\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6473\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5480\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4520\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3601\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2711\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1858\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1037\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0246\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9486\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8757\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8057\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7385\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6733\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6107\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5509\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4931\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4370\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3829\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3320\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2823\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2343\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1877\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1439\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1013\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0606\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0212\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9842\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9473\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9130\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8818\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8492\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8184\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7879\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7601\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7354\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7055\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6826\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6594\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6333\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6129\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5919\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5715\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5550\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5426\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5352\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5103\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4902\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4728\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4642\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4858\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4497\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4199\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3984\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3802\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3645\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3506\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3333\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3223\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3097\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2980\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2772\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2670\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:21,794] Trial 99 finished with value: 62.044510384425536 and parameters: {'lr': 0.006585817412694317, 'alpha': 0.020427505645992144, 'activation': 'tanh', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    }
   ],
   "source": [
    "def objective_mlp_fp(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-4, 2e-2, log=True)\n",
    "    alpha = trial.suggest_float('alpha', 1e-4, 5e-2, log=True)\n",
    "    act = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid', 'gelu'])\n",
    "    n1 = trial.suggest_int('n1', 128, 384, step=64)\n",
    "    n2 = trial.suggest_int('n2', 128, 384, step=64)\n",
    "\n",
    "    model = MLP(engine='tensorflow', nfeatures=X_train_fp_scaled.shape[1], nneurons=[n1, n2],\n",
    "                activations=[act, act], learning_rate=lr, alpha=alpha,\n",
    "                nepochs=100, batch_size=64, loss='mean_squared_error', is_regression=True)\n",
    "    \n",
    "    model.fit(X_train_fp_scaled, y_train_scaled)\n",
    "    preds_scaled = model.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "    preds = yscaler.inverse_transform(preds_scaled)\n",
    "    y_test_inv = yscaler.inverse_transform(y_test_scaled)\n",
    "    metrics = regression_metrics(y_test_inv, preds)\n",
    "    return metrics['MAE'][0]\n",
    "\n",
    "study_mlp_fp = optuna.create_study(direction='minimize')\n",
    "study_mlp_fp.optimize(objective_mlp_fp, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cac4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_mlp_cm(trial):\n",
    "#     lr = trial.suggest_float('lr', 1e-6, 1e-2, log=True)\n",
    "#     alpha = trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "#     act = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid', 'gelu'])\n",
    "#     n1 = trial.suggest_int('n1', 64, 256, step=64)\n",
    "#     n2 = trial.suggest_int('n2', 64, 256, step=64)\n",
    "\n",
    "#     model = MLP(engine='tensorflow', nfeatures=X_train_cm_scaled.shape[1], nneurons=[n1, n2],\n",
    "#                 activations=[act, act], learning_rate=lr, alpha=alpha,\n",
    "#                 nepochs=100, batch_size=64, loss='mean_squared_error', is_regression=True)\n",
    "\n",
    "#     model.fit(X_train_cm_scaled, y_train_scaled)\n",
    "#     preds_scaled = model.predict(X_test_cm_scaled).reshape(-1, 1)\n",
    "#     preds = yscaler.inverse_transform(preds_scaled)\n",
    "#     y_test_inv = yscaler.inverse_transform(y_test_scaled)\n",
    "#     metrics = regression_metrics(y_test_inv, preds)\n",
    "#     return metrics['MAE'][0]\n",
    "\n",
    "# study_mlp_cm = optuna.create_study(direction='minimize')\n",
    "# study_mlp_cm.optimize(objective_mlp_cm, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47ff58",
   "metadata": {},
   "source": [
    "## Retrain Models with Best Parameters Found in Respective Optuna Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2132a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned Kernel Ridge (RDKit FP):\n",
      "         MAE       RMSE  r_squared\n",
      "0  51.961371  69.519814   0.611854\n"
     ]
    }
   ],
   "source": [
    "best_krr = study_krr.best_params\n",
    "\n",
    "# build final model using best params\n",
    "if best_krr['kernel'] == 'rbf':\n",
    "    final_krr = KernelRidge(alpha=best_krr['alpha'], kernel='rbf', gamma=best_krr['gamma'])\n",
    "else:\n",
    "    final_krr = KernelRidge(alpha=best_krr['alpha'], kernel=best_krr['kernel'])\n",
    "\n",
    "# train on scaled data\n",
    "final_krr.fit(X_train_fp_scaled, y_train_scaled)\n",
    "# predict on test set (scaled)\n",
    "final_preds_krr_scaled = final_krr.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "# inverse transform both predictions and gt\n",
    "final_preds_krr = yscaler.inverse_transform(final_preds_krr_scaled)\n",
    "y_test_krr = yscaler.inverse_transform(y_test_scaled)\n",
    "# eval\n",
    "final_metrics_krr = regression_metrics(y_test_krr, final_preds_krr)\n",
    "print(\"Final Tuned Kernel Ridge (RDKit FP):\")\n",
    "print(final_metrics_krr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d89540fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned Random Forest (RDKit FP):\n",
      "         MAE       RMSE  r_squared\n",
      "0  52.849796  72.147222   0.581961\n"
     ]
    }
   ],
   "source": [
    "# rebuild and retrain the RFR model\n",
    "best_rfr = study_rfr.best_params\n",
    "final_rfr = RandomForestRegressor(n_estimators=best_rfr['n_estimators'], max_depth=best_rfr['max_depth'], random_state=42)\n",
    "final_rfr.fit(X_train_fp_unscaled, y_train_unscaled)\n",
    "\n",
    "# predict on test set\n",
    "final_preds_rfr = final_rfr.predict(X_test_fp_unscaled)\n",
    "\n",
    "# eval using unscaled targets\n",
    "final_metrics_rfr = regression_metrics(y_test_unscaled, final_preds_rfr)\n",
    "print(\"Final Tuned Random Forest (RDKit FP):\")\n",
    "print(final_metrics_rfr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68ac4ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 6.1200\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 5.3776\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 5.1536\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.9777\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.8416\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.7229\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.6043\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4930\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3931\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2974\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2036\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1140\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0264\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9411\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8577\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7762\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6967\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6188\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5427\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4684\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3953\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3243\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2544\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1859\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1191\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0537\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9897\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9271\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8657\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8057\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7470\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6895\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6332\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5781\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5242\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4714\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4198\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3692\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3197\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2712\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2238\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1320\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0875\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0439\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0013\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9595\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9188\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8788\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8396\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8013\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7638\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7271\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6911\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6560\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6216\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5879\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5549\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5226\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4910\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4600\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4297\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4001\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3710\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3426\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3148\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2876\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2609\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2349\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2094\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1843\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1599\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1359\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1124\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0895\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0670\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0450\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0234\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0024\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9817\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9615\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9418\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9225\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9035\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8850\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8668\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8490\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8317\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8147\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7980\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7816\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7657\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7500\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7347\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7197\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7051\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6907\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6766\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6629\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6495\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Final Tuned MLP (RDKit FP):\n",
      "         MAE       RMSE  r_squared\n",
      "0  55.969241  71.134271   0.593617\n"
     ]
    }
   ],
   "source": [
    "best_fp = study_mlp_fp.best_params\n",
    "final_mlp_fp = MLP(\n",
    "    engine='tensorflow', \n",
    "    nfeatures=X_train_fp_scaled.shape[1], \n",
    "    nneurons=[best_fp['n1'], best_fp['n2']], \n",
    "    activations=[best_fp['activation'], best_fp['activation']], \n",
    "    learning_rate=best_fp['lr'], \n",
    "    alpha=best_fp['alpha'], \n",
    "    nepochs=100, \n",
    "    batch_size=64, \n",
    "    loss='mean_squared_error', \n",
    "    is_regression=True\n",
    "    )\n",
    "\n",
    "# train on scaled data\n",
    "final_mlp_fp.fit(X_train_fp_scaled, y_train_scaled)\n",
    "\n",
    "# predict and inverse transform\n",
    "final_preds_fp_scaled = final_mlp_fp.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "final_preds_inv_fp = yscaler.inverse_transform(final_preds_fp_scaled)\n",
    "y_test_inv_fp = yscaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "# eval in eV\n",
    "final_metrics_fp = regression_metrics(y_test_inv_fp, final_preds_inv_fp)\n",
    "print(\"Final Tuned MLP (RDKit FP):\")\n",
    "print(final_metrics_fp[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406d6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_cm = study_mlp_cm.best_params\n",
    "# final_mlp_cm = MLP(engine='tensorflow', nfeatures=X_train_cm_scaled.shape[1], nneurons=[best_cm['n1'], best_cm['n2']], activations=[best_cm['activation'], best_cm['activation']], learning_rate=best_cm['lr'], alpha=best_cm['alpha'], nepochs=100, batch_size=64, loss='mean_squared_error', is_regression=True)\n",
    "\n",
    "# # train on scaled data\n",
    "# final_mlp_cm.fit(X_train_cm_scaled, y_train_scaled)\n",
    "\n",
    "# # predict and inverse transform\n",
    "# final_preds_cm_scaled = final_mlp_cm.predict(X_test_cm_scaled).reshape(-1, 1)\n",
    "# final_preds_inv_cm = yscaler.inverse_transform(final_preds_cm_scaled)\n",
    "# y_test_inv_cm = yscaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "# # eval in eV\n",
    "# final_metrics_cm = regression_metrics(y_test_inv_cm, final_preds_inv_cm)\n",
    "# print(\"Final Tuned MLP (Coulomb Matrix):\")\n",
    "# print(final_metrics_cm[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3c54319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHvCAYAAACFRmzmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAADwzklEQVR4nOzdd3RU1drH8e9kMuk9QEIg9N4RUMEGAlGqioJc1AtYLoqiiFhQlHJFBBVR7L4iKpdixQoSpCiCSu8gvYdQ0uskmfePOENC2iRMMpnk91mLtZh9zpnz7DmT5Mwzez/bYLFYLIiIiIiIiIiIiFQgN2cHICIiIiIiIiIi1Y+SUiIiIiIiIiIiUuGUlBIRERERERERkQqnpJSIiIiIiIiIiFQ4JaVERERERERERKTCKSklIiIiIiIiIiIVTkkpERERERERERGpcEpKiYiIiIiIiIhIhVNSSkREREREREREKpySUiIiIpdp3rx5GAwG5s2bV6Hn7d69OwaDoULPWVlNnjwZg8HA6tWry+0cZbnODRo0oEGDBuUWU1n179+fNm3akJOT4+xQSqUirrMjTJo0CX9/f86cOePsUERERCo1JaVERESKcOTIEQwGQ7H/XIW1LzfffHOh22fOnInBYKBRo0YcPHiwgqOreA0aNMh3HY1GI6GhofTs2ZMvvvjC2eGVq5UrV/Ljjz8yadIk3Nwu3gpaEz55//n4+NCmTRuee+45EhMTC32+S4/x9vYmPDyca6+9lvHjx7Nt27ZCj3PUe9L6PCNGjLD/RQBWr15d7M923mRiYb8LPDw8iIyMZNiwYWzfvj3fcz/++OMYjUZeeOGFUsUkIiJS3bg7OwAREZHKrnHjxtx9991Fbr/tttu4+uqrqV27dgVG5TgTJkzg5ZdfpnXr1ixfvpyIiAhnh1QhjEYjEydOBMBsNrN//36WLFnCypUrmT59Os8880y+/V39Ols9//zzNGjQgDvuuKPQ7bfffjtt2rQBICYmhqVLl/LSSy/xww8/8Ndff+Hp6VngmNDQUB555BEg97U8d+4cmzdv5rXXXuO1117j3nvv5Z133in02MIU9Z585JFHGDp0KPXq1StL1wvVqVMn+vfvX6A9KCioQFve3wXJycn88ccfLFy4kK+//pqVK1fSrVs327H3338/s2fP5tlnn6V+/foOi1dERKQqUVJKRESkBE2aNGHy5MlFbg8MDCQwMLDiAnKQnJwcRo8ezfvvv89VV13FTz/9REhIiLPDqjDu7u4Fruvvv//O9ddfz9SpU3n00Ufx8fGxbXPV65zXjh07WLduHRMnTixypN8dd9zB0KFDbY/T09O5+uqr2bZtGwsWLGDkyJEFjqlRo0ahPyM7duzg3//+N3PnziUzM5PPPvus2PhKek/WqFGDGjVq2Nlb+3Tu3LnYn++8CvtdMHHiRKZNm8Zzzz3HqlWrbO133303r732Gh9++CEvvviiAyMWERGpOjR9T0RE5DIVVWvIYDDQvXt3zp49y7333kutWrXw9vbm6quvLrQmzqZNm3jkkUdo06YNgYGBeHt707ZtW15++WXMZrNDYzabzQwbNoz333+fXr16sWLFigIJqczMTGbNmsUVV1yBr68v/v7+XHfddXz33XcFnm/EiBEYDAYOHTrE66+/TuvWrfH09LRNqbLWVkpJSWHcuHHUqVMHT09P2rVrx5dffllojKU5v6Ncc801tGjRgrS0NHbv3p1vW3E1pb799lu6dOmCt7c3YWFhPPDAA8TFxRV5niNHjnDnnXcSEhKCn58fN9xwA7/++muxNZN+/fVXBgwYQI0aNfD09KRp06ZMnDiR1NRUu/tnjX3w4MF2H+Pl5cVdd90F5L5HS6Nt27YsX76cWrVqMX/+fP76668i97XnPXnp6zNv3jwaNmwIwCeffJJvel1F1Z0aM2YMABs2bMjX3qFDB5o2bVrhteZERERciUZKiYiIlKP4+HiuueYaAgICuOuuu4iNjWXx4sXcdNNNbNq0yTZNCuDDDz/k+++/5/rrr6dv376kpqayevVqJkyYwIYNG/jqq68cElNqaip33HEHS5cuZdCgQSxcuBAPD498+2RkZHDzzTezevVqOnbsyH333YfZbObHH3/klltuYc6cObbpWnmNGTOGP/74g379+tG/f3/CwsJs28xmM1FRUVy4cIFBgwaRmprKokWLGDJkCMuWLSMqKuqyz+8IFosFyB1JZY9PP/2U4cOHExAQwD333ENQUBA//PADvXr1IjMzs8Bre/LkSbp168bp06fp27cv7du3Z9++fURFRdGjR49Cz/Hee+8xevRogoODGTBgADVr1mTDhg1MmzaNVatWsWrVqgLnKcwvv/yCn59fvvedPUr7muRVs2ZNHnzwQaZOncrixYu58sorC+xjz3uyMB06dOCxxx7jjTfeoH379tx66622bRVVYL642nJdu3bl008/Zd++fTRv3rxC4hEREXElSkqJiIiU4MCBA4VO77n55pu5+uqriz1227ZtjB49mjlz5tiKSt94443cf//9vPXWW7z33nu2fSdMmMDbb7+N0Wi0tVksFu6//37mzp3L77//zjXXXHNZfUlISCAqKorff/+de++9lw8++CDf+aymTp3K6tWrmTx5Mi+88ILtg3dSUhI33ngjTzzxBIMGDSpQf2r79u1s2bKl0Jo/p06dokuXLvkSKMOGDaNXr17MmjUrX1KqrOe/XL/++iv79u0jNDSUFi1alLh/YmIiY8aMwdfXlw0bNtCsWTMApk2bRq9evTh9+nSBekLPPPMMp0+f5pVXXmH8+PG29nnz5hU6NW737t2MGTOGDh06FBg99PLLLzNhwgTmzJnDE088UWysycnJ7Nixg65du+YrcF6StLQ05s+fD8C1115r93F53XDDDUDB0URg/3uyMB06dGDs2LG88cYbdOjQwe5peHlt3Lix0OOGDh1q13vgzTffBKBLly4FtnXq1IlPP/2UdevWKSklIiJSCCWlRERESnDw4EGmTJlSoD0oKKjEpJSvry8zZszIlwQYPnw4Dz74YIEP6IUVQzYYDDz88MPMnTuXFStWXHZS6o8//gByR3B89NFHhe6Tk5PDu+++S5MmTfIlhAD8/f154YUXGDhwIF9//XWB0UpPPvlksUWoX3/99XwjYHr27En9+vXzvRaXc/7SyMrKsiUj8hY6NxgMvP3223h5eZX4HEuWLLElpqwJKQCTycS0adO47rrr8u2fkZHBF198QVhYGI8++mi+bcOHD2fGjBns3bs3X/v7779PVlYWb775ZoHpbE899RSzZs1i4cKFJSalTp06RU5OTr7Ra4X58ssvbTGcOXOGH374gRMnTnDLLbcwaNCgYo8tijV5eO7cuQLb7HlPlqdNmzYVOi2xQ4cOBZJSeRPU1kLnv//+O15eXrz00ksFnsP6Wp84ccLxgYuIiFQBSkqJiIiU4KabbmLZsmVlOrZp06b4+fnla3N3dycsLIz4+Ph87ZmZmbz11lssWrSIvXv3kpycbJs2BblJhcvVqlUr4uPjWb9+PVOnTi10yfp9+/YRFxdHREREocm4s2fPAhRIngCFTs2yCgoKstX/yatu3bqsX7/eIecvjezs7ALPbzQaWbx4Mbfffrtdz7Ft2zaAAsknyE2yXDrdbd++fWRkZNC5c+cC09MMBgNdu3Yt0C9r0mbZsmWsWLGiwHlMJpNdr8X58+cBCA4OLna/r776qsBU0UGDBvHll18WO1WtOHnfx5ey5z1ZnkaNGpVvxGJx8iaoTSYTYWFhDBs2jGeeeYa2bdsW2N+aRCwsGSciIiJKSomIiJSrolZrc3d3Jzs7O1/bHXfcwffff0+zZs248847qVWrFiaTifj4eN544w0yMjIuO57IyEi+/fZbevTowaRJk8jJySkwdenChQsA7Nq1i127dhX5XCkpKQXaihuFU9xrkZOT45Dzl4anpyfp6elA7qiXlStXcu+99zJixAiaNGlC+/btS3yOhIQEAGrVqlVgm9FoJDQ0NF9bYmIikFtnqTCFvX7W12PatGklxlMcb29vIHc6XnEWLlzI0KFDycrKYt++fYwfP56vv/6aF154gf/+979lOvfp06eBwvttz3uysihtgtr6WuddxVFEREQu0up7IiIilcCGDRv4/vvvuemmm9i9ezcffvgh06ZNY/LkyQwdOtSh52rSpAmrV68mMjKSKVOmMGnSpHzbAwICALj99tuxWCxF/vv4448LPHdZR9I46vxl5efnx8CBA1m8eDHJycmMGDGi2NE9VtZEW2xsbIFt2dnZttFJVta+WUd7XerMmTMF2qzHJCYmFvt6lMSaELImuUri7u5O69at+eabb2jSpAnTpk1j8+bNdh17KetKeIXVXYKS35OuyvpaF5WEFBERqe6UlBIREakEDh48CEC/fv0KFHn+7bffHH6+xo0bs2bNGurXr8/UqVN5/vnnbdtatmxJQEAAGzduxGw2O/zcJXHm+Xv27Mmtt97K1q1bWbhwYYn7W0dTFXaN1q9fT1ZWVr625s2b4+npyaZNm8jMzMy3zWKx2Kbq5XXVVVcBFLqtNCIiIggNDWX//v2lOs7Ly4tXX30Vi8XCM888U+rznj17lvfffx+g2ARrce/J4lh/Xi4deVgZ7Nu3D6DQqX0iIiKipJSIiEilYC1yvnbt2nztu3btYvr06eVyzoYNG7J69WoaNGjAiy++yHPPPQfkjpB56KGHOHr0KOPHjy80MbRz585CRwc5grPPP3nyZAwGA1OmTCkx0XHLLbcQEBDA3Llz+fvvv23tZrOZiRMnFtjf09OTO+64g5iYGNuqbVaffvope/bsKXDM6NGjcXd3Z8yYMRw/frzA9vj4eLZs2VJivwwGA9dddx0HDx60e7SU1S233MIVV1xBdHR0qZKkO3fuJCoqitjYWEaMGEHnzp2L3b+o92RxgoODMRgMlbKY+J9//om7uzvdunVzdigiIiKVkmpKiYiIVAJXXnklV155JZ9//jmnT5/m6quv5tixY3z33Xf069ePL7/8slzO26BBA9asWUOPHj146aWXyMnJYfr06UyZMoXNmzfz5ptv8uOPP3LDDTdQs2ZNTp48yY4dO9i2bRvr168vtJaSIzjz/O3bt+e2227j66+/Zv78+QwfPrzIfQMDA3nzzTcZMWIEXbp0YejQoQQGBvLDDz/g7e1N7dq1Cxwzffp0VqxYwZNPPsmqVavo0KED+/bt44cffuDmm29m2bJl+VZrbNOmDe+88w4PPfQQzZs3p2/fvjRu3JjExEQOHTrEmjVrGDFihF3Fum+99VaWLFnCihUrGDJkSKlel8mTJzNw4EBeeOEFVq1alW/buXPnbHWgsrKyOH/+PJs2bbKtqnj//ffz9ttv23Weot6TRfHz86NLly78+uuvjBw5kqZNm+Lm5sawYcOKXQmyvFlX5+vduze+vr5Oi0NERKQy00gpERGRSsBoNPLDDz9w7733cvDgQebMmcPu3bt59dVXmTlzZrmeu169eqxevZrGjRvz8ssv8/TTT+Pp6cnSpUt5//33CQ8P58svv2T27Nn8+uuv1K5dm3fffbdcpyQ5+/yTJk3CYDAwderUAlPwLjV8+HC++eYbmjZtyieffMInn3zCNddcw4oVKwqssAe5hb3Xr1/P4MGD+f3335k9ezaxsbEsX76cJk2aABfrSFk98MADrF+/nltuuYX169fz+uuv8+WXX3Lu3Dkef/xxxo4da1e/hgwZQlBQEPPnz7fvhchjwIABdO7cmdWrV7Ny5cp8286fP8+UKVOYMmUKr776Kl9//TUeHh6MHz+ebdu28eGHHxb6WhSlsPdkcT777DNuvvlmlixZwsSJE5kwYQKHDh0qdR8d6auvviItLY1Ro0Y5NQ4REZHKzGCxpzKmiIiIiJS7a6+9lvXr15OQkICfn1+5nOPZZ5/l1Vdf5dChQ9StW7dcziFw/fXXExMTw549ewrUiRMREZFcGiklIiIiUsFOnz5doO1///sfv//+O7169Sq3hBTAM888Q2BgIC+99FK5naO6W7VqFb/99hszZsxQQkpERKQYqiklIiIiUsHatGlDx44dadWqFUajka1bt7J69Wr8/f159dVXy/XcAQEBzJ8/n82bN5OTk5OvfpU4RkJCAq+++iq33Xabs0MRERGp1DR9T0RERKSCPffcc3z//fccO3aMlJQUatasSY8ePXj++edp0aKFs8MTERERqRBKSomIiIiIiIiISIXTeG0REREREREREalwSkqJiIiIiIiIiEiFU1JKREREREREREQqnJJSIiIiIiIiIiJS4ZSUEhERERERERGRCqeklIiIiIiIiIiIVDglpUREREREREREpMIpKSUiIiIiIiIiIhVOSSkREREREREREalwSkqJiIiIiIiIiEiFU1JKREREREREREQqnJJSIiIiIiIiIiJS4ZSUEhERERERERGRCqeklIiIiIiIiIiIVDglpUREREREREREpMIpKSUiIiIiIiIiIhVOSSkREREREREREalwSkqJiIiIiIiIiEiFU1JKREREREREREQqnJJSIlJpzZs3D4PBYPvn7u5O3bp1GTlyJCdPnnTouRo0aMCIESNsj0+dOsXkyZPZunWrQ89jb59Wr16NwWBg9erVpT7HunXrmDx5MvHx8Y4LXEREpAoq7O9y7dq1GTp0KPv37y+3806ePBmDwWDXvpfeozg7npJ0796dNm3aFLrt3LlzGAwGJk+ebGsr6z3PO++8w7x588oeqIhUCu7ODkBEpCQff/wxLVq0IC0tjV9//ZXp06ezZs0aduzYga+vr0PO8c033xAQEGB7fOrUKaZMmUKDBg3o0KGDQ86RV3n2ad26dUyZMoURI0YQFBTkmIBFRESqMOvf5fT0dH7//XemTZvGqlWr2Lt3L8HBwQ4/3/3338/NN9/s8Od1RVdccQXr16+nVatWpTrunXfeoUaNGuWesBOR8qWklIhUem3atKFz584A9OjRg+zsbP773/+yZMkS7rrrrst67rS0NLy9venYsaMjQrVbefZJRERESifv3+Xu3buTnZ3NpEmTWLJkCSNHjnT4+erWrUvdunUd/ryuKCAggKuvvtrZYZRaamoqPj4+zg5DxOVp+p6IuBzrjcvRo0cBmDJlCldddRUhISEEBARwxRVX8NFHH2GxWPId16BBA/r378/XX39Nx44d8fLyYsqUKbZt1m/aVq9eTZcuXQAYOXKkbUj/5MmT+eyzzzAYDKxfv75AXFOnTsVkMnHq1KnL7lNRvvvuO7p27YqPjw/+/v707t07XyyTJ0/mySefBKBhw4a22MsyDVBERKS6siaozpw5k69948aNDBw4kJCQELy8vOjYsSOff/55vn1SU1MZP348DRs2xMvLi5CQEDp37szChQtt+xQ2Xc5sNvPUU08RHh6Oj48P1157LX/99VeB2IqaamedinjkyBFb2+LFi4mKiqJ27dp4e3vTsmVLnnnmGVJSUkp8DVauXEn37t0JDQ3F29ubevXqcfvtt5OamlrisaVR2PS9Q4cOMXToUCIiIvD09CQsLIyePXvayio0aNCAXbt2sWbNGtu9ToMGDWzHHzt2jLvvvptatWrh6elJy5Ytee2118jJycl37hMnTnDHHXfg7+9PUFAQd911Fxs2bMBgMOSbGjhixAj8/PzYsWMHUVFR+Pv707NnTwCio6O55ZZbqFu3Ll5eXjRp0oRRo0Zx7ty5fOeyXrft27czePBgAgMDCQkJYdy4cWRlZbFv3z5uvvlm/P39adCgATNnznTo6yxSWWmklIi4nAMHDgBQs2ZNAI4cOcKoUaOoV68eAH/88Qdjxozh5MmTvPDCC/mO3bx5M3v27GHixIk0bNiw0KlyV1xxBR9//DEjR45k4sSJ9OvXD8j9VrNWrVo89dRTvP3223Tt2tV2TFZWFu+//z633XYbERERl92nwixYsIC77rqLqKgoFi5cSEZGBjNnzqR79+788ssvXHvttdx///1cuHCBOXPm8PXXX1O7dm2AUg+JFxERqc4OHz4MQLNmzWxtq1at4uabb+aqq67ivffeIzAwkEWLFnHnnXeSmppq+3Jr3LhxfPbZZ7z44ot07NiRlJQUdu7cyfnz54s95wMPPMCnn37K+PHj6d27Nzt37mTQoEEkJSWVuR/79++nb9++jB07Fl9fX/bu3cuMGTP466+/WLlyZZHHHTlyhH79+nHdddcxd+5cgoKCOHnyJMuWLSMzM9OuEUJZWVkF2rKzs+2Ku2/fvmRnZzNz5kzq1avHuXPnWLduna1e5jfffMMdd9xBYGAg77zzDgCenp4AnD17lm7dupGZmcl///tfGjRowA8//MD48eM5ePCgbf+UlBR69OjBhQsXmDFjBk2aNGHZsmXceeedhcaUmZnJwIEDGTVqFM8884ytfwcPHqRr167cf//9BAYGcuTIEWbNmsW1117Ljh07MJlM+Z5nyJAh3H333YwaNYro6GhmzpyJ2WxmxYoVjB49mvHjx7NgwQKefvppmjRpwqBBg+x6zURclkVEpJL6+OOPLYDljz/+sJjNZktSUpLlhx9+sNSsWdPi7+9viYmJKXBMdna2xWw2W6ZOnWoJDQ215OTk2LbVr1/fYjQaLfv27StwXP369S3Dhw+3Pd6wYYMFsHz88ccF9p00aZLFw8PDcubMGVvb4sWLLYBlzZo1DunTqlWrLIBl1apVtn5FRERY2rZta8nOzrY9X1JSkqVWrVqWbt262dpeeeUVC2A5fPhwsbGIiIhUd4X9XV62bJklPDzccv3111vMZrNt3xYtWlg6duyYr81isVj69+9vqV27tu3vc5s2bSy33nprseedNGmSJe9HsT179lgAy+OPP55vv//9738WIN89yqXHXtqXov7+5+TkWMxms2XNmjUWwLJt27Yin/PLL7+0AJatW7cW24/C3HDDDRag2H+TJk2y7X/pPc+5c+csgGX27NnFnqd169aWG264oUD7M888YwEsf/75Z772hx56yGIwGGz3gW+//bYFsCxdujTffqNGjSpwDzh8+HALYJk7d26xMVlf46NHj1oAy7fffmvbZn2NX3vttXzHdOjQwQJYvv76a1ub2Wy21KxZ0zJo0KBizydSFWj6nohUeldffTUmkwl/f3/69+9PeHg4S5cuJSwsDMgdXt6rVy8CAwMxGo2YTCZeeOEFzp8/T2xsbL7nateuXb5vPcvioYceAuDDDz+0tb311lu0bduW66+/3iF9utS+ffs4deoU99xzD25uF391+/n5cfvtt/PHH384fDi9iIhIdZH37/LNN99McHAw3377Le7uuRNLDhw4wN69e211H7Oysmz/+vbty+nTp9m3bx8AV155JUuXLuWZZ55h9erVpKWllXj+VatWARSoKzlkyBBbDGVx6NAhhg0bRnh4uO0e6YYbbgBgz549RR7XoUMHPDw8+M9//sMnn3zCoUOHSnXexo0bs2HDhgL/VqxYUeKxISEhNG7cmFdeeYVZs2axZcuWAtPuirNy5UpatWrFlVdema99xIgRWCwW2wixNWvW2K53Xv/617+KfO7bb7+9QFtsbCwPPvggkZGRuLu7YzKZqF+/PlD4a9y/f/98j1u2bInBYKBPnz62Nnd3d5o0aVJiWQeRqkDT90Sk0vv0009p2bIl7u7uhIWF2aakAfz1119ERUXRvXt3PvzwQ+rWrYuHhwdLlixh2rRpBW4E8x5bVmFhYdx55528//77PPPMM+zatYvffvuN999/3yF9Kox1yH9h+0VERJCTk0NcXJwKboqIiJSB9e9yUlISixcv5v333+df//oXS5cuBS7Wlho/fjzjx48v9DmsNYTefPNN6taty+LFi5kxYwZeXl7cdNNNvPLKKzRt2rTQY61/58PDw/O1u7u7ExoaWqY+JScnc9111+Hl5cWLL75Is2bN8PHx4fjx4wwaNKjYZFnjxo1ZsWIFM2fO5OGHHyYlJYVGjRrx6KOP8thjj5V4bi8vL1tdrrwurbNUGIPBwC+//MLUqVOZOXMmTzzxBCEhIdx1111MmzYNf3//Yo8/f/58vvpSVtbyCtbX+vz584V+GVjUF4Q+Pj75VmoGyMnJISoqilOnTvH888/Ttm1bfH19ycnJ4eqrry70NQ4JCcn32MPDAx8fH7y8vAq0JyYmFt1RkSpCSSkRqfRatmxZ6I0NwKJFizCZTPzwww/5/pgvWbKk0P0LKwxaFo899hifffYZ3377LcuWLbMVx7RXcX0qjPWG9PTp0wW2nTp1Cjc3t3JZslpERKQ6yPt32boq7v/93//x5Zdfcscdd1CjRg0AJkyYUGSNn+bNmwPg6+vLlClTmDJlCmfOnLGNmhowYAB79+4t9Fjr3/mYmBjq1Klja8/KyipQi8p6v5ORkWGrowQFEz4rV67k1KlTrF692jY6CrDVZSrJddddx3XXXUd2djYbN25kzpw5jB07lrCwMIYOHWrXc5RV/fr1+eijjwD4+++/+fzzz5k8eTKZmZm89957xR4bGhpa5P0SYLuWoaGhhRaSj4mJKfR5C7uH3LlzJ9u2bWPevHkMHz7c1m6tFSoiJdP0PRFxaQaDAXd3d4xGo60tLS2Nzz777LKe13qTV9S3iJ06daJbt27MmDGD//3vf4wYMaLQoumO0rx5c+rUqcOCBQvyrSqYkpLCV199ZVuRz57YRUREpHgzZ84kODiYF154gZycHJo3b07Tpk3Ztm0bnTt3LvRfYSN4wsLCGDFiBP/617/Yt29fkVPtu3fvDsD//ve/fO2ff/55gYLh1lFA27dvz9f+/fff53tsTaLkTVwBpRrZDWA0Grnqqqt4++23gdxFYypSs2bNmDhxIm3bts13bk9Pz0LvdXr27Mnu3bsLxPnpp59iMBjo0aMHADfccANJSUm20XBWixYtsjs2R73GItWZRkqJiEvr168fs2bNYtiwYfznP//h/PnzvPrqqwVuDkqrcePGeHt787///Y+WLVvi5+dHREREvpX1HnvsMe68804MBgOjR4++3K4Uy83NjZkzZ3LXXXfRv39/Ro0aRUZGBq+88grx8fG8/PLLtn3btm0LwBtvvMHw4cMxmUw0b968xOHuIiIikis4OJgJEybw1FNPsWDBAu6++27ef/99+vTpw0033cSIESOoU6cOFy5cYM+ePWzevJkvvvgCgKuuuor+/fvTrl07goOD2bNnD5999lm+L5Au1bJlS+6++25mz56NyWSiV69e7Ny5k1dffbXAlLG+ffsSEhLCfffdx9SpU3F3d2fevHkcP348337dunUjODiYBx98kEmTJmEymfjf//7Htm3bSuz/e++9x8qVK+nXrx/16tUjPT2duXPnAtCrV6+yvKR22759O4888giDBw+madOmeHh4sHLlSrZv384zzzxj269t27YsWrSIxYsX06hRI7y8vGjbti2PP/44n376Kf369WPq1KnUr1+fH3/8kXfeeYeHHnrIVlt0+PDhvP7669x99928+OKLNGnShKVLl/Lzzz8D5KvhWZQWLVrQuHFjnnnmGSwWCyEhIXz//fdER0eXz4sjUgVppJSIuLQbb7yRuXPnsmPHDgYMGMBzzz3HHXfcke+mpSx8fHyYO3cu58+fJyoqii5duvDBBx/k2+fWW2/F09OTm266qcgaEY40bNgwlixZwvnz57nzzjsZOXIkAQEBrFq1imuvvda2X/fu3ZkwYQLff/891157LV26dGHTpk3lHp+IiEhVMmbMGOrVq8fUqVPJzs6mR48e/PXXXwQFBTF27Fh69erFQw89xIoVK/Ilam688Ua+++47Ro4cSVRUFDNnzuTf//53gZFMl/roo48YN24c8+bNY+DAgXz++ed89dVXBabnBwQEsGzZMvz9/bn77rt58MEHadOmDc8991y+/UJDQ/nxxx/x8fHh7rvv5t5778XPz4/FixeX2PcOHTqQlZXFpEmT6NOnD/fccw9nz57lu+++IyoqqhSvYumFh4fTuHFj3nnnHe644w5uueUWvv/+e1577TWmTp1q22/KlCnccMMNPPDAA1x55ZUMGDAAgJo1a7Ju3TpuvPFGJkyYQP/+/fn555+ZOXMmc+bMsR3v6+vLypUr6d69O0899RS33347x44d45133gEgKCioxFhNJhPff/89zZo1Y9SoUfzrX/8iNjbWroLuIpLLYMk7D0REROz2/fffM3DgQH788Uf69u3r7HBERERE5DK99NJLTJw4kWPHjlG3bl1nhyNS5SkpJSJSSrt37+bo0aM89thj+Pr6snnzZocVUBcRERGRivHWW28BudPwzGYzK1eu5M033+TOO+/k008/dXJ0ItWDakqJiJTS6NGj+f3337niiiv45JNPlJASERERcUE+Pj68/vrrHDlyhIyMDOrVq8fTTz/NxIkTnR2aSLWhkVIiIiIiIiIiIlLhVOhcREREREREREQqnJJSIiIiIiIiIiJS4ZSUEhERERERERGRCqdC52WQk5PDqVOn8Pf3V4FjERERAcBisZCUlERERARubtXnez/dF4mIiMil7L0vUlKqDE6dOkVkZKSzwxAREZFK6Pjx49StW9fZYVQY3ReJiIhIUUq6L1JSqgz8/f2B3Bc3ICDAydGUjtlsZvny5URFRWEymZwdToVQn6tHn6F69lt9Vp+rMlfrd2JiIpGRkbb7hOqiuPsiV7uGkp+un+vStXNtun6uS9fuInvvi5SUKgPr0PSAgACXTEr5+PgQEBBQbX5I1Ofq0Weonv1Wn9XnqsxV+13dprAVd1/kqtdQcun6uS5dO9em6+e6dO0KKum+qPoUPBARERERERERkUpDSSkREREREREREalwSkqJiIiIiIiIiEiFU1JKREREREREREQqnJJSIiIiIiIiIiJS4ZSUEhERERERERGRCqeklIiIiIiIiIiIVDglpUREREREREREpMIpKSUiIiIiIiIiIhVOSSkREREREREREalwSkqJiIiIiIiIiEiFU1JKREREpIr69ddfGTBgABERERgMBpYsWVLkvqNGjcJgMDB79uwKi09ERESqNyWlRERERKqolJQU2rdvz1tvvVXsfkuWLOHPP/8kIiKigiITERERAXdnByAiIiLlJDkZDh6E9u2dHYk4SZ8+fejTp0+x+5w8eZJHHnmEn3/+mX79+lVQZCIiIiJKSomIiFRNycnQpw9s3w7R0XDllc6OSCqhnJwc7rnnHp588klat25t1zEZGRlkZGTYHicmJgJgNpsxm8359rU+vrRdXIOun2s6d+4ccXFxAOzfvx+j0Viq4wMCAqhRo0Z5hCZ20s+e69K1u8je10BJKRERkarGmpBauxYCA8FgcHZEUknNmDEDd3d3Hn30UbuPmT59OlOmTCnQvnz5cnx8fAo9Jjo6uswxivPp+rmu/fv3OzsEuQz62XNdunaQmppq135KSomIiFQ1S5ZcTEhFR0OXLs6OSCqhTZs28cYbb7B582YMpUhcTpgwgXHjxtkeJyYmEhkZSVRUFAEBAfn2NZvNREdH07t3b0wmk8Nil4qh6+d6Dh06RMeOHXngxXe5sXEQm+O8yMH+n++4c6eZ+8JDbNmyhUaNGpVjpFIc/ey5Ll27i6wjqUuipJSIiEhVc/fdEBsL112nhJQU6bfffiM2NpZ69erZ2rKzs3niiSeYPXs2R44cKfQ4T09PPD09C7SbTKYib8CL2yaVn66f6zAajaSlpREQUhtIIziiHhaD/dP3sjGQlpaG0WjUNa8E9LPnunTtsLv/SkqJiIhUBUlJYLGAdaRKnpEsIoW555576NWrV762m266iXvuuYeRI0c6KSoRERGpTpSUEhERcXVJSdC3L+TkwNKlFxNTUu0lJydz4MAB2+PDhw+zdetWQkJCqFevHqGhofn2N5lMhIeH07x584oOVURERKohJaVERERcmTUhZa0hdeQItGvn7Kikkti4cSM9evSwPbbWgho+fDjz5s1zUlQiIiIiuZSUEhERcVWXJqRWrFBCSvLp3r07FovF7v2LqiMlIiIiUh7cnB2AiIiIlEFhCanOnZ0dlYiIiIiI3ZSUEhERcTVKSImIiIhIFeCySanp06djMBgYO3asrc1isTB58mQiIiLw9vame/fu7Nq1K99xGRkZjBkzhho1auDr68vAgQM5ceJEBUcvIiJyGU6dgn37lJASEREREZfmkkmpDRs28MEHH9DukroZM2fOZNasWbz11lts2LCB8PBwevfuTVJSkm2fsWPH8s0337Bo0SLWrl1LcnIy/fv3Jzs7u6K7ISIiUjbNm8PKlUpIiYiIiIhLc7mkVHJyMnfddRcffvghwcHBtnaLxcLs2bN57rnnGDRoEG3atOGTTz4hNTWVBQsWAJCQkMBHH33Ea6+9Rq9evejYsSPz589nx44drFixwlldEhERKZF7WhqGDRsuNrRpo4SUiIiIiLg0l0tKPfzww/Tr149evXrlaz98+DAxMTFERUXZ2jw9PbnhhhtYt24dAJs2bcJsNufbJyIigjZt2tj2ERERqXSSkrh66lSMvXvD6tXOjkZERERExCHcnR1AaSxatIjNmzezIe83xf+IiYkBICwsLF97WFgYR48ete3j4eGRb4SVdR/r8YXJyMggIyPD9jgxMREAs9mM2WwuW2ecxBqvq8V9OdTn6qM69lt9rgaSknAbMIDQPXuwBAaS5emJpZr03dWutavEKSIiIlJZuExS6vjx4zz22GMsX74cLy+vIvczGAz5HlsslgJtlyppn+nTpzNlypQC7cuXL8fHx6eEyCun6OhoZ4dQ4dTn6qM69lt9rprc09K4eupUQvfswezjw7qJE4mPjYWffnJ2aBXKVa51amqqs0MQERERcSkuk5TatGkTsbGxdOrUydaWnZ3Nr7/+yltvvcW+ffuA3NFQtWvXtu0TGxtrGz0VHh5OZmYmcXFx+UZLxcbG0q1btyLPPWHCBMaNG2d7nJiYSGRkJFFRUQQEBDisjxXBbDYTHR1N7969MZlMzg6nQqjP1aPPUD37rT5X4T4nJWEcOBC3f0ZIrZs4kS6jR1ftPl/C1a61dSS1iIiIiNjHZZJSPXv2ZMeOHfnaRo4cSYsWLXj66adp1KgR4eHhREdH07FjRwAyMzNZs2YNM2bMAKBTp06YTCaio6MZMmQIAKdPn2bnzp3MnDmzyHN7enri6elZoN1kMrnETXJhXDn2slKfq4/q2G/1uYpJToZbboHff4fAQLKXLiU+NrZq97kYrtJvV4hRREREpDJxmaSUv78/bdq0ydfm6+tLaGiorX3s2LG89NJLNG3alKZNm/LSSy/h4+PDsGHDAAgMDOS+++7jiSeeIDQ0lJCQEMaPH0/btm0LFE4XERFxGg8PqFkTAgMhOhpLhw7VbsqeiIiIiFR9LpOUssdTTz1FWloao0ePJi4ujquuuorly5fj7+9v2+f111/H3d2dIUOGkJaWRs+ePZk3bx5Go9GJkYuIiOTh4QGLF8PBg9CiBaiAtoiIiIhUQS6dlFp9ybLYBoOByZMnM3ny5CKP8fLyYs6cOcyZM6d8gxMRESmN5GT46CN49FEwGMBkyk1IiYiIiIhUUS6dlBIREakSkpOhTx9YuxZOnoRi6hyKiIiIiFQVbs4OQEREpFrLm5AKDITBg50dkYiIiIhIhVBSSkRExFkuTUhFR0OXLs6OSkRERESkQigpJSIi4gxKSImIiIhINaeklIiISEWzWGDgQCWkRERERKRaU1JKRESkohkM8NBDUKOGElIiIiIiUm1p9T0RERFnGDwYbroJAgKcHYmIiIiIiFNopJSIiEhFSEqCe+6B48cvtikhJSIiIiLVmEZKiYiIlLekJOjbN7eG1J49sGFD7hQ+EREREZFqTCOlREREylPehFRgILz3nhJSIiIiIiIoKSUiIlJ+Lk1IrVgBnTs7OyoRERERkUpBSSkREZHyoISUiIiIiEixlJQSEREpD489poSUiIiIiEgxlJQSEREpDy+9BF27KiElIiIiIlIErb4nIiLiKDk54PbP9z3h4fD77ypqLiIiIiJSBI2UEhERcYSkJOjRAz755GKbElIiIiIiIkVSUkpERORyWYua//orjBsH8fHOjkhEREREpNJTUkpERORyXLrK3rJlEBTk7KhERERERCo9JaVERETK6tKEVHQ0dOni7KhERERERFyCklIiIiJloYSUiIiIiMhlUVJKRESkLObPV0JKREREROQyuDs7ABEREZf04INw+jQMGKCElIiIiIhIGSgpJSIiYq/kZHB3By8vMBhg6lRnRyQiIiIi4rI0fU9ERMQeSUnQpw/cdhukpzs7GhERERERl6eklIiISEnyFjVfvx4OHnR2RCIiIiIiLk9JKRERkeIUtspe69bOjkpERERExOUpKSUiIlKUwhJSDixqnpyexb6YJDYfi+PvmCSS07Mc9twiAL/++isDBgwgIiICg8HAkiVLbNvMZjNPP/00bdu2xdfXl4iICP79739z6tQp5wUsIiIi1YoKnYuIiBSmnBNSJ+JSid59hvhUs60tyMdE71Zh1A32cdh5pHpLSUmhffv2jBw5kttvvz3fttTUVDZv3szzzz9P+/btiYuLY+zYsQwcOJCNGzc6KWIRERGpTpSUEhERKczBg7BtW7mNkLo0IQUQn2omevcZBneKxM9Lf6Ll8vXp04c+ffoUui0wMJDo6Oh8bXPmzOHKK6/k2LFj1KtXryJCFBERkWpMd7wiIiKF6dABli8Ho9GhCSmAk/FpBRJSVvGpZk7Gp9E83N+h5xSxR0JCAgaDgaCgIGeHIiIiItWAklIiIiJWyclw5Ai0aZP7+Oqry+U0KZnF145KLWG7SHlIT0/nmWeeYdiwYQQEBBS5X0ZGBhkZGbbHiYmJQG6NKrM5f7LV+vjSdnENun6uJzs7G29vb9ywAGCwZJfqeCMWvL29yc7O1nV3Iv3suS5du4vsfQ2UlBIREYHchFSfPrBrF6xYAVdcUW6n8vUo/s+vTwnbRRzNbDYzdOhQcnJyeOedd4rdd/r06UyZMqVA+/Lly/HxKbwe2qXTBMW16Pq5loULFwLpADRIP1iqYxsG5x6/d+9e9u7dWw7RSWnoZ8916drl1q60h+56RURErAkpa1Hz7NJ9s1xadYK8CfIxFTqFL8jHRJ0g73I9v0heZrOZIUOGcPjwYVauXFnsKCmACRMmMG7cONvjxMREIiMjiYqKKnCs2WwmOjqa3r17YzKZyiV+KT+6fq7n0KFDdOzYkSff+YYrgtM54tUYi8Fo9/HnTx3ntdG3smXLFho1alSOkUpx9LPnunTtLrKOpC6JklIiIlK9XZqQcnBR88L4ebnTu1VYkavvqci5VBRrQmr//v2sWrWK0NDQEo/x9PTE09OzQLvJZCryBry4bVL56fq5DqPRSFpaGjkYALAYjKVKSmVjIC0tDaPRqGteCehnz3Xp2mF3/3XXKyIi1ZcTElJWdYN9GNwpkpPxaaRmZuHj4U6dIG8lpMShkpOTOXDggO3x4cOH2bp1KyEhIURERHDHHXewefNmfvjhB7Kzs4mJiQEgJCQEDw8PZ4UtIiIi1YTufEVEpHpyYkLKys/LXavsSbnauHEjPXr0sD22TrsbPnw4kydP5rvvvgOgQ4cO+Y5btWoV3bt3r6gwRUREpJpSUkpERKonNzfw8HBaQkqkInTv3h2LxVLk9uK2iYiIiJQ3JaVERKR68vGB77+HQ4egTRtnRyMiIiIiUu24OTsAERGRCpOUBP/3f2AdHeLjo4SUiIiIiIiTaKSUiIhUD0lJ0Ldvbg2p2Fh49llnRyQiIiIiUq1ppJSIiFR9eRNSgYEQFeXsiEREREREqj0lpURExKWkZGQBsO1EPH/HJJGcnlX8AZcmpFasgM6dKyBSEREREREpjqbviYiIyzgRl0r0zlOEAGv3n8NiMBLkY6J3qzDqBvsUPEAJKRERERGRSksjpURExCUkp2cRvfsMCWnmfO3xqWaid58pOGIqOxv69VNCSkRERESkklJSSkREXMLJ+DTiU82FbotPNXMyPi1/o9EId98NwcFKSImIiIiIVEJKSomIiEtIySy+dlRqYdv/8x84cEAJKRERERGRSkhJKRERcQm+HsWXQfTxcM+tIfWf/8DZsxc3hISUc2SVV3J6Fvtikth8LM6+ovAiIiIiIhVIhc5FRMQl1AnyJsjHREJKdoFtQT4m6hizoO/A3BpSe/fCmjVgMDgh0srhRFwq0bvP5JvyWGxReBERERGRCqaRUiIi4hL8vNzp3SqMQG9TvvYgHxNRkT74DRp4saj5a69V64SUtSj8pTW4iiwKLyIiIiLiBBopJSIiLqNusA+3dazDml92cV3TGvh5e1HHmJU/IRUdDV26ODtUp7KnKHzzcP8KjkpEREREJD8lpURExKX4eub+6WpXNwhTevrFKXtKSNmUqSi8iIiIiEgFc5npe++++y7t2rUjICCAgIAAunbtytKlS23bLRYLkydPJiIiAm9vb7p3786uXbvyPUdGRgZjxoyhRo0a+Pr6MnDgQE6cOFHRXREREUcZNUoJqULYVRReRERERMTJXCYpVbduXV5++WU2btzIxo0bufHGG7nllltsiaeZM2cya9Ys3nrrLTZs2EB4eDi9e/cmKSnJ9hxjx47lm2++YdGiRaxdu5bk5GT69+9PdnbBorkiIuICXnwR2rVTQuoS1qLwhQnyMVEnyLuCIxIRERERKchlklIDBgygb9++NGvWjGbNmjFt2jT8/Pz4448/sFgszJ49m+eee45BgwbRpk0bPvnkE1JTU1mwYAEACQkJfPTRR7z22mv06tWLjh07Mn/+fHbs2MGKFSuc3DsREbGbxXLx/40awZYtSkhdwloU/tLElHX1PT8vjZQSEREREee7rLvS48ePYzAYqFu3rqPisUt2djZffPEFKSkpdO3alcOHDxMTE0NUVJRtH09PT2644QbWrVvHqFGj2LRpE2azOd8+ERERtGnThnXr1nHTTTcVeb6MjAwyMjJsjxMTEwEwm82YzYUXkq2srPG6WtyXQ32uPqpjv6tdn5OScBs0iPBu3TD37n2xvYqPeC3LdQ7zM3Fb+3BOxaeTZs7C2+RORJAXvp7uLvN+cbX3t6vEKSIiIlJZlDoplZWVxZQpU3jzzTdJTk4GwM/PjzFjxjBp0iRMpsKnCzjCjh076Nq1K+np6fj5+fHNN9/QqlUr1q1bB0BYWFi+/cPCwjh69CgAMTExeHh4EBwcXGCfmJiYYs87ffp0pkyZUqB9+fLl+Pj4XE6XnCY6OtrZIVQ49bn6qI79rg59dk9L4+qpUwnds4cOW7cS3a4d2d7Vaxra5V7n/Q6Ko6K5yvs7NTXV2SGIiIiIuJRSJ6UeeeQRvvnmG2bOnEnXrl0BWL9+PZMnT+bcuXO89957Dg/Sqnnz5mzdupX4+Hi++uorhg8fzpo1a2zbDQZDvv0tFkuBtkvZs8+ECRMYN26c7XFiYiKRkZFERUUREBBQhp44j9lsJjo6mt69e5drArEyUZ+rR5+heva72vQ5KQnjwIG47dmDJTCQPyZO5MaBA6t2n/OoNtf5Eq7Wb+tIahERERGxT6mTUgsXLmTRokX06dPH1tauXTvq1avH0KFDyzUp5eHhQZMmTQDo3LkzGzZs4I033uDpp58GckdD1a5d27Z/bGysbfRUeHg4mZmZxMXF5RstFRsbS7du3Yo9r6enJ56engXaTSaTS9wkF8aVYy8r9bn6qI79rtJ9TkqCW26B33+HwECyly4lPja2ave5CNWxz+A6/XaFGEVEREQqk1IXOvfy8qJBgwYF2hs0aICHh4cjYrKbxWIhIyODhg0bEh4enm94f2ZmJmvWrLElnDp16oTJZMq3z+nTp9m5c2eJSSkREXGSpCTo2xfWroXAQIiOxtK5s7OjEhERERERByj1SKmHH36Y//73v3z88ce20UMZGRlMmzaNRx55xOEBWj377LP06dOHyMhIkpKSWLRoEatXr2bZsmUYDAbGjh3LSy+9RNOmTWnatCkvvfQSPj4+DBs2DIDAwEDuu+8+nnjiCUJDQwkJCWH8+PG0bduWXr16lVvcIiJyGd57L19Cii5dQMWkRURERESqhFInpbZs2cIvv/xC3bp1ad++PQDbtm0jMzOTnj17MmjQINu+X3/9tcMCPXPmDPfccw+nT58mMDCQdu3asWzZMnr/s/rSU089RVpaGqNHjyYuLo6rrrqK5cuX4+/vb3uO119/HXd3d4YMGUJaWho9e/Zk3rx5GI1Gh8UpIiIO9MQTcPIk3HVXbkJKRERERESqjFInpYKCgrj99tvztUVGRjosoKJ89NFHxW43GAxMnjyZyZMnF7mPl5cXc+bMYc6cOQ6OTkREHCYlBTw9wd0d3Nxg9mxnRyQiIiIiIuWg1Empjz/+uDziEBERgeRk6NMH6taFzz7LTUyJiIiIiEiVpLt9ERGpHKwJKWsNqUOHoFkzZ0clIiIiIiLlpExJqS+//JLPP/+cY8eOkZmZmW/b5s2bHRKYiIhUI5cmpKKjlZASEREREani3Ep7wJtvvsnIkSOpVasWW7Zs4corryQ0NJRDhw7Rp0+f8ohRRESqssISUipqLiIiIiJS5ZU6KfXOO+/wwQcf8NZbb+Hh4cFTTz1FdHQ0jz76KAkJCeURo4iIVFVKSImIiIiIVFulTkodO3aMbt26AeDt7U1SUhIA99xzDwsXLnRsdCIiUrVt3w4bNyohJSIiIiJSDZU6KRUeHs758+cBqF+/Pn/88QcAhw8fxmKxODY6ERGp2rp1g+++U0JKRERERKQaKnVS6sYbb+T7778H4L777uPxxx+nd+/e3Hnnndx2220OD1BERKqYpCQ4cODi4969lZASEREREamGSr363gcffEBOTg4ADz74ICEhIaxdu5YBAwbw4IMPOjxAERGpQpKSoG/f3KTU6tXQvLmzIxIREREREScpdVLKzc0NN7eLA6yGDBnCkCFDHBqUiIhUQdaElLWo+T81CUVEREREpHoqVVIqMTGRgIAAAH766SeysrJs24xGI/369XNsdCIiUjVcmpBasQI6d3Z2VCIiIiIi4kR2J6V++OEHnn/+ebZs2QLAnXfeSUpKim27wWBg8eLF3HHHHY6PUkREXJcSUiIiIiIiUgi7C51/8MEHPPLII/naDhw4QE5ODjk5OUyfPp25c+c6PEAREXFhSkiJiIiIiEgR7E5Kbd++nfbt2xe5vU+fPmzcuNEhQYmISBWRnQ3p6UpIiYiIiIhIAXZP34uJiSE0NNT2eNWqVURGRtoe+/n5kZCQ4NjoRETEtQUFQXQ0HD0KxXyxISIiIiIi1Y/dI6VCQkI4ePCg7XHnzp0xmUy2x/v37yckJMSx0YmIiOtJSoLFiy8+DgpSQkrESX799VcGDBhAREQEBoOBJUuW5NtusViYPHkyEREReHt70717d3bt2uWcYEVERKTasTspdf311/Pmm28Wuf3NN9/k+uuvd0hQIiLioqw1pIYOhbffdnY0ItVeSkoK7du356233ip0+8yZM5k1axZvvfUWGzZsIDw8nN69e5OUlFTBkYqIiEh1ZPf0vaeffpquXbsyePBgnnrqKZo1awbAvn37mDFjBitWrGDdunXlFqiIiFRylxY1v/JKZ0ckUu316dOHPn36FLrNYrEwe/ZsnnvuOQYNGgTAJ598QlhYGAsWLGDUqFEVGaqIiIhUQ3YnpTp27MjixYu5//77+frrr/NtCw4OZtGiRVxxxRUOD1BERFzApQmp6Gjo0sXZUYlIMQ4fPkxMTAxRUVG2Nk9PT2644QbWrVtXZFIqIyODjIwM2+PExEQAzGYzZrM5377Wx5e2i2vQ9XM92dnZeHt744YFAIMlu1THG7Hg7e1Ndna2rrsT6WfPdenaXWTva2B3UgrglltuoXfv3vz888/s378fgKZNmxIVFYWvr2/poxQREdenhJSIS4qJiQEgLCwsX3tYWBhHjx4t8rjp06czZcqUAu3Lly/Hx8en0GOio6MvI1JxNl0/17Jw4UIgHYAG6QeL3/kSDYNzj9+7dy979+4th+ikNPSz57p07SA1NdWu/UqVlALw8fHhtttuK3VAIiJSBZnNSkiJuDiDwZDvscViKdCW14QJExg3bpztcWJiIpGRkURFRREQEJBvX7PZTHR0NL179863QI64Bl0/13Po0CE6duzIk+98wxXB6RzxaozFYLT7+POnjvPa6FvZsmULjRo1KsdIpTj62XNdunYXWUdSl6TUSSkREREbkyk3KbVjhxJSIi4mPDwcyB0xVbt2bVt7bGxsgdFTeXl6euLp6Vmg3WQyFXkDXtw2qfx0/VyH0WgkLS2NHHITyxaDsVRJqWwMpKWlYTQadc0rAf3suS5dO+zuv92r74mIiBRqwgTYu1cJKREX07BhQ8LDw/NNMcjMzGTNmjV069bNiZGJiIhIdaGklIiIlE5SEjz2GOQdkvvPiAsRqVySk5PZunUrW7duBXKLm2/dupVjx45hMBgYO3YsL730Et988w07d+5kxIgR+Pj4MGzYMOcGLiIiItWCpu+JiIj98hY1P3AAfvzR2RGJSDE2btxIjx49bI+ttaCGDx/OvHnzeOqpp0hLS2P06NHExcVx1VVXsXz5cvz9/Z0VsoiIiFQjpU5KnTx5kq+++oq///4bg8FAs2bNGDRoEHXq1CmP+EREpLK4dJW9QlbfEpHKpXv37lgsliK3GwwGJk+ezOTJkysuKBEREZF/lCop9c477zBu3DgyMzMJDAzEYrGQmJjIk08+yaxZsxg9enR5xSkiIs50aUJqxQro3NnZUYmIiIiIiAuzu6bUjz/+yKOPPsojjzzCyZMniYuLIz4+npMnTzJ69Ggee+wxfvrpp/KMVUREnEEJKRERERERKQd2j5SaOXMmzzzzDC+++GK+9tq1azNr1ix8fHyYMWMGffv2dXiQIiLiRMOHKyElIiIiIiIOZ/dIqS1btnDPPfcUuf2ee+5h8+bNDglKREQqkalToVkzJaRERERERMSh7B4plZOTg8lkKnK7yWQqtpCmiIi4EIsFDIbc/7dpA7t2gbsWbBUREREREcexe6RU69at+fbbb4vcvmTJElq3bu2QoERExImSk3NrSK1efbFNCSkREREREXEwuz9ljB49moceeghPT0/+85//4P7PB5SsrCzef/99Jk6cyDvvvFNugYqISAVIToY+fXJrSG3fDgcPgpeXs6MSEREREZEqyO6k1PDhw9mxYwePPPIIEyZMoHHjxgAcPHiQ5ORkHn30UUaMGFFecYqISHnLm5AKDIQlS5SQEhERERGRclOq+Rivvvoqd9xxBwsXLmT//v0AXH/99QwdOpSrr766XAIUEZEKcGlCKjoaunSpuNOnZ3EyPo2UzCz8PNyJCPLGz0tTBkVEREREqrJS3/FfffXVSkCJiFQlTk5InYhLJXr3GeJTzba2IB8TvVuFUTfYp8LiEBERERGRimV3UurYsWN27VevXr0yByMiIk7w6qtOHSF1aUIKID7VTPTuMwzuFKkRUyIiIiIiVZTdd/oNGza0/d9isQBgsC4X/k+bwWAgOzvbgeGJiEi5e+45OHoURo+u0IQUwMn4tAIJKav4VDMn49NoHu5foTGJiIiIiEjFsDspZTAYqFu3LiNGjGDAgAG21fdERKqDKlfzKDU1t4i5mxuYTPDxx04JIyUzq9jtqSVsFxERERER12X3J6oTJ07wySefMG/ePN577z3uvvtu7rvvPlq2bFme8YmIOF2Vq3mUlAR9+0LbtvDWW7mJKSfx9Sj+z5BPCdtFRERERMR12f1JJDw8nKeffpo9e/bw5ZdfEhcXx1VXXcXVV1/Nhx9+SE5OTnnGKSLiFCXVPEpOd7GRPNaE1Nq1sGBB7rQ9J6oT5E2Qj6nQbUE+JuoEeVdwRCIiIiIiUlHK9PX4tddey0cffcT+/fvx8fHhwQcfJD4+3sGhiYg4nz01j1xG3oRUYCCsWAF56gU6g5+XO71bhRVITFlHorn0FEkRERERESlWme72161bx9y5c/niiy9o3rw5b7/9NkFBQQ4OTUTE+apMzaPCElKdOzs7KgDqBvswuFMkJ+PTSM3MwsfDnTquXrNLRERERERKZPcd/+nTp/n000/5+OOPiYuL46677mLdunW0bt26POMTEXGqKlHzqBInpKz8vNy1yp6IiEgJ0jKzOXg2GXN2Dm4GA8E+HkSGeOdbFV1ExJXY/Wmqfv36REREMHz4cAYOHIjJZCI7O5vt27fn269du3YOD1JExFmsNY8Km8LnMjWP/vgD1q+vtAkpERGRqubs2bMkJCSU+Xiz2YzJZMJisbA7Np1fDiSy6WQKpxLNWC7Z18/DjWY1vLihkT+NTfGXFbeISEWzOymVlZXFsWPH+O9//8uLL74IgMWS/1eiwWAgOzvbsRGKiDiRteZRUavvucQUs969YfFiqF9fCSkREZFydvbsWZo0aUpiYtmTUhiM+LS4hqBrhmEKrZtvU3ZKPDnmdAwGN4y+wSRjYvOpVDafSiUnM53gnv8hMTUNgi+zIyIiFcDuT1OHDx8uzzhERCotl6x5lJQEiYlQp07u49tvd248IiIi1URCQgKJiQk8OGMewbUiSn38jt172XQWPMIaAeDuBnX93Kgf4EaIlwFv91q2fbMtFhIzLJxOsXAoIZtEvAjoPJCfjlvwMOYQ0cACmtknIpVYqabviYhUVy5V88haQ+rUKVi9GiIjnR2RiIhItRNcK4Kadez/DJWVk8Ofhy6ww60hHmEG3A0WujSsQYfIIDzci140PRxoBlxvsbDur42sO5wANevzxWEjjZLOENUqHE+T8fI7JCJSDuxOSv3666+FtgcGBtKkSRN8fX0dFpSIiJTRpUXNY2OVlBIREankktOz+H77KWKTMgADyTtXclvPq2nVMMTu5zAYDNQwmTn98Rj6vfgle5JMHDqXysINx+nfrjY1/DzLrwMiImVkd1Kqe/fuRW4zGo089NBDvPbaa5hMJkfEJSLiMMnpWZyMTyMlMws/D3ciKvvUu7K6NCEVHQ2dOjk7KhERESnGmcR0vt9+ipSMbLxMbrT0iGPJj7Pw6P152Z7QkkMjvyxuqu/GB/u9SEgz8+WmE9zasQ7hAV6ODV5E5DIVPQ70EnFxcYX+O3z4MAsWLOC7777jlVdeKbdAp0+fTpcuXfD396dWrVrceuut7Nu3L98+FouFyZMnExERgbe3N927d2fXrl359snIyGDMmDHUqFEDX19fBg4cyIkTJ8otbhFxrhNxqXyx6Tg/7TjNmn1n+XHHab7YdJwTcanODs2xCktIdeni7KhERESkGEfPp/DlphOkZGQT4uvB0C71CPPIdMhz1/ODu7rkJqIysnL4ZvNJTsalOeS5RUQcxe6kVGBgYKH/6tevz+DBg3njjTf43//+V26Brlmzhocffpg//viD6OhosrKyiIqKIiUlxbbPzJkzmTVrFm+99RYbNmwgPDyc3r17k5SUZNtn7NixfPPNNyxatIi1a9eSnJxM//79tWqgSBWUnJ5VYNU8gPhUM9G7z5CcnuWkyBzLPS0N48CBSkiJiIi4kMPnUvh++2mycizUD/FhSOe6BHo7dtaJl8nIbR3rUDfIm8zsHL7ddpLYxHSHnkNE5HLYnZQqSfv27Tl69Kijnq6AZcuWMWLECFq3bk379u35+OOPOXbsGJs2bQJyR0nNnj2b5557jkGDBtGmTRs++eQTUlNTWbBgAZC7EsZHH33Ea6+9Rq9evejYsSPz589nx44drFixotxiFxHnOBmfViAhZRWfauZkfNX4ttCYkYHh3DklpERERFzE4XMp/LD9FNk5FhrX9GVA+wg83cunGLmHuxu3dIigbrA35mwL3247RWJa4fdHIiIVzWFFVU6dOkWtWrVK3tFBEhISAAgJyS3+d/jwYWJiYoiKirLt4+npyQ033MC6desYNWoUmzZtwmw259snIiKCNm3asG7dOm666aZCz5WRkUFGRobtcWJiIgBmsxmz2bV+oVvjdbW4L4f6XH1c2u+ktHQMlqJHQSanpWM2u3ZtBbPZTEZQEGk//YTp3Dno0AGq+HWvLO/vlIwsTsWnk2rOwtfkTu0gL3w9y6dWWWXpc0VztX67Spwi4lyn4tP4ccdpcizQtJYfN7UOx+hmKNdzuhvd6N+uNl9uOsG55EyWbD3JkM6ReGlVPhFxMofcPcfGxjJx4kRuvPFGRzxdiSwWC+PGjePaa6+lTZs2AMTExAAQFhaWb9+wsDDbCK6YmBg8PDwIDg4usI/1+MJMnz6dKVOmFGhfvnw5Pj4+l9UXZ4mOjnZ2CBVOfa4+8va7YTH7ndj+Nye2l3885cE9LY3QXbs407kzANE7duRuOH3aiVFVrMr2/v67As5R2fpcUVyl36mpVaxWnYg43PnkDL7bljtCqkGoT4UkpKw83Y3c0r4OizceJy7VzM+7YhjYPgKDoWLOLyJSGLuTUh07diz0F1ZCQgInTpygZcuWLFq0yKHBFeWRRx5h+/btrF27tsC2S2O0WCwl/qItaZ8JEyYwbtw42+PExEQiIyOJiooiICCglNE7l9lsJjo6mt69e1eblRLV5+rRZyjY75SMLL7ZcpKEQoaoB3qbuK1jnXIb2VKukpIwDhyIYd06Mj/8kGU1alSra+3s97cz3lfO7rOzuFq/rSOpRUQKk5KRxZKtp8jIyiE8wIu+bWtXWELKys/LnQHta/P5xhMcOZ/KxqNxdGkQUqExiIjkZfdd86233lpoe0BAAC1atCAqKgqjsfyHf44ZM4bvvvuOX3/9lbp169raw8PDgdzRULVr17a1x8bG2kZPhYeHk5mZSVxcXL7RUrGxsXTr1q3Ic3p6euLp6Vmg3WQyucRNcmFcOfayUp+rD2u/g0wmereJKFDsPMjHRO9WYQT5eTsxyjJKSoJbboHff4fAQIytW8OZM9XyWjurz2fOpxOfngOGgn/z4tNzOJOcRfNyem9Vx+sMrtNvV4hRRJwjKyeHH3ecJjkjiyAfEwM7RGAyOqy8b6nU8veie/Oa/LInlvUHzxMe4EVkiGvO/hAR12d3UmrSpEnFbt+zZw/9+vXj0KFDlx1UYSwWC2PGjOGbb75h9erVNGyYf1JOw4YNCQ8PJzo6mo4dOwKQmZnJmjVrmDFjBgCdOnXCZDIRHR3NkCFDADh9+jQ7d+5k5syZ5RK3iDhX3WAfBneK5GR8GqmZWfh4uFMnyBs/L9ccIUXfvhdX2VuxAkv79vDTT86OrFpJySx+1cbUEraLiEj1YrFYWL3vLKcT0vFwd2Nguwi8nVzLqXXtAE7Fp7HndBI/747h7qvqq76UiDiFwz6VZWZmluvqew8//DALFizg22+/xd/f31YDKjAwEG9vbwwGA2PHjuWll16iadOmNG3alJdeegkfHx+GDRtm2/e+++7jiSeeIDQ0lJCQEMaPH0/btm3p1atXucUuIs7l5+VO83B/Z4dRasnpWZyMTyMlMwv/zDQaDR+Ccd3vtoQUnTtX+aLmjpb3NfXzcCeiDAlKX4/i9/cpYbuIiFQvO08msutUIgagT5twgn09nB0SBoOBHs1rcTohnfhUM6v3neXmNuHODktEqiGXuXN+9913AejevXu+9o8//pgRI0YA8NRTT5GWlsbo0aOJi4vjqquuYvny5fj7X/ww+vrrr+Pu7s6QIUNIS0ujZ8+ezJs3r0KmHopI1eOIJEdhTsSl2qYdGjMzuP2ZkRh3biInIBA3a0JKSiXva2plncpZN9j+aQt1grwJ8jHle568z1cnyAWnhYqISLmITUpnzf6zAHRrHEqDUF8nR3SRyejGTa3C+XzjcfadSaJxTV+CnB2UiFQ7LpOUslgsJe5jMBiYPHkykydPLnIfLy8v5syZw5w5cxwYnYhUR45KclwqOT0r3/Nmmzw43aI9oYf/ZvmsT7ixTQf8Ljv66uXS19QqPtVM9O4zDO4UaXcy0c/Lnd6twoq89i45NVRERBzOnG1h+Y4YsnMsNKzhS6f6wSUfVMHCA73o3CCYDUfiWLkvlr719UW9iFQs3TmLiJSBI5MclzoZn5b/eQ0GfnvgKbbeeg9JtSJoHp/mktMRnanAa5pHfKqZk6V8TatUrTIRESkXf8Vkk5CWg7+XO1GtwkpcEdxZrmoYyuFzKZxLzmRLrLOjEZHqxu675+Dg4GJ/kWZlqbCriFQfjk5y5JWSmYUpLYUrF77PH3c/TLaHJxgMJNWKAFRIuyzKozi5q9YqExGR8ufbqjtHk3IwGHLrSFXmIuJGNwM9W4SxeONxDifm4FWvnbNDEpFqxO6k1OzZs8sxDBER11KeK7D5mdO57bkHqLNzEwExJ1j67Kx821VIu/SqU3Hy8qpzJiIi9jmTZCYk6iEArmoYQu3Ayl9rMDzQi3Z1Atl+MoGQmx4mMyvH2SGJSDVh913q8OHDyzMOERGXUm5JjuRkGv97MMadm0jz8Wf5Tf/ifHIG/l4mPNzdqkUh7fJIqlSX4uTlVedMRETsk51jYcaa07h5+lLD20CX+iHODslu3ZqE8ndMAoTU4fMdF5jcwtkRiUh14HY5B48ePZpz5845KhYREZdhTXIUpsxJjuRk6NMH47rfMfsF8PYzb/N7cCP2xyaz+3QC7kaqfCHtE3GpfLHpOD/tOM2afWf5ccdpvth0nBNxqZf1vNbi5Jdes6pUnLykOmfJ6Zr2KSJS3j5bf4TtMWnkZKTSrbY7bm6Vs45UYTzdjVwRljvNcNG2C5xOSHNyRCJSHVxWUmr+/PkkJiY6KhYREZfh8CTHPwkp1q4lw8+fr17+iPBe19G/XW16twqjV8sw6gb5EOTt4cBeVC7lnVSxFifv27Y23ZvXpG/b2gzuFFllRhDZU+dM5FJZWVlMnDiRhg0b4u3tTaNGjZg6dSo5OZq6I1Jaxy+kMvPnfQDErf4YPw/XSUhZ1fd3I/3ELtKzLMxYutfZ4YhINXBZXw1bLBZHxSEi4nIcugLb0KGwdi3ZAYF8Ne3/ONOsHSRn2jYnAeeSMy+rgHplV57F462qcnHy8qxzJlXXjBkzeO+99/jkk09o3bo1GzduZOTIkQQGBvLYY485OzwRl2GxWHj2mx2kZmbTLtyb77cuAx53dlilZjAYiFvxAREj3mDJ1lPc07UBneoHOzssEanCLmuklIhIdWdNcnSsF0zzcP+yTwObOBHq1WP//K8407zoVW+qcmJBSZXLU52KuVd1jRo14vz58wXa4+PjadSokUPPtX79em655Rb69etHgwYNuOOOO4iKimLjxo0OPY9IVffV5pP8tv8cHu5ujLsuHHDdL+8zzxzkpmaBAEz9YbcGIohIubqsO9SkpCRHxSEiUr1dfTXs34/hQgbsOF3kblU5saCkyuWpLsXcq4MjR46QnZ1doD0jI4OTJ0869FzXXnst7733Hn///TfNmjVj27ZtrF27tthVlzMyMsjIyLA9tpZyMJvNmM3533/Wx5e2i2vQ9bPP2aQM/vvDLgAe7dGY2n4WvL29MWLBYCn4s1wSdzdyjzdQ6uPzHgulP95Ibuy9w9JYfcjAtuPxzIveTLf6fnY/R0BAADVq1CjVeSU//ey5Ll27i+x9Dcp0hx8fH8+BAwcwGAw0btyYoKCgsjyNiEj1lZQEd90FkyZBp065bR4e1Alyq3KJBXtX01NS5fJY65wVtfpeVSjmXtV99913tv///PPPBAYG2h5nZ2fzyy+/0KBBA4ee8+mnnyYhIYEWLVpgNBrJzs5m2rRp/Otf/yrymOnTpzNlypQC7cuXL8fHp/AabdHR0Q6LWSqerl/xPt7nRkKaG3V9LUQk7WHvXli4cCGQBml/l/r5GjYLpvfChbkPSnl8vmOBBukHS3d88D+xZ6VyfZgby0+68f760wSlZuNCNdurDP3suS5dO0hNtW+holLdoR45coSHH36Yn3/+2TaM02AwcPPNN/PWW285/EZJRFyHvYkHITch1bcvrF0LO3fCvn1gyi2YXtUSCyfiUovsy6UFxqta353BoXXOpMLdeuutQO691fDhw/NtM5lMNGjQgNdee82h51y8eDHz589nwYIFtG7dmq1btzJ27FgiIiIKxGA1YcIExo0bZ3ucmJhIZGQkUVFRBAQE5NvXbDYTHR1N7969MZkKX7FUKi9dv5L9vOsMW9dvw+hm4O3hV9OqdgCHDh2iY8eOPPHOEkIjIkv9nAe2/cncSaO5/+VPaNSiTZmOHTXjE7rX8+CIV2MsBmOpjx8yfiZh9Zvi4ZZFTJqBL4560jiw5MovcedOM/eFh9iyZYvDpxtXJ/rZc126dhfZuyie3Xepx48f5+qrr8ZkMvHf//6Xli1bYrFY2LNnD++++y5du3Zlw4YN1K1bt8xBi4hrKk3iodrLm5AKDITPP7clpKyqSmKhpNX0BneKLNCnqtJ3Z6rKxdyrOuuKdw0bNmTDhg0VMv3lySef5JlnnmHo0KEAtG3blqNHjzJ9+vQik1Kenp54enoWaDeZTEXegBe3TSo/Xb/CJWdkMfXH3BXqHryhEe3rhQJgNBpJS0sjG0OpEkJWWTnkHm+h1MfnPRZyjy/Nc1iP9w0NI7xeQ7rkXOD3g+fZGWfgihb1MZYwXCobA2lpaRiNRr1nHEA/e65L1w67+2/3Xf6kSZNo3rw5P//8M15eXrb22267jccff5ybb76ZSZMm8dFHH5U+WhFxWWVJPFRblyakVqyAzp0L3bUiEgvlPbqtrKvpKaki1d3hw4cr7Fypqam4ueUf/WA0Gm0JMhEp2hsr/iY2KYP6oT6MubGps8MpF+0jg9h6PJ7E9Cx2nkygfWSQs0MSkSrG7k8fy5Yt4/PPP8+XkLLy9vbmv//9r+1bNhGpPsqaeHA1l53AKUVCqiJUxOg2raYnUna//PILv/zyC7GxsQUSRHPnznXYeQYMGMC0adOoV68erVu3ZsuWLcyaNYt7773XYecQqYr2n0ni49+PADB5YGu8TKUfEeUKTEY3rmwYwqp9Z/nryAVaRQRgMmoBdxFxHLs/UZ0/f77YmlFFLV8sIlVbdUg8OCSBM3VqpUlIVdToNq2mJ1I2U6ZMYerUqXTu3JnatWtjMJRfdeE5c+bw/PPPM3r0aGJjY4mIiGDUqFG88MIL5XZOEVdnsVh44dtdZOVY6N0qjB7Nazk7pHLVOiKQTUfjSEzPYuvxeLo0CHF2SCJShdj9iSAiIoJdu3YVWTNq586d1K5d22GBiYhrqOqJB4clcKZMgUOHYMIEpyakoOJGt2k1PZGyee+995g3bx733HNPuZ/L39+f2bNnM3v27HI/l0hV8f3206w/dB5Pdzde6N/K2eGUO6Obga6NQvl59xk2HY2jbZ3AKjsyTEQqnt1jL2+55RaefPJJzp49W2BbbGwsTz/9tG3VGBGpPqyJh8JUhcSDPQmcImVkwD8rleLjA1995fSEFFTc6DbranqXvj+0mp5I8TIzM+nWrZuzwxCRQiRnZDHtx90APNyjCZEh1WNBl2bh/oT6epCRlcOmo3HODkdEqpBSFTr/6aefaNy4MXfffTctWrQAYPfu3SxYsIDw8HAN9RaphqyJh6Kmt7l64qHMCRxrDanu3XOn7pXj9JvScsToNntrbJW0ml55F1sXcUX3338/CxYs4Pnnn3d2KCJyiTm/7OdMYm5x8/9c38jZ4VQYN4OBro1D+WH7abafSKBT/WCNlhIRh7D7zj84OJg///yTZ599lkWLFhEfHw9AUFAQw4YNY9q0aYSEaH6xSHVUUuLBlZUpgZO3qPmOHTBqFBQx9bm8FJfsudxpdaWtsVXUanoVUWxdxBWlp6fzwQcfsGLFCtq1a1dgSeVZs2Y5KTKR6m3/mSQ+Wpu7OuakAa2qXVKmUQ1fQv08OJ+cydbj8VzdKNTZIYlIFVCqT4zBwcG8++67vPPOO7ZpfDVr1izXApwi4hqKSjy4ulIncC5dZS86usITUiUle8o6ui05PYsTcal8t+0UiWlm/L1MeLjnzgIvbY2tiiq2LuKKtm/fTocOHYDcmp156Z5LxDksFgtTf9hNVo6FXi3DuLFFmLNDqnAGg4ErG4SwdGcMW4/H07FeEJ7u1SsxJyKOV6Y7foPBQK1aVXuVCRERKOX0xMISUl26VGi89iZ7Sju6zZrocncz2GpJeJncaFTTjwAvk+0c9hZJr6hi6yKuaNWqVc4OQUQusXrfWX7bfw4PoxvP92/p7HCcpkktP4J9TMSlmtl+IkEr8YnIZbM7KXXjjTfatd/KlSvLHIyISGVkVwKnEiSkoHTJHntHt+VNdPl7XuxzujmHQ2eTaVU70DZiyt4i6RVVbF1ERORymbNzePGf4uYjr2lA/VBfJ0fkPG4GA10ahLB89xm2HIunQ2QQJqPda2eJiBRgd1Jq9erV1K9fn379+hWobSAiUtWVmMD55RenJ6SgfJI9eRNdnqb8N57p5hyS0s2E+nkC9hVJh8srtp6SkduHbSfiCfD2UnF0qXJ69OhR7DQ9fQEoUrEW/HmMg2dTCPX14OEbmzg7HKdrHubPH4fOk5iexc6TCXSsF+zskETEhdl9F//yyy8zb948vvjiC+666y7uvfde2rRpU56xiYi4jltvhY8+grZtnZaQAsesrHepvIkuAxDm78mZpAxbmzk7B7CvSLpVWYutn4hLJXrnKUKAtfvPYTEYVRxdqhxrPSkrs9nM1q1b2blzJ8OHD3dOUCLVVEKqmddX/A3A472b2aasV2dubrmjpX7ZG8umo3G0rROIu0ZLiUgZ2f3p5KmnnuKpp55i/fr1zJ07l2uuuYbmzZtz7733MmzYMAICAsozThGRyicpCTIyoEaN3Mf33uvceLj8lfUKkzfRdT4lk2ua1OD3A+dsiSmT0a3EIumXKkuxdes0woQ0M3krWKg4ulQ1r7/+eqHtkydPJjk5uYKjEane3ly5n/hUM83C/BjaJdLZ4VQaLWr78+fhCyRnZLH7dCLt6gY5OyQRcVGlTml37dqVDz/8kNOnT/Pwww8zd+5cIiIiSExMLI/4REQqJ2sNqRtvhH9WI60MrMmeIJ/83+SWNmmUlzXRBZBjgZjEdK5sGEL/drXp3642d3apx+BOkaUeqWSt1dW3bW26N69J37a1i30ee+pliVRld999N3PnznV2GCLVxuFzKXy6/ggAz/VrpdFAebi7udG5fu60vY1H48jOsTg5IhFxVWX+Snnz5s2sWbOGPXv20KZNG9WZEpHq49Ki5idOQM2azo7KprQr65XEz8udHi1qsuHwBRJSs/D0MILFQo7FQs+Wlzdtzt5i66Di6CLr16/Hy8vL2WGIVBvTf9qDOdtC9+Y1uaFZ5fk7X1m0jgjgryMXSErPYm9MIq0jAp0dkoi4oFJ9Qjl16hTz5s1j3rx5JCYmcvfdd/Pnn3/SqlWr8opPRKTCJadncTI+jZTMLPw83PMX0r40IbViBXTs6NyAC1GaZE9JTsSlsmrvWWITM0hKN2POziEswItbO9Sp0DpO5VEvS6QyGjRoUL7HFouF06dPs3HjRp5//nknRSVSvaw/eJ7lu89gdDMwsV9LZ4dTKbkb3biiXjBrD5xj09E4WtVWORcRKT277+D79u3LqlWriIqK4pVXXqFfv364u+sDgIhULSfiUousc1TXPbtgQqpzZydGW/6sdZziU814uLvZVtkDWLP/LLUCvCqsjpN1GmFCSnaBbWWtlyVSGQUG5h9t4ObmRvPmzZk6dSpRUVFOikqk+sjJsTB96R4Ahl1Zjya1HPMlT1XUpk7uaKm4VDMHz6agsVIiUlp2f5JYtmwZtWvX5tixY0yZMoUpU6YUut/mzZsdFpxIdVHsyJwqqLL2N28CJq/4VDOrNh5k2OSHMK77vdokpMC+Ok6OGpFVEltx9J2nIE/5qMuplyVSGX388cfODkGkWvtxx2m2n0jA18PIY72aOjucSs3T3Uj7uoFsOBLHxqMXuLG2akuJSOnYfQc/adKk8oxDpNoqdmROFVzivjL3t7gETMaZc+QcPYaxGiWkoPLVcaob7MNtHeuw5pddXNe0Bn7eXpdVL0ukMtu0aRN79uzBYDDQqlUrOlbCqcIiVU1mVg6v/LwPgFE3NKZGnhHCUrgOkUFsPhbPmcQMYgP191hESkdJKREnKm5kTlVc4r6y97e4BExSWB3+XvQdrb2zoVOnCozKuSpjHSdfz9xztqsbpEU2pEqKjY1l6NChrF69mqCgICwWCwkJCfTo0YNFixZRsxItrCBS1Sz48yjHLqRS09+T+69r6OxwXIKPhzutIwLYfiKBXRcKTrEXESlOmdY13b59O19++SVfffUV27dvd3RMItVGdVvivrL399IEjCkthbrb/rQ9dm/SuNCEVHJ6Fvtikth8LI6/Y5JITq86q8BZ6zgVRnWcRMrHmDFjSExMZNeuXVy4cIG4uDh27txJYmIijz76qLPDE6myktLNvLnyAABjezXVAhqlcEW9YAwGiEmx4BHW2NnhiIgLKdVv2r/++ov77ruP3bt3Y7Hkzhc2GAy0bt2ajz76iC5dupRLkCJVVWWbGlXeKnt/rQmY+FQzprQUbnvuAcL3bueH59/kQs+bCk3AVObpiI5gq+NURB+r0kg+kcpi2bJlrFixgpYtL6741apVK95++20VOpdq5ezZsyQkJJTpWLPZXOrRtB9vPMeFlEwiAz1o75fCgQMHynTuo0ePluk4VxbobaJZmD/7YpIIuOp2Z4cjIi7E7k8Tu3fvpmfPnrRs2ZL58+fTsmVLLBYLe/bs4fXXX6dnz5788ccftGrVqjzjFalSKuPUqPJU2ftrTcCs2niIG597gDo7N5Hu649bRLgtAZO3SLuvyciav8+Skpl/qHplmY7oKHWDfRjcKZKT8WmkZmbh4+GuOk4i5SgnJ6fQD9Mmk4mcnBwnRCRS8c6ePUuTJk1JTCxbUgqDG1js/3kx+oUQ8Z8PcDN5senjSbR97s9SHV+Y9PTUyzre1XSuH8y+mCR8ml/DiYRMmjg7IBFxCaWqKdW7d2+++uorDAaDrb1jx47861//YtCgQUyePJnPP/+8XAIVqYryjsy5VFWcGuUK/a1rymHY5Acx7txEVkAAZxZ/S4/u1+Ln5V5gVFQNPw9+P3iORjX9CPDK/wGyolemK29+Xu5Vpi8ild2NN97IY489xsKFC4mIiADg5MmTPP744/Ts2dPJ0YlUjISEBBITE3hwxjyCa0WU6tgju7ew8JWnueu5N6nXpIVdx/x5OouDCTnU8DbQ9dZbWfTK+lIdX9j5MzIyS32sK6vh50mEr4FTKUa+2HGB7tWnBKeIXAa7k1KrV69m6dKl+RJSVgaDgWeffZa+ffs6NDiRqq66TY2q9P1NToY+fTCu+x0CA3GPjqb+P9OSCyvSnmHOId2cw6GzybSqHYiHe/4yfc6ejigirumtt97illtuoUGDBkRGRmIwGDh27Bht27Zl/vz5zg5PpEIF14qgZp36pTrmwpmTAATWDLfr2AspmRzamzvlrkerOiQdii3V8UWdvzpqFWrkVEoWy/9O5ExiOmEBXs4OSUQqObs/ASYlJREWFlbk9vDwcJKSkhwSlEh1Ut2mRlXa/qamQp8+sHYtBAZCdDTkqZNXWJF2T1NuEirdnENSupnQS5aNdvZ0RBFxTZGRkWzevJno6Gj27t2LxWKhVatW9OrVy9mhiVRJfxw6jwVoVMOXiCBv9jk7IBdWy8eN9BO7oG5r5q49zIS+LUs+SESqNbtX32vQoAF//fVXkdv//PNP6tcv/TcJInJxalTHesE0D/d3foKmnDmrv8WukuflBc2aFZqQgsKLtBuAMP/cRJQ5O3/dicoyHVFEXMfKlStp1aoViYmJAPTu3ZsxY8bw6KOP0qVLF1q3bs1vv/3m5ChFqpbYxHT2xyYD0LVxqJOjqRoS//gSgPl/HCWhiFWXRUSs7E5K3XnnnYwbN46dO3cW2LZjxw7Gjx/P0KFDHRqciIijnIhL5YtNx/lpx2nW7DvLjztO88Wm45yI+6cIqZsbfPghbNpUICEFhRdpP5+SyTVNahDm74nJePHXaaWZjigiLmX27Nk88MADBAQEFNgWGBjIqFGjmDVrlhMiE6m61h06D0DzcH9qXDLiWcom7eBGGgR7kJKZzfw/q99KhCJSOnYnpSZMmEDdunXp0KEDffr0Ydy4cYwbN46bb76Zjh07EhERwYQJE8ozVhGRMimsHhRAyrk4Yp96nuTk9NwGNzdo3LjQ57AWac8rxwIxien0aFGLO7vUo3vzmvRtW5vBnSKpG+xTLn0Rkapr27Zt3HzzzUVuj4qKYtOmTRUYkUjVdjIujaPnU3EzwNUNQ5wdThViYWi73Ndz7trDpJuzS9hfRKozu7/G9/LyYtWqVbz++ussXLiQNWvWANCsWTNefPFFHn/8cTw99e2CiJS/5PQsTsankZKZhZ+HOxEl1KQqrB6UKTWZ2yb+hzo7NxGfHgefzS32nEUVaQ/wNtGlYYiSUCJy2c6cOYPJZCpyu7u7O2fPnq3AiESqLovFwrqD5wBoHRFIkI+HkyOqWro3DuCzbQmcjE/ji43HuadrA2eHJCKVVKnmlnh4ePD000/z9NNPl1c8IiLFOhGXWuTqfWF+hX+Yu7QeVN6EVLqvPzF33k2QHeeutEXaRaRKqFOnDjt27KBJkyaFbt++fTu1a9eu4KhEqqaj51M5lZCO0c3AlQ00SsrR3N0MjLqhES98u4v3fz3Ev66sh7vR7kk6IlKN6DeDiLiMoqbhxaeaid59hpSMgsXIIX89qEsTUl/P+BhD54I1pIpyuUXaiy22LiLVWt++fXnhhRdIT08vsC0tLY1JkybRv39/J0QmUrXkjpLKrSXVvm6gvlwqJ4M7RRLq68GJuDR+3HHa2eGISCVl92/g4OBgDAZDiftduHDhsgISESlKYdPwrOJTzZyKL/hBDi7Wg0o5F1cgIZXR4YoKWyWvuFFemv4nIhMnTuTrr7+mWbNmPPLIIzRv3hyDwcCePXt4++23yc7O5rnnnnN2mCIub39sMmeTM/AwutFZo6TKjbeHkZHXNODV5X/z7uqDDGwfYdfnSRGpXuxOSs2ePdv2f4vFwkMPPcTUqVOpVatWecQlIlVcaetCQcFpeJlZOSSlm8nMzsHD6EZiWmahx/l5udO7ZS0MN/+7QEKqolbJK2mU1+BOkfqmVqSaCwsLY926dTz00ENMmDABi8UCgMFg4KabbuKdd94hLCzMyVGKuLacHAvr/1lx74p6QXibjE6OqGq75+oGvLv6IHtjkli97yw9Wuizo4jkZ/cnoOHDh+d7PGbMGG6//XYaNWrk8KBEpGor64ihvNPwEtPNHDqbTLo5x9Z2PM6PosqU1g3xJe2FZ8m6byRHPlpAp85dKrQeVEmjvE7Gp9E83L9CYhGRyqt+/fr89NNPxMXFceDAASwWC02bNiU4ONjZoYlUCbtjEolPNeNtMtKxnn6uylugj4m7rq7PB78e4t3VB5WUEpECVFNKRCpUSSOGiquxZJ2Gl5mVUyAhFebvScY/j4uqLeXdvw/uRw7Tov+NZaoHdTkuHeV1qdQStotI9RIcHEyXLl248sorlZAScZCs7Bz+PJRbaqRzg2A83PVRqCLcd21DPIxu/HXkAhuPqNSLiOSn38QiUqHsGTFUFD8vd3q3CsNkNBRISF3TpAYXUnOn79lqSyUlweDBsG/fxSfxrpj6UZfKO8qrMD4lbLeHiqiLiIgUbcfJBJIzsvDzdKddnUBnh1NthAV4MeiKOgC8u/qgk6MRkcpGBUxEpMIkp2dxIi6V0wlpeBjd8PcyFfiWsqQRQ3WDfejZMoya/p5kZOXg6e6GAYhJTOef8iukmbNyE1J9+8LatbBrF+zYAUbn1Y2wjvIqLCEX5GO67GLrp+LTWPn3eRVRFxERKURmVg4bjsQBcFXDENyN+m6+Iv3n+kYs3nicX/bGsjcmkRbhAc4OSUQqCbuTUuPGjcv3ODMzk2nTphEYmP9bhlmzZjkmskL8+uuvvPLKK2zatInTp0/zzTffcOutt9q2WywWpkyZwgcffEBcXBxXXXUVb7/9Nq1bt7btk5GRwfjx41m4cCFpaWn07NmTd955h7p165Zb3CJysY6Uu5uBo+dTMQCB3iYCvN0xGAy2JJU9I4a8TEbOJeeOikrK025dz8U3Iw36DspNSAUGwiefODUhBRdHeRVVS+typxKu3BtLfHpOvjYVURcREcm17UQ8aeZsAr1NtKythEhFa1TTjz5twvlpRwzvrznE63d2cHZIIlJJ2P0pZcuWLfked+vWjUOHDuVrK+8lPlNSUmjfvj0jR47k9ttvL7B95syZzJo1i3nz5tGsWTNefPFFevfuzb59+/D3zy0gPHbsWL7//nsWLVpEaGgoTzzxBP3792fTpk0YnfyhVaSqyltHqqafB+EBnqRkZHP4XAoZWdnU9PfC6GagXogPnqaSf48UN+rIPS2NJvf+C9avy01IRUdDly7l0a1Sqxvsw+BOkZyMTyM1MwsfD3eHFVtPSDODoeDvMBVRFxGR6i4zK4fNxy6OkjK6le9nFincQzc04acdMXy37RTjejcjMkQjuUWkFEmpVatWlWccdunTpw99+vQpdJvFYmH27Nk899xzDBo0CIBPPvmEsLAwFixYwKhRo0hISOCjjz7is88+o1evXgDMnz+fyMhIVqxYwU033VRhfREpreT0LE7Gp5GSmYWfhzsRFbhy3OXKW0fqfEomvVuF8cWmE7bi3xlZ2TQM9aVz/WDW7DtLjSu88PNyL7LPRY06CrVkcPXUqbjv2VPpElJWfl7uFZ4gUhF1ERGpzrafiCfdnEOQt4nmYfqSxlna1g3kuqY1+G3/Of7vt0NMuaWNs0MSkUrANT7R2uHw4cPExMQQFRVla/P09OSGG25g3bp1jBo1ik2bNmE2m/PtExERQZs2bVi3bp2SUlJpWae+OaJekDOSW3lXnsux5I7qqRfsQ8vaAZizLdT088DP052YxHRyLLlJLF9PY7F9LmzUUYMXxuO5Zw+WwEAMlTAh5SyOKKIuIiLiijKzctj0zyipKxuG4KZRUk710A2N+W3/ORZtOM6Ynk2p4efp7JBExMmqzCeVmJgYAMLCwvK1h4WFcfToUds+Hh4eBZZWDgsLsx1fmIyMDDIyMmyPExMTATCbzZjNha8iVllZ43W1uC+Hq/c5JSOL6J2nSEgzk/c2KiElm+idp7itYx18PfP/KBfV51PxaazcG5s71esfgd4mbmxRi4jLLLRdHC83MFiybY/TM8wcOpt4Md6afoT4egC5daHiklJZtz+pxD5nZWWRnZVFdnYWOVmQ/NxEEv76k4A5czB26ACV7JqnZGRxKj6dVHMWviZ3agd5Fbh2pWW9xoFebiSkZxfYHuhtIszP3WXf/4Vx9Z/psqiOfQbX67erxClSnWw/mTtKKlCjpCqFro1DaV83kG0nEvhk3RGeiGru7JBExMmqTFLK6tK6VhaLpcRaVyXtM336dKZMmVKgffny5fj4uOZc6OjoaGeHUOFcuc8h//wrIA3W/LKryOMK63OB50qDret2sfWyIixZw0vOOSRf/vgcpF18dGa3/X02ZGdj+ace3N8AU6bAhQvw008Oirz8/O3A5wqJ21um94grc+Wf6bKqjn0G1+l3amqqs0Mok5MnT/L000+zdOlS0tLSaNasGR999BGdOnVydmgilyUrBzYfjQdya0lplJTzGQwGHuremAfnb+aTdUcYdUNj/C7zCzoRcW1V5jdAeHg4kDsaqnbt2rb22NhY2+ip8PBwMjMziYuLyzdaKjY2lm7duhX53BMmTMi3+mBiYiKRkZFERUUREOBaq3eYzWaio6Pp3bs3JpPJ2eFUCFfv87YT8azdf67I7dc1rUG7ukH52grr8/4zySzfXfSIwKhW4TQN83NIzIWNyHI3QmSwL0fPpxDi48Gmo3EkZphpEOqHv5c7bgYI8fHA05S7Ct/Z5EwMFgsXUjPJseR//hua1WTr8XhSz8dz6wujOHBtb7YMGo7Bkk2D9INcc8ONBPp6OaQvjpCSkcU3W07mez2sAr1NhY52s1fea52ZY+BUfDpp5iy8Te5EOGAkVmXk6j/TZVEd+wyu12/rSGpXEhcXxzXXXEOPHj1YunQptWrV4uDBgwQFBTk7NJHLdjTV3bbinkZJVR5RrcJpVNOXQ2dTWPjnMR64vpGzQxIRJ6oyn1YaNmxIeHg40dHRdOzYEYDMzEzWrFnDjBkzAOjUqRMmk4no6GiGDBkCwOnTp9m5cyczZ84s8rk9PT3x9Cw439lkMrnETXJhXDn2snLVPvt7e2EpZFU1Kz9vryL7lbfP6TkU+zwZOdj9+hRXlyo5PYuVf58nPj0n32pw5hw4k2Qmqk0d0s3ZtIkM4a/DF0jJzMZggLAALzYejcPPyx1zVg77Y5MJ8/fkmiY1bLWmrNKzIeVCIrc9/yB1dm0m9OgB9tx4C+n/fIiKTc6iRlDludZnzqcXeD2s4tNzOJOcRXO/y5s+aTKZ8DGZCLrM53ElrvozfTmqY5/BdfrtCjFeasaMGURGRvLxxx/b2ho0aOC8gEQcxGDy5FBK7s+kaklVLm5uBh68vjFPfbWd/1t7iH93q4+nu1ZBF6mu7EpKbd++3e4nbNeuXZmDKUlycjIHDhywPT58+DBbt24lJCSEevXqMXbsWF566SWaNm1K06ZNeemll/Dx8WHYsGEABAYGct999/HEE08QGhpKSEgI48ePp23btrbV+EQqmzpB3gT5mPIV/LYK8jFRx85aUL4lFLu2txh2SUXX8660d6ncBJSBDvVyRyo2qeXPyfg00s3Z/LLnDDX8PPFwdyMzKwcvkxtnkjL4/cA5rmwYwtnkTNu53FOSuW3if6izcxPpvv58/fJc0oJDbXWrMrKy2ReT5JBi7o4oDJ9Swup3Wh1PRJzlu+++46abbmLw4MGsWbOGOnXqMHr0aB544AFnhyZyWfw79iMzx0Cgt4kWGiVV6dzSMYJZ0X8Tk5jOki0nubNLPWeHJCJOYtcnqw4dOmAwGOyqz5SdXbDQrqNs3LiRHj162B5bp9QNHz6cefPm8dRTT5GWlsbo0aOJi4vjqquuYvny5fj7X/xD9Prrr+Pu7s6QIUNIS0ujZ8+ezJs3D6NR2XmpnPy83OndKqzIRJC9CRJHJLeS07MKxAEQn2omevcZBneKLFUCxs/Lnebh/uyLScJgMODhnvv7xcPdjUY1/Th0NpkzSRlYB0kF+ZiIivQhePBt+FgTUjM+5mzzttT09chNSqXBz7tOY3Az4eHuZjuuLCsVOmrVQ0clBEVEHO3QoUO8++67jBs3jmeffZa//vqLRx99FE9PT/79738XekxpFoBxtWL1kp8zr192djbe3t4YseRbLMUuBgi86nYArmwQhNGQA5YSjsnD3Y3ccxso/bmdfHzeY+Hyji9L7EYseHt7k52dXez7xg0Y2a0e05f9zburD3JLu3CMGs1mo9+drkvX7iJ7XwODxWIp8Ve0dfU6gC1btjB+/HiefPJJunbtCsD69et57bXXmDlzJrfeemvZInYhiYmJBAYGkpCQ4JI1pX766Sf69u3rktMMyqKq9Nk6Yic1MwsfD3fqFDNip6g+n4hLZcPhCyRnZJFhzsHTw4ifh5EuDUPsSrLsi0nipx2ni9zet21uPbeS9mkenv8by83H4liz72yBfTOzckhKN3Nd05o0qOFLHWMWfoMGwtq1ZPj589XLuQmp8AAvfj9wjmBvI1e4HWHR6VA8PEw0qulHgFdu/4N8TAzuFGl3Ei85PYsvNh0vMonnrOe6VFV5f5eG+lw9+gyu129XvD/w8PCgc+fOrFu3ztb26KOPsmHDBtavX1/oMZMnTy50AZgFCxa47AIwUrWsPGXg26NGanhaeLZjti1BI5VLejZM2WQkNdvAyGbZdAgtReZQRCq91NRUhg0bVuJ9kV2fgurXr2/7/+DBg3nzzTfp27evra1du3ZERkby/PPPV4uklIgzWEcVXa6zSRkcu5CKOTsHk9GNeiH2f4CwZxRU01r+pR6RVdRIIg93N0L9PGlQwze37/Pnw9q1EBhI/Nc/kOFZh1A3A78fOMeZpAwahAZAem6tgnRzDofOJtOqdiAe7m7Ep5o5GZ9m92tY3DTE0j6Xo0a7iYg4Wu3atWnVqlW+tpYtW/LVV18VeUxpFoBxtWL1kp8zr9+hQ4fo2LEjT7yzhNCISLuPM2fnsPTYIQDqemdyzKdlqc99YNufzJ00mvtf/oRGLdq41PHWY0fN+ITu9Tw44tW42Jqijjw3wPlTx3lt9K1s2bKFRo1KLmB+zOcAb68+xF/JQUy4++oSZ+VUF/rd6bp07S6ydwGYUn8S2rFjBw0bNizQ3rBhQ3bv3l3apxORCmKdepeSmU2o38XC/SmZ2bapdyUlR+yZhlaWBIzdUwvvvhvOnoXrriOsc2cGp2ex42Q8O04m0LSWH36eJki/eGy6OXeklbW/pand5Og6UHWDfRjcKdLu0W4iIhXhmmuuYd++ffna/v7773xfSF6qLAvAuEqxeimcM66f0WgkLS2NbAylSqpsP5lIpsUNc9xpaocHlupYq6wccs9tKX6RmMp4fN5jIff40jzH5caejYG0tDSMRqNd75l7r23E3N+PsutUEr8djKNny7BSn7Mq0+9O16VrZ/8CMG6lfeKWLVvy4osvkp5+8ZNfRkYGL774Ii1blv6bCBGpGPaM/CmJNXlUmLzJI2sCpm/b2nRvXpO+bWszuFNkkVMErYmsS587yMdEVD1f/DJTLzY+/jh07mw7ztNkJDzQm1A/T7xNBW+ezNk5tv+XpnZTedSBso5261gvmObh/kpIiYjTPf744/zxxx+89NJLHDhwgAULFvDBBx/w8MMPOzs0kVIzZ+ew8WgcAAnrF6MSRZVfqJ8n/+6WmwSfFf03dlSWEZEqptSfiN577z0GDBhAZGQk7du3B2Dbtm0YDAZ++OEHhwcoIo7hiJE/pRkFVdrphoWOJHLPxu+2AZCTA0uXQiFzkfMmjwq79zQZLxY7t3elQnDcqociIpVZly5d+Oabb5gwYQJTp06lYcOGzJ49m7vuusvZoYmU2o4TCaSZs/F2yyZl1yrgP84OSeww6vrGzF9/lF2nEvl5Vww3t6nt7JBEpAKVOil15ZVXcvjwYebPn8/evXuxWCzceeedDBs2DF9f3/KIUUQc4HJH/lgLradkZtGlfgjuRgPp5my8HTgNLV8iKzkZ+gyw1ZDiyBFo167AMXmTRxdSM/EHavl5cirJjJfJDX8vU5lqN6kOlIhUF/3796d///7ODkPksuQdJdXYK5W9OeW3Irg4VoivB/de25A5Kw/wevR+olqF46ZhbiLVRpk+Vfn4+PCf/+ibBxFXcjkjf07EpRaZnLFn1b5SS06GPn0uJqSiowtNSEH+5FFCSu4NaKf6wXTzNBEW4EVYgHeZk2aqAyUiIuIadpzMHSUV4OVOhEd6yQdIpXL/tY2Yt+4I+84k8eOO0wxoH+HskESkgpS6phTAZ599xrXXXktERARHjx4F4PXXX+fbb791aHAi4jjF1W0qbuSPtUD6pcms+FQz0bvPkJxeuoLfJSosIdWlS7GHWJNHUa3CAbiifgh92kRwfbNal127SXWgREREKjdzdg6b/hkl1aVhiGpJuaBAHxP3X5u7Wt/sFX+TnaPaUiLVRamTUu+++y7jxo2jT58+xMXFkZ2dOzIhODiY2bNnOzo+EXGg0hYgB8cUSLdbGRJSVn5e7jQN8wOgaZifkkciIiLVxI6TCaRm5o6SahlesP6kuIZ7r21AoLeJg2dT+G7bSWeHIyIVpNRJqTlz5vDhhx/y3HPP4e5+8UNf586d2bFjh0ODE5HSS07PYv+ZZAAOnEkuMJKpqJE/yelZ7ItJYvOxOP6OSbId54gC6XY7dQr27St1QspZinrNREREpGLkGyXVIASjhkm5LH8vE/+5Pne01Bsr9pOVZwVlEam6Sj2U4PDhw3Ts2LFAu6enJykpKQ4JSkTKxlr7KSElnYbAz7tjCPSNL7H2U3E1o0pTID1vMXQ/D3ciSlt/qVkzWLUKUlMrfUKqwutsiYiISAE7846Sqq1RUq5uRLcGfLT2MEfOp/L1lpMM6Rzp7JBEpJyVeqRUw4YN2bp1a4H2pUuX0qpVK0fEJCJlUNbaTyUdF+LrUaAOlVXeAukn4lL5YtNxftpxmjX7zvLjjtN8sek4J+JSiw88KQn++utiPI2bsy+yRaUefVThdbZERESkgKw8K+5plFTV4OvpzoM3XBwtlW7WKooiVV2pk1JPPvkkDz/8MIsXL8ZisfDXX38xbdo0nn32WZ588snyiFFE7FDW2k8lHXchJbPEAunJ6Vn8sucMJjcDNfw88Pd0p4a/JyY3A7/sKSZJk5QEfftCjx6wenXZE1sVrELrbImIiEihrLWk/DVKqkr5d9cG1A704mR8Gh//fsTZ4YhIOSv19L2RI0eSlZXFU089RWpqKsOGDaNOnTq88cYbDB06tDxiFBE7lLX2kz3HNQ/3Z3CnSE7Gp5GamYWPhzt18kzNOxmfhpe7kd8PnONMUobt2DB/T65pUoOT8Wk0D/fP/8TWhNQ/Rc1T3T2LHX00uFNkpSleXqF1tkRERKSAvKOkrtQoqSrFy2RkfFRznvhiG++sOsCdXSIJ8fVwdlgiUk7K9AnvgQce4IEHHuDcuXPk5ORQq1YtR8clIqVUXO0nNwN4m4zsi0kqUO/J3ppR1gLpULB2VKY5mz8Onc+XkAI4k5TB7wfO0eLSby8vSUgRHc3xyBbE7zhdaAzW0UcFElt2uOw6V4UoTZ0tERERcTyNkqrabutYh4/WHmb36UTe/GU/kwe2dnZIIlJOSv3J6cYbb+Trr78mKCiIGjVq2NoTExO59dZbWblypUMDFBH71AnypkGoD8kZWWRmmiENavh6EJeeTb1QX379+ywpmRfn5Vun39UJ8ibIx1TodLS8NaOsCivwnWbOIiLImzNJGWTnWPLtfyYpI//IoUISUnTpQsqxuGL7V9Loo+T0LI6du7jqYGQNf+LTMsulGHlpXzMRERFxnCytuFflubkZmNivJcP+70/m/3GU4d0a0LCGr7PDEpFyUOqaUqtXryYzM7NAe3p6Or/99ptDghKR0otPy+REfCor9pxh5b5YADYdjaN5WAAn4lLyJaTg4rQ4oNCaUb4eRjpGBrE/NslWcLyoAt8XkjPZdCyOxoXcLHiZ3DAa/rlZTE4uNCGVe76yjz6y1qJavjsGyF11cMGfR9l0NI7ENMcXI/fzci+xzpaIiIiUj52nEkn5Z5RUK42SqrK6NalBj+Y1ycqxMGPpXmeHIyLlxO5PTtu3b7f9f/fu3cTExNgeZ2dns2zZMurUqePY6KTaKo8pV1WZNVmUlQ2tageSkp4BnMPf28S2E/HUDvTibHLBZHLeaXF5a0Zl5+Rw/EIaa/4+i3XgU5CPibZ1AgodHeRlMpJuzibQ13RJuxuNavoR6PNPHQBPT6hZs0BCCso++ihvoizv96THLqSy82QCVzYMKdD3y5kOaFU32KfYOlsl0XtcRESk9LKyc9h45AIAXeprlFRVN6FvS9b8fZZlu2LYeOQCnRuEODskEXEwuz8BdejQAYPBgMFg4MYbbyyw3dvbmzlz5jg0OKmeCpse5ogpV1VZ3tXgPNzd8PT1gDQI8fXgVGIG4YFeRR5rnRZnrRmVnJ7FF5uOF1pwfM/pJDKzcvBwzz/I0t/LRKC3CX9PE01r+WHOzsFkdMPfy0StAM+LCSWTCRYvhoMHoUWLfM9hHX1U1LUvKmFT1Ep4mdk5nEnKwFLIMXn7fTny1tkqDb3HRUREysY6SsrP051WERolVdU1C/Pnzi6RLPzrONN+2sPXD3XDYFAiUqQqsTspdfjwYSwWC40aNeKvv/6iZs2atm0eHh7UqlULo9FYLkFK9VHU9LDKuAJbZVLcanAeRjcysnKK3H7ptLiikjxWSelmQv0885/DPXdEVIividTMi9uCfExERfrg995b8Oij4OaWm5i6JCFlVZbRR0X13cOYmzgrqu/OKkau97j8f3v3Hd9U1f8B/JOd7pbuRSmUPctQgQfZGwRxgILCT3CAiAouXAwfxYXiQkEZ+jhwMFRApMieYocUyioFugelu02bcX5/lIamA5q2NE3yeb9eVXLvPTffk5s2J997BhER1U/5invlvaS44p79eHZYO/wak4roxFxsPZGG8d0DLB0SETWiOn/zCQkJAQAYDLV/uSVqqBslRBpjyJWtutF8TOW9mOQoqGEOpZqGxd0owSUB4OqgqHFfyxaOGNTeF1eLyq4nlGQ6OE+6Czh4EGWXk3DxxcUoKtNBKZVCLpOgRKuHU5Wha+b2Pqqt7i5qBdQKKVRyKQrqUO+mwvc4ERFR/ZxKzUdRKXtJ2RsfVzUev7MNPtx1Dv/dFofBHXzgrOINPCJbYfZv87Jly+Dr64tHHnnEZPvatWuRlZWFF198sdGCI/tzo4QI0DhDrqxZbfMQVZ2PSXutd1BGvgY+ro4ID/ZAYemVOg2Lu1GCK7uoDCM6+SI6KbfGc3m7qODtcq2nVEEBMKY8IWVwdcOfnQcgPjYN+RotErIK4aZWoH+YF9LzNXB1qP/QtdrmolLKpejdygPOKjmuVJpTytKTkfM9TkREZD6d3oDj13pJ9WnlwV5Sdubxga2xKToZl7OLsSLiHF4d18nSIRFRIzH7W9mqVavw/fffV9veuXNnTJkyhUkpapCGrMBm6242D1HFfEyJV4uReCUf7VoAmjI9AtwdcCThCgZ38EapVtx0WNyNJhx3dVAgzMcFYT4uNx5iV1BgXGVPuLlh2/vrER/SCWU6AxKyCqHRGqDRluJQ/BXjROT1HbpWeS6qvKLrKwxWvDbuDsp6T0Z+K/A9TkREZD72krJvaoUMS+7qjBnrjmPd4Uu4p1cQOnLlRSKbIL35IabS09Ph7+9fbbu3tzfS0tIaJSiyXxUJkZpYcsiVpd1sHqJCjQ5BHo4Y1y0Anfxd0K+NFwCgV4gH0vM1uFKoxc6TGRBCQAC40b3FiiRP1etQuYdRxRC78JYexqFmZ9MLEJWYg/PxqdCPGg0cPAi4uSFxwxbEh5TfzSrQaKHRXh8CXHki8oqha/VRMRfViE5+AIARnfxwX69gBHk4VovV0vM18T1ORERknvK5pHIAlPeSkkvN/gpDNmBQex+M6eoHvUHg1S0nYTDUtpwNEVkTs7+dBQcH49ChQwgNDTXZfujQIQQEcNI5apj6rsDWHNU21K4+6joP0dWiMiTnaCARengBuFJUBiGRIV+jRUxSDhyUMuNQthut9mbOhOMmPbiEwL0vPAzZv3/D4OoGaUQEsn3DgLNZAMpXxKuq8kTkDRm65qyWo62vM84DaOvrDIWieb5XbOk9TkRE1BROpeajsFTHXlKE18Z1wr6zWYi8nIOfI5MwuU9Lk/1ZWVnIy8ur9/nd3NxMFvRqahXx6/Xlvf8TEhLqvJiYpWMnqi+zv/3MmjULzzzzDLRaLYYMGQIA+Ouvv/DCCy9gwYIFjR4g2Z/6rMDW3NxsqJ256joPUU3HVR4yVzkBdLPV3uoy4Xi1HlwSCf4d/yA8L53HX++vxeCu4XCq1PupYkW8yipPRG4vQ9ds4T1ORETUFPQGYewl1Zu9pOyev5sDnh3eDv/ddhrL/jiD4Z380MJJCaA8oRMW1hb5+fVPSrm6uiE+/rxFkjuV43dwcMAPP/yA8PBwlJTUbSSBJWMnagizvwG98MILuHr1KubMmYOysvIeF2q1Gi+++CIWLlzY6AGSfTJ3Bbbm5GZD7eozb1Jd5yGq6bjKQ+aqrkTX0NXeaurBdf7O0bjcawDKnJzRLrfEZI6qihXxKuLxdVEZhxLa29A1a36PExERNZULeQYUXptLqjN7SRGA6f1a4ZfIZJxJL8C7O87g7Xu6AQDy8vKQn5+HJ95ZDw8f80fw5GSm4osXZyAvL88iiZ3K8Xv5+AMowYKVW6C/4cQb5SwdO1FDmJ2UkkgkeOedd/Daa6/h9OnTcHBwQNu2baFSqW5FfERWp65D7cxxo8nHKydzKo6rPOF3xZC5ygmgyswdMlcxLFGj1SOrQIMAaRlue/91RD+2AEku3jAIoMzJ2XjuqsPVWns7V1t9j0PXiIiIqBqZHHHZ5W0a9pKiCgqZFP+d2AX3fnEEG44n4e7wQNze2tO438MnAN6BIRaMsGE8fALgGRAElJyDZ0AwhKRuw/eIrFW9vwE6OzujT58+jRkLkU2o61A7c9R1HiLjcSdTgWs9fZUyKXxdVMYEUFXmDJlLzinGX6czoJbLcCj+CtJTsvDa588j9GIs5GdOQ7thB9ILSlEx72TFuasOV5NLpVDIJNBo9ejR0oND14iIiKga567DUawDe0lRNb1btcCUPsHYcDwJL2w8gT+eHmDpkIionur0LXDSpElYv349XF1dMWnSpBseu2nTpkYJjMha1XWonbkTodd1HqIgD0fcHR6IfX+dwoC2XlAqlIjPLEDi1WJUXaTEnCFzFcMSJQLYdToDV9OzsXT1i+h8MRaFaiesfeglZF/Ixm2hLZBVWFbt3ByuRkRERHVVpjfAre/9AIDeIewlRdW9PLYj9p3LwuXsYrz351lM7ciRO0TWqE5JKTc3N0gkEuO/iah2dRlqZ85E6FWTV3XpVeSkKt/fLcgdCoUCHk4K5JZoG7TaW0puCRKvFsNJJcOlS+l4f/3L6HzpJArUTnjh8eXQhHZEcUEpRD3OTURERFTZjrN5kLt6w0EO9pKiGrmqFXj7nm6YvvZvrD98CV3dgy0dEhHVQ52+Ma5bt67GfxNRdTcbagegzhOhV01eSSVAyxaOCG7hAKlUWqceVkDjrPaWW1yGhKxCdHKW4v31L6P7tYTUMzPfxTn/tghXyeHjokKAuwNuD/VkQoqIiIjqpVSnxw//XgUAdPKUQV7D6r1EADCwnTcm9w7Gj/8k4d196ZAozV/lmogsi98aiW6BGyWBzqYX1Gki9Kqr+EklgJ+rGnvOZCJPo0Unfzco5dJae1hVqNrTqq2PS70SRgYhoNEaMPqrd9CtUkLqTFB7QAgo5FL4uTkgyMORCSkiIiKqt5//SUZWkQ66gmyEtfOzdDjUzL06riMOJ1xB0tUStBj+hKXDISIz1embY3h4uHH43s1ERUU1KCAiW1HbHEp1nQi96ip+nk5KHIq/goyCUgBAgUYLT2dVjT2sKqTmluDPuCwkXi1Gmd4ApUyKli0cMaabf61JrNo4KuXwdVHhjylPQXkhHu+NfgJngtpDIpHA31UNg0FAqzcAQqBQozOJxdz5s4iIiMg+lekMWLknHgCQf/RnyPrMs3BE1Ny5qBVYMbkH7vviCJy7DMGlPD28Ay0dFRHVVZ2+FU6cONH4b41Gg5UrV6JTp07o27cvAODo0aM4deoU5syZc0uCJLIldZ0IvWrySgDGhBSA8gTQNZV7WFX2+4kUHL+cD422/FiZVAKlXIJ9ZzMR5uMCD0dl3RJEBgPUChn6h3nhaIIEv3/6I/Iv5UCSr0FIC0fklWhRWKpDSAtH7DiVDleH6723zJk/i4iIiOzbz5FJSM3TwNNRhsv//gmASSm6uV4hLTC1hyf+F52N4xl6tG1VBndHpaXDIqI6qFNSatGiRcZ/z5o1C/PmzcMbb7xR7ZikpKTGjY7IBtVlInSgevKqVGsweayoMr9CcQ09sKITc6G59jQyqQThwe74++JV/HU6E/3aeMHHVX3zBFFhITBuHEKmPYyjnQajV4gHJBJgiq8zVDIZLmQVokSrh7NKjrjUfDiq5DCI8t5b47oF1Hn+LCIiIrJv5b2kLgAApnT3RJS+5ukOiGoyLdwTX/6+HwjqjO0n03F/ryDOR0ZkBcz+Lf3555/x8MMPV9s+bdo0bNy4sVGCIrJlFROhuzsqTLZXXbGuInlVQaW4/uuqVkjhojYt71hDDyxNpURWGy8n/H3xKlLzSqAzCGNPrIoEUaGmhmGFhYXA6NHAvn1Qv/g8hgWooDUIZBaUITG7BOn5Gvx5Kh3xGYU4eP4KzmQUIC4tD/ma8pX+4jNvPn8WEREREQD8EpmMlNwS+LioMLY9V/wm88ikElz57V2oZEBWQSn2nc+ydEhEVAdmd1FwcHDAwYMH0bZtW5PtBw8ehFqtbrTAiGxZXVbDq7qKnwSAr4sKeRotWns7Qym/nqSq3MOqNk5qOVLzrieBpJXmiatx+F9FQurgQcDNDdixA4GtAnCfX/n8UHnFZbh4pQi+rmoUluogrhXTaA3lq/T5uyG/pHqiq0xnQIFGizK9ASk5xWavAkhERES2p0xnwGfX5pKaPagNlHK9hSMia6QvyEa/ADn2JOlwMiUf/m4O6OTvaumwiOgGzP4m+Mwzz2D27NmIjIzEHXfcAaB8Tqm1a9fi9ddfb/QAiWxVbROhV1Y5eVVSpkOXQDf8ffEqisquN9Sq9rCqzMdZhdSC8p5KWr0wbndSyuGkMj3eZPhf1YRURATQp49J3GfTC1CmL0BxWfVGo0ZbnnhydTB9jnyNFglZhcYeXCm5Jfg5MonzSxEREdm5jVHlvaS8XVR44LaWSL580dIhkZXyd5Li9tAWOHbxKnafyUQLRyX83Nh5gqi5Mjsp9dJLL6F169b46KOP8P333wMAOnbsiPXr1+P+++9v9ACJ7F3V5FWYj8sNe1hVNqiDD/46U75in0JW3jPKSSlHa28nuNY2/O8GCanKisp0xt5blSdgr+DqoECYjwvOpJcP4SvTGUwSUr4uKkjA+aWIiIjsXZnOgE93X+slNbAN1AqZhSMia3d7aAtcKSzFhawibD2Riim3tYSziu1MouaoXr+Z999/PxNQRI2kUFM+HK6oTAdnpfymq+HVpYdVhR7B7jBAisJSHZzUMkxRBkNvEFDKZXBxUEAiBLKLyuDqUGn437ff3jQhBZQnt7KLytA/zAuH4q+YJKZ8XVQY0ckX3i4q4xDEC5mmCan+YV5Iz9cAqH31QCIiIrJ9lXtJPXh7S0uHQzZAIpFgRCc//PRPErKLyvD7v6m4t1dQtYWCiMjy6pWUys3NxS+//IKEhAQ899xzaNGiBaKiouDr64vAwMDGjpHIZiXnFFdbne6mq+GZIcDdAZ4ujuVzQJWUIT6jCCeSc41D+XxdVBjayRe9QjyuJ8IefxxITwfGjq01IQWUT8Tu6qBAer4Gt4W2gABQqjNAJZfCWSVHmE95gqliCGJk4lW08nKCSi6FBEB6vgaG6yMKa1w9kIiIiGxb5bmknmAvKWpESrkU47r546d/kpFZUIo/TqZjXFd/SKWSmxcmoiZjdqr4xIkTaNeuHd555x289957yM3NBQBs3rwZCxcubOz4iGxWoUZXLSEF3GQ1vHpwVpcP8TuVmg+FTIquge5o6+OMVp6OcHVQICNPA3d9GaAp77UEiQRYvPiGCamK8w7v5AtXBwWyCstwpbAMBRoddAaBPqEtqk3a7ufqgAKNDlcKy5BVWGaSkAJqXj2QiIiIbNumqGQk55T3kprKXlLUyNwdlRjf3R8yqQQXrxRh77ksCCFuXpCImozZ3wLnz5+PGTNm4N1334WLy/WhNqNHj8aDDz7YqMER2bKU3JJqCakKjTWc7XxGITQGoFSrR2Z+KZRyKZRyKTydVcZjynLzIB37ENDCDdi8GTBjFc26rCJYIdDdAe6OihrrXJfVA4mIiMi2aPUGfMpeUnSL+bs5YFRnP2yLTUNsSh4cFDL0beNp6bCI6Bqzk1LHjx/HqlWrqm0PDAxEenp6owRFZA+KbjJcrSHD2VJzSwAAO+PSISQyuKjkiEvLQ2tvZ5MJzhXFhbj71cfgeDKyfA6pCxeAzp3Neq66znFV0bOqtuGKnOSciIjIvlT0kvJyZi8purXCfJwxuL039pzNwt+XrkIhl6B3SAtLh0VEqEdSSq1WIz8/v9r2s2fPwtvbu1GCIrIHTjcZrlbf4WyFGl358reVtqkUUmi05avfdfJ3g1IuhaK4EBNeeQyBpyKhc3FFyoYt8GzTHs71eta6MadnFREREdkurd6AT3ZX9JJqzV5SdMt1C3JHmc6AQxeycSg+G3KpFD2C3S0dFpHdM3tOqQkTJmDp0qXQast7OkgkEiQmJuKll17CPffc0+gBEtmqiuFsNWnIcLbySc1Nh8hJUD6puUZrQIFGC0VxIca//CiCT0Wi2NEZER9+g02yAPwcmYTknOJ6PW9dVfSsCm/pgfZ+LkxIERE1I8uWLYNEIsEzzzxj6VDIxm2OSqnUSyrE0uGQnejdqgX6tPIAAOw7l4WoxBwLR0REZiel3n//fWRlZcHHxwclJSUYOHAgwsLC4OLigjfffPNWxEhkkyqGs1VNTDV0OFtNwwKzi8rQP8wLvi4qSAoLMOGVxxASF4ViR2cc+ux7nAvpCODmk6wXanQ4m16AqMQcnEsvaLTJ2ImIyPKOHz+O1atXo1u3bpYOhWycVm/AJ3vOAyjvJeWgZC8pajp9W3saE1MHzl/B35eucvJzIgsy+1uvq6srDh48iN27dyMqKgoGgwE9e/bEsGHDbkV8RDbtVgxnqzossExX3jsqPU+DDv6u6JufC//L51Dm7IJ9K/6Hc0HtTVbCq22S9eSc4lrngwrycKx3vEREZHmFhYWYOnUqvvzyS/z3v/+1dDhk436JTEbSVfaSIsuQSCTo29oTUokExy5exZEL2dCU6dHBkYkpIksw65uvTqeDWq1GTEwMhgwZgiFDhtyquIjsRl0nCq+rQHcHuDkogBKgQKND/JViaLQGAEBRqQ7+HdoBazbgdGYxMlp2BGr4/K06yXqhRlctIQVc71l1X69gDsMjIrJiTz75JMaOHYthw4bdNClVWlqK0tJS4+OKuUa1Wq1xeocKFY+rbifrcCuuX5nOgE/+Ku8l9diAVpBLDNBea6dUptfr4eDgABkEJEJv1nPIpSgvK4HZZa29fOWyQMPK1yd2GQQcHBxw6dIl6PXmlwfK328KRc1TXNxIUlJSnd8zEgB9Q92hlAEH4q8iOikXOa4SODi7QK/XW+RvVk3v+bpeg4rX3VKx03X83Luurq+BWd8i5XI5QkJC6v0HhsiaFWp0SMktQVGZDs5KOQKa6QTdzmo5hnTwQczhU7iUXQiNFlBritChJButw/si8WoxdK27IMmlGMpazlF1kvWU3JJqCakKtfWsMpe1vL5ERLZmw4YNiIqKwvHjx+t0/LJly7BkyZJq23fu3AlHx5p7zkZERDQoRrKsxrx+B9MlSM2TwVUh4JF9Ctu3n6r12B9++AFACVByzqznCG3ngeE//FD+wMyy1l7epCyAVpoLTfbcABDqUX7dioqKcObMGbPLN5S575lQbyAEEnx/QYpL+UDfl77HP7FnLBI7UCn+a9etrtev4nU/c8ZysZMpfu4BxcV1m6vY7G98r776KhYuXIhvv/0WLVpY7zKaK1euxHvvvYe0tDR07twZK1aswIABAywdFjVT1jZ0LcDdATEABrXzgaGwCKNenAf3hHPY5LoOhrZdUKo1QFFxC62KmiZZr2meqsqq9qwyl7W9vkREtiIpKQlPP/00du7cCbVaXacyCxcuxPz5842P8/PzERwcjBEjRsDV1dXkWK1Wi4iICAwfPrxePR/Ishr7+pVq9Vi24iCAUjwzoiMm3tGy1mMTEhIQHh6OBSu3wDMg2Kznif/3GNYumoNZb3+N1h26mB2nNZevKPv4O19jUEslLqnbQEjqPmdXY8V+/3PvIrh1O7PLXz57Ar989Hq9yleUNTd2r5bABKdibI1Nx4UCCT4+o8aa6X0adSRDXVR+z3v5B6CV5kKdr192ahKWz5mI6OhotG7dugmipdrwc++6ip7UN2N2Uurjjz9GfHw8AgICEBISAicnJ5P9UVFR5p6yyf3444945plnsHLlSvTv3x+rVq3C6NGjERcXh5Yta/9wJPtkzUPX8rNyMPG1J+B7MhIaJxcIQ3n3+OyiMvynrRdOpebXmAiqWp+q81RVVbVnlTms+fUlIrJ2kZGRyMzMRK9evYzb9Ho99u/fj08//RSlpaWQyUy/EKlUKqhUqmrnUigUtTbAb7SPmr/Gun7fH09Ben4p/N3UePCOVlAoav+yLZPJUFJSAj0kZiVVAEBnQHlZAbPLWnv5ymWB8vLmnKOxYnfy9EWLwFZml8/KSK13+Yqy9Ym9pZcLRoRkY0vUZWQgAPeuPoYld3XG/b2DIZHUfCO3sdX0nq/r9dNDgpKSEshkMv6tbSb4uYc619/sb3oTJkxosl/MW+WDDz7AzJkzMWvWLADAihUr8Oeff+Lzzz/HsmXLLBwdNTdNMXTtVpCXlGDifx9H4KkoaJxcsOnttcho3w1SCeDppITBINCzpQeKy3SQSSRwc1TWOsl6oLsD3B0VNb4ONfWsMoe1vr5ERLZg6NChiI2NNdn2f//3f+jQoQNefPHFagkpovrSaPVYuTceADBncBjUN0hIEVmCm0qC9G8WYNJ7v+F4chFe3BiLIxey8ebdXeGk4g1SolvF7N+uxYsX34Iwmk5ZWRkiIyPx0ksvmWwfMWIEDh8+bKGoqDnLLS5DdmEpyvQGKGVSuKgVUMqlxv0NHbp2KxRdycEdS5fC8/RplDm7YM+K/yErpCOkAPxc1fjncg5ScjXGetTWQ6qCs1qO4Z18ax1i15CeTLd6aCAREdXOxcUFXbqYDnNxcnKCp6dnte1EDfH9sURk5Jci0N0B9/cOsnQ4RDUyaArw5shA/JUixfs7z2JLTCpOpOThswd7oqO/681PQERmq/M3yeLiYjz//PPYsmULtFothg0bho8//hheXl63Mr5Gd+XKFej1evj6+pps9/X1RXp6eo1lzFllprmzx9UAGlLn1NwSJF7Jx8Ws6+Nh1QopWnk6w+VaIkYltfzrWVSqQ2quBiVaHWRFhfB78F74nT4NjaMz3nv2Q1x1CMQdzgroDQZEX86Gq0oOlUwA11b0yCvSI+JkKu4OD6z1TpCvswJ3d/czPo+DQo4AdzWcVPIG1V8trX1lEakEUEoF4pJzUKzVwUkhh/+156wJ39/2gXW2H9ZWb2uJk6iplZTpsXJv+YTNc4eEQSVnLylqvqQSCWYPaoPerTww74doJGQVYeJnh/DciPZ45D+hkEmte9QQUXNT56TUokWLsH79ekydOhVqtRo//PADZs+ejZ9//vlWxnfLVB2CKISodVhifVaZae7scTWA+tZZCeB+3yobRSZQUv7P85HncL5BkTUuWWkpAqGF1tERx5YsQre2XgBSgIwUAEBfJQABY/xGJcC+v2pfAacmjVXv0Bvsi480XT2lLmup8P1tH1hn+2Et9a7rKjPN3d69ey0dAtmYb49expXCUgS3cMC9vdhLiqxDn1YtsG3eADz387/YfSYTb24/ja0nUvHuvd05tQRRI6pzUmrTpk1Ys2YNpkyZAgCYNm0a+vfvD71eb1XzDXh5eUEmk1XrFZWZmVmt91QFc1aZae7scTWA+tb5fEYhdsalQyoBfF3UOJqQjczC6z3meod4YFLPIAQ0YD6lhioq1WFzdArySsrvzns6KbHjVDp+fWw5HjCcRnSbwZAprv+a9wh2Q0xSXq3nG9DWC92C3G912NWk5pZg95lMYz0AIKSFI1LyiqGroROVm4Oixl5dfH+zzrbKHusMWF+967rKDJE9KS7T4Yt95b2knhrcFgqZ9CYliJqPFk5KrJneGz//k4w3tsXh3+Q8jPvkAJ4cHIY5g8JMpvQgovqpc1IqKSkJAwYMMD6+7bbbIJfLkZqaiuBg85ZptSSlUolevXohIiICd999t3F7REQEJkyYUGOZ+qwy09xZc+z1ZW6dNYbyFS/0ANILtegV6gUBoFRngEouRbcgd4R4WzYpmZGtQa7GAEVJCdrv+wOXJ0yBTkhRrHREgW8I8soM8FBeTxrrceMVPJwd1BZ5X4R4K3CfiyNScktQXKaDo1KOMp0Bl3JKgRo6MOZqDMgo1KG9c80JQb6/7QPrbD+spd7WECNRU/vmyGVkF5UhxNMRd/cMtHQ4RGaTSCS4v08wBrb3xqtbTiIiLgMrdp3H9tg0LB7fGf3CrGs6G6Lmps5JKb1eD6VSaVpYLodOZ32TEM+fPx8PPfQQevfujb59+2L16tVITEzEE088YenQqBlxUl7/9TAIIKuwzPi4AGgWq8ZotHr4Scow+LXH4Rf7D06X5WN397vLh+cB0OkNJsf7uKjh7lh8S1bRayhntdykK3RUYs4Nj+cE6ERERM1bYakOq671kpo3hL2kyLr5uqqx+qFe2HoiDYt/O4VzGYV48KtjGN3FDy+P6YjgFtY5rQuRpdU5KSWEwIwZM0x6DGk0GjzxxBNwcnIybtu0aVPjRngLTJ48GdnZ2Vi6dCnS0tLQpUsXbN++HSEhIZYOjZqRQHcHuDsqmmUCBwCSc4qxP/IChj0/E37x/6LIwRkRwd0xIMwLRy5kAgDklRp/7o4KhHo5wcNJcUtW0WtslZOCNXG8yX4iIiKyrK8PX0JOsRatvZwwoUeApcMhajCJRILx3QMwoK0XPow4h/8dvYw/TqZj95lMPH5nazwxqA3bqERmqvNvzPTp06ttmzZtWqMG05TmzJmDOXPmWDoMasac1XIM7+TbLBM4hRod9vxzARNffRzB1xJS/33mI1x0D0Xo1WL0CHQDyrLgcm3OpcoxO6vluK9XsMlQuUB3h2aVkAKaf1KQiIiIapdXosXq/QkAgHlD25rcKCOydu6OSiyZ0AUP3N4SS36Lw5GEbHy8Ox4//ZOMBSPaYVLPIK7SR1RHdf4Wum7dulsZB1GzFOTh2CwTOKnJmRgy//8QeCoSGicXvDv/YyQEtgcAXLxShDv6BAJJwJCOPnB2UFeLuepQueaoOScFiYiI6MZW77+AvBIt2vo4Y3x39pIi29TBzxXfP3o7dpxMx3+3nUZKbgme/+UE1hy8iJfHdMSd7bwtHSJRs8dvdUQ30ewSOHo9/KfeC5eT5QmpTe+sg2Przmir0UKrN0Ahk8LXRYUMAN2C3K164t3mmhQkIiKi2mUVlGLtwUsAgOdGtmePEbJpEokEo7v6Y3AHH3xz5BI+2R2PM+kFeHjt37iznTcWju6Ajv7WtWI7UVPiNzsiayOToei+B6A4HYdNy9Ygo11XKAF4Ol+f783VQYkMy0XYqJpdUpCIiIhu6LM98SjR6tE92B0jOvlaOhyiJqFWyPDYnW1wX69gfLI7Hv87egn7z2XhwPks3NszCAtGtIefm9rSYRI1OxzcTWSFnOfOxsYf9yCjXddq+9wdFQhw5wceERERNb2kq8X47thlAMALI9tDImEvKbIvHk5KvD6+E3bNH4ixXf0hBPBzZDIGvb8Hy3eeRWEpV5AmqoxJKSJrUFgIPPYYkJUFoLz30MA72sPd0XRoXsV8S04qdoIkIiKiprdi13lo9QL9wzzRP8zL0uEQWUyIpxM+m9oTG2f3Q68QD2i0BnyyOx6D3tuDb49ehk5vsHSIRM0Cv7kSNXeFhcDo0cDBg8CZM8C+fYBEcsP5lrTa6ivWEREREd1K5zMKsDk6GQDw/MgOFo6GqHnoFeKBX57oiz9PpePtP87gUnYxXt1yEusOXcTC0R0xtKMPexSSXWNSiqg5q5yQcnMDli8HKn1ocb4lIiIiai7e33kWBgGM7OyLHsHulg6HqNmQSCQY1cUfQzr44vtjl/HRX+dxIasIs775B7eHtsArYzvC0dJBElkIk1JEzVVhIfQjR0F2+BB0rq5I2bAFnl3D4WzGKc5nFEJjAJyVcgRw1ToiIiK6Rf5NysWfpzIgkQALRrS3dDhEzZJSLsWM/qGY1CsIK/dcwNpDF3Hs4lXc9ekhDGnjApmrj6VDJGpy/IZK1BwVFqJ0+Eiojh6GxskFm95cgwxZANwjkzC8ky+CPG58LyU1twQAsDMuHUIiA3B9vqmblSUiIiIyhxAC7+w4AwC4OzwQ7XzZi5voRlzVCrw0ugOm3dESy3eew+boFOy+UIDAR1fhRJYOg3w53xTZD050TtQMaWc9ej0h9fZaZLTvBgDILdYiIi4DhZraV+0o1Oiw+0xmte11KUtERERkrr1ns3D4QjaUMimeHdbO0uEQWY0gD0d8OLkHtj71H4QHOEIiV+BktgHf/p2Cc3mcZ4rsA5NSRM1Q4oJXkNm6g0lCqkJusRYp13pC1SQltwR5JTVPdH6zskRERETm0OkNWPbHaQDAjP6tENyCPbKJzNUl0A3vjg5C1pZlcJADuSVafBYnw59xmSgu4w1lsm0cvkfUXAhhnMQ8zzcQv63cDEhrzhvf6MOp6CYfXLWVLdTokJJbgqIyHeegIiIiojr5JTIZ5zIK4eagwJODwiwdDpHVkkgkKD57CGNDFThX7IDYlDycTi/ExexiDG7vw2GxZLP4jZOoOSgoACZOBObNAyZMgJNSXmtCCgAclbX/6jrdYF9tZZNzihERl4Hc4us9rDgHFREREd1IcZkOH0ScAwA8NSQMbo4KC0dEZP2UMgmGtPfCUI+r+N8lR1wpLMMfJ9NxIasQg9v7QK2QWTpEokbFpBSRpRUUAGPGAAcPArGxwNChCHR3gLujwiRJVMHdUYFAd4daTxfo7gA3BwVQwyi9msoWanTVElLA9Tmo7usVzB5TREREVM2X+y8is6AUwS0c8FDfkGr7s7KykJeXV69zX758uaHhEdVLQ957Wq0WCkX9krNVn7eVC/BA70Acu5SH45ev4lxGIVJySzC8oy9CPJ3qdA5zuLm5wdvbu97lieqL3zSJLKlyQsrNDdi2DXB2hjOA4Z18a+29dKMkkbNajiEdfBBz+JTJ9trKpuSW1Jj8Aq7PQdXej92FiYiI6LrMAg1W7b8AAHhhZAeo5Ka9N7KyshAW1hb5+fVLSlXQaIobVJ6ororzcwFIMGzYsPqfRCIFRMNWzqv8npdJJejbxhOhXk74My4ducVabIlJRbdANwxo6wW5TNposbu6uiE+/jwTU9TkmJQispSqCamICKBPH+PuIA9H3NcrGCm5JSgu08FRKUdgHed5CnB3QAyAEZ38UGrADcvWdw4qIiIisl8f7TqP4jI9uge7Y1w3/2r78/LykJ+fhyfeWQ8PnwCzz38pLho/vPciSkvLGiNcopvSlBQBEJj6ysdoGdbB7PIV79mGlq/pPe/npsaDt7XEofgr+Dc5DydS8pCWp8GYrn5wd1Q2OPaczFR88eIM5OXlMSlFTY5JKSJLuElCqoKzWt6gXkptfZ1v2oW4PnNQERERkf2KzyzAhuNJAIBXxnSERFL70vUePgHwDqw+tO9mrmak1Ds+ooZw8/Zr0Hu2oeVro5BJMai9T3mvqVMZyCosxQ9/J2FYRx/jMfV9biJLqn0mZSK6dVatumlCqqlUzF9Vk5vNX0VERET2RQiBN7aeht4gMLyTL24LbWHpkIjsSoinEx68rSUC3NQo0xuw/WQ64oqdARlvJJN1YlKKyBLmzweeftriCSmgvDfW8E6+1RJTdZm/ioiIiOzL7jOZ2HcuCwqZBC+P6WjpcIjskrNajnt6BqFXiAcAILHUAX4PvgONvvZei0TNFb9tEjWVoiJApQLkckAqBVassHRERg2Zv4qIiIjsQ6lOjze2xgEAHvlPKEK9al4BjIhuPalUgv+EeSHQ3QF/nEgGAtrj4BUDvPI18HNVWzo8ojpjTymiplBQAIwaBUybBuia58ThFfNXhbf0QHs/FyakiIiIyMTag5dwKbsY3i4qPDWkraXDISIAoV5O6OuSg7Irl1FqkOKXyGScSc+3dFhEdcakFNGtVnlS8x07gIQES0d0SxRqdDibXoCoxBycSy9AoaZ5Jt+IiIjIfJn5Gny6+zwA4MVRHeCs4s0roubCUWZA+v+eg49KD71B4M9TGTgYfwUGISwdGtFN8dOE6Faqusrerl1Au3aWjqrRJecUIyIuA7nFWuO2ijmpgjwcLRgZERERNYa3d5xBUZke3YPdMSk80NLhEFEVoqwEvT1KkakKxD+XcxB5OQe5xWUY2dkPChn7olDzxXcn0a1SU0Kqd29LR9XoCjW6agkpAMgt1iIiLoM9poiIiKxcTFIuNkWVL1e/5K7OkEo5mTJRcySRAP3DvDCysy9kEgkuZBVhU1QKisvYHqfmi0kpolvBThJSAJCSW1ItIVUht1iLlNySJo6IiIiIGotBAG9sPwMAuLdXEHoEu1s2ICK6qQ5+rrg7PBAquRTp+Rr89E8ycorLLB0WUY2YlCK6FWJjgX/+sfmEFAAU3eTOC+/MEBERWa+jmRKcSM6Hk1KGF0a1t3Q4RFRHgR4OuL93MFzVcuSVaPHzP8lIy+PNYmp+mJQiuhX69QN++83mE1IA4KS88dR0jjfZT0RERM1TVkEpfrtc/nVhwYj28HHhMvNE1qSFkxL39w6Gj4sKJVo9NkalICGr0NJhEZlgUoqosRQUAPHx1x8PH27zCSkACHR3gLujosZ97o4KBLo7NHFERERE1Bje/OMsSvQSdAlwxfR+rSwdDhHVg5NKjnt7BSHUywl6g8DW2DScTsu3dFhERkxKETWGijmkBgwAzpyxdDRNylktx/BOvtUSUxWr7zmr2VOKiIjI2uw9m4ltsemQQOCNuzpBxsnNiayWQibFuK7+6OjnAiGAnXEZiE7MsXRYRAAAflskaqiqk5oX2l+X2CAPR9zXKxgpuSUoLtPBUSlHoLsDE1JERERWqKRMj9d+PQkAuNNfoEugq4UjIqKGkkolGN7JFyqFDDFJudh//go0WgPuaN3C0qGRneM3RqKGsKNV9m7GWS1Hez8XS4dBREREDfTx7vNIuloCP1cVxgQXWTocImokEokEd7b1goNChiMJ2fj70lVodHp0dhKWDo3sGIfvEdUXE1JERERkY86k5+PL/QkAgEXjOkIts3BARNSoJBIJbgttgcHtvQEAJ5LzcDhND0j5y06WwaQUUX0wIUVEREQ2Rm8QeHlTLHQGgRGdfDGso4+lQyKiW6RbkDtGdfaDVAJczjfAZ9Jr0OgMlg6L7BCTUkT1odcDpaVMSBEREZHN+OpAAqISc+GskmPxXZ0tHQ4R3WLt/VwwvlsAZBLAoU1vLNyRjHyN1tJhkZ1hUoqoPtzdgZ07gX37mJAiIiIiq3cuowDLd54DALw+rhMC3B0sHBERNYVWXk4YEiyHQVOI2PQSPPjlUVwtKrN0WGRHmJQiqquCAmDDhuuP3d2B7t0tFg4REVFDLVu2DH369IGLiwt8fHwwceJEnD171tJhURPT6g2Y/1MMyvQGDOngg/t6B1k6JCJqQt6OUqT/8DLc1TKcTMnH/auOID1PY+mwyE4wKUVUFxVzSD3wAPDZZ5aOhoiIqFHs27cPTz75JI4ePYqIiAjodDqMGDECRUVccc2efLYnHidT8uHmoMDbk7pCIpFYOiQiamLazAR8MC4Y/m5qxGcW4r5Vh5GYXWzpsMgOMClFdDNVJzW/7TZLR0RERNQoduzYgRkzZqBz587o3r071q1bh8TERERGRlo6NGoiscl5+HR3PADgjYld4OOqtnBERGQpLd1V+PmJvmjl6YikqyW494vDOJdRYOmwyMbJLR0AUbNWNSEVEQH06WPpqIiIiG6JvLw8AECLFi1qPaa0tBSlpaXGx/n5+QAArVYLrdZ0gtyKx1W3U91cuXLF+PrWh6urK7y8vGrdX6rVY/5P0dAZBEZ39sWojl4m1yojIwMAcP78echk5i0Xn5SUBAcHB8ggIBF6s2OXS1FeXgKzyzekrLWXr1wWsK/Xzppjr618Xc/T0OeWQcDBwQF6vR6+zgp8P7MPZqyPxLnMQtz/xRGsebgnugW5mX1ee8TPvevq+hpIhBDiFsdic/Lz8+Hm5oa8vDy4urpaOhyzaLVabN++HWPGjIFCobB0OE2i3nW24oSUPV5nwD7rzTqzzrbM2uptze0DABBCYMKECcjJycGBAwdqPW7x4sVYsmRJte3ff/89HB0db2WI1Mi2XJJiT5oULgqBl7rr4dz8f82IqIkUaYFVZ2S4XCiBSibwWHs9wpiXIjMUFxfjwQcfvGm7iD2liGqi1VptQoqIiKg+5s6dixMnTuDgwYM3PG7hwoWYP3++8XF+fj6Cg4MxYsSIao1OrVaLiIgIDB8+3CoSi81JQkICwsPD8cjSz+Hh5W92+ZwraVj7+mxER0ejdevW1fbvPpuFPUeiAQDv3R+OoR18qj1/v379sHbtWkTlqGGAefNMXT57Ar989Dpmvf01WnfoYnb88f8ew9pFc+pVviFlrb18RdnH3/kag1oqcUndBkJS915utlB3a4y9avk27TuileZCna9fQ587OzUJy+dMrPb3YvQoHWZ/F42jF3Ow+pwSnz7QHYPaeZt9fnvCz73r6trTl0kpopooFMDYsUBsLBNSRERk85566in89ttv2L9/P4KCbrzymkqlgkqlqrZdoVDU2gC/0T6qmUwmQ0lJCVy9AtAiMMTs8npIUFJSAplMVu21T8ktwYubTgIA/q9/K4zqGljr8wOAR0BLsxIbAJCVkYqSkhLoBcwuCwA6A+pdviFlrb185bJAeXlzzmErdbe22GsrX9fr19Dnru3vhYdCgfWP3I6530dh1+lMzP4uBh9O7oHx3QPMfg57w8891Ln+nOicqDYvvQScOcOEFBER2SwhBObOnYtNmzZh9+7dCA0NtXRIdItp9QY89X0Ucou16B7khoWjO1o6JCJqxtQKGT6f1gt3dQ+AziAwb0M0NvydaOmwyIYwKUVUoaAAePppoHI3Qz8/y8VDRER0iz355JP49ttv8f3338PFxQXp6elIT0839pAh2/P+n2cRlZgLF7Ucnz7YE0o5vw4Q0Y0pZFJ8OLkHHry9JYQAXtoUi68OJFg6LLIR/BQiAq5Pav7xx8ADD1g6GiIioibx+eefIy8vD4MGDYK/v7/x58cff7R0aHQL/HU6A6v2l3+RfO/e7ghuwYnpiahuZFIJ3pzYBY8PLJ9z6r/bTuODiHPgumnUUJxTiqjqKnuLF1s6IiIioibBLxP2IzmnGAt+/hfAtXmkurA3OBGZRyKR4KVRHeCqVuC9P8/i47/OI79Ei9fHdYJUat5iCEQV2FOK7FvVhBQnNSciIiIbU1Sqw6yv/+E8UkTUYBKJBE8ODsOSuzoDANYfvoTnfvkXZTqDhSMja8WkFNkvJqSIiIjIxukNAk9viMGZ9AJ4OSuxclovziNFRA02vV8rLL+vO2RSCTZFpWDm18dRoNFaOiyyQvxEIvs1YwYTUkRERGTT1v5zBbtOZ0Apl2L1w70R6O5g6ZCIyEbc0ysIXz3cGw4KGQ6cv4LJq44iI19j6bDIyjApRfZr6VKgXTsmpIiIiMgmOXUZih9PXAUAvHdvN/Rs6WHhiIjI1gzu4IMfH78DXs5KxKXlY9LKwzifUWDpsMiKMClF9qXyhK6dOwOnTjEhRURERDYns9gAz1FzAQDzhoRhQo9AC0dERLaqW5A7Ns3uj9ZeTkjJLcE9nx/GsYRsS4dFVsJqklJvvvkm+vXrB0dHR7i7u9d4TGJiIsaPHw8nJyd4eXlh3rx5KCsrMzkmNjYWAwcOhIODAwIDA7F06VKuPGMvCgqA0aOBvXuvb5NzAUoiIiKyLTnFZTiQooNEpsCdoc54Zlg7S4dERDaupacjfpndDz1buiNfo8NDa/7GthNplg6LrIDVJKXKyspw3333Yfbs2TXu1+v1GDt2LIqKinDw4EFs2LABGzduxIIFC4zH5OfnY/jw4QgICMDx48fxySef4P3338cHH3zQVNUgC5GXlEB2113An38CU6cCGo51JiIiIttToNFic3QKSvVAado5vDDQn0u1E1GTaOGkxPeP3oGRnX1Rpjfgye+jsHr/BXYCoRuymqTUkiVL8Oyzz6Jr16417t+5cyfi4uLw7bffIjw8HMOGDcPy5cvx5ZdfIj8/HwDw3XffQaPRYP369ejSpQsmTZqEl19+GR988AF/UWxZQQHuWLoU0kOHyic1//VXQK22dFREREREjapEq8eWmFQUaHRwUQKZvyyBmivtEVETUitkWDm1F6b3DQEAvLX9DF745QRKdXoLR0bNlc2MXTpy5Ai6dOmCgIAA47aRI0eitLQUkZGRGDx4MI4cOYKBAwdCpVKZHLNw4UJcunQJoaGhNZ67tLQUpaWlxscVSS6tVgut1rqWvayI19rirreCAkjHj4fn6dMQbm7Q79gB0b07YOP1t7vrfI091pt1tg/2WGfA+uptLXGSbdJo9dgSnYKrRWVwVskxJEiCk8V5lg6LiOyQTCrB4rs6I8TTCf/dFoefI5Nx8UoRvnioF7ycVTc/AdkVm0lKpaenw9fX12Sbh4cHlEol0tPTjce0atXK5JiKMunp6bUmpZYtW4YlS5ZU275z5044Ojo2QvRNLyIiwtIh3HLykhLcsXQpPE+fhtbREYdfew25GRnA9u2WDq3J2MN1rok91pt1tg/2WGfAeupdXFxs6RDITpVq9dgSk4LMglI4KGS4OzwQ+lzO5UJEliORSPDIf0LRxscZc7+Pwj+XczDh00P4anpvdPR3tXR41IxYNCm1ePHiGpM9lR0/fhy9e/eu0/kkkurj5YUQJturHlMxbK+mshUWLlyI+fPnGx/n5+cjODgYI0aMgKurdf1CabVaREREYPjw4VAoFJYO55aSLl0K2bUeUodfew19Zs+2+TpXsKfrXJk91pt1Zp1tmbXVu6InNVFT0lxLSGXklyekJvUMRAsnJbJyLR0ZEREwsJ03Ns/pj1lfH8el7GLc8/lhLL+vO0Z39bd0aNRMWDQpNXfuXEyZMuWGx1Tt2VQbPz8/HDt2zGRbTk4OtFqtsTeUn5+fsddUhczMTACo1suqMpVKZTLkr4JCobCKRnJNrDn2Onv9dSA5GfrHH0duRoZ91LkKe6wzYJ/1Zp3tgz3WGbCeeltDjGRbikp12BKTgiuFZVDLpbg7PJBDY4io2QnzccaWJ/vjye+jcCg+G7O/i8KjA0Lx4qgOkMs47529s2hSysvLC15eXo1yrr59++LNN99EWloa/P3Ls647d+6ESqVCr169jMe8/PLLKCsrg1KpNB4TEBBQ5+QXNXPFxeWTmEulgEIBrFsHodXa1ZA9IiIisn35JVpsjklBbrEWjkoZE1JE1Ky5Oyrx9f/dhnf/PIvV+xPw5YGL+Dc5D58+GA4fFy5CZc+sJi2ZmJiImJgYJCYmQq/XIyYmBjExMSgsLAQAjBgxAp06dcJDDz2E6Oho/PXXX3juuefw6KOPGofYPfjgg1CpVJgxYwZOnjyJzZs346233sL8+fNvOHyPrERBATByJPDkk4DBYOloiIiIiG6JjHwNfvwnCbnFWrio5bivVxATUkTU7MllUrw8piM+n9oTzio5/r54FWM/Pojjl65aOjSyIKtJSr3++usIDw/HokWLUFhYiPDwcISHh+Off/4BAMhkMmzbtg1qtRr9+/fH/fffj4kTJ+L99983nsPNzQ0RERFITk5G7969MWfOHMyfP99kviiyUgUFwJgxwMGDwA8/AJcuWToiIiIiokaXcKUQG6OSUVymh5ezEvf1CoK7o9LSYRER1dnorv74dW5/tPVxRlZBKaasPorP9sRDbxCWDo0swGpW31u/fj3Wr19/w2NatmyJrVu33vCYrl27Yv/+/Y0YGVlc5YSUmxuwaxfQurWloyIiIiJqNEIIHL+cgyMXsgEALVs4YkxXP6jkMgtHRkRkvjbe5fNMvbw5Fr/GpOK9P8/i4Pkr+HByD/i5cTifPbGanlJENaopIVXH1RqJiIiIrEGpTo/tJ9ONCamugW64q3sAE1JEZNWcVHKsmNwD797bDY5KGY4kZGP0R/sREZdh6dCoCVlNTymiapiQIiIisnlZWVnIy8urd3mtVtuglRHd3Nzg7e1d7/INdVVjwLa/k5BXooVUAgxu74MugW4Wi4eIbNfly5frXbYhf2t7ugMfjfHHuweycD67FI9+8w/Gd3THY7d5w0FRt340lv5bbUkN+ZxsDq8bk1JkvY4dA44cYUKKiIjIRmVlZSEsrC3y8+uflIJECoj6L4Di6uqG+PjzTd5o1xsEXG+7Gzsv62AQgItajtFd/ODv5tCkcRCR7SvOzwUgwbBhw+p/kgb+rYVECkilcL/zYbjdNgm/n87FpsOnkf3HRyhNOnnT4pb6W21pDf2cbA6vG5NSZL2GDQN++glo2ZIJKSIiIhuUl5eH/Pw8PPHOenj4BJhd/lJcNH5470VMfeVjtAzrYHb5nMxUfPHiDOTl5TVpg/3SlSLM35YEj8EzYRBAay8nDO/kC7WCw/WIqPFpSooAiHr/rWzo31pj+ZdWoGVYB6QVGXAsTYdiD3/4Pfg22nlI0cNbBrlUUmN5S/2tbg4a8jnZXF43JqXIuhQUAHl5QFBQ+eNJkywbDxEREd1yHj4B8A4MMbvc1YwUAICbt1+9yje1Up0eq/cl4NM98SjVGWAoLcYdIS64o5M/JJKav4wRETWW+v6tbOjf2qrlvQG0b63HwfNXcDI1H+dyDMjQyDCsozeCPBzNPr89qO/nZHPAic7JelTMITVwIJCYaOloiIiIiBqFEAJ7zmRizEcHsDziHEp1BoQHOCJ17VyEucuYkCIiu6OSyzC0oy8m9giAs0qOvBItNkal4M9T6Sgq1Vk6PGpE7ClF1qHqpOZZWeXD9oiIiIis2MmUPLyz4wwOnL8CAPByVuLVsZ3Q2bkYW57OtHB0RESWFeLphGl3tMSh+GzEpuThTHoBLl4pQr82nugS6AYpk/ZWj0kpav6qJqQiIoBevSwdFREREVG9nUzJw8d/ncfOa0ufK2VSzOjfCk8ODoObgwLx8fEWjpCIqHlQyWUY0sEHnfxdsedsJjILSrHnbBZOpeZjcHsfcLY968akFDVvNSWk+vSxdFREREREZtMbBPafy8JXBxNwKD4bACCVAHd1D8D84e3R0pNzpRAR1cbPTY3JfYIRm5yHwxeykVlQih//SUJLFynkbr6WDo/qiUkpar6YkCIiIiIbcPFKETZGJmNjVDLS8jQAAJlUgnHd/PHUkLYI83G2cIRERNZBKpGge7A7wnyccejCFZxOK0BigQEBs77AqmOZeDUgBG6OCkuHSWZgUoqar+JiIDubCSkiIiKyOml5Jdh9JhNbolNw/FKOcburWo77egfjkf+EItDdwYIREhFZLyeVHCM6+SE82AN/nUxCRrECP8fmIOLCHjx2Z2s83LcVnFVMd1gDXiVqvnx9gT17gJQUoGdPS0dDREREVCut3oCYpFzsOZOJ3WcycSa9wLhPKgEGtPXGfb2DMKyjL9QKzoBCRNQYvF1UGBIsx4r/vozbHl2Gy7lleHfHWazen4BHB7TG9H5MTjV3vDrUvPn6lv8QERERNRNCCKTlaRCTlIuYpFxEJ+YgNiUPGq3BeIxEAvQIdseITn64OzwQfm5qC0ZMRGS7JBIJNAmRWD2pFeKKHPDJX/FIuFKE9/48iy8PJGDWf0Ix9fYQeDgpLR0q1YBJKSIiIiKiKoQQKNMLKLxb4cjlQvyVcgHxmYWIzypEfGYhCjS6amXcHRUY2M4bg9v74M523mjBL0BERE1GJpXg7vAgjO8WgN9PpBqTU+/vPIdP98RjUs8gPNI/lPP4NTNMShERERGRXRBCQKsXKNHqUVymQ0mZHsVaPUrKrv1c+3dhqQ4FGh3K9AYEPPIpXotIqXYuqQTo4OeK8Jbu6BHsjvCWHmjt5QSpVGKBmhERUQW5TIq7w4NwV/dA/P5vKr48kIBTqfn4/lgivj+WiEHtvTG9Xyvc2dYbMv7NtjgmpYiIiIjIaglRkWSq+NEZ/51e5AKfexfj4BUV9h28iBKtHnqDMOv8+uI8dAj2QfvAFgjzcTb+tPJ04txQRETNmEwqwcTwQEzoEYCjCVex5uBF/HUmA3vPZmHv2Sz4uapxb68g3Nc7CCGeTpYO124xKUVEREREzZZE6YgcjQEFWeVD5vI1WuP/CzU6FGv1ELXmmdRwaNMbeVoAuD7cTi6VwEEpg4NCBkelDA5KGRwVcuM2J5UMLmoFSq+m4r2ZU7Hn/HmEhYU1QW2JiKixSSQS9G3jib5tPHHxShG+OXIJm6NTkJ6vwad74vHpnnjcHtoCd/UIwIhOfvB2UVk6ZLvCpBQRERERNUtv7k5Fy2d/wh+XdADSbnisWiGFo1IOR6Xs2o8cRVnJOLJpDUZNfRxt2rQ1JqAUMmmdnj8rl8M6iIhsSaiXExaN74yXRnfArrhM/PhPEg6cz8Kxi1dx7OJVvLblJHq3aoHRXfwwsrMfAtwdLB2yzWNSioiIiIiaJXeH8uFxKhng5qiCi1oOF7UCLmo5XK/930lZ3sOppnlBzhaex67YCPiqH+Xqd0REZKSSyzC2mz/GdvNHam4JtsSkYMfJdJxIzsPfF6/i74tXseT3OLT1cUb/MC/0D/PC7a1bwFWtsHToNodJKSIiIiJqlh7u6YWPZg7FS6t/h3dgS0uHQ0RENijA3QFzBoVhzqAwJOcUY8fJdOw4mY7IxByczyzE+cxCrD98CTKpBF0CXNEtyB3dgtzQPdgdbbydOVl6AzEpRURERETNkotKBqEttXQYRERkJ4I8HDFrQGvMGtAaucVlOHIhG4cuXMGh+GxcvFKEf5Pz8G9ynvF4R6UMbX1d0MbLCa29ndDSQ42UIiCvRAtPuRwSCRNWN8OkFBERERERERFRJe6OSozu6o/RXf0BACm5JYi6nIMTybn4NzkPJ1PyUFymx79Jufg3KbdSSTnePbEHKrkUvq5q+Lqq4O2igouqfNi587Wh6I7Xhp7LpZJr/5caH0skgM4goNML6AwG6PQCeoOA1mCAvtL2jKxsuPWbghNZOqhLrsAgBAwC1/4vYDCUr1KrF8K4KIjk2n9KS3TwHLcA0alFsORaHkxKERERERERERHdQKC7AwLdHTC+ewAAQG8QSMgqRHxmIRKuFOFCViESsgpxPi0XRToJSnUGJF4tRuLV4lsal/uAaTiZbQCyc8wu69x5MFLztbcgqrpjUoqIiIjIzq1cuRLvvfce0tLS0LlzZ6xYsQIDBgywdFhERETNlkwqQVtfF7T1dTFu02q12L59O4YOH4kcjQGZBRpk5Jciq6AUhaU65Gu0KNDoUKDRoaRMD4MQ13pEGaAzlPeG0hkEhBCQSyWQy6Sm/5dKIJeV96qSSyUoLirEzz9tQM9BY+Hk4gqpBJBKJOU/0kr/vrYdAATKe08V5uVg14ZV6Hj3GxZ6BcsxKUVERERkx3788Uc888wzWLlyJfr3749Vq1Zh9OjRiIuLQ8uWnFyciIjIXCqFDMGOagS3cLylzxMfH49VMz9DnykT4B3obVbZrJR8bD6+Ba0937tF0dWN1KLPTkREREQW9cEHH2DmzJmYNWsWOnbsiBUrViA4OBiff/65pUMjIiIiG8ekFBEREZGdKisrQ2RkJEaMGGGyfcSIETh8+LCFoiIiIiJ7weF79SCuTVufn59v4UjMp9VqUVxcjPz8fCgUCkuH0yRYZ/uoM2Cf9WadWWdbZm31rmgXVLQTrMGVK1eg1+vh6+trst3X1xfp6ek1liktLUVpaanxcV5e+dLYV69ehVZrOllqxTXMzs6u1zXMy8uDWq3GleQL0JUUml0+NyMZarUaOamXkKY0v9mbm50BtVqNU6dOGetpLolEUq/3RHJycsPq3sDYK56/uLgY6amnYYB5y5o3+LVvQHlLPrely1eUzU27jGLvQLOvnS3U3Rpjr1o+XSmDr3tpna9fc4rdIuUb+Peuvn+nayqv1+tRXFyM6OhoyGSyW/78DfmsqHjd8vLykJ2dXa/nv5GCggIAN28XSYQ1tZyaieTkZAQHB1s6DCIiImqGkpKSEBQUZOkw6iQ1NRWBgYE4fPgw+vbta9z+5ptv4n//+x/OnDlTrczixYuxZMmSpgyTiIiIrNTN2kXsKVUPAQEBSEpKgouLCyQS8+4aWVp+fj6Cg4ORlJQEV1dXS4fTJFhn+6gzYJ/1Zp1ZZ1tmbfUWQqCgoAABAQGWDqXOvLy8IJPJqvWKyszMrNZ7qsLChQsxf/5842ODwYCrV6/C09OzWrvI2q4hmeL1s168dtaN18968dpdV9d2EZNS9SCVSq3mDmhtXF1d7e6XhHW2H/ZYb9bZPthjnQHrqrebm5ulQzCLUqlEr169EBERgbvvvtu4PSIiAhMmTKixjEqlgkqlMtnm7u5+w+expmtI1fH6WS9eO+vG62e9eO3K1aVdxKQUERERkR2bP38+HnroIfTu3Rt9+/bF6tWrkZiYiCeeeMLSoREREZGNY1KKiIiIyI5NnjwZ2dnZWLp0KdLS0tClSxds374dISEhlg6NiIiIbByTUnZGpVJh0aJF1brd2zLW2X7YY71ZZ/tgj3UG7LfeljBnzhzMmTOn0c/La2jdeP2sF6+ddeP1s168dubj6ntERERERERERNTkpJYOgIiIiIiIiIiI7A+TUkRERERERERE1OSYlCIiIiIiIiIioibHpJQNunTpEmbOnInQ0FA4ODigTZs2WLRoEcrKykyOS0xMxPjx4+Hk5AQvLy/Mmzev2jGxsbEYOHAgHBwcEBgYiKVLl6K5TkP25ptvol+/fnB0dIS7u3uNx9hanWuzcuVKhIaGQq1Wo1evXjhw4IClQ6q3/fv3Y/z48QgICIBEIsGWLVtM9gshsHjxYgQEBMDBwQGDBg3CqVOnTI4pLS3FU089BS8vLzg5OeGuu+5CcnJyE9bCPMuWLUOfPn3g4uICHx8fTJw4EWfPnjU5xtbq/fnnn6Nbt25wdXWFq6sr+vbtiz/++MO439bqW5Nly5ZBIpHgmWeeMW6ztXovXrwYEonE5MfPz8+439bqa0/ste1hK9iGsj221Ba0FfbYprUV9tg2b1KCbM4ff/whZsyYIf78809x4cIF8euvvwofHx+xYMEC4zE6nU506dJFDB48WERFRYmIiAgREBAg5s6dazwmLy9P+Pr6iilTpojY2FixceNG4eLiIt5//31LVOumXn/9dfHBBx+I+fPnCzc3t2r7bbHONdmwYYNQKBTiyy+/FHFxceLpp58WTk5O4vLly5YOrV62b98uXnnlFbFx40YBQGzevNlk/9tvvy1cXFzExo0bRWxsrJg8ebLw9/cX+fn5xmOeeOIJERgYKCIiIkRUVJQYPHiw6N69u9DpdE1cm7oZOXKkWLdunTh58qSIiYkRY8eOFS1bthSFhYXGY2yt3r/99pvYtm2bOHv2rDh79qx4+eWXhUKhECdPnhRC2F59q/r7779Fq1atRLdu3cTTTz9t3G5r9V60aJHo3LmzSEtLM/5kZmYa99tafe2JvbY9bAXbULbF1tqCtsIe27S2wh7b5k2JSSk78e6774rQ0FDj4+3btwupVCpSUlKM23744QehUqlEXl6eEEKIlStXCjc3N6HRaIzHLFu2TAQEBAiDwdB0wZtp3bp1NTaobLnOld12223iiSeeMNnWoUMH8dJLL1koosZT9QPcYDAIPz8/8fbbbxu3aTQa4ebmJr744gshhBC5ublCoVCIDRs2GI9JSUkRUqlU7Nixo8lib4jMzEwBQOzbt08IYT/19vDwEF999ZXN17egoEC0bdtWREREiIEDBxqTUrZY70WLFonu3bvXuM8W62vv7KntYSvsvQ1lK2y5LWgr7LVNayvstW1+q3D4np3Iy8tDixYtjI+PHDmCLl26ICAgwLht5MiRKC0tRWRkpPGYgQMHQqVSmRyTmpqKS5cuNVnsjcUe6lxWVobIyEiMGDHCZPuIESNw+PBhC0V161y8eBHp6ekm9VWpVBg4cKCxvpGRkdBqtSbHBAQEoEuXLlbzmuTl5QGA8XfY1uut1+uxYcMGFBUVoW/fvjZf3yeffBJjx47FsGHDTLbbar3Pnz+PgIAAhIaGYsqUKUhISABgu/W1Z2x72A5eO+thb21BW8HPQOtib23zW41JKTtw4cIFfPLJJ3jiiSeM29LT0+Hr62tynIeHB5RKJdLT02s9puJxxTHWxB7qfOXKFej1+hrrYA3xm6uiTjeqb3p6OpRKJTw8PGo9pjkTQmD+/Pn4z3/+gy5dugCw3XrHxsbC2dkZKpUKTzzxBDZv3oxOnTrZbH0BYMOGDYiKisKyZcuq7bPFet9+++345ptv8Oeff+LLL79Eeno6+vXrh+zsbJusrz1j28O28NpZD3trC9oKfgZaD3tqmzcVJqWsSE0TxFb9+eeff0zKpKamYtSoUbjvvvswa9Ysk30SiaTacwghTLZXPUZcm6yyprK3Qn3qfCPWUOfGUFMdrCl+c9WnvtbymsydOxcnTpzADz/8UG2frdW7ffv2iImJwdGjRzF79mxMnz4dcXFxxv22Vt+kpCQ8/fTT+Pbbb6FWq2s9zpbqPXr0aNxzzz3o2rUrhg0bhm3btgEAvv76a+MxtlRfW2CPbQ9bwTaUfbO3tqCt4Gdg82dPbfOmIrd0AFR3c+fOxZQpU254TKtWrYz/Tk1NxeDBg9G3b1+sXr3a5Dg/Pz8cO3bMZFtOTg60Wq0xw+vn51cta5uZmQmgehb4VjG3zjdiLXVuCC8vL8hkshrrYA3xm6ti1a709HT4+/sbt1eur5+fH8rKypCTk2NyZyIzMxP9+vVr2oDN9NRTT+G3337D/v37ERQUZNxuq/VWKpUICwsDAPTu3RvHjx/HRx99hBdffBGA7dU3MjISmZmZ6NWrl3GbXq/H/v378emnnxpXdbG1elfm5OSErl274vz585g4cSIA266vNbLHtoetYBvKPtlbW9BW2GrbztbYW9u8qbCnlBXx8vJChw4dbvhTcbc9JSUFgwYNQs+ePbFu3TpIpaaXum/fvjh58iTS0tKM23bu3AmVSmX8gtS3b1/s37/fZLnfnTt3IiAgoM6NmIYyp843Yy11bgilUolevXohIiLCZHtERIRN/rELDQ2Fn5+fSX3Lysqwb98+Y3179eoFhUJhckxaWhpOnjzZbF8TIQTmzp2LTZs2Yffu3QgNDTXZb6v1rkoIgdLSUput79ChQxEbG4uYmBjjT+/evTF16lTExMSgdevWNlnvykpLS3H69Gn4+/vb7HW2dvbY9rAVbEPZJ3trC9oKfgY2b2yb32JNMp06NamUlBQRFhYmhgwZIpKTk02W3q5QsbTv0KFDRVRUlNi1a5cICgoyWdo3NzdX+Pr6igceeEDExsaKTZs2CVdX12a7tO/ly5dFdHS0WLJkiXB2dhbR0dEiOjpaFBQUCCFss841qVgGeM2aNSIuLk4888wzwsnJSVy6dMnSodVLQUGB8VoCEB988IGIjo42Lmv89ttvCzc3N7Fp0yYRGxsrHnjggRqXXw0KChK7du0SUVFRYsiQIc16+dXZs2cLNzc3sXfvXpPf3+LiYuMxtlbvhQsXiv3794uLFy+KEydOiJdffllIpVKxc+dOIYTt1bc2lVffE8L26r1gwQKxd+9ekZCQII4ePSrGjRsnXFxcjH+fbK2+9sRe2x62gm0o22JrbUFbYY9tWlthj23zpsSklA1at26dAFDjT2WXL18WY8eOFQ4ODqJFixZi7ty5Jsv4CiHEiRMnxIABA4RKpRJ+fn5i8eLFzXZZ3+nTp9dY5z179hiPsbU61+azzz4TISEhQqlUip49exqXK7VGe/bsqfG6Tp8+XQhRvgTrokWLhJ+fn1CpVOLOO+8UsbGxJucoKSkRc+fOFS1atBAODg5i3LhxIjEx0QK1qZvafn/XrVtnPMbW6v3II48Y37Pe3t5i6NChxoSUELZX39pUTUrZWr0nT54s/P39hUKhEAEBAWLSpEni1KlTxv22Vl97Yq9tD1vBNpTtsaW2oK2wxzatrbDHtnlTkghxbQZCIiIiIiIiIiKiJsI5pYiIiIiIiIiIqMkxKUVERERERERERE2OSSkiIiIiIiIiImpyTEoREREREREREVGTY1KKiIiIiIiIiIiaHJNSRERERERERETU5JiUIiIiIiIiIiKiJsekFBERERERERERNTkmpYio2ZFIJNiyZYulwyAiIiIiIqJbiEkpIjt2+PBhyGQyjBo1yuyyrVq1wooVKxo/qDqYMWMGJk6cWG373r17IZFIkJuba9ym1+vx4Ycfolu3blCr1XB3d8fo0aNx6NAhk7Lr16+HRCJBx44dq533p59+gkQiQatWrUy2l5SUYNGiRWjfvj1UKhW8vLxw77334tSpUzetQ02xVo7F3d29xnLu7u5Yv3698bFEIoFEIsHRo0dNjistLYWnpyckEgn27t1rsm/r1q0YNGgQXFxc4OjoiD59+pic80bi4+PxyCOPoGXLllCpVAgMDMTQoUPx3XffQafT1ekcRERE1uxmN88uXboEiUSCmJiYRn3eurS9ysrKEBYWVq2d01zdqM3TXFVthw4aNAjPPPNMk8dRtS25detWhIeHw2AwNHksRA3BpBSRHVu7di2eeuopHDx4EImJiZYOp9EJITBlyhQsXboU8+bNw+nTp7Fv3z4EBwdj0KBB1RqUTk5OyMzMxJEjR0y2r127Fi1btjTZVlpaimHDhmHt2rV44403cO7cOWzfvh16vR633357tSTRrRQcHIx169aZbNu8eTOcnZ2rHfvJJ59gwoQJ6NevH44dO4YTJ05gypQpeOKJJ/Dcc8/d8Hn+/vtv9OzZE6dPn8Znn32GkydPYuvWrXjkkUfwxRdf1CkZR0REdCvNmDHDeMNGLpejZcuWmD17NnJychrtOdLS0jB69OhGO19jWr16NUJCQtC/f/9q+x577DHIZDJs2LDBrHPe6EZaczFo0CDjdVepVGjXrh3eeust6PX6W/7cmzZtwhtvvFGnY2/lazlu3DhIJBJ8//33jX5uoluJSSkiO1VUVISffvoJs2fPxrhx42rsKfPbb7+hd+/eUKvV8PLywqRJkwCUf/BfvnwZzz77rLEBAACLFy9Gjx49TM6xYsUKkx5Gx48fx/Dhw+Hl5QU3NzcMHDgQUVFRt6SOP/30E3755Rd88803mDVrFkJDQ9G9e3esXr0ad911F2bNmoWioiLj8XK5HA8++CDWrl1r3JacnIy9e/fiwQcfrFavI0eOYOvWrbj//vsREhKC2267DRs3bkTHjh0xc+ZMCCFuSb2qmj59OjZs2ICSkhLjtrVr12L69OkmxyUlJWHBggV45pln8NZbb6FTp04ICwvDggUL8N5772H58uU4duxYjc8hhMCMGTPQrl07HDp0COPHj0fbtm0RHh6OqVOn4sCBA+jWrZvx+BdffBHt2rWDo6MjWrdujddeew1arda4v+K9smrVKgQHB8PR0RH33Xdfs27wEhGRdRg1ahTS0tJw6dIlfPXVV/j9998xZ86cRju/n58fVCpVo52vMX3yySeYNWtWte3FxcX48ccf8fzzz2PNmjUWiOzWe/TRR5GWloazZ89i3rx5ePXVV/H+++/XeGxZWVmjPW+LFi3g4uLSaOdriP/7v//DJ598YukwiMzCpBSRnfrxxx/Rvn17tG/fHtOmTcO6detMkijbtm3DpEmTMHbsWERHR+Ovv/5C7969AZTfEQoKCsLSpUuRlpaGtLS0Oj9vQUEBpk+fjgMHDuDo0aNo27YtxowZg4KCgkav4/fff4927dph/Pjx1fYtWLAA2dnZiIiIMNk+c+ZM/PjjjyguLgZQ3q181KhR8PX1rXbu4cOHo3v37ibbpVIpnn32WcTFxeHff/9t5BrVrFevXggNDcXGjRsBlCef9u/fj4ceesjkuF9++QVarbbGHlGPP/44nJ2d8cMPP9T4HDExMTh9+jSee+45SKU1f3RUJCcBwMXFBevXr0dcXBw++ugjfPnll/jwww9Njo+Pj8dPP/2E33//HTt27EBMTAyefPJJs+pORERUlUqlgp+fH4KCgjBixAhMnjwZO3fuNDlm3bp16NixI9RqNTp06ICVK1ca95WVlWHu3Lnw9/eHWq1Gq1atsGzZMuP+qsP3/v77b4SHh0OtVqN3796Ijo42ea6ahqht2bLF5HPzwoULmDBhAnx9feHs7Iw+ffpg165dZtU7KioK8fHxGDt2bLV9P//8Mzp16oSFCxfi0KFDuHTpksn+0tJSvPDCCwgODoZKpULbtm2xZs0aXLp0CYMHDwYAeHh4QCKRYMaMGQBqHk7Yo0cPLF682Pj4gw8+QNeuXeHk5ITg4GDMmTMHhYWFZtWrrhwdHeHn54dWrVph7ty5GDp0qPE6VQy5W7ZsGQICAtCuXTsAQEpKCiZPngwPDw94enpiwoQJJq+NXq/H/Pnz4e7uDk9PT7zwwgvVbjpWHb5Xn9dSCIF3330XrVu3hoODA7p3745ffvnF5Hm2b9+Odu3awcHBAYMHD652DQHgrrvuwt9//42EhISGvZhETYhJKSI7tWbNGkybNg1A+R3FwsJC/PXXX8b9b775JqZMmYIlS5agY8eO6N69O15++WUA5XeEZDIZXFxc4OfnBz8/vzo/75AhQzBt2jR07NgRHTt2xKpVq1BcXIx9+/aZFf/WrVvh7Oxs8lO1K/25c+dqnCMKgHH7uXPnTLb36NEDbdq0wS+//AIhBNavX49HHnmkWvn6nPtW+r//+z9jD69169ZhzJgx8Pb2Njnm3LlzcHNzg7+/f7XySqUSrVu3rjXmiu3t27c3bsvMzDR5/Ss36F999VX069cPrVq1wvjx47FgwQL89NNPJufUaDT4+uuv0aNHD9x555345JNPsGHDBqSnp9fvRSAiIqoiISEBO3bsgEKhMG778ssv8corr+DNN9/E6dOn8dZbb+G1117D119/DQD4+OOP8dtvv+Gnn37C2bNn8e2331abV7JCUVERxo0bh/bt2yMyMhKLFy++6XD4mhQWFmLMmDHYtWsXoqOjMXLkSIwfP96s6RX279+Pdu3awdXVtdq+inafm5sbxowZU23Y/8MPP4wNGzbg448/xunTp/HFF1/A2dkZwcHBxpteZ8+eRVpaGj766KM6xySVSvHxxx/j5MmT+Prrr7F792688MILdS7fEA4ODia9tP/66y+cPn0aERER2Lp1K4qLizF48GA4Oztj//79OHjwIJydnTFq1ChjT6rly5dj7dq1WLNmDQ4ePIirV69i8+bNN3ze+ryWr776KtatW4fPP/8cp06dwrPPPotp06YZ28dJSUmYNGkSxowZg5iYGMyaNQsvvfRStecOCQmBj48PDhw40CivIVFTkFs6ACJqemfPnsXff/+NTZs2ASgftjZ58mSsXbsWw4YNA1DeM+bRRx9t9OfOzMzE66+/jt27dyMjIwN6vR7FxcVmz2k1ePBgfP755ybbjh07Zky01VXlu5QVHnnkEaxbtw4tW7Y0NhI//fTTOp+z4g5axbk7d+6My5cvAwAGDBiAP/74w6wY62LatGl46aWXkJCQgPXr1+Pjjz82+xxCiBpfj8oq7/f09DRO4jpo0CCTrvC//PILVqxYgfj4eBQWFkKn01VrJLds2RJBQUHGx3379oXBYMDZs2fNSnQSERFVVnHjSq/XQ6PRACjvsVPhjTfewPLly43TEoSGhiIuLg6rVq3C9OnTkZiYiLZt2+I///kPJBIJQkJCan2u7777Dnq9HmvXroWjoyM6d+6M5ORkzJ4926yYu3fvbtL7+r///S82b96M3377DXPnzq3TOS5duoSAgIBq28+fP4+jR48a233Tpk3DvHnzsGjRIkilUpw7dw4//fQTIiIijO3A1q1bG8u3aNECAODj42P2pOSVexCFhobijTfewOzZs01uZDU2g8GAnTt34s8//zR5ficnJ3z11VdQKpUAyqc6kEql+Oqrr4ztm3Xr1sHd3R179+7FiBEjsGLFCixcuBD33HMPAOCLL77An3/+Wetz1+e1LCoqwgcffIDdu3ejb9++xjIHDx7EqlWrMHDgQHz++edo3bo1PvzwQ0gkErRv3x6xsbF45513qsUQGBhYYy8qouaKSSkiO7RmzRrodDoEBgYatwkhoFAokJOTAw8PDzg4OJh9XqlUWq1Lc+U7VEB59+msrCysWLECISEhUKlU6Nu3r9lj+52cnBAWFmayLTk52eRxu3btEBcXV2P506dPAwDatm1bbd/UqVPxwgsvYPHixXj44Ychl1f/U3mjc585c8bk3Nu3bze+DnV5XV1dXVFYWAi9Xg+ZTGbcrtfrUVhYCDc3t2plPD09MW7cOMycORMajQajR4+uNiSyXbt2yMvLQ2pqarVGa1lZGRISEjBkyJAaY6qoy5kzZ4zzhslkMuM1qPwaHT161NjLbuTIkXBzc8OGDRuwfPnyG9a7okF4s8QYERHRjVTcuCouLsZXX32Fc+fO4amnngIAZGVlISkpCTNnzjS5+abT6YyfrzNmzMDw4cPRvn17jBo1CuPGjcOIESNqfK7Tp0+je/fucHR0NG6rSCyYo6ioCEuWLMHWrVuRmpoKnU6HkpISs27alZSUQK1WV9u+Zs0ajBw5El5eXgCAMWPGYObMmdi1axdGjBiBmJgYyGQyDBw40Oy4b2bPnj146623EBcXh/z8fOh0Omg0GhQVFcHJyemm5UePHm3s9RMSEnLDRVVWrlyJr776ytimfOihh7Bo0SLj/q5duxoTUgAQGRmJ+Pj4avNBaTQaXLhwAXl5eUhLSzO5nnK5HL1796513tD6vJZxcXHQaDQYPny4yfaysjKEh4cDKH+f3XHHHSZtpNreZw4ODsZpKIisAYfvEdkZnU6Hb775BsuXL0dMTIzx599//0VISAi+++47AEC3bt1MhvNVpVQqq61o4u3tjfT0dJMP6qrLIR84cADz5s3DmDFj0LlzZ6hUKly5cqXxKljJlClTcP78efz+++/V9i1fvhyenp7VGgBA+V2su+66C/v27atx6F7FuXft2lVt3iiDwYAPP/wQnTp1Mt7xDAkJQVhYGMLCwkwSgbXp0KED9Hp9tTkpoqKioNfrTYbQVfbII49g7969ePjhh02SWRXuueceyOXyGpNDX3zxBYqKivDAAw/UeO7w8HB06NAB77///k2XGj506BBCQkLwyiuvoHfv3mjbtq2xp1hliYmJSE1NNT4+cuQIpFKpcZ4HIiKi+qi4cdWtWzd8/PHHKC0txZIlSwDA+Bn25ZdfmrSDTp48aVw5t2fPnrh48SLeeOMNlJSU4P7778e9995b43PVZVGTuty0e/7557Fx40a8+eabOHDgAGJiYtC1a1ezbtp5eXlVW2VQr9fjm2++wbZt2yCXyyGXy+Ho6IirV68aJzyvz43IutTr8uXLGDNmDLp06YKNGzciMjISn332WbXjbuSrr74yXqPt27ff8NipU6ciJiYGFy5cQElJCdasWWOSLKyaBDMYDOjVq5fJ+yAmJgbnzp2rtsBNXdXntax4T27bts0kjri4OOO8UuYsnnP16tVqUzgQNWfsKUVkZ7Zu3YqcnBzMnDmzWo+be++9F2vWrMHcuXOxaNEiDB06FG3atMGUKVOg0+nwxx9/GOcBaNWqFfbv348pU6ZApVLBy8sLgwYNQlZWFt59913ce++92LFjB/744w+TYVthYWH43//+h969eyM/Px/PP/98vRtDNzNlyhT8/PPPmD59Ot577z0MHToU+fn5+Oyzz/Dbb7/h559/rvUu3fr167Fy5Up4enrWuP/ZZ5/Fr7/+ivHjx2P58uW4/fbbkZGRgbfeegunT5/Grl276tTjJzY2ttoduh49emD06NF45JFH8MEHH6BNmza4cOEC5s+fj9GjR6NTp041nmvUqFHIysqqcS4JoHy43LvvvovnnnsOarUaDz30EBQKBX799Ve8/PLLWLBgAW6//fYay0okEqxbtw7Dhw9H//79sXDhQnTs2BFarRb79+9HVlaWMREWFhaGxMREbNiwAX369MG2bdtqnH9BrVZj+vTpeP/995Gfn4958+bh/vvv59A9IiJqVIsWLcLo0aMxe/ZsBAQEIDAwEAkJCZg6dWqtZVxdXTF58mRMnjwZ9957L0aNGoWrV68ah19V6NSpE/73v/+hpKTE2J6pSG5V8Pb2RkFBgUnvoJpu2s2YMQN33303gPI5pswdghUeHo7PP//cZDj+9u3bUVBQgOjoaJMbVmfOnMHUqVORnZ2Nrl27wmAwYN++fcYhZ5VV9C6q6WZk5cVu8vPzcfHiRePjf/75BzqdDsuXLzcuklJ1fsmbqcvNvApubm7VetHfSM+ePfHjjz/Cx8en1raTv78/jh49ijvvvBNA+c3dyMhI9OzZs8bj6/NadurUCSqVComJibX2sOrUqZPJ5PpA9fcZcL2XV0UPKyKrIIjIrowbN06MGTOmxn2RkZECgIiMjBRCCLFx40bRo0cPoVQqhZeXl5g0aZLx2CNHjohu3boJlUolKv8p+fzzz0VwcLBwcnISDz/8sHjzzTdFSEiIcX9UVJTo3bu3UKlUom3btuLnn38WISEh4sMPPzQeA0Bs3ry51jpMnz5dTJgwodr2PXv2CAAiJyfHuE2r1Yr3339fdO7cWahUKuHq6ipGjhwpDhw4YFJ23bp1ws3Nrdbn/PDDD03qIYQQRUVF4tVXXxVhYWFCoVCIFi1aiHvuuUfExsbWep6qsdb0I4QQeXl54tlnnxVhYWFCrVaLsLAw8cwzz4jc3FyT89zotcrJyREAxJ49e0y2//rrr2LAgAHCyclJqNVq0atXL7F27dqbxiyEEGfPnhXTp08XQUFBQi6XCzc3N3HnnXeKVatWCa1Wazzu+eefF56ensLZ2VlMnjxZfPjhhyav76JFi0T37t3FypUrRUBAgFCr1WLSpEni6tWrdYqDiIioJrW1EXr16iWefPJJIYQQX375pXBwcBArVqwQZ8+eFSdOnBBr164Vy5cvF0II8cEHH4gffvhBnD59Wpw9e1bMnDlT+Pn5Cb1eL4Qw/ewtKCgQXl5e4oEHHhCnTp0S27ZtE2FhYQKAiI6OFkIIkZ2dLZycnMS8efPE+fPnxXfffScCAgJM2k8TJ04UPXr0ENHR0SImJkaMHz9euLi4iKefftp4TNX2UlVXrlwRSqXSpB0yYcIEMXny5GrHGgwGERgYKFasWCGEEGLGjBkiODhYbN68WSQkJIg9e/aIH3/8UQghRHJyspBIJGL9+vUiMzNTFBQUCCGEeOmll4Sfn5/Yv3+/iI2NFRMnThTOzs5i0aJFQgghoqOjBQCxYsUKceHCBfHNN9+IwMBAk7bazdpfdTVw4ECT16qqmt4XRUVFom3btmLQoEFi//79IiEhQezdu1fMmzdPJCUlCSGEePvtt4WHh4fYtGmTOH36tHj00UeFi4uLybmqPnd9XstXXnlFeHp6ivXr14v4+HgRFRUlPv30U7F+/XohhBCXL18WSqVSPPvss+LMmTPiu+++E35+ftXavXv27BHOzs6iqKio/i8mURNjUoqIiJpcRVKKiIioMdWWlPruu++EUqkUiYmJxscVN948PDzEnXfeKTZt2iSEEGL16tWiR48ewsnJSbi6uoqhQ4eKqKgo47mq3hA6cuSI6N69u1AqlaJHjx5i48aNJkkpIYTYvHmz8UbTuHHjxOrVq02SUhcvXhSDBw8WDg4OIjg4WHz66afVkh03S0oJIcSUKVPESy+9JIQQIj09XcjlcvHTTz/VeOxTTz0lunbtKoQQoqSkRDz77LPC399fKJVKERYWZnLDaunSpcLPz09IJBIxffp0IUT5DbT7779fuLq6iuDgYLF+/XrRvXt3Y1JKiPIEn7+/v3BwcBAjR44U33zzTbNJSgkhRFpamnj44YeFl5eXUKlUonXr1uLRRx8VeXl5Qojym5tPP/20cHV1Fe7u7mL+/Pni4YcfvmFSqj6vpcFgEB999JFo3769UCgUwtvbW4wcOVLs27fPWO73338XYWFhQqVSiQEDBoi1a9dWS0o99thj4vHHHzfrtSOyNIkQZgxQJSIiagSLFy/Gli1bqg1fICIiovqLjY3FsGHDapzAm2xbVlYWOnTogH/++QehoaGWDoeozjjRORERERERkQ3o2rUr3n33XbPnoyLrd/HiRaxcuZIJKbI67ClFRERERERERERNjj2liIiIiIiIiIioyTEpRURERERERERETY5JKSIiIiIiIiIianJMShERERERERERUZNjUoqIiIiIiIiIiJock1JERERERERERNTkmJQiIiIiIiIiIqImx6QUERERERERERE1OSaliIiIiIiIiIioyf0/Ztdgzq+tB14AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_regression_results(y_test_krr, final_preds_krr, title=\"Final Kernel Ridge (RDKit FP)\", save_dir=\"plots\")\n",
    "plot_regression_results(y_test_unscaled, final_preds_rfr, title=\"Final Random Forest (RDKit FP)\", save_dir=\"plots\")\n",
    "plot_regression_results(y_test_inv_fp, final_preds_inv_fp, title=\"Final MLP (RDKit FP)\", save_dir=\"plots\")\n",
    "# plot_regression_results(y_test_inv_cm, final_preds_inv_cm, title=\"Final MLP (Coulomb Matrix)\", save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4771aa",
   "metadata": {},
   "source": [
    "\n",
    "| Model Type             | Featurization        |   MAE |  RMSE |   R² | Notes             |\n",
    "|------------------------|----------------------|-------|-------|------|-------------------|\n",
    "| MLP (Tuned)          | RDKit Fingerprints   | 0.426 | 0.574 | 0.798 | Strong performance across all metrics   |\n",
    "| KRR (Tuned)          | RDKit Fingerprints   | 0.454 | 0.593 | 0.784 | Good overall, slightly lower R² than MLP|\n",
    "| RF (Tuned)           | RDKit Fingerprints   | 0.423| 0.583 | 0.791  | Top MAE, but slightly higher R²/RMSE    |\n",
    "| MLP (Tuned)          | Coulomb Matrix       | 0.636 | 0.819 | 0.588 | Significantly worse than FP models      |\n",
    "| MLP (Untuned Baseline) | RDKit Fingerprints | 0.467 | 0.609 | 0.772 | Reasonable baseline performance         |\n",
    "| KRR (Untuned Baseline) | RDKit Fingerprints | 0.519 | 0.668 | 0.726 | Noticeable drop from tuned KRR          |\n",
    "| RF (Untuned Baseline) | RDKit Fingerprints  | 0.426| 0.587 | 0.788  | Surprisingly strong untuned performance |\n",
    "| MLP (Untuned Baseline) | Coulomb Matrix     | 0.663 | 0.847 | 0.559 | Confirms Coulomb Matrix as weak         |\n",
    "\n",
    "Save best model and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbd2c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_Tg/best_mlp_fp_model_keras\\assets\n"
     ]
    }
   ],
   "source": [
    "# create a save directory\n",
    "os.makedirs(\"saved_models_Tg\", exist_ok=True)\n",
    "\n",
    "# save the final trained MLP model (Keras backend)\n",
    "final_mlp_fp.model.save(\"saved_models_Tg/best_mlp_fp_model_keras\")\n",
    "\n",
    "# save the X and Y scalers\n",
    "joblib.dump(xscaler_fp, \"saved_models_Tg/xscaler_fp.pkl\")\n",
    "joblib.dump(yscaler, \"saved_models_Tg/yscaler.pkl\")\n",
    "\n",
    "# save evaluation metrics\n",
    "final_metrics_fp.to_csv(\"saved_models_Tg/best_mlp_fp_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c226234",
   "metadata": {},
   "source": [
    "If you wanted to reload these later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "136af5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # load model and scalersand metrics\n",
    "# mlp_model = load_model(\"saved_models/best_mlp_fp_model_keras\")\n",
    "# xscaler_fp = joblib.load(\"saved_models/xscaler_fp.pkl\")\n",
    "# yscaler = joblib.load(\"saved_models/yscaler.pkl\")\n",
    "# metrics_df = pd.read_csv(\"saved_models/best_mlp_fp_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39535b4",
   "metadata": {},
   "source": [
    "# Training a Baseline GNN with ChemML\n",
    "ChemML's `tensorise_molecules` generates its own graph. Its important to note this graph is not the official graph from PCQM4Mv2. It may miss out on features OGB uses like formal charge, aromatacity flags, atomic chirality, and explicit hydrogens. However, tensorise_molecules is a good choice for quick prototyping and it handles graph generation and tensor formatting in a numpy-friendly way which was easier for me to understand. Final training will use smiles2graph for compatability with OGB splits and better feature representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccf8404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorising molecules in batches of 3000 ...\n",
      "504/504 [==================================================] - 10s 21ms/step\n",
      "Merging batch tensors ...    [DONE]\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 211.7961 - val_loss: 4.2279\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 46.4533 - val_loss: 14.0274\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28.2108 - val_loss: 3.2301\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.4109 - val_loss: 1.5478\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.2681 - val_loss: 1.6073\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2334 - val_loss: 0.9518\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8695 - val_loss: 1.7679\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8212 - val_loss: 0.9395\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2838 - val_loss: 1.1337\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9148 - val_loss: 0.7203\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6777 - val_loss: 0.8583\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6795 - val_loss: 0.7020\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6499 - val_loss: 0.7226\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6196 - val_loss: 0.7228\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5953 - val_loss: 0.6909\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5893 - val_loss: 0.7078\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5822 - val_loss: 0.6924\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5646 - val_loss: 0.6915\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5587 - val_loss: 0.6715\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5430 - val_loss: 0.6900\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5471 - val_loss: 0.7025\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5288 - val_loss: 0.6764\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5226 - val_loss: 0.7052\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5216 - val_loss: 0.6499\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5155 - val_loss: 0.6368\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5142 - val_loss: 0.6304\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5326 - val_loss: 1.0120\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6685 - val_loss: 0.6601\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5541 - val_loss: 0.6479\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4863 - val_loss: 0.6632\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4917 - val_loss: 0.6229\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4726 - val_loss: 0.7242\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5008 - val_loss: 0.6272\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5132 - val_loss: 0.6747\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4792 - val_loss: 0.6368\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4688 - val_loss: 0.6301\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4696 - val_loss: 0.6288\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4554 - val_loss: 0.6082\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4514 - val_loss: 0.6020\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4562 - val_loss: 0.7418\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5110 - val_loss: 0.5845\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4618 - val_loss: 0.6125\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4417 - val_loss: 0.5801\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4365 - val_loss: 0.6427\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4417 - val_loss: 0.6012\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4398 - val_loss: 0.5700\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4700 - val_loss: 0.5857\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4523 - val_loss: 0.7112\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5394 - val_loss: 0.6151\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5749 - val_loss: 0.6894\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8199 - val_loss: 0.5804\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5987 - val_loss: 0.7847\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6360 - val_loss: 0.5950\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5132 - val_loss: 0.7455\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5105 - val_loss: 0.6626\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4553 - val_loss: 0.6309\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4611 - val_loss: 0.6041\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4396 - val_loss: 0.5399\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4441 - val_loss: 0.5729\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4739 - val_loss: 0.5355\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4396 - val_loss: 0.5156\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4136 - val_loss: 0.5944\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4283 - val_loss: 0.6399\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4233 - val_loss: 0.5263\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4101 - val_loss: 0.5203\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4088 - val_loss: 0.5100\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4426 - val_loss: 0.5161\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4946 - val_loss: 0.5158\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5028 - val_loss: 0.5596\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3919 - val_loss: 0.4978\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4081 - val_loss: 0.5164\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3929 - val_loss: 0.6080\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4218 - val_loss: 0.5481\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3995 - val_loss: 0.5227\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4007 - val_loss: 0.7335\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4996 - val_loss: 0.5636\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4202 - val_loss: 0.4919\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4053 - val_loss: 0.5299\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3869 - val_loss: 0.4896\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3812 - val_loss: 0.4675\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3813 - val_loss: 0.5008\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3748 - val_loss: 0.5493\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3724 - val_loss: 0.4691\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4298 - val_loss: 0.4635\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4619 - val_loss: 0.4724\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3935 - val_loss: 0.4819\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3688 - val_loss: 0.5240\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3841 - val_loss: 0.4516\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3668 - val_loss: 0.4893\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3832 - val_loss: 0.4782\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3919 - val_loss: 0.4692\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5588 - val_loss: 0.4972\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6389 - val_loss: 0.6583\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5432 - val_loss: 0.5554\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4932 - val_loss: 0.4556\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4090 - val_loss: 0.5302\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4351 - val_loss: 0.5617\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4033 - val_loss: 0.4695\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3590 - val_loss: 0.4851\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3740 - val_loss: 0.4935\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "\n",
      "GNN Model Results:\n",
      "         MAE       RMSE  r_squared\n",
      "0  64.024827  82.887383    0.50126\n"
     ]
    }
   ],
   "source": [
    "# tensorize molecules\n",
    "X_atoms, X_bonds, X_edges = tensorise_molecules(valid_mol_objs)\n",
    "y = df_clean['Tg'].values.reshape(-1, 1)\n",
    "\n",
    "# train test split (80/20)\n",
    "split = int(0.8 * len(y))\n",
    "X_atoms_train, X_atoms_test = X_atoms[:split], X_atoms[split:]\n",
    "X_bonds_train, X_bonds_test = X_bonds[:split], X_bonds[split:]\n",
    "X_edges_train, X_edges_test = X_edges[:split], X_edges[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# scale target\n",
    "yscaler = StandardScaler()\n",
    "y_train_scaled = yscaler.fit_transform(y_train)\n",
    "\n",
    "# model input shapes\n",
    "max_atoms = X_atoms.shape[1]\n",
    "max_degree = X_bonds.shape[2]\n",
    "num_atom_features = X_atoms.shape[-1]\n",
    "num_bond_features = X_bonds.shape[-1]\n",
    "\n",
    "# input layers\n",
    "atoms_input = Input(shape=(max_atoms, num_atom_features), name=\"atom_inputs\")\n",
    "bonds_input = Input(shape=(max_atoms, max_degree, num_bond_features), name=\"bond_inputs\")\n",
    "edges_input = Input(shape=(max_atoms, max_degree), name=\"edge_inputs\", dtype=\"int32\")\n",
    "\n",
    "# GNN layers\n",
    "conv1 = NeuralGraphHidden(8, activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "conv2 = NeuralGraphHidden(8, activation='relu')([conv1, bonds_input, edges_input])\n",
    "\n",
    "fp1 = NeuralGraphOutput(128, activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "fp2 = NeuralGraphOutput(128, activation='relu')([conv1, bonds_input, edges_input])\n",
    "fp3 = NeuralGraphOutput(128, activation='relu')([conv2, bonds_input, edges_input])\n",
    "\n",
    "# fingerprint aggregation\n",
    "fingerprint = Add()([fp1, fp2, fp3])\n",
    "\n",
    "# dense layers\n",
    "dense1 = Dense(128, activation='relu')(fingerprint)\n",
    "dense2 = Dense(64, activation='relu')(dense1)\n",
    "output = Dense(1, activation='linear')(dense2)\n",
    "\n",
    "# model compilation\n",
    "model = Model(inputs=[atoms_input, bonds_input, edges_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# model training\n",
    "model.fit([X_atoms_train, X_bonds_train, X_edges_train], y_train_scaled, epochs=100, batch_size=64, verbose=1, validation_split=0.1)\n",
    "\n",
    "# preds and eval\n",
    "y_pred = model.predict([X_atoms_test, X_bonds_test, X_edges_test])\n",
    "y_pred = yscaler.inverse_transform(y_pred)\n",
    "metrics = regression_metrics(y_test, y_pred)\n",
    "print(\"\\nGNN Model Results:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a97ae357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plot_regression_results(y_test, y_pred, title=\"GNN Model Untuned(ChemML)\", save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2fb6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:17:31,688] A new study created in memory with name: no-name-db90c8e1-5bb4-4a60-b540-debf549064f0\n",
      "[I 2025-09-04 20:17:38,194] Trial 0 finished with value: 0.5784119963645935 and parameters: {'conv_width': 16, 'fp_length': 160, 'n1': 160, 'n2': 64, 'lr': 0.0074779903531160775, 'alpha': 1.1713607039847262e-05}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:17:44,489] Trial 1 finished with value: 0.6189797520637512 and parameters: {'conv_width': 8, 'fp_length': 160, 'n1': 192, 'n2': 96, 'lr': 2.0096572916443418e-05, 'alpha': 6.93435054090891e-07}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:17:50,936] Trial 2 finished with value: 1.3424192667007446 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 1.0740694360574098e-05, 'alpha': 4.07655092722975e-07}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:17:57,470] Trial 3 finished with value: 0.6044057607650757 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 64, 'lr': 6.596998891781441e-05, 'alpha': 1.941359685789118e-05}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:18:03,767] Trial 4 finished with value: 0.6049039959907532 and parameters: {'conv_width': 16, 'fp_length': 128, 'n1': 192, 'n2': 96, 'lr': 0.00027988431131782123, 'alpha': 1.159506120928712e-05}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:18:10,498] Trial 5 finished with value: 0.5962063074111938 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0018054056294628683, 'alpha': 1.7557314840648281e-06}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:18:16,875] Trial 6 finished with value: 0.5641050934791565 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 64, 'lr': 0.0060757578056530245, 'alpha': 1.721509024173768e-07}. Best is trial 6 with value: 0.5641050934791565.\n",
      "[I 2025-09-04 20:18:23,410] Trial 7 finished with value: 0.5705327987670898 and parameters: {'conv_width': 16, 'fp_length': 160, 'n1': 128, 'n2': 64, 'lr': 0.006647279938663217, 'alpha': 1.7247199953302038e-08}. Best is trial 6 with value: 0.5641050934791565.\n",
      "[I 2025-09-04 20:18:29,854] Trial 8 finished with value: 0.5577208399772644 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0029586076211748423, 'alpha': 6.276447369983516e-07}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:35,969] Trial 9 finished with value: 0.5714065432548523 and parameters: {'conv_width': 16, 'fp_length': 160, 'n1': 160, 'n2': 64, 'lr': 0.0009738613712093438, 'alpha': 4.715300931273199e-08}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:42,603] Trial 10 finished with value: 0.6675637364387512 and parameters: {'conv_width': 32, 'fp_length': 128, 'n1': 128, 'n2': 96, 'lr': 0.0003263552163811872, 'alpha': 7.709695168770715e-05}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:49,582] Trial 11 finished with value: 0.5724877119064331 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.002252920145793403, 'alpha': 9.883023293820313e-08}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:56,067] Trial 12 finished with value: 0.5720522999763489 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.009925460457487913, 'alpha': 1.5944183054400058e-07}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:19:02,579] Trial 13 finished with value: 0.559759795665741 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.001986914000079734, 'alpha': 2.2965734881221143e-06}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:19:09,042] Trial 14 finished with value: 0.6146386861801147 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.0006072112617258865, 'alpha': 2.937041447079816e-06}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:19:15,651] Trial 15 finished with value: 0.537324070930481 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0020164019475540753, 'alpha': 3.465355151599912e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:22,090] Trial 16 finished with value: 0.7567039132118225 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.00014040897926649256, 'alpha': 5.823941393086069e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:28,545] Trial 17 finished with value: 0.561646044254303 and parameters: {'conv_width': 32, 'fp_length': 128, 'n1': 128, 'n2': 96, 'lr': 0.0027867540318616607, 'alpha': 6.140867853012933e-07}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:34,939] Trial 18 finished with value: 0.564617931842804 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0006355932927206463, 'alpha': 4.090645773300607e-05}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:41,591] Trial 19 finished with value: 0.5807154178619385 and parameters: {'conv_width': 32, 'fp_length': 128, 'n1': 128, 'n2': 96, 'lr': 0.003244941112614663, 'alpha': 5.55485584606677e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:48,045] Trial 20 finished with value: 0.5718845129013062 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0011164544070239126, 'alpha': 1.3647780168139255e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:54,486] Trial 21 finished with value: 0.5342585444450378 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.004041990960813106, 'alpha': 3.2842280041595312e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:01,059] Trial 22 finished with value: 0.5475216507911682 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0039136896910184705, 'alpha': 3.0960292215100224e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:07,548] Trial 23 finished with value: 0.5465244054794312 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.005029828858431721, 'alpha': 2.645806301792376e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:13,999] Trial 24 finished with value: 0.5760974884033203 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.00141425990182562, 'alpha': 4.560527980867315e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:20,765] Trial 25 finished with value: 0.5863977074623108 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.004342575290405733, 'alpha': 4.603889221331369e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:27,583] Trial 26 finished with value: 0.5919985771179199 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.0006690605825164465, 'alpha': 1.1532872007705319e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:34,118] Trial 27 finished with value: 0.5598962306976318 and parameters: {'conv_width': 8, 'fp_length': 128, 'n1': 160, 'n2': 96, 'lr': 0.0054903208790964934, 'alpha': 2.078603916227733e-05}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:40,499] Trial 28 finished with value: 0.5905507206916809 and parameters: {'conv_width': 32, 'fp_length': 160, 'n1': 192, 'n2': 64, 'lr': 0.0002597243753261715, 'alpha': 1.132694885097053e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:47,123] Trial 29 finished with value: 0.581702470779419 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.008655632825834132, 'alpha': 9.596447288930111e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:53,913] Trial 30 finished with value: 0.5551465153694153 and parameters: {'conv_width': 32, 'fp_length': 160, 'n1': 160, 'n2': 64, 'lr': 0.00496881669997927, 'alpha': 3.268332862528285e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:00,639] Trial 31 finished with value: 0.554656445980072 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.003906554291532843, 'alpha': 3.1506959143936316e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:07,344] Trial 32 finished with value: 0.5641250610351562 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0014519175592323209, 'alpha': 2.883619043205416e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:14,442] Trial 33 finished with value: 0.6160750389099121 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0035726584929979483, 'alpha': 8.341838407088706e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:20,927] Trial 34 finished with value: 0.6618874073028564 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 4.256581098756559e-05, 'alpha': 6.865754482198901e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:27,466] Trial 35 finished with value: 0.5780915021896362 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.007105025368208672, 'alpha': 5.042153213061166e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:34,161] Trial 36 finished with value: 0.538110077381134 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0021748847115820665, 'alpha': 2.0007329921186313e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:40,626] Trial 37 finished with value: 0.603560745716095 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.0008420589418001226, 'alpha': 1.5820737554131193e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:47,274] Trial 38 finished with value: 0.5781627893447876 and parameters: {'conv_width': 8, 'fp_length': 160, 'n1': 160, 'n2': 96, 'lr': 0.002210393525207414, 'alpha': 8.59709298242375e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:53,988] Trial 39 finished with value: 0.5526089072227478 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.001505996205233068, 'alpha': 1.9979152635099817e-05}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:00,622] Trial 40 finished with value: 0.5688043236732483 and parameters: {'conv_width': 8, 'fp_length': 128, 'n1': 160, 'n2': 64, 'lr': 0.002518946674988459, 'alpha': 1.5628752663946832e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:07,047] Trial 41 finished with value: 0.6949878931045532 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 1.0326341508593729e-05, 'alpha': 2.666760116293639e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:13,670] Trial 42 finished with value: 0.5842966437339783 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.005108891492545455, 'alpha': 1.2545596698485203e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:20,108] Trial 43 finished with value: 0.5730230212211609 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.007320894795257771, 'alpha': 3.9001066492494993e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:26,617] Trial 44 finished with value: 0.6084129214286804 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.003448015490816507, 'alpha': 8.797166508380697e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:33,181] Trial 45 finished with value: 0.5656376481056213 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0004410837401054787, 'alpha': 2.1642658132693283e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:39,985] Trial 46 finished with value: 0.5588310360908508 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.001896598865677006, 'alpha': 8.686045414635347e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:46,468] Trial 47 finished with value: 0.5685777068138123 and parameters: {'conv_width': 32, 'fp_length': 160, 'n1': 128, 'n2': 96, 'lr': 0.0011520140448633685, 'alpha': 2.9433059437832768e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:52,864] Trial 48 finished with value: 0.5571005344390869 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.00970425029035456, 'alpha': 1.8215717787647826e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:59,293] Trial 49 finished with value: 0.5857318639755249 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.00553543963449258, 'alpha': 4.931892543453002e-07}. Best is trial 21 with value: 0.5342585444450378.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "def objective_gnn(trial):\n",
    "    conv_width = trial.suggest_categorical('conv_width', [8, 16, 32])\n",
    "    fp_length = trial.suggest_categorical('fp_length', [96, 128, 160])\n",
    "    n1 = trial.suggest_int('n1', 128, 192, step=32)\n",
    "    n2 = trial.suggest_int('n2', 64, 96, step=32)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    alpha = trial.suggest_float('alpha', 1e-8, 1e-4, log=True)\n",
    "    activation = 'relu'\n",
    "\n",
    "    # model definition\n",
    "    atoms_input = Input(shape=(max_atoms, num_atom_features), name=\"atom_inputs\")\n",
    "    bonds_input = Input(shape=(max_atoms, max_degree, num_bond_features), name=\"bond_inputs\")\n",
    "    edges_input = Input(shape=(max_atoms, max_degree), name=\"edge_inputs\", dtype=\"int32\")\n",
    "\n",
    "    conv1 = NeuralGraphHidden(conv_width, activation=activation)([atoms_input, bonds_input, edges_input])\n",
    "    conv2 = NeuralGraphHidden(conv_width, activation=activation)([conv1, bonds_input, edges_input])\n",
    "\n",
    "    fp1 = NeuralGraphOutput(fp_length, activation=activation)([atoms_input, bonds_input, edges_input])\n",
    "    fp2 = NeuralGraphOutput(fp_length, activation=activation)([conv1, bonds_input, edges_input])\n",
    "    fp3 = NeuralGraphOutput(fp_length, activation=activation)([conv2, bonds_input, edges_input])\n",
    "    fingerprint = Add()([fp1, fp2, fp3])\n",
    "\n",
    "    dense1 = Dense(n1, activation=activation, kernel_regularizer=regularizers.l2(alpha))(fingerprint)\n",
    "    dense2 = Dense(n2, activation=activation, kernel_regularizer=regularizers.l2(alpha))(dense1)\n",
    "    output = Dense(1, activation='linear')(dense2)\n",
    "\n",
    "    model = Model(inputs=[atoms_input, bonds_input, edges_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mean_squared_error', metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit([X_atoms_train, X_bonds_train, X_edges_train], y_train_scaled, epochs=100, batch_size=64, verbose=0, validation_split=0.2)\n",
    "\n",
    "    # return best validation MAE\n",
    "    val_mae = min(history.history[\"val_mean_absolute_error\"])  \n",
    "    return val_mae\n",
    "\n",
    "study_gnn = optuna.create_study(direction='minimize')  \n",
    "study_gnn.optimize(objective_gnn, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf7a39",
   "metadata": {},
   "source": [
    "## Retraining ChemML GNN with Best Parameter Found in Optuna Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b42b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 29ms/step - loss: 1828.2208\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 83.8997\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 36.6573\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 12.0149\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 2.5238\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.7810\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9541\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6475\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6104\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5773\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6357\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5952\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5855\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6282\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5679\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5756\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7490\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6103\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8978\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5940\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.5970\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1729\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6433\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6396\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6033\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5880\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5465\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5005\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4977\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4888\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5279\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5266\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5108\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4905\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6250\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6263\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6872\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5321\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5040\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4851\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4948\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4488\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4801\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4589\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5944\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5019\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5447\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6054\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4802\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5260\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4407\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4370\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4353\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5234\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5044\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5047\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6158\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5042\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4602\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4912\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4307\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4939\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4422\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4177\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4197\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4769\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4585\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4371\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4901\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4971\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4136\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4761\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4384\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4103\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4164\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4595\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4228\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4113\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3974\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4181\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4769\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4770\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4617\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3903\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4006\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4033\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4014\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4113\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4275\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3906\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3882\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4155\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3907\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3932\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3954\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3798\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3986\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4250\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4703\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6096\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4939\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4746\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4528\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5432\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4354\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3802\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3677\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4294\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4542\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4317\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5032\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3869\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3672\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4195\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5143\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5925\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5765\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5279\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5752\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6548\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4994\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4859\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5152\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3848\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4057\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4008\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4022\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3477\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4596\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3874\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4219\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6346\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4464\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4780\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5022\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6741\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6913\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6828\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5262\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3459\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4105\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4824\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4417\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3424\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3827\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3952\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4203\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3621\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3811\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3764\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3494\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3422\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3342\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3948\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5323\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5102\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4940\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4958\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3296\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3462\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3762\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3377\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4346\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4526\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4875\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3503\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3610\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3752\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3289\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3597\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3698\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3610\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4692\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3836\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3808\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4367\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5109\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5578\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4529\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4756\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6174\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6124\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4004\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3989\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3363\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3772\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3728\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5978\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4394\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4070\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3210\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4358\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4208\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4671\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3532\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3693\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3585\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "\n",
      "Final Tuned GNN Results:\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.193508  72.170596    0.62189\n"
     ]
    }
   ],
   "source": [
    "params = study_gnn.best_params\n",
    "\n",
    "# redefine and compile using best params\n",
    "atoms_input = Input(shape=(max_atoms, num_atom_features), name=\"atom_inputs\")\n",
    "bonds_input = Input(shape=(max_atoms, max_degree, num_bond_features), name=\"bond_inputs\")\n",
    "edges_input = Input(shape=(max_atoms, max_degree), name=\"edge_inputs\", dtype=\"int32\")\n",
    "\n",
    "conv1 = NeuralGraphHidden(params['conv_width'], activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "conv2 = NeuralGraphHidden(params['conv_width'], activation='relu')([conv1, bonds_input, edges_input])\n",
    "\n",
    "fp1 = NeuralGraphOutput(params['fp_length'], activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "fp2 = NeuralGraphOutput(params['fp_length'],activation='relu')([conv1, bonds_input, edges_input])\n",
    "fp3 = NeuralGraphOutput(params['fp_length'], activation='relu')([conv2, bonds_input, edges_input])\n",
    "fingerprint = Add()([fp1, fp2, fp3])\n",
    "\n",
    "dense1 = Dense(params['n1'], activation='relu', kernel_regularizer=regularizers.l2(params['alpha']))(fingerprint)\n",
    "dense2 = Dense(params['n2'], activation='relu', kernel_regularizer=regularizers.l2(params['alpha']))(dense1)\n",
    "output = Dense(1, activation='linear')(dense2)\n",
    "\n",
    "final_gnn = Model(inputs=[atoms_input, bonds_input, edges_input], outputs=output)\n",
    "final_gnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']), loss='mean_squared_error')\n",
    "\n",
    "final_gnn.fit([X_atoms_train, X_bonds_train, X_edges_train], y_train_scaled, epochs=200, batch_size=64, verbose=1)\n",
    "\n",
    "# final eval\n",
    "y_pred_final = final_gnn.predict([X_atoms_test, X_bonds_test, X_edges_test])\n",
    "y_pred_final = yscaler.inverse_transform(y_pred_final)\n",
    "final_metrics = regression_metrics(y_test, y_pred_final)\n",
    "print(\"\\nFinal Tuned GNN Results:\")\n",
    "print(final_metrics[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3bf3a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_regression_results(y_test, y_pred_final, title=\"Tuned ChemML GNN\", save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64159a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_Tg/gnn_tensorise_molecules_model\\gnn_tensorise_molecules_model_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# make a directory for this specific model\n",
    "save_dir = \"saved_models_Tg/gnn_tensorise_molecules_model\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. save the trained GNN model\n",
    "final_gnn.save(os.path.join(save_dir, \"gnn_tensorise_molecules_model_tf\"), save_format=\"tf\")\n",
    "\n",
    "# 2. save the y target scaler\n",
    "with open(os.path.join(save_dir, \"gnn_tensorise_molecules_target_scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(yscaler, f)\n",
    "\n",
    "# 3. save the final metrics\n",
    "final_metrics.to_csv(os.path.join(save_dir, \"gnn_tensorise_molecules_metrics.csv\"), index=False)\n",
    "\n",
    "# 4. save predictions\n",
    "pred_df = pd.DataFrame({\"true_gap\": y_test.flatten(), \"predicted_gap\": y_pred_final.flatten()})\n",
    "pred_df.to_csv(os.path.join(save_dir, \"gnn_tensorise_molecules_predictions.csv\"), index=False)\n",
    "\n",
    "# 5. save the best hyperparameters\n",
    "with open(os.path.join(save_dir, \"gnn_tensorise_molecules_best_params.json\"), \"w\") as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77f7ec",
   "metadata": {},
   "source": [
    "## ChemML GNN Model Results\n",
    "| Model Type             | Featurization        |   MAE |  RMSE |   R² | Notes             |\n",
    "|------------------------|----------------------|-------|-------|------|-------------------|\n",
    "| GNN (Tuned)            | tensorise_molecules Graph   | 0.302 | 0.411 | 0.900 | Best performance across all metrics   |\n",
    "| GNN (Untuned)          | tensorise_molecules Graph   | 0.400 | 0.519 | 0.841 | Good overall|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42db218",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Model Training\n",
    "\n",
    "Having explored different molecular graph representations and model architectures, I am now moving to training what is expected to be the best-performing model using the full dataset. The earlier GNN model was based on `tensorise_molecules` (ChemML) graphs and had strong performance with a **mean absolute error (MAE) around 0.30**. These graphs are based on RDKit's internal descriptors and do not reflect the original PCQM4Mv2 graph structure used in the Open Graph Benchmark (OGB). Therefore, I will shift focus to the `smiles2graph` representation provided by OGB, which aligns more directly with the benchmark's evaluation setup and top-performing models on the leaderboard.\n",
    "\n",
    "\n",
    "| Source                         | Atom/Bond Features                                                 | Format                                          | Customizable?     | Alignment with PCQM4Mv2?  |\n",
    "| ------------------------------ | ------------------------------------------------------------------ | ----------------------------------------------- | ----------------- | ---------------------- |\n",
    "| `tensorise_molecules` (ChemML) | RDKit-based descriptors (ex: atom number, degree, hybridization) | NumPy tensors (`X_atoms`, `X_bonds`, `X_edges`) | Limited           |  Not aligned          |\n",
    "| `smiles2graph` (OGB / PyG)     | Predefined categorical features from PCQM4Mv2                      | PyTorch Geometric `Data` objects                |  Highly flexible |  Matches OGB standard |\n",
    "\n",
    "By using `smiles2graph`, we:\n",
    "\n",
    "* Use OGB-standard graph construction and feature encoding for fair comparisons with leaderboard models\n",
    "* Include learnable AtomEncoder and BondEncoder embeddings from `ogb.graphproppred.mol_encoder`, which improve model expressiveness\n",
    "* Maintain compatibility with PyTorch Geometric, DGL, and OGB tools\n",
    "\n",
    "I will also concatenate GNN-derived embeddings with SMILES-based RDKit descriptors, feeding this hybrid representation into MLP head. This allows you to combine structural and cheminformatics perspectives for improved prediction accuracy. With this setup, I aim to improve upon the MAE of \\~0.30 achieved earlier and push closer toward state-of-the-art performance.\n",
    "\n",
    "\n",
    "## Step 1: Load PyG-Compatible Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf8037c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu118\n",
      "CUDA available?  True\n",
      "Device count: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3070 Ti\n",
      "Current device: 0\n"
     ]
    }
   ],
   "source": [
    "def check_cuda():\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA available? \", torch.cuda.is_available())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Device count:\", torch.cuda.device_count())\n",
    "        print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "        print(\"Current device:\", torch.cuda.current_device())\n",
    "    else:\n",
    "        print(\"Running on CPU\")\n",
    "\n",
    "check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52c907b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load OGB dataset \n",
    "df_tg = pd.read_csv('cleaned_tg_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a988df2",
   "metadata": {},
   "source": [
    "#  Step 2: Extract SMILES from Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a684ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 504 molecules.\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract SMILES and FFV targets\n",
    "# Your `df_ffv` already contains the SMILES and FFV columns.\n",
    "smiles_list = df_tg['SMILES'].tolist()\n",
    "ffv_list = df_tg['Tg'].tolist()\n",
    "\n",
    "num_mols = len(smiles_list)\n",
    "print(f\"Loaded {num_mols} molecules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7aa26be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of RDKit features: (504, 9)\n"
     ]
    }
   ],
   "source": [
    "def compute_rdkit_features(smiles):\n",
    "    cleaned_smiles = canonicalize_polymer_smiles(smiles)\n",
    "    mol = Chem.MolFromSmiles(cleaned_smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * 9  # Update the number of NaNs to match new features\n",
    "\n",
    "    # Check for empty molecule\n",
    "    if mol.GetNumAtoms() == 0:\n",
    "        return [np.nan] * 9\n",
    "\n",
    "    # Add features that capture size, shape, and interactions\n",
    "    return [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.RingCount(mol),\n",
    "        Descriptors.FractionCSP3(mol),  # New: Fraction of sp3 hybridized carbons\n",
    "        Descriptors.MolLogP(mol),      # New: Octanol-water partition coefficient\n",
    "        Descriptors.NumSaturatedRings(mol) # New: Number of saturated rings\n",
    "    ]\n",
    "\n",
    "rdkit_features = np.array([compute_rdkit_features(smi) for smi in smiles_list])\n",
    "print(f\"Shape of RDKit features: {rdkit_features.shape}\") # Should be (N, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f6d257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 504 molecules with valid RDKit features.\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN values (failed RDKit featurization)\n",
    "valid_indices = ~np.isnan(rdkit_features).any(axis=1)\n",
    "rdkit_features = rdkit_features[valid_indices]\n",
    "smiles_list = np.array(smiles_list)[valid_indices].tolist()\n",
    "ffv_list = np.array(ffv_list)[valid_indices].tolist()\n",
    "\n",
    "print(f\"Kept {len(smiles_list)} molecules with valid RDKit features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c75372",
   "metadata": {},
   "source": [
    "# Step 4: attach RDKit features to PyG data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "755a330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1032, 9], edge_index=[2, 2182], edge_attr=[2182, 3], y=[32], rdkit_feats=[288], batch=[1032], ptr=[33])\n",
      "Batch's node features shape: torch.Size([1032, 9])\n",
      "Batch's RDKit features shape: torch.Size([288])\n",
      "Batch's targets shape: torch.Size([32])\n",
      "Batch's 'batch' attribute shape: torch.Size([1032])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Assuming your previous cells have loaded and processed the data into these lists:\n",
    "# smiles_list: list of SMILES strings\n",
    "# rdkit_features: numpy array of RDKit features (N, 6)\n",
    "# ffv_list: list of FFV values (N,)\n",
    "\n",
    "# 1. Create a list of PyG Data objects\n",
    "rdkit_features_tensor = torch.tensor(rdkit_features, dtype=torch.float32)\n",
    "ffv_targets_tensor = torch.tensor(ffv_list, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "data_list = []\n",
    "for i in range(len(smiles_list)):\n",
    "    # smiles2graph returns a dictionary\n",
    "    graph_dict = smiles2graph(smiles_list[i])\n",
    "    \n",
    "    # Create the Data object from the dictionary keys, converting to tensors\n",
    "    # Convert node and edge features to LongTensor \n",
    "    data = Data(\n",
    "        x=torch.tensor(graph_dict['node_feat'], dtype=torch.long),\n",
    "        edge_index=torch.tensor(graph_dict['edge_index'], dtype=torch.long),\n",
    "        edge_attr=torch.tensor(graph_dict['edge_feat'], dtype=torch.long),\n",
    "        rdkit_feats=rdkit_features_tensor[i],\n",
    "        y=ffv_targets_tensor[i]\n",
    "    )\n",
    "    data_list.append(data)\n",
    "\n",
    "# 2. Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create PyG DataLoaders\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Verification\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    print(\"Batch's node features shape:\", batch.x.shape)\n",
    "    print(\"Batch's RDKit features shape:\", batch.rdkit_feats.shape)\n",
    "    print(\"Batch's targets shape:\", batch.y.shape)\n",
    "    print(\"Batch's 'batch' attribute shape:\", batch.batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2984411",
   "metadata": {},
   "source": [
    "## Step 5: Define the Hybrid GNN Model\n",
    "\n",
    "The final architecture uses both structural and cheminformatics data by combining GNN-learned graph embeddings with SMILES-derived RDKit descriptors. This Hybrid GNN model uses `smiles2graph` for graph construction and augments it with RDKit-based molecular features for improved prediction accuracy.\n",
    "\n",
    "### Model Components:\n",
    "\n",
    "* **AtomEncoder / BondEncoder**\n",
    "  Transforms categorical atom and bond features (provided by OGB) into learnable embeddings using the encoders from `ogb.graphproppred.mol_encoder`. These provide a strong foundation for expressive graph learning.\n",
    "\n",
    "* **GINEConv Layers (x2)**\n",
    "  I use two stacked GINEConv layers (Graph Isomorphism Network with Edge features). These layers perform neighborhood aggregation based on edge attributes, allowing the model to capture localized chemical environments.\n",
    "\n",
    "* **Global Mean Pooling**\n",
    "  After message passing, node level embeddings are aggregated into a fixed size graph level representation using `global_mean_pool`.\n",
    "\n",
    "* **Concatenation with RDKit Descriptors**\n",
    "  The pooled GNN embedding is concatenated with external RDKit descriptors, which capture global molecular properties not easily inferred from graph data alone.\n",
    "\n",
    "* **MLP Prediction Head**\n",
    "  A multilayer perceptron processes the combined feature vector with ReLU activations, dropout regularization, and linear layers to predict the HOMO–LUMO gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ccbf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGNN(Module):\n",
    "    def __init__(self, gnn_dim, rdkit_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.gnn_dim = gnn_dim\n",
    "        self.rdkit_dim = rdkit_dim\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim=gnn_dim)\n",
    "        self.bond_encoder = BondEncoder(emb_dim=gnn_dim)\n",
    "\n",
    "        self.conv1 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), ReLU(), Linear(gnn_dim, gnn_dim)))\n",
    "        self.conv2 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), ReLU(), Linear(gnn_dim, gnn_dim)))\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        self.mlp = Sequential(Linear(gnn_dim + rdkit_dim, hidden_dim), ReLU(), \n",
    "                              Dropout(dropout_rate),\n",
    "                              Linear(hidden_dim, hidden_dim // 2), ReLU(), \n",
    "                              Dropout(dropout_rate),\n",
    "                              Linear(hidden_dim // 2, 1))\n",
    "\n",
    "    def forward(self, data):\n",
    "        # encode atoms and bonds\n",
    "        x = self.atom_encoder(data.x)\n",
    "        edge_attr = self.bond_encoder(data.edge_attr)\n",
    "\n",
    "        # GNN convolutions\n",
    "        x = self.conv1(x, data.edge_index, edge_attr)\n",
    "        x = self.conv2(x, data.edge_index, edge_attr)\n",
    "        x = self.pool(x, data.batch)\n",
    "\n",
    "        # handle RDKit features\n",
    "        rdkit_feats = getattr(data, 'rdkit_feats', None)\n",
    "        if rdkit_feats is not None:\n",
    "            # Reshape the RDKit features tensor to be (batch_size, rdkit_dim)\n",
    "            # The number of samples in the batch is given by x.shape[0] after pooling\n",
    "            reshaped_rdkit_feats = rdkit_feats.view(x.shape[0], self.rdkit_dim)\n",
    "            \n",
    "            # The check for shape mismatch is now more accurate\n",
    "            if x.shape[0] != reshaped_rdkit_feats.shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: GNN output ({x.shape[0]}) vs rdkit_feats ({reshaped_rdkit_feats.shape[0]})\")\n",
    "            \n",
    "            x = torch.cat([x, reshaped_rdkit_feats], dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"RDKit features not found in the data object\")\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252f39e",
   "metadata": {},
   "source": [
    "# Step 7: training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b42e8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 13/13 [00:00<00:00, 56.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 14966.3594 | Val Loss: 11512.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 13/13 [00:00<00:00, 108.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 11906.9951 | Val Loss: 10899.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 13/13 [00:00<00:00, 146.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 10743.5882 | Val Loss: 9611.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 13/13 [00:00<00:00, 143.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 8785.2728 | Val Loss: 7241.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 13/13 [00:00<00:00, 174.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 7528.4167 | Val Loss: 5260.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 13/13 [00:00<00:00, 174.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 6511.8596 | Val Loss: 4957.6357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 13/13 [00:00<00:00, 189.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 6373.2477 | Val Loss: 4830.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 13/13 [00:00<00:00, 181.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 6298.0631 | Val Loss: 5033.8071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 13/13 [00:00<00:00, 185.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 6202.5309 | Val Loss: 5345.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 13/13 [00:00<00:00, 179.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 6072.5673 | Val Loss: 4692.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 13/13 [00:00<00:00, 182.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 5881.2335 | Val Loss: 4204.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 13/13 [00:00<00:00, 187.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 6033.7601 | Val Loss: 4466.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 13/13 [00:00<00:00, 188.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 5463.4788 | Val Loss: 4294.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 13/13 [00:00<00:00, 190.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 5408.3220 | Val Loss: 4383.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 13/13 [00:00<00:00, 188.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 5344.6625 | Val Loss: 4296.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 13/13 [00:00<00:00, 160.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 5411.0325 | Val Loss: 3983.4153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 13/13 [00:00<00:00, 192.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 5319.1668 | Val Loss: 4663.2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 13/13 [00:00<00:00, 180.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 5129.0778 | Val Loss: 4066.8186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 13/13 [00:00<00:00, 186.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 5256.7686 | Val Loss: 3979.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 13/13 [00:00<00:00, 189.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 5255.6155 | Val Loss: 3947.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 13/13 [00:00<00:00, 187.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 5253.9092 | Val Loss: 4706.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 13/13 [00:00<00:00, 186.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 5246.5679 | Val Loss: 3758.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 13/13 [00:00<00:00, 190.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 5158.5457 | Val Loss: 4060.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 13/13 [00:00<00:00, 182.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 5331.8837 | Val Loss: 3814.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 13/13 [00:00<00:00, 195.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 5026.8245 | Val Loss: 3753.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 13/13 [00:00<00:00, 193.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 5182.1413 | Val Loss: 3896.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 13/13 [00:00<00:00, 180.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 5047.7241 | Val Loss: 4028.5186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 13/13 [00:00<00:00, 181.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 4811.0276 | Val Loss: 3648.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 13/13 [00:00<00:00, 194.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 5646.3687 | Val Loss: 4162.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 13/13 [00:00<00:00, 191.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 4846.5465 | Val Loss: 3878.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 13/13 [00:00<00:00, 191.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 6162.0335 | Val Loss: 4631.7622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 13/13 [00:00<00:00, 158.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 5209.3660 | Val Loss: 3894.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 13/13 [00:00<00:00, 145.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 4992.0203 | Val Loss: 3679.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 13/13 [00:00<00:00, 190.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 4755.7412 | Val Loss: 4186.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 13/13 [00:00<00:00, 188.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 4899.7240 | Val Loss: 4629.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 13/13 [00:00<00:00, 190.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 5413.9676 | Val Loss: 3831.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 13/13 [00:00<00:00, 189.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 5086.3598 | Val Loss: 3549.2380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 13/13 [00:00<00:00, 197.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 4901.6471 | Val Loss: 3913.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 13/13 [00:00<00:00, 186.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 5115.3100 | Val Loss: 3815.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 13/13 [00:00<00:00, 191.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 5137.0548 | Val Loss: 3621.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 13/13 [00:00<00:00, 190.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 4767.4431 | Val Loss: 3557.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 13/13 [00:00<00:00, 197.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 4819.3917 | Val Loss: 3636.8264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 13/13 [00:00<00:00, 186.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 4575.3529 | Val Loss: 4151.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 13/13 [00:00<00:00, 188.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 4343.1091 | Val Loss: 3672.1860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 13/13 [00:00<00:00, 186.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 4261.4937 | Val Loss: 3389.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 13/13 [00:00<00:00, 193.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 4333.4151 | Val Loss: 3795.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 13/13 [00:00<00:00, 197.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 4247.1842 | Val Loss: 3430.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 13/13 [00:00<00:00, 194.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 4515.8931 | Val Loss: 3460.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 13/13 [00:00<00:00, 199.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 4662.5827 | Val Loss: 3846.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 13/13 [00:00<00:00, 196.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 4598.3637 | Val Loss: 3573.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 13/13 [00:00<00:00, 158.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 4344.3891 | Val Loss: 3504.3071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 13/13 [00:00<00:00, 196.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 4150.7536 | Val Loss: 3829.3174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 13/13 [00:00<00:00, 189.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 4090.6537 | Val Loss: 3471.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 13/13 [00:00<00:00, 182.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 4166.8423 | Val Loss: 4461.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 13/13 [00:00<00:00, 187.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 4184.6097 | Val Loss: 3463.1172\n",
      "Early stopping triggered at epoch 55\n",
      "\n",
      "GNN Evaluation:\n",
      "         MAE       RMSE  r_squared\n",
      "0  41.288761  58.218231   0.727795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_31444\\2343932047.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(save_dir, \"hybridgnn_untuned.pt\")))\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = HybridGNN(gnn_dim=128, rdkit_dim=rdkit_features.shape[1], hidden_dim=256)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            preds.append(pred.cpu())\n",
    "            targets.append(batch.y.view(-1, 1).cpu())\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    loss = F.mse_loss(preds, targets)\n",
    "    return loss.item(), preds, targets\n",
    "\n",
    "# training loop\n",
    "for epoch in range(1, 101): # long since early stopping\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch:02d}\"):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_loss, val_preds, val_targets = evaluate(model, valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        save_dir = \"saved_models/gnn_smiles2graph_model\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"hybridgnn_untuned.pt\"))\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# final eval on val set\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, \"hybridgnn_untuned.pt\")))\n",
    "model.eval()\n",
    "_, final_preds, final_targets = evaluate(model, valid_loader)\n",
    "metrics = regression_metrics(final_targets.numpy(), final_preds.numpy())\n",
    "print(\"\\nGNN Evaluation:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34585261",
   "metadata": {},
   "source": [
    "# Step 8: Optuna tuning of Hybrid GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85485072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGNN(Module):\n",
    "    def __init__(self, gnn_dim, rdkit_dim, hidden_dim, dropout_rate=0.2, activation='ReLU'):\n",
    "        super().__init__()\n",
    "        act_map = {'ReLU': torch.nn.ReLU(), 'ELU': torch.nn.ELU(), 'GELU': torch.nn.GELU(), 'LeakyReLU': torch.nn.LeakyReLU(), 'PReLU': torch.nn.PReLU(), 'Swish': torch.nn.SiLU()}\n",
    "        act_fn = act_map[activation]\n",
    "        self.gnn_dim = gnn_dim\n",
    "        self.rdkit_dim = rdkit_dim\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim=gnn_dim)\n",
    "        self.bond_encoder = BondEncoder(emb_dim=gnn_dim)\n",
    "\n",
    "        self.conv1 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), act_fn, Linear(gnn_dim, gnn_dim)))\n",
    "        self.conv2 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), act_fn, Linear(gnn_dim, gnn_dim)))\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        self.mlp = Sequential(Linear(gnn_dim + rdkit_dim, hidden_dim), act_fn, \n",
    "                              Dropout(dropout_rate), \n",
    "                              Linear(hidden_dim, hidden_dim // 2), act_fn, \n",
    "                              Dropout(dropout_rate), \n",
    "                              Linear(hidden_dim // 2, 1))\n",
    "\n",
    "    def forward(self, data):\n",
    "        # encode atoms and bonds\n",
    "        x = self.atom_encoder(data.x)\n",
    "        edge_attr = self.bond_encoder(data.edge_attr)\n",
    "\n",
    "        # GNN convolutions\n",
    "        x = self.conv1(x, data.edge_index, edge_attr)\n",
    "        x = self.conv2(x, data.edge_index, edge_attr)\n",
    "        x = self.pool(x, data.batch)\n",
    "\n",
    "        # handle RDKit features\n",
    "        rdkit_feats = getattr(data, 'rdkit_feats', None)\n",
    "        if rdkit_feats is not None:\n",
    "            # Reshape the RDKit features tensor to be (batch_size, rdkit_dim)\n",
    "            # The number of samples in the batch is given by x.shape[0] after pooling\n",
    "            reshaped_rdkit_feats = rdkit_feats.view(x.shape[0], self.rdkit_dim)\n",
    "            \n",
    "            # The check for shape mismatch is now more accurate\n",
    "            if x.shape[0] != reshaped_rdkit_feats.shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: GNN output ({x.shape[0]}) vs rdkit_feats ({reshaped_rdkit_feats.shape[0]})\")\n",
    "            \n",
    "            x = torch.cat([x, reshaped_rdkit_feats], dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"RDKit features not found in the data object\")\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f1fc3",
   "metadata": {},
   "source": [
    "Multiple rounds of tuning have suggested to refine my search space to ReLU, GELU, and Swish activation functions and Adam and AdamW optimizers. Therefore, I have commented out unused parameters like momentum for SGD and the unused optimizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f95a50c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:32:50,405] A new study created in RDB with name: final_2d_gnn_study_Tg_4\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning:\n",
      "\n",
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch 01 | Train Loss: 22615.4778 | Val Loss: 24309.1672 | Optimizer: Adam\n",
      "Trial 0 | Epoch 02 | Train Loss: 22246.0442 | Val Loss: 23994.1601 | Optimizer: Adam\n",
      "Trial 0 | Epoch 03 | Train Loss: 21980.5986 | Val Loss: 23684.7207 | Optimizer: Adam\n",
      "Trial 0 | Epoch 04 | Train Loss: 21612.3958 | Val Loss: 23385.0100 | Optimizer: Adam\n",
      "Trial 0 | Epoch 05 | Train Loss: 21344.4977 | Val Loss: 23090.7039 | Optimizer: Adam\n",
      "Trial 0 | Epoch 06 | Train Loss: 21109.8644 | Val Loss: 22797.8876 | Optimizer: Adam\n",
      "Trial 0 | Epoch 07 | Train Loss: 20819.2765 | Val Loss: 22505.9068 | Optimizer: Adam\n",
      "Trial 0 | Epoch 08 | Train Loss: 20556.8369 | Val Loss: 22203.4485 | Optimizer: Adam\n",
      "Trial 0 | Epoch 09 | Train Loss: 20250.1706 | Val Loss: 21891.5765 | Optimizer: Adam\n",
      "Trial 0 | Epoch 10 | Train Loss: 19961.2807 | Val Loss: 21563.0911 | Optimizer: Adam\n",
      "Trial 0 | Epoch 11 | Train Loss: 19638.6439 | Val Loss: 21221.8345 | Optimizer: Adam\n",
      "Trial 0 | Epoch 12 | Train Loss: 19396.7511 | Val Loss: 20872.6697 | Optimizer: Adam\n",
      "Trial 0 | Epoch 13 | Train Loss: 19104.0750 | Val Loss: 20520.4865 | Optimizer: Adam\n",
      "Trial 0 | Epoch 14 | Train Loss: 18728.5989 | Val Loss: 20155.0744 | Optimizer: Adam\n",
      "Trial 0 | Epoch 15 | Train Loss: 18339.2386 | Val Loss: 19768.6885 | Optimizer: Adam\n",
      "Trial 0 | Epoch 16 | Train Loss: 18025.7015 | Val Loss: 19362.1463 | Optimizer: Adam\n",
      "Trial 0 | Epoch 17 | Train Loss: 17682.6301 | Val Loss: 18922.3060 | Optimizer: Adam\n",
      "Trial 0 | Epoch 18 | Train Loss: 17185.8709 | Val Loss: 18448.6687 | Optimizer: Adam\n",
      "Trial 0 | Epoch 19 | Train Loss: 16826.0104 | Val Loss: 17915.7495 | Optimizer: Adam\n",
      "Trial 0 | Epoch 20 | Train Loss: 16186.0697 | Val Loss: 17322.7723 | Optimizer: Adam\n",
      "Trial 0 | Epoch 21 | Train Loss: 15683.7281 | Val Loss: 16652.7939 | Optimizer: Adam\n",
      "Trial 0 | Epoch 22 | Train Loss: 15029.1602 | Val Loss: 15907.9860 | Optimizer: Adam\n",
      "Trial 0 | Epoch 23 | Train Loss: 14396.7742 | Val Loss: 15087.2606 | Optimizer: Adam\n",
      "Trial 0 | Epoch 24 | Train Loss: 13593.7761 | Val Loss: 14207.0675 | Optimizer: Adam\n",
      "Trial 0 | Epoch 25 | Train Loss: 12806.2443 | Val Loss: 13302.6819 | Optimizer: Adam\n",
      "Trial 0 | Epoch 26 | Train Loss: 12008.6944 | Val Loss: 12473.8035 | Optimizer: Adam\n",
      "Trial 0 | Epoch 27 | Train Loss: 11357.0122 | Val Loss: 11775.5379 | Optimizer: Adam\n",
      "Trial 0 | Epoch 28 | Train Loss: 10774.1126 | Val Loss: 11293.7984 | Optimizer: Adam\n",
      "Trial 0 | Epoch 29 | Train Loss: 10426.1889 | Val Loss: 11052.6720 | Optimizer: Adam\n",
      "Trial 0 | Epoch 30 | Train Loss: 10392.3436 | Val Loss: 10920.3809 | Optimizer: Adam\n",
      "Trial 0 | Epoch 31 | Train Loss: 10322.6869 | Val Loss: 10782.9776 | Optimizer: Adam\n",
      "Trial 0 | Epoch 32 | Train Loss: 9871.9281 | Val Loss: 10655.4947 | Optimizer: Adam\n",
      "Trial 0 | Epoch 33 | Train Loss: 10146.3506 | Val Loss: 10537.9100 | Optimizer: Adam\n",
      "Trial 0 | Epoch 34 | Train Loss: 9828.0271 | Val Loss: 10440.8842 | Optimizer: Adam\n",
      "Trial 0 | Epoch 35 | Train Loss: 9826.6306 | Val Loss: 10340.0558 | Optimizer: Adam\n",
      "Trial 0 | Epoch 36 | Train Loss: 9747.7663 | Val Loss: 10225.0922 | Optimizer: Adam\n",
      "Trial 0 | Epoch 37 | Train Loss: 9522.9517 | Val Loss: 10087.6765 | Optimizer: Adam\n",
      "Trial 0 | Epoch 38 | Train Loss: 9614.7308 | Val Loss: 9943.0863 | Optimizer: Adam\n",
      "Trial 0 | Epoch 39 | Train Loss: 9394.5177 | Val Loss: 9811.3013 | Optimizer: Adam\n",
      "Trial 0 | Epoch 40 | Train Loss: 9327.1049 | Val Loss: 9695.3026 | Optimizer: Adam\n",
      "Trial 0 | Epoch 41 | Train Loss: 9439.3707 | Val Loss: 9584.0163 | Optimizer: Adam\n",
      "Trial 0 | Epoch 42 | Train Loss: 9182.5715 | Val Loss: 9466.1826 | Optimizer: Adam\n",
      "Trial 0 | Epoch 43 | Train Loss: 9031.8112 | Val Loss: 9332.2222 | Optimizer: Adam\n",
      "Trial 0 | Epoch 44 | Train Loss: 9169.7262 | Val Loss: 9230.9752 | Optimizer: Adam\n",
      "Trial 0 | Epoch 45 | Train Loss: 8675.4700 | Val Loss: 9118.5248 | Optimizer: Adam\n",
      "Trial 0 | Epoch 46 | Train Loss: 9099.5186 | Val Loss: 8996.5626 | Optimizer: Adam\n",
      "Trial 0 | Epoch 47 | Train Loss: 8782.9053 | Val Loss: 8878.3265 | Optimizer: Adam\n",
      "Trial 0 | Epoch 48 | Train Loss: 8906.1860 | Val Loss: 8779.6928 | Optimizer: Adam\n",
      "Trial 0 | Epoch 49 | Train Loss: 8824.0024 | Val Loss: 8639.8873 | Optimizer: Adam\n",
      "Trial 0 | Epoch 50 | Train Loss: 8442.1729 | Val Loss: 8536.2289 | Optimizer: Adam\n",
      "Trial 0 | Epoch 51 | Train Loss: 8359.4557 | Val Loss: 8416.2089 | Optimizer: Adam\n",
      "Trial 0 | Epoch 52 | Train Loss: 8288.8698 | Val Loss: 8315.8868 | Optimizer: Adam\n",
      "Trial 0 | Epoch 53 | Train Loss: 8096.1286 | Val Loss: 8189.2475 | Optimizer: Adam\n",
      "Trial 0 | Epoch 54 | Train Loss: 8205.8618 | Val Loss: 8072.2686 | Optimizer: Adam\n",
      "Trial 0 | Epoch 55 | Train Loss: 8347.7238 | Val Loss: 7993.4790 | Optimizer: Adam\n",
      "Trial 0 | Epoch 56 | Train Loss: 8272.9531 | Val Loss: 7913.2498 | Optimizer: Adam\n",
      "Trial 0 | Epoch 57 | Train Loss: 7826.2738 | Val Loss: 7836.5246 | Optimizer: Adam\n",
      "Trial 0 | Epoch 58 | Train Loss: 7748.2079 | Val Loss: 7729.6205 | Optimizer: Adam\n",
      "Trial 0 | Epoch 59 | Train Loss: 7881.0961 | Val Loss: 7654.3849 | Optimizer: Adam\n",
      "Trial 0 | Epoch 60 | Train Loss: 7749.4573 | Val Loss: 7586.7036 | Optimizer: Adam\n",
      "Trial 0 | Epoch 61 | Train Loss: 7843.1721 | Val Loss: 7490.0121 | Optimizer: Adam\n",
      "Trial 0 | Epoch 62 | Train Loss: 7625.7205 | Val Loss: 7412.1600 | Optimizer: Adam\n",
      "Trial 0 | Epoch 63 | Train Loss: 7688.3552 | Val Loss: 7366.1606 | Optimizer: Adam\n",
      "Trial 0 | Epoch 64 | Train Loss: 7604.8483 | Val Loss: 7306.7716 | Optimizer: Adam\n",
      "Trial 0 | Epoch 65 | Train Loss: 7771.2487 | Val Loss: 7274.2074 | Optimizer: Adam\n",
      "Trial 0 | Epoch 66 | Train Loss: 7359.6361 | Val Loss: 7240.9383 | Optimizer: Adam\n",
      "Trial 0 | Epoch 67 | Train Loss: 7770.6951 | Val Loss: 7233.9434 | Optimizer: Adam\n",
      "Trial 0 | Epoch 68 | Train Loss: 7609.8339 | Val Loss: 7164.2206 | Optimizer: Adam\n",
      "Trial 0 | Epoch 69 | Train Loss: 7450.9874 | Val Loss: 7108.8407 | Optimizer: Adam\n",
      "Trial 0 | Epoch 70 | Train Loss: 7384.5700 | Val Loss: 7064.6655 | Optimizer: Adam\n",
      "Trial 0 | Epoch 71 | Train Loss: 7694.1370 | Val Loss: 7041.6822 | Optimizer: Adam\n",
      "Trial 0 | Epoch 72 | Train Loss: 7435.0106 | Val Loss: 7008.0157 | Optimizer: Adam\n",
      "Trial 0 | Epoch 73 | Train Loss: 7309.4527 | Val Loss: 7017.9330 | Optimizer: Adam\n",
      "Trial 0 | Epoch 74 | Train Loss: 7146.3913 | Val Loss: 7027.3506 | Optimizer: Adam\n",
      "Trial 0 | Epoch 75 | Train Loss: 7588.5007 | Val Loss: 6980.5170 | Optimizer: Adam\n",
      "Trial 0 | Epoch 76 | Train Loss: 7359.1691 | Val Loss: 6940.7146 | Optimizer: Adam\n",
      "Trial 0 | Epoch 77 | Train Loss: 7350.8672 | Val Loss: 6910.3349 | Optimizer: Adam\n",
      "Trial 0 | Epoch 78 | Train Loss: 7354.2306 | Val Loss: 6881.2468 | Optimizer: Adam\n",
      "Trial 0 | Epoch 79 | Train Loss: 7258.0120 | Val Loss: 6837.2702 | Optimizer: Adam\n",
      "Trial 0 | Epoch 80 | Train Loss: 7136.1331 | Val Loss: 6836.0012 | Optimizer: Adam\n",
      "Trial 0 | Epoch 81 | Train Loss: 7142.2563 | Val Loss: 6837.0625 | Optimizer: Adam\n",
      "Trial 0 | Epoch 82 | Train Loss: 7314.9018 | Val Loss: 6808.9244 | Optimizer: Adam\n",
      "Trial 0 | Epoch 83 | Train Loss: 7353.7410 | Val Loss: 6792.7547 | Optimizer: Adam\n",
      "Trial 0 | Epoch 84 | Train Loss: 7190.5820 | Val Loss: 6798.4499 | Optimizer: Adam\n",
      "Trial 0 | Epoch 85 | Train Loss: 7277.2570 | Val Loss: 6772.9008 | Optimizer: Adam\n",
      "Trial 0 | Epoch 86 | Train Loss: 7084.2263 | Val Loss: 6761.9945 | Optimizer: Adam\n",
      "Trial 0 | Epoch 87 | Train Loss: 7059.2477 | Val Loss: 6713.0454 | Optimizer: Adam\n",
      "Trial 0 | Epoch 88 | Train Loss: 6974.4703 | Val Loss: 6648.6095 | Optimizer: Adam\n",
      "Trial 0 | Epoch 89 | Train Loss: 7035.5207 | Val Loss: 6623.3845 | Optimizer: Adam\n",
      "Trial 0 | Epoch 90 | Train Loss: 6858.4877 | Val Loss: 6617.0073 | Optimizer: Adam\n",
      "Trial 0 | Epoch 91 | Train Loss: 6941.1799 | Val Loss: 6584.6560 | Optimizer: Adam\n",
      "Trial 0 | Epoch 92 | Train Loss: 7114.5953 | Val Loss: 6625.8146 | Optimizer: Adam\n",
      "Trial 0 | Epoch 93 | Train Loss: 6889.2123 | Val Loss: 6619.5697 | Optimizer: Adam\n",
      "Trial 0 | Epoch 94 | Train Loss: 6862.7284 | Val Loss: 6600.7345 | Optimizer: Adam\n",
      "Trial 0 | Epoch 95 | Train Loss: 7166.0674 | Val Loss: 6532.3083 | Optimizer: Adam\n",
      "Trial 0 | Epoch 96 | Train Loss: 6871.5638 | Val Loss: 6484.4392 | Optimizer: Adam\n",
      "Trial 0 | Epoch 97 | Train Loss: 6919.9145 | Val Loss: 6458.3331 | Optimizer: Adam\n",
      "Trial 0 | Epoch 98 | Train Loss: 6836.8068 | Val Loss: 6473.6814 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:32:55,969] Trial 0 finished with value: 6458.3331190052595 and parameters: {'gnn_dim': 384, 'hidden_dim': 512, 'dropout_rate': 0.3114341269529591, 'lr': 2.259564567566569e-05, 'activation': 'ReLU', 'optimizer': 'Adam', 'weight_decay': 1.6988711084377392e-06}. Best is trial 0 with value: 6458.3331190052595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch 99 | Train Loss: 7003.8059 | Val Loss: 6477.6510 | Optimizer: Adam\n",
      "Trial 1 | Epoch 01 | Train Loss: 20828.6091 | Val Loss: 22035.8284 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 02 | Train Loss: 19948.8897 | Val Loss: 21343.6321 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 03 | Train Loss: 19216.1397 | Val Loss: 20591.3654 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 04 | Train Loss: 18560.1985 | Val Loss: 19650.2190 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 05 | Train Loss: 17722.9433 | Val Loss: 18435.8160 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 06 | Train Loss: 16546.4409 | Val Loss: 16935.1610 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 07 | Train Loss: 15046.4045 | Val Loss: 15237.5526 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 08 | Train Loss: 13602.8463 | Val Loss: 13750.5290 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 09 | Train Loss: 12135.6541 | Val Loss: 12400.6063 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 10 | Train Loss: 11069.5191 | Val Loss: 11519.3872 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 11 | Train Loss: 10189.3951 | Val Loss: 11062.3215 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 12 | Train Loss: 10157.0473 | Val Loss: 10786.2557 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 13 | Train Loss: 9821.3657 | Val Loss: 10548.3824 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 14 | Train Loss: 9606.1063 | Val Loss: 10368.5607 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 15 | Train Loss: 10080.9392 | Val Loss: 10206.9085 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 16 | Train Loss: 9567.4996 | Val Loss: 10052.5139 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 17 | Train Loss: 9273.5067 | Val Loss: 9919.9486 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 18 | Train Loss: 9655.1203 | Val Loss: 9743.0587 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 19 | Train Loss: 9233.7025 | Val Loss: 9632.6791 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 20 | Train Loss: 9390.8574 | Val Loss: 9455.5891 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 21 | Train Loss: 9363.8771 | Val Loss: 9365.7774 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 22 | Train Loss: 8950.6616 | Val Loss: 9220.9521 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 23 | Train Loss: 8778.2244 | Val Loss: 9046.4961 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 24 | Train Loss: 9380.9206 | Val Loss: 8950.1315 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 25 | Train Loss: 8851.0677 | Val Loss: 8798.9334 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 26 | Train Loss: 8455.2126 | Val Loss: 8664.2562 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 27 | Train Loss: 8748.4257 | Val Loss: 8562.9479 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 28 | Train Loss: 8283.5857 | Val Loss: 8423.8261 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 29 | Train Loss: 8392.0675 | Val Loss: 8303.4540 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 30 | Train Loss: 8213.6036 | Val Loss: 8142.1424 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 31 | Train Loss: 8068.3124 | Val Loss: 7941.5675 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 32 | Train Loss: 7985.3711 | Val Loss: 7879.0289 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 33 | Train Loss: 8220.0402 | Val Loss: 7783.8202 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 34 | Train Loss: 8116.6777 | Val Loss: 7762.8027 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 35 | Train Loss: 7885.8230 | Val Loss: 7641.8863 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 36 | Train Loss: 7942.1339 | Val Loss: 7555.5747 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 37 | Train Loss: 7819.5538 | Val Loss: 7490.9647 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 38 | Train Loss: 7597.6125 | Val Loss: 7394.8451 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 39 | Train Loss: 7419.7286 | Val Loss: 7351.0185 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 40 | Train Loss: 7367.2417 | Val Loss: 7265.9561 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 41 | Train Loss: 7886.0949 | Val Loss: 7227.6068 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 42 | Train Loss: 7851.8480 | Val Loss: 7274.9958 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 43 | Train Loss: 7481.9760 | Val Loss: 7183.3156 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 44 | Train Loss: 7600.7884 | Val Loss: 7175.3957 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 45 | Train Loss: 7561.0616 | Val Loss: 7106.5488 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 46 | Train Loss: 7761.7104 | Val Loss: 7095.5680 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 47 | Train Loss: 7570.3166 | Val Loss: 7053.7706 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 48 | Train Loss: 7491.9528 | Val Loss: 7021.6802 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 49 | Train Loss: 7454.9354 | Val Loss: 7021.5573 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 50 | Train Loss: 7455.6520 | Val Loss: 6973.9584 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 51 | Train Loss: 7440.2363 | Val Loss: 6992.1933 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 52 | Train Loss: 7473.7480 | Val Loss: 6993.6010 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 53 | Train Loss: 7482.4705 | Val Loss: 6913.1617 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 54 | Train Loss: 7276.3196 | Val Loss: 6933.3909 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 55 | Train Loss: 7219.1979 | Val Loss: 6905.8661 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 56 | Train Loss: 7461.4364 | Val Loss: 6879.4101 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 57 | Train Loss: 7299.9637 | Val Loss: 6795.1828 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 58 | Train Loss: 7152.3851 | Val Loss: 6792.5579 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 59 | Train Loss: 7365.5129 | Val Loss: 6789.7703 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 60 | Train Loss: 7362.9583 | Val Loss: 6782.2046 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 61 | Train Loss: 7535.2444 | Val Loss: 6761.0443 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 62 | Train Loss: 7216.9372 | Val Loss: 6797.5369 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 63 | Train Loss: 6850.3753 | Val Loss: 6784.7933 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 64 | Train Loss: 7134.4636 | Val Loss: 6751.8870 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 65 | Train Loss: 7235.1243 | Val Loss: 6710.5943 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 66 | Train Loss: 7254.4007 | Val Loss: 6707.3370 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 67 | Train Loss: 7102.2871 | Val Loss: 6626.6053 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 68 | Train Loss: 7206.6380 | Val Loss: 6666.1278 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 69 | Train Loss: 7226.8812 | Val Loss: 6637.8336 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 70 | Train Loss: 7109.2986 | Val Loss: 6684.9561 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 71 | Train Loss: 7367.8189 | Val Loss: 6656.0353 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 72 | Train Loss: 7230.9749 | Val Loss: 6656.7293 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 73 | Train Loss: 7086.1379 | Val Loss: 6560.8356 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 74 | Train Loss: 7135.2461 | Val Loss: 6600.6956 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 75 | Train Loss: 6894.4554 | Val Loss: 6522.2794 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 76 | Train Loss: 7122.6674 | Val Loss: 6486.1945 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 77 | Train Loss: 7405.4888 | Val Loss: 6611.8710 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 78 | Train Loss: 7039.6622 | Val Loss: 6492.1601 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 79 | Train Loss: 6992.9965 | Val Loss: 6495.1116 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 80 | Train Loss: 7049.1213 | Val Loss: 6449.6396 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 81 | Train Loss: 7195.8334 | Val Loss: 6480.1792 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 82 | Train Loss: 6844.8060 | Val Loss: 6497.4737 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 83 | Train Loss: 7382.3269 | Val Loss: 6496.9093 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 84 | Train Loss: 7010.7087 | Val Loss: 6426.4020 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 85 | Train Loss: 7145.0127 | Val Loss: 6434.6562 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 86 | Train Loss: 7002.6594 | Val Loss: 6466.0322 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 87 | Train Loss: 6870.2391 | Val Loss: 6430.3519 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 88 | Train Loss: 7000.2235 | Val Loss: 6483.2520 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 89 | Train Loss: 6827.2049 | Val Loss: 6403.0041 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 90 | Train Loss: 7164.3948 | Val Loss: 6393.0047 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 91 | Train Loss: 6873.5550 | Val Loss: 6354.9338 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 92 | Train Loss: 6808.7486 | Val Loss: 6283.1746 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 93 | Train Loss: 6987.7514 | Val Loss: 6341.3066 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 94 | Train Loss: 6897.6189 | Val Loss: 6292.2613 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 95 | Train Loss: 7025.3118 | Val Loss: 6372.4128 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 96 | Train Loss: 7193.2860 | Val Loss: 6320.9068 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 97 | Train Loss: 6546.9150 | Val Loss: 6251.1368 | Optimizer: RMSprop\n",
      "Trial 1 | Epoch 98 | Train Loss: 6993.3501 | Val Loss: 6201.0814 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:00,910] Trial 1 finished with value: 6176.655341120049 and parameters: {'gnn_dim': 384, 'hidden_dim': 256, 'dropout_rate': 0.279674211400994, 'lr': 2.6204602506041883e-05, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 9.585616350224761e-06}. Best is trial 1 with value: 6176.655341120049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 | Epoch 99 | Train Loss: 6898.1923 | Val Loss: 6176.6553 | Optimizer: RMSprop\n",
      "Trial 2 | Epoch 01 | Train Loss: 20582.0657 | Val Loss: 20821.8570 | Optimizer: Adam\n",
      "Trial 2 | Epoch 02 | Train Loss: 18057.5555 | Val Loss: 17460.6442 | Optimizer: Adam\n",
      "Trial 2 | Epoch 03 | Train Loss: 13466.6776 | Val Loss: 11086.3165 | Optimizer: Adam\n",
      "Trial 2 | Epoch 04 | Train Loss: 11673.1376 | Val Loss: 10528.1342 | Optimizer: Adam\n",
      "Trial 2 | Epoch 05 | Train Loss: 9967.3166 | Val Loss: 10457.7427 | Optimizer: Adam\n",
      "Trial 2 | Epoch 06 | Train Loss: 9864.9967 | Val Loss: 9364.2067 | Optimizer: Adam\n",
      "Trial 2 | Epoch 07 | Train Loss: 8623.7742 | Val Loss: 7958.8890 | Optimizer: Adam\n",
      "Trial 2 | Epoch 08 | Train Loss: 8450.6232 | Val Loss: 7461.8945 | Optimizer: Adam\n",
      "Trial 2 | Epoch 09 | Train Loss: 8130.6314 | Val Loss: 7597.0396 | Optimizer: Adam\n",
      "Trial 2 | Epoch 10 | Train Loss: 7645.9180 | Val Loss: 6198.2959 | Optimizer: Adam\n",
      "Trial 2 | Epoch 11 | Train Loss: 7196.8555 | Val Loss: 6265.8615 | Optimizer: Adam\n",
      "Trial 2 | Epoch 12 | Train Loss: 6736.2665 | Val Loss: 5571.2101 | Optimizer: Adam\n",
      "Trial 2 | Epoch 13 | Train Loss: 6767.1162 | Val Loss: 5967.0777 | Optimizer: Adam\n",
      "Trial 2 | Epoch 14 | Train Loss: 6550.4560 | Val Loss: 5587.6177 | Optimizer: Adam\n",
      "Trial 2 | Epoch 15 | Train Loss: 6605.2287 | Val Loss: 5898.4898 | Optimizer: Adam\n",
      "Trial 2 | Epoch 16 | Train Loss: 7370.3109 | Val Loss: 6685.7428 | Optimizer: Adam\n",
      "Trial 2 | Epoch 17 | Train Loss: 7104.2174 | Val Loss: 5597.2474 | Optimizer: Adam\n",
      "Trial 2 | Epoch 18 | Train Loss: 6956.8236 | Val Loss: 6833.2084 | Optimizer: Adam\n",
      "Trial 2 | Epoch 19 | Train Loss: 6210.9020 | Val Loss: 5530.8517 | Optimizer: Adam\n",
      "Trial 2 | Epoch 20 | Train Loss: 6300.2413 | Val Loss: 5594.9081 | Optimizer: Adam\n",
      "Trial 2 | Epoch 21 | Train Loss: 6189.6520 | Val Loss: 5971.3310 | Optimizer: Adam\n",
      "Trial 2 | Epoch 22 | Train Loss: 6066.6390 | Val Loss: 5337.4307 | Optimizer: Adam\n",
      "Trial 2 | Epoch 23 | Train Loss: 5762.3613 | Val Loss: 5565.1441 | Optimizer: Adam\n",
      "Trial 2 | Epoch 24 | Train Loss: 5721.8116 | Val Loss: 5288.1432 | Optimizer: Adam\n",
      "Trial 2 | Epoch 25 | Train Loss: 5432.1257 | Val Loss: 5490.0976 | Optimizer: Adam\n",
      "Trial 2 | Epoch 26 | Train Loss: 5685.5554 | Val Loss: 5457.5182 | Optimizer: Adam\n",
      "Trial 2 | Epoch 27 | Train Loss: 5830.9227 | Val Loss: 5487.5677 | Optimizer: Adam\n",
      "Trial 2 | Epoch 28 | Train Loss: 5892.5406 | Val Loss: 5105.8426 | Optimizer: Adam\n",
      "Trial 2 | Epoch 29 | Train Loss: 5329.3083 | Val Loss: 5363.0738 | Optimizer: Adam\n",
      "Trial 2 | Epoch 30 | Train Loss: 5393.0637 | Val Loss: 5161.1804 | Optimizer: Adam\n",
      "Trial 2 | Epoch 31 | Train Loss: 5404.0169 | Val Loss: 5066.4330 | Optimizer: Adam\n",
      "Trial 2 | Epoch 32 | Train Loss: 5742.5413 | Val Loss: 6126.6774 | Optimizer: Adam\n",
      "Trial 2 | Epoch 33 | Train Loss: 5741.4260 | Val Loss: 5089.4967 | Optimizer: Adam\n",
      "Trial 2 | Epoch 34 | Train Loss: 5456.0490 | Val Loss: 5200.8769 | Optimizer: Adam\n",
      "Trial 2 | Epoch 35 | Train Loss: 5369.8444 | Val Loss: 5158.1813 | Optimizer: Adam\n",
      "Trial 2 | Epoch 36 | Train Loss: 5191.5763 | Val Loss: 5301.0717 | Optimizer: Adam\n",
      "Trial 2 | Epoch 37 | Train Loss: 5735.9602 | Val Loss: 5160.1718 | Optimizer: Adam\n",
      "Trial 2 | Epoch 38 | Train Loss: 5564.3536 | Val Loss: 5192.6359 | Optimizer: Adam\n",
      "Trial 2 | Epoch 39 | Train Loss: 5379.6796 | Val Loss: 5102.4840 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:03,125] Trial 2 finished with value: 5066.432979772587 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.2954992251671889, 'lr': 0.000359806924945697, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 9.784632875052921e-05}. Best is trial 2 with value: 5066.432979772587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 | Epoch 40 | Train Loss: 4990.5533 | Val Loss: 5158.2643 | Optimizer: Adam\n",
      "Trial 2 | Epoch 41 | Train Loss: 5316.0933 | Val Loss: 5188.9939 | Optimizer: Adam\n",
      "Trial 2 - Early stopping triggered at epoch 41\n",
      "Trial 3 | Epoch 01 | Train Loss: 20294.8619 | Val Loss: 23701.0880 | Optimizer: SGD\n",
      "Trial 3 | Epoch 02 | Train Loss: 20785.9923 | Val Loss: 11416.8872 | Optimizer: SGD\n",
      "Trial 3 | Epoch 03 | Train Loss: 15812.2334 | Val Loss: 22964.4979 | Optimizer: SGD\n",
      "Trial 3 | Epoch 04 | Train Loss: 18984.2436 | Val Loss: 23531.4586 | Optimizer: SGD\n",
      "Trial 3 | Epoch 05 | Train Loss: 21613.3964 | Val Loss: 23480.7724 | Optimizer: SGD\n",
      "Trial 3 | Epoch 06 | Train Loss: 21561.6076 | Val Loss: 23431.0366 | Optimizer: SGD\n",
      "Trial 3 | Epoch 07 | Train Loss: 21518.8821 | Val Loss: 23394.9444 | Optimizer: SGD\n",
      "Trial 3 | Epoch 08 | Train Loss: 21491.9968 | Val Loss: 23375.7330 | Optimizer: SGD\n",
      "Trial 3 | Epoch 09 | Train Loss: 21473.4174 | Val Loss: 23357.8303 | Optimizer: SGD\n",
      "Trial 3 | Epoch 10 | Train Loss: 21455.8850 | Val Loss: 23340.0188 | Optimizer: SGD\n",
      "Trial 3 | Epoch 11 | Train Loss: 21438.2902 | Val Loss: 23322.7731 | Optimizer: SGD\n",
      "Trial 3 | Epoch 12 | Train Loss: 21421.1879 | Val Loss: 23305.1272 | Optimizer: SGD\n",
      "Trial 3 - Early stopping triggered at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:03,760] Trial 3 finished with value: 11416.88718285891 and parameters: {'gnn_dim': 384, 'hidden_dim': 256, 'dropout_rate': 0.27004144501157257, 'lr': 1.6130666533531174e-05, 'activation': 'ReLU', 'optimizer': 'SGD', 'momentum': 0.8078316510437843, 'weight_decay': 2.5197851309764388e-05}. Best is trial 2 with value: 5066.432979772587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 | Epoch 01 | Train Loss: 21108.2479 | Val Loss: 22499.7998 | Optimizer: Adam\n",
      "Trial 4 | Epoch 02 | Train Loss: 20354.1674 | Val Loss: 21774.7888 | Optimizer: Adam\n",
      "Trial 4 | Epoch 03 | Train Loss: 19768.8500 | Val Loss: 20995.7016 | Optimizer: Adam\n",
      "Trial 4 | Epoch 04 | Train Loss: 19050.8290 | Val Loss: 20076.8817 | Optimizer: Adam\n",
      "Trial 4 | Epoch 05 | Train Loss: 17960.2417 | Val Loss: 18806.3985 | Optimizer: Adam\n",
      "Trial 4 | Epoch 06 | Train Loss: 16631.9339 | Val Loss: 16841.4042 | Optimizer: Adam\n",
      "Trial 4 | Epoch 07 | Train Loss: 14442.4576 | Val Loss: 13810.8011 | Optimizer: Adam\n",
      "Trial 4 | Epoch 08 | Train Loss: 11614.8852 | Val Loss: 11053.7547 | Optimizer: Adam\n",
      "Trial 4 | Epoch 09 | Train Loss: 11369.6263 | Val Loss: 11195.3047 | Optimizer: Adam\n",
      "Trial 4 | Epoch 10 | Train Loss: 10356.0719 | Val Loss: 10394.4846 | Optimizer: Adam\n",
      "Trial 4 | Epoch 11 | Train Loss: 9972.8905 | Val Loss: 10384.9702 | Optimizer: Adam\n",
      "Trial 4 | Epoch 12 | Train Loss: 9766.0867 | Val Loss: 9835.2212 | Optimizer: Adam\n",
      "Trial 4 | Epoch 13 | Train Loss: 9552.2406 | Val Loss: 9270.0918 | Optimizer: Adam\n",
      "Trial 4 | Epoch 14 | Train Loss: 8960.3243 | Val Loss: 8702.2141 | Optimizer: Adam\n",
      "Trial 4 | Epoch 15 | Train Loss: 8813.1866 | Val Loss: 8173.0258 | Optimizer: Adam\n",
      "Trial 4 | Epoch 16 | Train Loss: 8272.4054 | Val Loss: 7813.7282 | Optimizer: Adam\n",
      "Trial 4 | Epoch 17 | Train Loss: 8183.9913 | Val Loss: 7687.6077 | Optimizer: Adam\n",
      "Trial 4 | Epoch 18 | Train Loss: 7912.7276 | Val Loss: 7288.2729 | Optimizer: Adam\n",
      "Trial 4 | Epoch 19 | Train Loss: 7988.4635 | Val Loss: 7080.8072 | Optimizer: Adam\n",
      "Trial 4 | Epoch 20 | Train Loss: 7359.4161 | Val Loss: 7053.3307 | Optimizer: Adam\n",
      "Trial 4 | Epoch 21 | Train Loss: 7389.8186 | Val Loss: 6955.5249 | Optimizer: Adam\n",
      "Trial 4 | Epoch 22 | Train Loss: 7275.1249 | Val Loss: 6788.0974 | Optimizer: Adam\n",
      "Trial 4 | Epoch 23 | Train Loss: 7599.1371 | Val Loss: 6684.8359 | Optimizer: Adam\n",
      "Trial 4 | Epoch 24 | Train Loss: 7127.9654 | Val Loss: 6461.1428 | Optimizer: Adam\n",
      "Trial 4 | Epoch 25 | Train Loss: 7110.4424 | Val Loss: 6351.3290 | Optimizer: Adam\n",
      "Trial 4 | Epoch 26 | Train Loss: 6874.8090 | Val Loss: 6068.4406 | Optimizer: Adam\n",
      "Trial 4 | Epoch 27 | Train Loss: 6796.4741 | Val Loss: 6071.9129 | Optimizer: Adam\n",
      "Trial 4 | Epoch 28 | Train Loss: 6989.8283 | Val Loss: 5762.5483 | Optimizer: Adam\n",
      "Trial 4 | Epoch 29 | Train Loss: 6515.6229 | Val Loss: 5676.2819 | Optimizer: Adam\n",
      "Trial 4 | Epoch 30 | Train Loss: 6450.5302 | Val Loss: 5588.0362 | Optimizer: Adam\n",
      "Trial 4 | Epoch 31 | Train Loss: 6808.1258 | Val Loss: 5779.2838 | Optimizer: Adam\n",
      "Trial 4 | Epoch 32 | Train Loss: 6408.3504 | Val Loss: 5634.2921 | Optimizer: Adam\n",
      "Trial 4 | Epoch 33 | Train Loss: 6213.5775 | Val Loss: 5603.7745 | Optimizer: Adam\n",
      "Trial 4 | Epoch 34 | Train Loss: 6419.4298 | Val Loss: 5859.8655 | Optimizer: Adam\n",
      "Trial 4 | Epoch 35 | Train Loss: 6707.1933 | Val Loss: 5990.8900 | Optimizer: Adam\n",
      "Trial 4 | Epoch 36 | Train Loss: 6342.4245 | Val Loss: 5645.0327 | Optimizer: Adam\n",
      "Trial 4 | Epoch 37 | Train Loss: 6187.4264 | Val Loss: 5699.8706 | Optimizer: Adam\n",
      "Trial 4 | Epoch 38 | Train Loss: 6092.8910 | Val Loss: 5712.7766 | Optimizer: Adam\n",
      "Trial 4 | Epoch 39 | Train Loss: 6053.7473 | Val Loss: 5573.3234 | Optimizer: Adam\n",
      "Trial 4 | Epoch 40 | Train Loss: 6081.8396 | Val Loss: 5699.2159 | Optimizer: Adam\n",
      "Trial 4 | Epoch 41 | Train Loss: 6179.9643 | Val Loss: 5493.3125 | Optimizer: Adam\n",
      "Trial 4 | Epoch 42 | Train Loss: 5660.8021 | Val Loss: 5529.0965 | Optimizer: Adam\n",
      "Trial 4 | Epoch 43 | Train Loss: 5807.8279 | Val Loss: 5569.9970 | Optimizer: Adam\n",
      "Trial 4 | Epoch 44 | Train Loss: 5648.4907 | Val Loss: 5430.5851 | Optimizer: Adam\n",
      "Trial 4 | Epoch 45 | Train Loss: 5504.6667 | Val Loss: 5346.6829 | Optimizer: Adam\n",
      "Trial 4 | Epoch 46 | Train Loss: 5810.4282 | Val Loss: 5411.5916 | Optimizer: Adam\n",
      "Trial 4 | Epoch 47 | Train Loss: 5774.4003 | Val Loss: 5521.7137 | Optimizer: Adam\n",
      "Trial 4 | Epoch 48 | Train Loss: 5804.3983 | Val Loss: 5303.4467 | Optimizer: Adam\n",
      "Trial 4 | Epoch 49 | Train Loss: 5840.3408 | Val Loss: 5275.5570 | Optimizer: Adam\n",
      "Trial 4 | Epoch 50 | Train Loss: 5628.1034 | Val Loss: 5336.4419 | Optimizer: Adam\n",
      "Trial 4 | Epoch 51 | Train Loss: 5846.3331 | Val Loss: 5454.8280 | Optimizer: Adam\n",
      "Trial 4 | Epoch 52 | Train Loss: 5492.4191 | Val Loss: 5279.7240 | Optimizer: Adam\n",
      "Trial 4 | Epoch 53 | Train Loss: 5907.2687 | Val Loss: 5233.0075 | Optimizer: Adam\n",
      "Trial 4 | Epoch 54 | Train Loss: 5504.2140 | Val Loss: 5372.8704 | Optimizer: Adam\n",
      "Trial 4 | Epoch 55 | Train Loss: 5777.5296 | Val Loss: 5291.6143 | Optimizer: Adam\n",
      "Trial 4 | Epoch 56 | Train Loss: 5493.7640 | Val Loss: 5090.7048 | Optimizer: Adam\n",
      "Trial 4 | Epoch 57 | Train Loss: 5535.5955 | Val Loss: 5543.7123 | Optimizer: Adam\n",
      "Trial 4 | Epoch 58 | Train Loss: 5741.0436 | Val Loss: 5488.6299 | Optimizer: Adam\n",
      "Trial 4 | Epoch 59 | Train Loss: 5499.3897 | Val Loss: 5137.2318 | Optimizer: Adam\n",
      "Trial 4 | Epoch 60 | Train Loss: 5290.0059 | Val Loss: 5445.2373 | Optimizer: Adam\n",
      "Trial 4 | Epoch 61 | Train Loss: 5400.4791 | Val Loss: 5221.1592 | Optimizer: Adam\n",
      "Trial 4 | Epoch 62 | Train Loss: 5620.5001 | Val Loss: 5098.4248 | Optimizer: Adam\n",
      "Trial 4 | Epoch 63 | Train Loss: 5601.2455 | Val Loss: 5570.4618 | Optimizer: Adam\n",
      "Trial 4 | Epoch 64 | Train Loss: 5246.2104 | Val Loss: 5110.4861 | Optimizer: Adam\n",
      "Trial 4 | Epoch 65 | Train Loss: 5433.0576 | Val Loss: 5042.9596 | Optimizer: Adam\n",
      "Trial 4 | Epoch 66 | Train Loss: 5486.9196 | Val Loss: 5332.8342 | Optimizer: Adam\n",
      "Trial 4 | Epoch 67 | Train Loss: 5389.3512 | Val Loss: 5183.1501 | Optimizer: Adam\n",
      "Trial 4 | Epoch 68 | Train Loss: 5419.5534 | Val Loss: 5028.1165 | Optimizer: Adam\n",
      "Trial 4 | Epoch 69 | Train Loss: 5175.2046 | Val Loss: 5141.6913 | Optimizer: Adam\n",
      "Trial 4 | Epoch 70 | Train Loss: 5248.0757 | Val Loss: 5143.9400 | Optimizer: Adam\n",
      "Trial 4 | Epoch 71 | Train Loss: 5290.4709 | Val Loss: 5259.4669 | Optimizer: Adam\n",
      "Trial 4 | Epoch 72 | Train Loss: 5273.8134 | Val Loss: 5176.9317 | Optimizer: Adam\n",
      "Trial 4 | Epoch 73 | Train Loss: 5118.6522 | Val Loss: 5074.8160 | Optimizer: Adam\n",
      "Trial 4 | Epoch 74 | Train Loss: 5102.3055 | Val Loss: 5083.6905 | Optimizer: Adam\n",
      "Trial 4 | Epoch 75 | Train Loss: 5230.8926 | Val Loss: 5028.0179 | Optimizer: Adam\n",
      "Trial 4 | Epoch 76 | Train Loss: 5299.4185 | Val Loss: 5171.9196 | Optimizer: Adam\n",
      "Trial 4 | Epoch 77 | Train Loss: 5374.8294 | Val Loss: 4996.4583 | Optimizer: Adam\n",
      "Trial 4 | Epoch 78 | Train Loss: 5263.4232 | Val Loss: 5318.8843 | Optimizer: Adam\n",
      "Trial 4 | Epoch 79 | Train Loss: 5217.0225 | Val Loss: 4971.0217 | Optimizer: Adam\n",
      "Trial 4 | Epoch 80 | Train Loss: 5102.8003 | Val Loss: 5142.0769 | Optimizer: Adam\n",
      "Trial 4 | Epoch 81 | Train Loss: 5000.5517 | Val Loss: 4955.8348 | Optimizer: Adam\n",
      "Trial 4 | Epoch 82 | Train Loss: 5418.7225 | Val Loss: 5148.7068 | Optimizer: Adam\n",
      "Trial 4 | Epoch 83 | Train Loss: 5434.7545 | Val Loss: 5597.9162 | Optimizer: Adam\n",
      "Trial 4 | Epoch 84 | Train Loss: 4948.6738 | Val Loss: 5009.4035 | Optimizer: Adam\n",
      "Trial 4 | Epoch 85 | Train Loss: 5061.4483 | Val Loss: 5182.4510 | Optimizer: Adam\n",
      "Trial 4 | Epoch 86 | Train Loss: 5216.2209 | Val Loss: 5064.4001 | Optimizer: Adam\n",
      "Trial 4 | Epoch 87 | Train Loss: 5082.7573 | Val Loss: 4976.9084 | Optimizer: Adam\n",
      "Trial 4 | Epoch 88 | Train Loss: 5037.6078 | Val Loss: 5290.0869 | Optimizer: Adam\n",
      "Trial 4 | Epoch 89 | Train Loss: 4796.3264 | Val Loss: 4884.7352 | Optimizer: Adam\n",
      "Trial 4 | Epoch 90 | Train Loss: 5129.5880 | Val Loss: 5186.6371 | Optimizer: Adam\n",
      "Trial 4 | Epoch 91 | Train Loss: 4971.0501 | Val Loss: 5114.8418 | Optimizer: Adam\n",
      "Trial 4 | Epoch 92 | Train Loss: 4917.4680 | Val Loss: 4901.1615 | Optimizer: Adam\n",
      "Trial 4 | Epoch 93 | Train Loss: 4960.2826 | Val Loss: 5251.1533 | Optimizer: Adam\n",
      "Trial 4 | Epoch 94 | Train Loss: 5201.9369 | Val Loss: 5003.3008 | Optimizer: Adam\n",
      "Trial 4 | Epoch 95 | Train Loss: 5189.2104 | Val Loss: 5155.3616 | Optimizer: Adam\n",
      "Trial 4 | Epoch 96 | Train Loss: 4938.7748 | Val Loss: 4953.6638 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:09,191] Trial 4 finished with value: 4884.735221031869 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.2855393115752087, 'lr': 0.00010785040998541331, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 6.181383857104351e-05}. Best is trial 4 with value: 4884.735221031869.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 | Epoch 97 | Train Loss: 4818.5021 | Val Loss: 4913.0885 | Optimizer: Adam\n",
      "Trial 4 | Epoch 98 | Train Loss: 5169.4385 | Val Loss: 5000.8569 | Optimizer: Adam\n",
      "Trial 4 | Epoch 99 | Train Loss: 4811.7896 | Val Loss: 5131.5078 | Optimizer: Adam\n",
      "Trial 4 - Early stopping triggered at epoch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:09,342] Trial 5 pruned. \n",
      "[I 2025-09-04 20:33:09,493] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 | Epoch 01 | Train Loss: 21470.5019 | Val Loss: 22512.6190 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 01 | Train Loss: 21534.0195 | Val Loss: 23147.7430 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:09,590] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 8 | Epoch 01 | Train Loss: 18279.4363 | Val Loss: 13247.2091 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 02 | Train Loss: 12073.5674 | Val Loss: 10872.7915 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 03 | Train Loss: 9942.4329 | Val Loss: 9473.4938 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 04 | Train Loss: 9137.9622 | Val Loss: 8720.4748 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 05 | Train Loss: 8099.5203 | Val Loss: 7851.2888 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 06 | Train Loss: 8075.6828 | Val Loss: 7265.3741 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 07 | Train Loss: 7621.8743 | Val Loss: 7014.5474 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 08 | Train Loss: 7843.0348 | Val Loss: 7810.5635 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 09 | Train Loss: 7870.2962 | Val Loss: 6790.0211 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 10 | Train Loss: 7619.0797 | Val Loss: 6780.4913 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 11 | Train Loss: 7556.3600 | Val Loss: 6528.8556 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 12 | Train Loss: 7329.8596 | Val Loss: 7043.4989 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 13 | Train Loss: 7312.4348 | Val Loss: 6702.3655 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 14 | Train Loss: 7137.7205 | Val Loss: 6150.8768 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 15 | Train Loss: 6959.4905 | Val Loss: 5898.5856 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 16 | Train Loss: 6701.6422 | Val Loss: 6126.0587 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 17 | Train Loss: 6725.3408 | Val Loss: 5847.4899 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 18 | Train Loss: 6719.1587 | Val Loss: 6113.7877 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 19 | Train Loss: 6481.8232 | Val Loss: 5821.8151 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 20 | Train Loss: 6525.9031 | Val Loss: 5708.0858 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 21 | Train Loss: 6502.3679 | Val Loss: 5703.0179 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 22 | Train Loss: 6499.6405 | Val Loss: 5671.3497 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 23 | Train Loss: 6149.2823 | Val Loss: 5692.1168 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 24 | Train Loss: 6242.9842 | Val Loss: 5577.5090 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 25 | Train Loss: 6136.2234 | Val Loss: 5731.1532 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 26 | Train Loss: 6280.0819 | Val Loss: 6136.3223 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 27 | Train Loss: 6384.8762 | Val Loss: 6449.2008 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 28 | Train Loss: 5943.1055 | Val Loss: 5610.0558 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 29 | Train Loss: 5953.0625 | Val Loss: 5658.7426 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 30 | Train Loss: 5932.9744 | Val Loss: 5456.7954 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 31 | Train Loss: 6133.7522 | Val Loss: 6224.4233 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 32 | Train Loss: 6150.3418 | Val Loss: 5610.8960 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 33 | Train Loss: 6033.5421 | Val Loss: 5698.7653 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 34 | Train Loss: 5975.0577 | Val Loss: 5661.1760 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 35 | Train Loss: 6272.3535 | Val Loss: 5886.3634 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 36 | Train Loss: 5903.4866 | Val Loss: 5281.8747 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 37 | Train Loss: 5676.8841 | Val Loss: 5891.6751 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 38 | Train Loss: 5651.4166 | Val Loss: 5434.6576 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 39 | Train Loss: 5451.7333 | Val Loss: 5249.0319 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 40 | Train Loss: 5746.6909 | Val Loss: 5611.5122 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 41 | Train Loss: 5565.7278 | Val Loss: 5243.9472 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 42 | Train Loss: 5504.8836 | Val Loss: 5755.6531 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 43 | Train Loss: 6192.3925 | Val Loss: 5264.8420 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 44 | Train Loss: 5836.9102 | Val Loss: 5206.1318 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 45 | Train Loss: 5619.8667 | Val Loss: 5390.8141 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 46 | Train Loss: 5710.9174 | Val Loss: 5213.8072 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 47 | Train Loss: 5622.6793 | Val Loss: 5171.9884 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 48 | Train Loss: 5586.3956 | Val Loss: 6264.1020 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 49 | Train Loss: 5760.5483 | Val Loss: 5334.2074 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 50 | Train Loss: 5656.7835 | Val Loss: 5153.8191 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 51 | Train Loss: 5640.9127 | Val Loss: 5425.6895 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 52 | Train Loss: 5761.0785 | Val Loss: 5158.2498 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 53 | Train Loss: 5681.2646 | Val Loss: 5357.1075 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 54 | Train Loss: 5540.8422 | Val Loss: 5316.4449 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 55 | Train Loss: 6000.0272 | Val Loss: 5260.8751 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 56 | Train Loss: 5522.1513 | Val Loss: 5331.7870 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 57 | Train Loss: 5648.5983 | Val Loss: 6437.2050 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 58 | Train Loss: 5419.1191 | Val Loss: 5368.3326 | Optimizer: RMSprop\n",
      "Trial 8 | Epoch 59 | Train Loss: 5327.7751 | Val Loss: 6584.1732 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:12,825] Trial 8 finished with value: 5153.819055538366 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.38647214299409266, 'lr': 8.184948648838637e-05, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 1.4045095239369073e-05}. Best is trial 4 with value: 4884.735221031869.\n",
      "[I 2025-09-04 20:33:12,932] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 | Epoch 60 | Train Loss: 5973.6327 | Val Loss: 5183.9962 | Optimizer: RMSprop\n",
      "Trial 8 - Early stopping triggered at epoch 60\n",
      "Trial 9 | Epoch 01 | Train Loss: 21347.2123 | Val Loss: 23172.1336 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:13,052] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 | Epoch 01 | Train Loss: 22248.0734 | Val Loss: 23666.7557 | Optimizer: Adam\n",
      "Trial 11 | Epoch 01 | Train Loss: 20829.7745 | Val Loss: 21486.3354 | Optimizer: Adam\n",
      "Trial 11 | Epoch 02 | Train Loss: 19069.4527 | Val Loss: 19131.5603 | Optimizer: Adam\n",
      "Trial 11 | Epoch 03 | Train Loss: 16312.2804 | Val Loss: 15272.7141 | Optimizer: Adam\n",
      "Trial 11 | Epoch 04 | Train Loss: 12221.8207 | Val Loss: 11269.9803 | Optimizer: Adam\n",
      "Trial 11 | Epoch 05 | Train Loss: 11508.2263 | Val Loss: 10481.9567 | Optimizer: Adam\n",
      "Trial 11 | Epoch 06 | Train Loss: 10113.6274 | Val Loss: 10934.5436 | Optimizer: Adam\n",
      "Trial 11 | Epoch 07 | Train Loss: 10062.5310 | Val Loss: 9727.4533 | Optimizer: Adam\n",
      "Trial 11 | Epoch 08 | Train Loss: 9123.3747 | Val Loss: 8319.3348 | Optimizer: Adam\n",
      "Trial 11 | Epoch 09 | Train Loss: 8544.9009 | Val Loss: 7673.2426 | Optimizer: Adam\n",
      "Trial 11 | Epoch 10 | Train Loss: 7993.3461 | Val Loss: 7702.6019 | Optimizer: Adam\n",
      "Trial 11 | Epoch 11 | Train Loss: 7655.6682 | Val Loss: 6536.4494 | Optimizer: Adam\n",
      "Trial 11 | Epoch 12 | Train Loss: 7358.4163 | Val Loss: 6504.6742 | Optimizer: Adam\n",
      "Trial 11 | Epoch 13 | Train Loss: 7181.2071 | Val Loss: 5784.6149 | Optimizer: Adam\n",
      "Trial 11 | Epoch 14 | Train Loss: 6895.1477 | Val Loss: 5601.1638 | Optimizer: Adam\n",
      "Trial 11 | Epoch 15 | Train Loss: 6718.9875 | Val Loss: 5683.1833 | Optimizer: Adam\n",
      "Trial 11 | Epoch 16 | Train Loss: 6459.4231 | Val Loss: 5581.2761 | Optimizer: Adam\n",
      "Trial 11 | Epoch 17 | Train Loss: 6448.9853 | Val Loss: 5584.9153 | Optimizer: Adam\n",
      "Trial 11 | Epoch 18 | Train Loss: 6632.0298 | Val Loss: 5678.2383 | Optimizer: Adam\n",
      "Trial 11 | Epoch 19 | Train Loss: 6464.5996 | Val Loss: 5576.7784 | Optimizer: Adam\n",
      "Trial 11 | Epoch 20 | Train Loss: 5995.3014 | Val Loss: 5792.0357 | Optimizer: Adam\n",
      "Trial 11 | Epoch 21 | Train Loss: 6081.6387 | Val Loss: 5611.6752 | Optimizer: Adam\n",
      "Trial 11 | Epoch 22 | Train Loss: 6151.5180 | Val Loss: 5736.1918 | Optimizer: Adam\n",
      "Trial 11 | Epoch 23 | Train Loss: 5928.7834 | Val Loss: 5444.5273 | Optimizer: Adam\n",
      "Trial 11 | Epoch 24 | Train Loss: 5887.0687 | Val Loss: 5400.3215 | Optimizer: Adam\n",
      "Trial 11 | Epoch 25 | Train Loss: 6085.3811 | Val Loss: 5574.2219 | Optimizer: Adam\n",
      "Trial 11 | Epoch 26 | Train Loss: 5946.1075 | Val Loss: 5296.4320 | Optimizer: Adam\n",
      "Trial 11 | Epoch 27 | Train Loss: 5997.7024 | Val Loss: 5358.0419 | Optimizer: Adam\n",
      "Trial 11 | Epoch 28 | Train Loss: 6089.5664 | Val Loss: 5258.4509 | Optimizer: Adam\n",
      "Trial 11 | Epoch 29 | Train Loss: 5675.2215 | Val Loss: 5297.7853 | Optimizer: Adam\n",
      "Trial 11 | Epoch 30 | Train Loss: 5496.6029 | Val Loss: 5282.2995 | Optimizer: Adam\n",
      "Trial 11 | Epoch 31 | Train Loss: 5466.0748 | Val Loss: 5278.9333 | Optimizer: Adam\n",
      "Trial 11 | Epoch 32 | Train Loss: 5597.7122 | Val Loss: 5363.2120 | Optimizer: Adam\n",
      "Trial 11 | Epoch 33 | Train Loss: 5550.6947 | Val Loss: 5236.6170 | Optimizer: Adam\n",
      "Trial 11 | Epoch 34 | Train Loss: 5363.6833 | Val Loss: 5034.6308 | Optimizer: Adam\n",
      "Trial 11 | Epoch 35 | Train Loss: 5656.4151 | Val Loss: 5550.7818 | Optimizer: Adam\n",
      "Trial 11 | Epoch 36 | Train Loss: 5434.7138 | Val Loss: 5255.1049 | Optimizer: Adam\n",
      "Trial 11 | Epoch 37 | Train Loss: 5338.9271 | Val Loss: 5231.4769 | Optimizer: Adam\n",
      "Trial 11 | Epoch 38 | Train Loss: 5330.3139 | Val Loss: 5018.7350 | Optimizer: Adam\n",
      "Trial 11 | Epoch 39 | Train Loss: 5290.6685 | Val Loss: 5187.6408 | Optimizer: Adam\n",
      "Trial 11 | Epoch 40 | Train Loss: 5342.2963 | Val Loss: 5016.3821 | Optimizer: Adam\n",
      "Trial 11 | Epoch 41 | Train Loss: 5204.8417 | Val Loss: 5178.5923 | Optimizer: Adam\n",
      "Trial 11 | Epoch 42 | Train Loss: 5324.3372 | Val Loss: 5610.9090 | Optimizer: Adam\n",
      "Trial 11 | Epoch 43 | Train Loss: 5112.8809 | Val Loss: 4962.8838 | Optimizer: Adam\n",
      "Trial 11 | Epoch 44 | Train Loss: 5437.4274 | Val Loss: 5231.0449 | Optimizer: Adam\n",
      "Trial 11 | Epoch 45 | Train Loss: 4998.0208 | Val Loss: 5081.8121 | Optimizer: Adam\n",
      "Trial 11 | Epoch 46 | Train Loss: 5278.0806 | Val Loss: 5364.1688 | Optimizer: Adam\n",
      "Trial 11 | Epoch 47 | Train Loss: 5184.9087 | Val Loss: 5033.2069 | Optimizer: Adam\n",
      "Trial 11 | Epoch 48 | Train Loss: 5081.9968 | Val Loss: 5161.5233 | Optimizer: Adam\n",
      "Trial 11 | Epoch 49 | Train Loss: 5138.2808 | Val Loss: 5279.7968 | Optimizer: Adam\n",
      "Trial 11 | Epoch 50 | Train Loss: 4935.0222 | Val Loss: 4951.5539 | Optimizer: Adam\n",
      "Trial 11 | Epoch 51 | Train Loss: 5373.1284 | Val Loss: 5438.2583 | Optimizer: Adam\n",
      "Trial 11 | Epoch 52 | Train Loss: 5263.6952 | Val Loss: 4965.7840 | Optimizer: Adam\n",
      "Trial 11 | Epoch 53 | Train Loss: 5257.4998 | Val Loss: 5060.9763 | Optimizer: Adam\n",
      "Trial 11 | Epoch 54 | Train Loss: 4987.5212 | Val Loss: 5043.8711 | Optimizer: Adam\n",
      "Trial 11 | Epoch 55 | Train Loss: 4860.3831 | Val Loss: 4923.9641 | Optimizer: Adam\n",
      "Trial 11 | Epoch 56 | Train Loss: 4928.3444 | Val Loss: 5144.0369 | Optimizer: Adam\n",
      "Trial 11 | Epoch 57 | Train Loss: 5044.3619 | Val Loss: 5184.0337 | Optimizer: Adam\n",
      "Trial 11 | Epoch 58 | Train Loss: 4958.7065 | Val Loss: 4923.8066 | Optimizer: Adam\n",
      "Trial 11 | Epoch 59 | Train Loss: 5262.9747 | Val Loss: 5919.0482 | Optimizer: Adam\n",
      "Trial 11 | Epoch 60 | Train Loss: 5333.4953 | Val Loss: 5278.6196 | Optimizer: Adam\n",
      "Trial 11 | Epoch 61 | Train Loss: 5680.0663 | Val Loss: 5901.0527 | Optimizer: Adam\n",
      "Trial 11 | Epoch 62 | Train Loss: 4897.5643 | Val Loss: 5039.0014 | Optimizer: Adam\n",
      "Trial 11 | Epoch 63 | Train Loss: 5224.5886 | Val Loss: 5487.4472 | Optimizer: Adam\n",
      "Trial 11 | Epoch 64 | Train Loss: 5231.7330 | Val Loss: 4956.9419 | Optimizer: Adam\n",
      "Trial 11 | Epoch 65 | Train Loss: 5034.5355 | Val Loss: 5183.5267 | Optimizer: Adam\n",
      "Trial 11 | Epoch 66 | Train Loss: 5175.5285 | Val Loss: 4846.0889 | Optimizer: Adam\n",
      "Trial 11 | Epoch 67 | Train Loss: 4938.2050 | Val Loss: 5292.4927 | Optimizer: Adam\n",
      "Trial 11 | Epoch 68 | Train Loss: 4904.5692 | Val Loss: 4848.6783 | Optimizer: Adam\n",
      "Trial 11 | Epoch 69 | Train Loss: 4624.4910 | Val Loss: 5098.3674 | Optimizer: Adam\n",
      "Trial 11 | Epoch 70 | Train Loss: 4939.9496 | Val Loss: 4864.1165 | Optimizer: Adam\n",
      "Trial 11 | Epoch 71 | Train Loss: 4627.9710 | Val Loss: 4912.1318 | Optimizer: Adam\n",
      "Trial 11 | Epoch 72 | Train Loss: 4860.2421 | Val Loss: 4852.6674 | Optimizer: Adam\n",
      "Trial 11 | Epoch 73 | Train Loss: 4742.9162 | Val Loss: 4991.6492 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:17,230] Trial 11 finished with value: 4846.0888671875 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.29301594324415503, 'lr': 0.0002714126951500106, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 9.667669781987394e-05}. Best is trial 11 with value: 4846.0888671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 | Epoch 74 | Train Loss: 4687.4568 | Val Loss: 4906.1127 | Optimizer: Adam\n",
      "Trial 11 | Epoch 75 | Train Loss: 4966.2586 | Val Loss: 4851.4250 | Optimizer: Adam\n",
      "Trial 11 | Epoch 76 | Train Loss: 4908.5821 | Val Loss: 5349.6235 | Optimizer: Adam\n",
      "Trial 11 - Early stopping triggered at epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:17,362] Trial 12 pruned. \n",
      "[I 2025-09-04 20:33:17,496] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 | Epoch 01 | Train Loss: 21189.3381 | Val Loss: 22138.7909 | Optimizer: Adam\n",
      "Trial 13 | Epoch 01 | Train Loss: 21450.1851 | Val Loss: 22592.3709 | Optimizer: Adam\n",
      "Trial 14 | Epoch 01 | Train Loss: 20511.5070 | Val Loss: 20356.3333 | Optimizer: Adam\n",
      "Trial 14 | Epoch 02 | Train Loss: 17264.1507 | Val Loss: 15322.1643 | Optimizer: Adam\n",
      "Trial 14 | Epoch 03 | Train Loss: 12234.9293 | Val Loss: 11845.7909 | Optimizer: Adam\n",
      "Trial 14 | Epoch 04 | Train Loss: 11097.4948 | Val Loss: 11102.0175 | Optimizer: Adam\n",
      "Trial 14 | Epoch 05 | Train Loss: 10117.2835 | Val Loss: 9777.0024 | Optimizer: Adam\n",
      "Trial 14 | Epoch 06 | Train Loss: 9097.7193 | Val Loss: 8101.3998 | Optimizer: Adam\n",
      "Trial 14 | Epoch 07 | Train Loss: 8506.6445 | Val Loss: 7615.9942 | Optimizer: Adam\n",
      "Trial 14 | Epoch 08 | Train Loss: 8289.9513 | Val Loss: 7399.4764 | Optimizer: Adam\n",
      "Trial 14 | Epoch 09 | Train Loss: 7536.4210 | Val Loss: 5821.9428 | Optimizer: Adam\n",
      "Trial 14 | Epoch 10 | Train Loss: 7019.1754 | Val Loss: 6376.3751 | Optimizer: Adam\n",
      "Trial 14 | Epoch 11 | Train Loss: 7154.2533 | Val Loss: 5566.3136 | Optimizer: Adam\n",
      "Trial 14 | Epoch 12 | Train Loss: 6728.9581 | Val Loss: 6014.9783 | Optimizer: Adam\n",
      "Trial 14 | Epoch 13 | Train Loss: 6869.3589 | Val Loss: 5777.0344 | Optimizer: Adam\n",
      "Trial 14 | Epoch 14 | Train Loss: 6407.9780 | Val Loss: 5636.3629 | Optimizer: Adam\n",
      "Trial 14 | Epoch 15 | Train Loss: 6439.7574 | Val Loss: 5535.3940 | Optimizer: Adam\n",
      "Trial 14 | Epoch 16 | Train Loss: 6427.0967 | Val Loss: 5529.3572 | Optimizer: Adam\n",
      "Trial 14 | Epoch 17 | Train Loss: 6139.0358 | Val Loss: 5542.7051 | Optimizer: Adam\n",
      "Trial 14 | Epoch 18 | Train Loss: 5966.6584 | Val Loss: 5422.6180 | Optimizer: Adam\n",
      "Trial 14 | Epoch 19 | Train Loss: 5936.8838 | Val Loss: 5432.9533 | Optimizer: Adam\n",
      "Trial 14 | Epoch 20 | Train Loss: 5906.0577 | Val Loss: 5758.8676 | Optimizer: Adam\n",
      "Trial 14 | Epoch 21 | Train Loss: 6325.3489 | Val Loss: 5234.3363 | Optimizer: Adam\n",
      "Trial 14 | Epoch 22 | Train Loss: 5458.8272 | Val Loss: 5441.1804 | Optimizer: Adam\n",
      "Trial 14 | Epoch 23 | Train Loss: 5831.7036 | Val Loss: 5173.0592 | Optimizer: Adam\n",
      "Trial 14 | Epoch 24 | Train Loss: 5838.2036 | Val Loss: 5338.1461 | Optimizer: Adam\n",
      "Trial 14 | Epoch 25 | Train Loss: 5510.5056 | Val Loss: 5410.0889 | Optimizer: Adam\n",
      "Trial 14 | Epoch 26 | Train Loss: 5756.6739 | Val Loss: 5587.3362 | Optimizer: Adam\n",
      "Trial 14 | Epoch 27 | Train Loss: 5601.1422 | Val Loss: 5312.7129 | Optimizer: Adam\n",
      "Trial 14 | Epoch 28 | Train Loss: 5428.2431 | Val Loss: 5128.8951 | Optimizer: Adam\n",
      "Trial 14 | Epoch 29 | Train Loss: 5716.8735 | Val Loss: 6993.8813 | Optimizer: Adam\n",
      "Trial 14 | Epoch 30 | Train Loss: 5857.1080 | Val Loss: 5304.7023 | Optimizer: Adam\n",
      "Trial 14 | Epoch 31 | Train Loss: 5635.0814 | Val Loss: 6424.9606 | Optimizer: Adam\n",
      "Trial 14 | Epoch 32 | Train Loss: 5591.4871 | Val Loss: 5373.8067 | Optimizer: Adam\n",
      "Trial 14 | Epoch 33 | Train Loss: 5728.0541 | Val Loss: 5965.1303 | Optimizer: Adam\n",
      "Trial 14 | Epoch 34 | Train Loss: 5150.1549 | Val Loss: 5123.3148 | Optimizer: Adam\n",
      "Trial 14 | Epoch 35 | Train Loss: 5467.1263 | Val Loss: 5743.6089 | Optimizer: Adam\n",
      "Trial 14 | Epoch 36 | Train Loss: 5073.4168 | Val Loss: 5052.5261 | Optimizer: Adam\n",
      "Trial 14 | Epoch 37 | Train Loss: 5263.3474 | Val Loss: 5201.2522 | Optimizer: Adam\n",
      "Trial 14 | Epoch 38 | Train Loss: 5309.2675 | Val Loss: 5170.5184 | Optimizer: Adam\n",
      "Trial 14 | Epoch 39 | Train Loss: 5018.8294 | Val Loss: 5468.4122 | Optimizer: Adam\n",
      "Trial 14 | Epoch 40 | Train Loss: 5278.9454 | Val Loss: 4992.9777 | Optimizer: Adam\n",
      "Trial 14 | Epoch 41 | Train Loss: 5246.0219 | Val Loss: 5332.9526 | Optimizer: Adam\n",
      "Trial 14 | Epoch 42 | Train Loss: 4996.4832 | Val Loss: 4984.7680 | Optimizer: Adam\n",
      "Trial 14 | Epoch 43 | Train Loss: 5087.1640 | Val Loss: 5485.5001 | Optimizer: Adam\n",
      "Trial 14 | Epoch 44 | Train Loss: 5196.5392 | Val Loss: 5008.3814 | Optimizer: Adam\n",
      "Trial 14 | Epoch 45 | Train Loss: 5252.7613 | Val Loss: 5015.8831 | Optimizer: Adam\n",
      "Trial 14 | Epoch 46 | Train Loss: 4784.6198 | Val Loss: 5152.8735 | Optimizer: Adam\n",
      "Trial 14 | Epoch 47 | Train Loss: 5119.5180 | Val Loss: 5049.9251 | Optimizer: Adam\n",
      "Trial 14 | Epoch 48 | Train Loss: 5012.2125 | Val Loss: 6517.5113 | Optimizer: Adam\n",
      "Trial 14 | Epoch 49 | Train Loss: 5997.7117 | Val Loss: 5064.7249 | Optimizer: Adam\n",
      "Trial 14 | Epoch 50 | Train Loss: 5490.2328 | Val Loss: 5966.8652 | Optimizer: Adam\n",
      "Trial 14 | Epoch 51 | Train Loss: 5617.8185 | Val Loss: 4911.2141 | Optimizer: Adam\n",
      "Trial 14 | Epoch 52 | Train Loss: 5121.4185 | Val Loss: 4939.9243 | Optimizer: Adam\n",
      "Trial 14 | Epoch 53 | Train Loss: 5417.5778 | Val Loss: 4951.8841 | Optimizer: Adam\n",
      "Trial 14 | Epoch 54 | Train Loss: 5353.4674 | Val Loss: 5321.0911 | Optimizer: Adam\n",
      "Trial 14 | Epoch 55 | Train Loss: 5329.2228 | Val Loss: 5392.7640 | Optimizer: Adam\n",
      "Trial 14 | Epoch 56 | Train Loss: 5016.1686 | Val Loss: 4882.5695 | Optimizer: Adam\n",
      "Trial 14 | Epoch 57 | Train Loss: 5314.0187 | Val Loss: 5313.3167 | Optimizer: Adam\n",
      "Trial 14 | Epoch 58 | Train Loss: 4946.4268 | Val Loss: 4873.6099 | Optimizer: Adam\n",
      "Trial 14 | Epoch 59 | Train Loss: 4849.5605 | Val Loss: 5246.5352 | Optimizer: Adam\n",
      "Trial 14 | Epoch 60 | Train Loss: 4624.5094 | Val Loss: 5024.1630 | Optimizer: Adam\n",
      "Trial 14 | Epoch 61 | Train Loss: 5291.0923 | Val Loss: 5078.7466 | Optimizer: Adam\n",
      "Trial 14 | Epoch 62 | Train Loss: 4685.2545 | Val Loss: 4918.2209 | Optimizer: Adam\n",
      "Trial 14 | Epoch 63 | Train Loss: 4949.1528 | Val Loss: 5134.4489 | Optimizer: Adam\n",
      "Trial 14 | Epoch 64 | Train Loss: 4585.1338 | Val Loss: 5011.9093 | Optimizer: Adam\n",
      "Trial 14 | Epoch 65 | Train Loss: 4475.9765 | Val Loss: 4952.6728 | Optimizer: Adam\n",
      "Trial 14 | Epoch 66 | Train Loss: 4972.0738 | Val Loss: 5464.4348 | Optimizer: Adam\n",
      "Trial 14 | Epoch 67 | Train Loss: 4914.9975 | Val Loss: 4976.4107 | Optimizer: Adam\n",
      "Trial 14 | Epoch 68 | Train Loss: 5020.2082 | Val Loss: 5198.8688 | Optimizer: Adam\n",
      "Trial 14 - Early stopping triggered at epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:21,324] Trial 14 finished with value: 4873.60986328125 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.3187463467127898, 'lr': 0.000438907245775387, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 8.136665679414679e-05}. Best is trial 11 with value: 4846.0888671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 | Epoch 01 | Train Loss: 20209.1246 | Val Loss: 18247.9258 | Optimizer: Adam\n",
      "Trial 15 | Epoch 02 | Train Loss: 12508.1860 | Val Loss: 14238.9238 | Optimizer: Adam\n",
      "Trial 15 | Epoch 03 | Train Loss: 10812.3279 | Val Loss: 11399.4610 | Optimizer: Adam\n",
      "Trial 15 | Epoch 04 | Train Loss: 10554.0751 | Val Loss: 9661.0975 | Optimizer: Adam\n",
      "Trial 15 | Epoch 05 | Train Loss: 8576.9618 | Val Loss: 8089.3537 | Optimizer: Adam\n",
      "Trial 15 | Epoch 06 | Train Loss: 8937.6952 | Val Loss: 7970.8856 | Optimizer: Adam\n",
      "Trial 15 | Epoch 07 | Train Loss: 8335.3669 | Val Loss: 7565.6737 | Optimizer: Adam\n",
      "Trial 15 | Epoch 08 | Train Loss: 8041.9585 | Val Loss: 7004.0863 | Optimizer: Adam\n",
      "Trial 15 | Epoch 09 | Train Loss: 7447.3887 | Val Loss: 7122.6990 | Optimizer: Adam\n",
      "Trial 15 | Epoch 10 | Train Loss: 7862.3477 | Val Loss: 6754.4833 | Optimizer: Adam\n",
      "Trial 15 | Epoch 11 | Train Loss: 8508.6092 | Val Loss: 8024.9493 | Optimizer: Adam\n",
      "Trial 15 | Epoch 12 | Train Loss: 8959.5341 | Val Loss: 7551.8475 | Optimizer: Adam\n",
      "Trial 15 | Epoch 13 | Train Loss: 8663.4826 | Val Loss: 6316.4086 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:22,149] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 | Epoch 14 | Train Loss: 7743.5622 | Val Loss: 7499.0941 | Optimizer: Adam\n",
      "Trial 16 | Epoch 01 | Train Loss: 20321.3145 | Val Loss: 18596.6719 | Optimizer: Adam\n",
      "Trial 16 | Epoch 02 | Train Loss: 13982.8582 | Val Loss: 10448.0028 | Optimizer: Adam\n",
      "Trial 16 | Epoch 03 | Train Loss: 10083.5926 | Val Loss: 10992.7728 | Optimizer: Adam\n",
      "Trial 16 | Epoch 04 | Train Loss: 8989.7336 | Val Loss: 8109.4397 | Optimizer: Adam\n",
      "Trial 16 | Epoch 05 | Train Loss: 7505.4520 | Val Loss: 8140.0062 | Optimizer: Adam\n",
      "Trial 16 | Epoch 06 | Train Loss: 7430.4936 | Val Loss: 6103.6015 | Optimizer: Adam\n",
      "Trial 16 | Epoch 07 | Train Loss: 7052.5916 | Val Loss: 6773.3869 | Optimizer: Adam\n",
      "Trial 16 | Epoch 08 | Train Loss: 7128.2188 | Val Loss: 6044.4059 | Optimizer: Adam\n",
      "Trial 16 | Epoch 09 | Train Loss: 7511.0206 | Val Loss: 6804.1212 | Optimizer: Adam\n",
      "Trial 16 | Epoch 10 | Train Loss: 6601.3437 | Val Loss: 5852.8562 | Optimizer: Adam\n",
      "Trial 16 | Epoch 11 | Train Loss: 6301.7338 | Val Loss: 6035.8222 | Optimizer: Adam\n",
      "Trial 16 | Epoch 12 | Train Loss: 6527.0179 | Val Loss: 5442.6809 | Optimizer: Adam\n",
      "Trial 16 | Epoch 13 | Train Loss: 6078.8526 | Val Loss: 6566.9039 | Optimizer: Adam\n",
      "Trial 16 | Epoch 14 | Train Loss: 6499.9860 | Val Loss: 5651.2565 | Optimizer: Adam\n",
      "Trial 16 | Epoch 15 | Train Loss: 5980.4318 | Val Loss: 6093.0471 | Optimizer: Adam\n",
      "Trial 16 | Epoch 16 | Train Loss: 6169.6753 | Val Loss: 5343.7010 | Optimizer: Adam\n",
      "Trial 16 | Epoch 17 | Train Loss: 6289.9313 | Val Loss: 5605.2323 | Optimizer: Adam\n",
      "Trial 16 | Epoch 18 | Train Loss: 5772.1889 | Val Loss: 5314.1794 | Optimizer: Adam\n",
      "Trial 16 | Epoch 19 | Train Loss: 5505.1576 | Val Loss: 5373.9023 | Optimizer: Adam\n",
      "Trial 16 | Epoch 20 | Train Loss: 5871.7578 | Val Loss: 6366.1223 | Optimizer: Adam\n",
      "Trial 16 | Epoch 21 | Train Loss: 6046.1982 | Val Loss: 5169.0100 | Optimizer: Adam\n",
      "Trial 16 | Epoch 22 | Train Loss: 5483.0445 | Val Loss: 5492.8340 | Optimizer: Adam\n",
      "Trial 16 | Epoch 23 | Train Loss: 5474.5806 | Val Loss: 5282.8971 | Optimizer: Adam\n",
      "Trial 16 | Epoch 24 | Train Loss: 5893.8630 | Val Loss: 5198.7113 | Optimizer: Adam\n",
      "Trial 16 | Epoch 25 | Train Loss: 5562.5254 | Val Loss: 6226.6787 | Optimizer: Adam\n",
      "Trial 16 | Epoch 26 | Train Loss: 5339.4371 | Val Loss: 5115.5761 | Optimizer: Adam\n",
      "Trial 16 | Epoch 27 | Train Loss: 5289.7844 | Val Loss: 5437.3816 | Optimizer: Adam\n",
      "Trial 16 | Epoch 28 | Train Loss: 5405.8907 | Val Loss: 5307.3141 | Optimizer: Adam\n",
      "Trial 16 | Epoch 29 | Train Loss: 5622.4027 | Val Loss: 5902.0734 | Optimizer: Adam\n",
      "Trial 16 | Epoch 30 | Train Loss: 4947.6337 | Val Loss: 5153.7971 | Optimizer: Adam\n",
      "Trial 16 | Epoch 31 | Train Loss: 5201.0144 | Val Loss: 5136.4964 | Optimizer: Adam\n",
      "Trial 16 | Epoch 32 | Train Loss: 5014.3469 | Val Loss: 5359.0988 | Optimizer: Adam\n",
      "Trial 16 | Epoch 33 | Train Loss: 5238.4441 | Val Loss: 5087.8373 | Optimizer: Adam\n",
      "Trial 16 | Epoch 34 | Train Loss: 5132.5073 | Val Loss: 5340.6351 | Optimizer: Adam\n",
      "Trial 16 | Epoch 35 | Train Loss: 5255.5683 | Val Loss: 5567.5727 | Optimizer: Adam\n",
      "Trial 16 | Epoch 36 | Train Loss: 5386.0840 | Val Loss: 5149.4195 | Optimizer: Adam\n",
      "Trial 16 | Epoch 37 | Train Loss: 5281.6726 | Val Loss: 5240.3092 | Optimizer: Adam\n",
      "Trial 16 | Epoch 38 | Train Loss: 4976.9420 | Val Loss: 5660.9041 | Optimizer: Adam\n",
      "Trial 16 | Epoch 39 | Train Loss: 5222.4259 | Val Loss: 5124.4473 | Optimizer: Adam\n",
      "Trial 16 | Epoch 40 | Train Loss: 5219.3398 | Val Loss: 5137.7097 | Optimizer: Adam\n",
      "Trial 16 | Epoch 41 | Train Loss: 4624.8289 | Val Loss: 5733.6656 | Optimizer: Adam\n",
      "Trial 16 | Epoch 42 | Train Loss: 5223.6297 | Val Loss: 5310.4116 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:25,829] Trial 16 finished with value: 5087.837315323329 and parameters: {'gnn_dim': 1024, 'hidden_dim': 384, 'dropout_rate': 0.3256627759126541, 'lr': 0.0004879332577688947, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.006692826269477e-06}. Best is trial 11 with value: 4846.0888671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 | Epoch 43 | Train Loss: 4845.5991 | Val Loss: 5422.9363 | Optimizer: Adam\n",
      "Trial 16 - Early stopping triggered at epoch 43\n",
      "Trial 17 | Epoch 01 | Train Loss: 20883.9487 | Val Loss: 20551.3976 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 02 | Train Loss: 17456.0502 | Val Loss: 15308.7175 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 03 | Train Loss: 11584.1281 | Val Loss: 11992.8177 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 04 | Train Loss: 11025.2797 | Val Loss: 10551.9201 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 05 | Train Loss: 10138.1744 | Val Loss: 9587.7090 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 06 | Train Loss: 8949.5203 | Val Loss: 7715.4695 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 07 | Train Loss: 8572.5036 | Val Loss: 7776.2444 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 08 | Train Loss: 7847.9508 | Val Loss: 6998.5405 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 09 | Train Loss: 7397.1628 | Val Loss: 5938.1631 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 10 | Train Loss: 6581.7983 | Val Loss: 6196.9473 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 11 | Train Loss: 7165.4538 | Val Loss: 5495.2161 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 12 | Train Loss: 6916.6575 | Val Loss: 5874.6009 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 13 | Train Loss: 6598.4541 | Val Loss: 5719.9327 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 14 | Train Loss: 6893.4974 | Val Loss: 5943.2506 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 15 | Train Loss: 6356.4418 | Val Loss: 5519.1492 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 16 | Train Loss: 6366.6691 | Val Loss: 5757.1702 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 17 | Train Loss: 6276.2899 | Val Loss: 5602.6081 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 18 | Train Loss: 6252.1592 | Val Loss: 5734.4773 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 19 | Train Loss: 6078.8014 | Val Loss: 5440.0177 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 20 | Train Loss: 6007.7767 | Val Loss: 5437.9236 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 21 | Train Loss: 5808.7769 | Val Loss: 5564.4952 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 22 | Train Loss: 5568.5988 | Val Loss: 5200.1476 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 23 | Train Loss: 5670.9648 | Val Loss: 6109.2105 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 24 | Train Loss: 5695.8666 | Val Loss: 5288.5814 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 25 | Train Loss: 6292.3504 | Val Loss: 5422.7968 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 26 | Train Loss: 6187.1886 | Val Loss: 6148.1984 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 27 | Train Loss: 6272.9427 | Val Loss: 5153.8528 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 28 | Train Loss: 6258.2327 | Val Loss: 5972.5861 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 29 | Train Loss: 5917.3910 | Val Loss: 5365.5007 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 30 | Train Loss: 5831.0348 | Val Loss: 5147.0839 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 31 | Train Loss: 5951.8288 | Val Loss: 5586.9926 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 32 | Train Loss: 5735.3359 | Val Loss: 5187.7984 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 33 | Train Loss: 5406.6839 | Val Loss: 5567.9291 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 34 | Train Loss: 5447.1290 | Val Loss: 5048.5759 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 35 | Train Loss: 5413.1731 | Val Loss: 5119.0932 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 36 | Train Loss: 5187.1144 | Val Loss: 5250.7343 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 37 | Train Loss: 5325.0255 | Val Loss: 5095.7688 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 38 | Train Loss: 5652.0386 | Val Loss: 5726.2850 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 39 | Train Loss: 5483.0895 | Val Loss: 5054.0704 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 40 | Train Loss: 4945.8541 | Val Loss: 5547.4497 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 41 | Train Loss: 5311.3940 | Val Loss: 4976.4566 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 42 | Train Loss: 5059.9472 | Val Loss: 5234.3969 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 43 | Train Loss: 5156.9632 | Val Loss: 4986.0832 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 44 | Train Loss: 5357.4840 | Val Loss: 5190.2880 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 45 | Train Loss: 5473.1172 | Val Loss: 5051.8525 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 46 | Train Loss: 5240.6060 | Val Loss: 5405.8451 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 47 | Train Loss: 5150.1463 | Val Loss: 5103.9434 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 48 | Train Loss: 5077.7308 | Val Loss: 5106.9019 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 49 | Train Loss: 5102.7663 | Val Loss: 5178.8322 | Optimizer: AdamW\n",
      "Trial 17 | Epoch 50 | Train Loss: 4886.5038 | Val Loss: 5005.0532 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:28,776] Trial 17 finished with value: 4976.4566154857675 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.35855691959411123, 'lr': 0.000437006768112207, 'activation': 'Swish', 'optimizer': 'AdamW', 'weight_decay': 3.014555325100063e-05}. Best is trial 11 with value: 4846.0888671875.\n",
      "[I 2025-09-04 20:33:28,895] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 | Epoch 51 | Train Loss: 4787.4010 | Val Loss: 5053.4240 | Optimizer: AdamW\n",
      "Trial 17 - Early stopping triggered at epoch 51\n",
      "Trial 18 | Epoch 01 | Train Loss: 493090.7111 | Val Loss: 2677134581771031.0000 | Optimizer: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:29,128] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 | Epoch 01 | Train Loss: 20566.4984 | Val Loss: 21025.7727 | Optimizer: Adam\n",
      "Trial 19 | Epoch 02 | Train Loss: 17890.6230 | Val Loss: 16475.9246 | Optimizer: Adam\n",
      "Trial 20 | Epoch 01 | Train Loss: 19022.4986 | Val Loss: 15961.6448 | Optimizer: Adam\n",
      "Trial 20 | Epoch 02 | Train Loss: 12411.4374 | Val Loss: 10400.3121 | Optimizer: Adam\n",
      "Trial 20 | Epoch 03 | Train Loss: 10121.6602 | Val Loss: 8939.2182 | Optimizer: Adam\n",
      "Trial 20 | Epoch 04 | Train Loss: 8556.1521 | Val Loss: 6951.9284 | Optimizer: Adam\n",
      "Trial 20 | Epoch 05 | Train Loss: 7678.0732 | Val Loss: 5474.0226 | Optimizer: Adam\n",
      "Trial 20 | Epoch 06 | Train Loss: 7350.6140 | Val Loss: 5588.6621 | Optimizer: Adam\n",
      "Trial 20 | Epoch 07 | Train Loss: 7224.0398 | Val Loss: 6039.6183 | Optimizer: Adam\n",
      "Trial 20 | Epoch 08 | Train Loss: 7799.3100 | Val Loss: 8396.1523 | Optimizer: Adam\n",
      "Trial 20 | Epoch 09 | Train Loss: 7601.5630 | Val Loss: 5710.4954 | Optimizer: Adam\n",
      "Trial 20 | Epoch 10 | Train Loss: 7068.6818 | Val Loss: 6354.5349 | Optimizer: Adam\n",
      "Trial 20 | Epoch 11 | Train Loss: 6849.1278 | Val Loss: 5849.9976 | Optimizer: Adam\n",
      "Trial 20 | Epoch 12 | Train Loss: 6356.0083 | Val Loss: 5303.8292 | Optimizer: Adam\n",
      "Trial 20 | Epoch 13 | Train Loss: 5914.1816 | Val Loss: 5878.9299 | Optimizer: Adam\n",
      "Trial 20 | Epoch 14 | Train Loss: 6138.6812 | Val Loss: 5293.4251 | Optimizer: Adam\n",
      "Trial 20 | Epoch 15 | Train Loss: 5721.2171 | Val Loss: 5456.7934 | Optimizer: Adam\n",
      "Trial 20 | Epoch 16 | Train Loss: 5932.5015 | Val Loss: 5166.7749 | Optimizer: Adam\n",
      "Trial 20 | Epoch 17 | Train Loss: 5252.3459 | Val Loss: 5220.7930 | Optimizer: Adam\n",
      "Trial 20 | Epoch 18 | Train Loss: 5267.4368 | Val Loss: 6130.7596 | Optimizer: Adam\n",
      "Trial 20 | Epoch 19 | Train Loss: 5877.0088 | Val Loss: 5482.0064 | Optimizer: Adam\n",
      "Trial 20 | Epoch 20 | Train Loss: 5242.6809 | Val Loss: 5505.9167 | Optimizer: Adam\n",
      "Trial 20 | Epoch 21 | Train Loss: 5319.2550 | Val Loss: 6322.6523 | Optimizer: Adam\n",
      "Trial 20 | Epoch 22 | Train Loss: 5947.9045 | Val Loss: 5207.9267 | Optimizer: Adam\n",
      "Trial 20 | Epoch 23 | Train Loss: 4858.6258 | Val Loss: 5750.6369 | Optimizer: Adam\n",
      "Trial 20 | Epoch 24 | Train Loss: 5578.1601 | Val Loss: 5107.3978 | Optimizer: Adam\n",
      "Trial 20 | Epoch 25 | Train Loss: 5498.5301 | Val Loss: 5053.2048 | Optimizer: Adam\n",
      "Trial 20 | Epoch 26 | Train Loss: 4807.3230 | Val Loss: 5105.6990 | Optimizer: Adam\n",
      "Trial 20 | Epoch 27 | Train Loss: 5314.8024 | Val Loss: 5427.5059 | Optimizer: Adam\n",
      "Trial 20 | Epoch 28 | Train Loss: 4947.2387 | Val Loss: 5988.7753 | Optimizer: Adam\n",
      "Trial 20 | Epoch 29 | Train Loss: 5504.5424 | Val Loss: 5203.7313 | Optimizer: Adam\n",
      "Trial 20 | Epoch 30 | Train Loss: 5871.2709 | Val Loss: 5150.0326 | Optimizer: Adam\n",
      "Trial 20 | Epoch 31 | Train Loss: 6657.6315 | Val Loss: 7126.9241 | Optimizer: Adam\n",
      "Trial 20 | Epoch 32 | Train Loss: 6140.1702 | Val Loss: 5067.6616 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:31,030] Trial 20 finished with value: 5053.204797725866 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.3959820471173325, 'lr': 0.0008955535563152082, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 4.2481757087975294e-05}. Best is trial 11 with value: 4846.0888671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 | Epoch 33 | Train Loss: 5367.0800 | Val Loss: 5871.1535 | Optimizer: Adam\n",
      "Trial 20 | Epoch 34 | Train Loss: 5213.1507 | Val Loss: 5060.9880 | Optimizer: Adam\n",
      "Trial 20 | Epoch 35 | Train Loss: 5548.4930 | Val Loss: 5074.8233 | Optimizer: Adam\n",
      "Trial 20 - Early stopping triggered at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:31,147] Trial 21 pruned. \n",
      "[I 2025-09-04 20:33:31,260] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 | Epoch 01 | Train Loss: 21305.2083 | Val Loss: 22424.1203 | Optimizer: Adam\n",
      "Trial 22 | Epoch 01 | Train Loss: 21390.2906 | Val Loss: 22799.5198 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:31,379] Trial 23 pruned. \n",
      "[I 2025-09-04 20:33:31,492] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 | Epoch 01 | Train Loss: 21092.6200 | Val Loss: 21565.1739 | Optimizer: Adam\n",
      "Trial 24 | Epoch 01 | Train Loss: 21631.0561 | Val Loss: 23213.2843 | Optimizer: Adam\n",
      "Trial 25 | Epoch 01 | Train Loss: 19615.0781 | Val Loss: 18581.2195 | Optimizer: Adam\n",
      "Trial 25 | Epoch 02 | Train Loss: 14620.8432 | Val Loss: 11100.6994 | Optimizer: Adam\n",
      "Trial 25 | Epoch 03 | Train Loss: 11649.1373 | Val Loss: 11078.4135 | Optimizer: Adam\n",
      "Trial 25 | Epoch 04 | Train Loss: 10766.3087 | Val Loss: 10964.9803 | Optimizer: Adam\n",
      "Trial 25 | Epoch 05 | Train Loss: 9847.7837 | Val Loss: 8120.2234 | Optimizer: Adam\n",
      "Trial 25 | Epoch 06 | Train Loss: 8473.6820 | Val Loss: 6995.3566 | Optimizer: Adam\n",
      "Trial 25 | Epoch 07 | Train Loss: 8048.5810 | Val Loss: 6029.3503 | Optimizer: Adam\n",
      "Trial 25 | Epoch 08 | Train Loss: 7107.2939 | Val Loss: 5786.0110 | Optimizer: Adam\n",
      "Trial 25 | Epoch 09 | Train Loss: 7639.9669 | Val Loss: 5487.8008 | Optimizer: Adam\n",
      "Trial 25 | Epoch 10 | Train Loss: 7781.8567 | Val Loss: 7059.5067 | Optimizer: Adam\n",
      "Trial 25 | Epoch 11 | Train Loss: 7543.9184 | Val Loss: 6259.2019 | Optimizer: Adam\n",
      "Trial 25 | Epoch 12 | Train Loss: 6857.8200 | Val Loss: 5690.8862 | Optimizer: Adam\n",
      "Trial 25 | Epoch 13 | Train Loss: 6658.3157 | Val Loss: 6289.9397 | Optimizer: Adam\n",
      "Trial 25 | Epoch 14 | Train Loss: 6603.9525 | Val Loss: 5446.6557 | Optimizer: Adam\n",
      "Trial 25 | Epoch 15 | Train Loss: 6120.7476 | Val Loss: 6261.3237 | Optimizer: Adam\n",
      "Trial 25 | Epoch 16 | Train Loss: 6199.5083 | Val Loss: 5312.4481 | Optimizer: Adam\n",
      "Trial 25 | Epoch 17 | Train Loss: 5864.2298 | Val Loss: 5548.2191 | Optimizer: Adam\n",
      "Trial 25 | Epoch 18 | Train Loss: 5930.6994 | Val Loss: 5451.6628 | Optimizer: Adam\n",
      "Trial 25 | Epoch 19 | Train Loss: 5802.9744 | Val Loss: 5498.8940 | Optimizer: Adam\n",
      "Trial 25 | Epoch 20 | Train Loss: 5875.1522 | Val Loss: 5273.9161 | Optimizer: Adam\n",
      "Trial 25 | Epoch 21 | Train Loss: 5923.1665 | Val Loss: 6597.1560 | Optimizer: Adam\n",
      "Trial 25 | Epoch 22 | Train Loss: 6509.4844 | Val Loss: 5291.1034 | Optimizer: Adam\n",
      "Trial 25 | Epoch 23 | Train Loss: 6245.8781 | Val Loss: 5675.3023 | Optimizer: Adam\n",
      "Trial 25 | Epoch 24 | Train Loss: 5831.2266 | Val Loss: 5110.7886 | Optimizer: Adam\n",
      "Trial 25 | Epoch 25 | Train Loss: 5805.3945 | Val Loss: 5412.4393 | Optimizer: Adam\n",
      "Trial 25 | Epoch 26 | Train Loss: 5699.3282 | Val Loss: 5119.1998 | Optimizer: Adam\n",
      "Trial 25 | Epoch 27 | Train Loss: 5240.8600 | Val Loss: 5075.8559 | Optimizer: Adam\n",
      "Trial 25 | Epoch 28 | Train Loss: 6177.0016 | Val Loss: 7196.1936 | Optimizer: Adam\n",
      "Trial 25 | Epoch 29 | Train Loss: 6400.5202 | Val Loss: 5139.3179 | Optimizer: Adam\n",
      "Trial 25 | Epoch 30 | Train Loss: 5864.8102 | Val Loss: 5546.7814 | Optimizer: Adam\n",
      "Trial 25 | Epoch 31 | Train Loss: 6001.5701 | Val Loss: 5220.8149 | Optimizer: Adam\n",
      "Trial 25 | Epoch 32 | Train Loss: 5392.1073 | Val Loss: 5316.5595 | Optimizer: Adam\n",
      "Trial 25 | Epoch 33 | Train Loss: 5232.5628 | Val Loss: 5395.9710 | Optimizer: Adam\n",
      "Trial 25 | Epoch 34 | Train Loss: 5581.0230 | Val Loss: 5026.3827 | Optimizer: Adam\n",
      "Trial 25 | Epoch 35 | Train Loss: 5163.2579 | Val Loss: 5201.5589 | Optimizer: Adam\n",
      "Trial 25 | Epoch 36 | Train Loss: 4956.9160 | Val Loss: 5078.4616 | Optimizer: Adam\n",
      "Trial 25 | Epoch 37 | Train Loss: 5028.8373 | Val Loss: 5138.7309 | Optimizer: Adam\n",
      "Trial 25 | Epoch 38 | Train Loss: 4790.3536 | Val Loss: 5055.8135 | Optimizer: Adam\n",
      "Trial 25 | Epoch 39 | Train Loss: 5141.8863 | Val Loss: 6004.2692 | Optimizer: Adam\n",
      "Trial 25 | Epoch 40 | Train Loss: 5117.5178 | Val Loss: 5116.0696 | Optimizer: Adam\n",
      "Trial 25 | Epoch 41 | Train Loss: 5208.9272 | Val Loss: 5584.7999 | Optimizer: Adam\n",
      "Trial 25 | Epoch 42 | Train Loss: 4913.5701 | Val Loss: 4899.9782 | Optimizer: Adam\n",
      "Trial 25 | Epoch 43 | Train Loss: 4679.3296 | Val Loss: 5131.6732 | Optimizer: Adam\n",
      "Trial 25 | Epoch 44 | Train Loss: 4754.5781 | Val Loss: 4981.6557 | Optimizer: Adam\n",
      "Trial 25 | Epoch 45 | Train Loss: 4705.6920 | Val Loss: 4992.9580 | Optimizer: Adam\n",
      "Trial 25 | Epoch 46 | Train Loss: 4824.9981 | Val Loss: 5202.0034 | Optimizer: Adam\n",
      "Trial 25 | Epoch 47 | Train Loss: 4879.6082 | Val Loss: 5020.7229 | Optimizer: Adam\n",
      "Trial 25 | Epoch 48 | Train Loss: 4667.4872 | Val Loss: 5041.3079 | Optimizer: Adam\n",
      "Trial 25 | Epoch 49 | Train Loss: 4617.9189 | Val Loss: 4956.2847 | Optimizer: Adam\n",
      "Trial 25 | Epoch 50 | Train Loss: 5049.7706 | Val Loss: 5024.8849 | Optimizer: Adam\n",
      "Trial 25 | Epoch 51 | Train Loss: 4575.4405 | Val Loss: 5680.7600 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:34,377] Trial 25 finished with value: 4899.978186881188 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.33494778058802105, 'lr': 0.0005964304841631316, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 3.216413359805328e-05}. Best is trial 11 with value: 4846.0888671875.\n",
      "[I 2025-09-04 20:33:34,494] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 | Epoch 52 | Train Loss: 5374.5741 | Val Loss: 5050.9702 | Optimizer: Adam\n",
      "Trial 25 - Early stopping triggered at epoch 52\n",
      "Trial 26 | Epoch 01 | Train Loss: 21298.2394 | Val Loss: 21434.9718 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:34,606] Trial 27 pruned. \n",
      "[I 2025-09-04 20:33:34,764] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 28 | Epoch 01 | Train Loss: 20163.0626 | Val Loss: 20654.0111 | Optimizer: RMSprop\n",
      "Trial 28 | Epoch 02 | Train Loss: 17705.2643 | Val Loss: 16215.2989 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:34,924] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 | Epoch 01 | Train Loss: 21541.1643 | Val Loss: 22953.7727 | Optimizer: Adam\n",
      "Trial 30 | Epoch 01 | Train Loss: 19210.5903 | Val Loss: 16945.9202 | Optimizer: Adam\n",
      "Trial 30 | Epoch 02 | Train Loss: 13611.5587 | Val Loss: 11245.3658 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:35,217] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 | Epoch 03 | Train Loss: 11666.2520 | Val Loss: 10667.9493 | Optimizer: Adam\n",
      "Trial 30 | Epoch 04 | Train Loss: 11053.0350 | Val Loss: 11346.6743 | Optimizer: Adam\n",
      "Trial 30 | Epoch 05 | Train Loss: 11097.8944 | Val Loss: 11124.9072 | Optimizer: Adam\n",
      "Trial 31 | Epoch 01 | Train Loss: 19256.3119 | Val Loss: 16625.6809 | Optimizer: Adam\n",
      "Trial 31 | Epoch 02 | Train Loss: 13669.3940 | Val Loss: 10841.5691 | Optimizer: Adam\n",
      "Trial 31 | Epoch 03 | Train Loss: 10648.0289 | Val Loss: 11653.1487 | Optimizer: Adam\n",
      "Trial 31 | Epoch 04 | Train Loss: 10631.7175 | Val Loss: 9471.3373 | Optimizer: Adam\n",
      "Trial 31 | Epoch 05 | Train Loss: 9600.1889 | Val Loss: 7798.3609 | Optimizer: Adam\n",
      "Trial 31 | Epoch 06 | Train Loss: 8493.5508 | Val Loss: 7131.1121 | Optimizer: Adam\n",
      "Trial 31 | Epoch 07 | Train Loss: 7406.5723 | Val Loss: 5750.8413 | Optimizer: Adam\n",
      "Trial 31 | Epoch 08 | Train Loss: 7404.1877 | Val Loss: 6271.5541 | Optimizer: Adam\n",
      "Trial 31 | Epoch 09 | Train Loss: 7225.0237 | Val Loss: 5816.7009 | Optimizer: Adam\n",
      "Trial 31 | Epoch 10 | Train Loss: 6846.2273 | Val Loss: 6237.0031 | Optimizer: Adam\n",
      "Trial 31 | Epoch 11 | Train Loss: 6899.1988 | Val Loss: 5625.9991 | Optimizer: Adam\n",
      "Trial 31 | Epoch 12 | Train Loss: 6354.4234 | Val Loss: 5338.4384 | Optimizer: Adam\n",
      "Trial 31 | Epoch 13 | Train Loss: 6217.0766 | Val Loss: 5579.8335 | Optimizer: Adam\n",
      "Trial 31 | Epoch 14 | Train Loss: 5701.9573 | Val Loss: 5212.2129 | Optimizer: Adam\n",
      "Trial 31 | Epoch 15 | Train Loss: 5579.8897 | Val Loss: 5275.0061 | Optimizer: Adam\n",
      "Trial 31 | Epoch 16 | Train Loss: 5686.0778 | Val Loss: 5320.7890 | Optimizer: Adam\n",
      "Trial 31 | Epoch 17 | Train Loss: 6031.0935 | Val Loss: 5130.0705 | Optimizer: Adam\n",
      "Trial 31 | Epoch 18 | Train Loss: 5580.3481 | Val Loss: 7230.5304 | Optimizer: Adam\n",
      "Trial 31 | Epoch 19 | Train Loss: 6359.5401 | Val Loss: 5471.7461 | Optimizer: Adam\n",
      "Trial 31 | Epoch 20 | Train Loss: 5991.4301 | Val Loss: 5609.5709 | Optimizer: Adam\n",
      "Trial 31 | Epoch 21 | Train Loss: 5558.3736 | Val Loss: 5212.4128 | Optimizer: Adam\n",
      "Trial 31 | Epoch 22 | Train Loss: 5274.1516 | Val Loss: 5081.5583 | Optimizer: Adam\n",
      "Trial 31 | Epoch 23 | Train Loss: 5623.8694 | Val Loss: 5794.2796 | Optimizer: Adam\n",
      "Trial 31 | Epoch 24 | Train Loss: 5746.2366 | Val Loss: 5067.7711 | Optimizer: Adam\n",
      "Trial 31 | Epoch 25 | Train Loss: 5442.8237 | Val Loss: 4991.1179 | Optimizer: Adam\n",
      "Trial 31 | Epoch 26 | Train Loss: 5203.2311 | Val Loss: 5138.6370 | Optimizer: Adam\n",
      "Trial 31 | Epoch 27 | Train Loss: 5070.6805 | Val Loss: 5184.2884 | Optimizer: Adam\n",
      "Trial 31 | Epoch 28 | Train Loss: 5264.3007 | Val Loss: 5185.1236 | Optimizer: Adam\n",
      "Trial 31 | Epoch 29 | Train Loss: 5328.8403 | Val Loss: 5108.7258 | Optimizer: Adam\n",
      "Trial 31 | Epoch 30 | Train Loss: 5029.3832 | Val Loss: 5113.0068 | Optimizer: Adam\n",
      "Trial 31 | Epoch 31 | Train Loss: 5096.6865 | Val Loss: 5731.1416 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:37,107] Trial 31 finished with value: 4991.117936842513 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.3418458742399081, 'lr': 0.0007189770870424607, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 3.231936509665378e-05}. Best is trial 11 with value: 4846.0888671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 | Epoch 32 | Train Loss: 4810.7695 | Val Loss: 5079.8297 | Optimizer: Adam\n",
      "Trial 31 | Epoch 33 | Train Loss: 5145.4689 | Val Loss: 5124.1796 | Optimizer: Adam\n",
      "Trial 31 | Epoch 34 | Train Loss: 5332.2251 | Val Loss: 5935.8274 | Optimizer: Adam\n",
      "Trial 31 | Epoch 35 | Train Loss: 5114.8725 | Val Loss: 5139.6424 | Optimizer: Adam\n",
      "Trial 31 - Early stopping triggered at epoch 35\n",
      "Trial 32 | Epoch 01 | Train Loss: 20279.8598 | Val Loss: 19578.9506 | Optimizer: Adam\n",
      "Trial 32 | Epoch 02 | Train Loss: 15739.6873 | Val Loss: 11595.8695 | Optimizer: Adam\n",
      "Trial 32 | Epoch 03 | Train Loss: 12548.8450 | Val Loss: 10605.6378 | Optimizer: Adam\n",
      "Trial 32 | Epoch 04 | Train Loss: 11195.9990 | Val Loss: 12421.8579 | Optimizer: Adam\n",
      "Trial 32 | Epoch 05 | Train Loss: 11047.0544 | Val Loss: 10280.8355 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:37,434] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 | Epoch 01 | Train Loss: 19635.6133 | Val Loss: 19735.8321 | Optimizer: Adam\n",
      "Trial 33 | Epoch 02 | Train Loss: 16664.6850 | Val Loss: 15111.6786 | Optimizer: Adam\n",
      "Trial 33 | Epoch 03 | Train Loss: 11528.3984 | Val Loss: 11436.8225 | Optimizer: Adam\n",
      "Trial 33 | Epoch 04 | Train Loss: 11013.5016 | Val Loss: 10069.1775 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:37,753] Trial 33 pruned. \n",
      "[I 2025-09-04 20:33:37,871] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 | Epoch 05 | Train Loss: 10199.2145 | Val Loss: 10447.7079 | Optimizer: Adam\n",
      "Trial 34 | Epoch 01 | Train Loss: 21009.7138 | Val Loss: 21565.8145 | Optimizer: Adam\n",
      "Trial 35 | Epoch 01 | Train Loss: 18308.9952 | Val Loss: 13795.2123 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 02 | Train Loss: 14740.4170 | Val Loss: 17541.8665 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 03 | Train Loss: 14033.5199 | Val Loss: 9830.9397 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 04 | Train Loss: 10078.7600 | Val Loss: 7108.5690 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 05 | Train Loss: 8622.2781 | Val Loss: 11531.8442 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 06 | Train Loss: 8442.3853 | Val Loss: 5997.5640 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 07 | Train Loss: 8289.1253 | Val Loss: 6174.2820 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 08 | Train Loss: 6898.0516 | Val Loss: 6084.1636 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 09 | Train Loss: 6772.5208 | Val Loss: 5624.8616 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 10 | Train Loss: 6675.1642 | Val Loss: 7826.5454 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 11 | Train Loss: 8510.3239 | Val Loss: 5717.6039 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 12 | Train Loss: 6771.8967 | Val Loss: 6708.3542 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 13 | Train Loss: 6500.9041 | Val Loss: 6825.3027 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 14 | Train Loss: 6644.2546 | Val Loss: 5260.6554 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 15 | Train Loss: 5892.0372 | Val Loss: 5347.4081 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 16 | Train Loss: 6175.0382 | Val Loss: 7103.5931 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 17 | Train Loss: 5926.8864 | Val Loss: 6477.4704 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 18 | Train Loss: 8352.8554 | Val Loss: 5218.0482 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 19 | Train Loss: 7739.7338 | Val Loss: 5299.7472 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 20 | Train Loss: 5661.7018 | Val Loss: 6468.6472 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 21 | Train Loss: 5954.2556 | Val Loss: 5457.0619 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 22 | Train Loss: 8260.5661 | Val Loss: 5188.0344 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 23 | Train Loss: 5731.9575 | Val Loss: 5216.9691 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 24 | Train Loss: 6054.0568 | Val Loss: 5114.5869 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 25 | Train Loss: 5571.4854 | Val Loss: 6080.9293 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 26 | Train Loss: 5502.1583 | Val Loss: 5360.7068 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 27 | Train Loss: 5910.7673 | Val Loss: 5160.4614 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 28 | Train Loss: 6308.3168 | Val Loss: 5889.5384 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 29 | Train Loss: 7947.4657 | Val Loss: 5756.0672 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 30 | Train Loss: 5936.1349 | Val Loss: 5718.4828 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 31 | Train Loss: 5381.8028 | Val Loss: 4950.2066 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 32 | Train Loss: 5723.8195 | Val Loss: 5561.5911 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 33 | Train Loss: 5356.6120 | Val Loss: 5146.5878 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 34 | Train Loss: 5552.3810 | Val Loss: 5031.2494 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 35 | Train Loss: 5787.1122 | Val Loss: 5425.5550 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 36 | Train Loss: 5477.2500 | Val Loss: 5341.4258 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 37 | Train Loss: 5460.7303 | Val Loss: 7120.9100 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 38 | Train Loss: 5831.6392 | Val Loss: 5095.3847 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 39 | Train Loss: 5292.1380 | Val Loss: 5197.0372 | Optimizer: RMSprop\n",
      "Trial 35 | Epoch 40 | Train Loss: 5009.3649 | Val Loss: 5580.0007 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:39,967] Trial 35 finished with value: 4950.2066348236385 and parameters: {'gnn_dim': 384, 'hidden_dim': 256, 'dropout_rate': 0.2795496735999456, 'lr': 0.0006474066450772411, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 8.610469228489611e-06}. Best is trial 11 with value: 4846.0888671875.\n",
      "[I 2025-09-04 20:33:40,087] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 | Epoch 41 | Train Loss: 5345.4982 | Val Loss: 6759.8921 | Optimizer: RMSprop\n",
      "Trial 35 - Early stopping triggered at epoch 41\n",
      "Trial 36 | Epoch 01 | Train Loss: 21203.0503 | Val Loss: 21995.8578 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:40,185] Trial 37 pruned. \n",
      "[I 2025-09-04 20:33:40,342] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 38 | Epoch 01 | Train Loss: 21929.6074 | Val Loss: 23825.8477 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:40,504] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 | Epoch 01 | Train Loss: 20502.6826 | Val Loss: 20176.0624 | Optimizer: AdamW\n",
      "Trial 39 | Epoch 02 | Train Loss: 17329.2823 | Val Loss: 16573.7507 | Optimizer: AdamW\n",
      "Trial 40 | Epoch 01 | Train Loss: 20236.6547 | Val Loss: 20848.7607 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:40,621] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 | Epoch 01 | Train Loss: 18164.0029 | Val Loss: 14468.8596 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 02 | Train Loss: 11497.1845 | Val Loss: 8430.7332 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 03 | Train Loss: 13141.9744 | Val Loss: 11173.7688 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 04 | Train Loss: 8858.6250 | Val Loss: 6989.2716 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 05 | Train Loss: 7673.1583 | Val Loss: 8489.0155 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 06 | Train Loss: 7918.7804 | Val Loss: 7554.5679 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 07 | Train Loss: 7248.4943 | Val Loss: 11259.7657 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 08 | Train Loss: 8145.2396 | Val Loss: 5817.1526 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 09 | Train Loss: 6759.6830 | Val Loss: 6793.0462 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 10 | Train Loss: 7737.3725 | Val Loss: 6219.6398 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 11 | Train Loss: 6172.8905 | Val Loss: 5659.8482 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 12 | Train Loss: 7048.7756 | Val Loss: 6543.1815 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 13 | Train Loss: 6499.5898 | Val Loss: 5318.2043 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 14 | Train Loss: 6411.2196 | Val Loss: 9803.0398 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 15 | Train Loss: 7432.0136 | Val Loss: 5159.0251 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 16 | Train Loss: 6788.3625 | Val Loss: 5128.9449 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 17 | Train Loss: 6395.7063 | Val Loss: 5205.2907 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 18 | Train Loss: 5605.7567 | Val Loss: 5339.0836 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 19 | Train Loss: 6951.6556 | Val Loss: 6031.8354 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 20 | Train Loss: 6460.1368 | Val Loss: 5919.2932 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 21 | Train Loss: 6656.3843 | Val Loss: 5248.3869 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 22 | Train Loss: 5735.5090 | Val Loss: 6580.4243 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:42,008] Trial 41 finished with value: 5128.944872563428 and parameters: {'gnn_dim': 384, 'hidden_dim': 256, 'dropout_rate': 0.2761721195674439, 'lr': 0.0005955154334385722, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 7.685258288063121e-06}. Best is trial 11 with value: 4846.0888671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 | Epoch 23 | Train Loss: 5574.1360 | Val Loss: 5874.1053 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 24 | Train Loss: 5909.9749 | Val Loss: 7513.0029 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 25 | Train Loss: 5721.4240 | Val Loss: 7538.1079 | Optimizer: RMSprop\n",
      "Trial 41 | Epoch 26 | Train Loss: 5843.7563 | Val Loss: 5200.3543 | Optimizer: RMSprop\n",
      "Trial 41 - Early stopping triggered at epoch 26\n",
      "Trial 42 | Epoch 01 | Train Loss: 18788.6000 | Val Loss: 15041.5131 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 02 | Train Loss: 14452.8428 | Val Loss: 14316.3792 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 03 | Train Loss: 11806.9046 | Val Loss: 7828.8584 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 04 | Train Loss: 8719.5100 | Val Loss: 8196.6507 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 05 | Train Loss: 9776.7235 | Val Loss: 6107.0455 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 06 | Train Loss: 7479.8304 | Val Loss: 6623.3169 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 07 | Train Loss: 7851.5545 | Val Loss: 10049.0434 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 08 | Train Loss: 7532.8335 | Val Loss: 7070.6698 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 09 | Train Loss: 7958.4811 | Val Loss: 11280.4046 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 10 | Train Loss: 7552.6103 | Val Loss: 6079.7516 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 11 | Train Loss: 6544.4363 | Val Loss: 5427.6486 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 12 | Train Loss: 6492.3648 | Val Loss: 5962.1472 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 13 | Train Loss: 5664.4027 | Val Loss: 6239.2673 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 14 | Train Loss: 7394.9690 | Val Loss: 5287.4235 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 15 | Train Loss: 6559.3186 | Val Loss: 7635.5810 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 16 | Train Loss: 6811.8391 | Val Loss: 5320.6925 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 17 | Train Loss: 6167.0054 | Val Loss: 5596.3467 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 18 | Train Loss: 6112.4024 | Val Loss: 5222.7175 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 19 | Train Loss: 6114.6811 | Val Loss: 5229.6965 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 20 | Train Loss: 5800.8379 | Val Loss: 5136.2124 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 21 | Train Loss: 5568.3856 | Val Loss: 5022.4478 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 22 | Train Loss: 5904.1356 | Val Loss: 8461.0777 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 23 | Train Loss: 6632.9402 | Val Loss: 5318.5394 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 24 | Train Loss: 5762.9542 | Val Loss: 5080.6017 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 25 | Train Loss: 6502.6355 | Val Loss: 5073.1855 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 26 | Train Loss: 5034.5194 | Val Loss: 5410.9101 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 27 | Train Loss: 5602.3778 | Val Loss: 5633.4576 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 28 | Train Loss: 6212.9492 | Val Loss: 5169.0908 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 29 | Train Loss: 6103.4816 | Val Loss: 5696.8527 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 30 | Train Loss: 5544.8352 | Val Loss: 4995.8615 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 31 | Train Loss: 5616.2386 | Val Loss: 5259.8940 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 32 | Train Loss: 5128.0281 | Val Loss: 6711.8903 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 33 | Train Loss: 5906.2883 | Val Loss: 5691.3577 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 34 | Train Loss: 5826.2173 | Val Loss: 8495.6312 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 35 | Train Loss: 6368.1031 | Val Loss: 5051.3215 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 36 | Train Loss: 5093.4824 | Val Loss: 4722.9131 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 37 | Train Loss: 5514.0573 | Val Loss: 4895.1407 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 38 | Train Loss: 4819.1876 | Val Loss: 5521.8942 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 39 | Train Loss: 4813.3318 | Val Loss: 6838.3045 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 40 | Train Loss: 5187.7794 | Val Loss: 6011.8717 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 41 | Train Loss: 5478.5459 | Val Loss: 7016.0602 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 42 | Train Loss: 5814.3562 | Val Loss: 5022.3245 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 43 | Train Loss: 5074.8651 | Val Loss: 6369.6866 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 44 | Train Loss: 6162.1184 | Val Loss: 4954.2593 | Optimizer: RMSprop\n",
      "Trial 42 | Epoch 45 | Train Loss: 5026.9976 | Val Loss: 5345.4672 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:44,346] Trial 42 finished with value: 4722.913093189201 and parameters: {'gnn_dim': 384, 'hidden_dim': 256, 'dropout_rate': 0.26438482774499983, 'lr': 0.0006367169549716812, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 5.193545641666849e-06}. Best is trial 42 with value: 4722.913093189201.\n",
      "[I 2025-09-04 20:33:44,460] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 | Epoch 46 | Train Loss: 4960.1209 | Val Loss: 4870.9802 | Optimizer: RMSprop\n",
      "Trial 42 - Early stopping triggered at epoch 46\n",
      "Trial 43 | Epoch 01 | Train Loss: 14737.6657 | Val Loss: 53618.2435 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 01 | Train Loss: 27784.8303 | Val Loss: 15418.7694 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 02 | Train Loss: 12681.4595 | Val Loss: 9936.1393 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 03 | Train Loss: 9361.7700 | Val Loss: 8967.1691 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 04 | Train Loss: 8306.0979 | Val Loss: 8709.9288 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 05 | Train Loss: 8254.3213 | Val Loss: 6508.8343 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 06 | Train Loss: 7045.8287 | Val Loss: 6095.2782 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 07 | Train Loss: 7901.1035 | Val Loss: 11103.1338 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 08 | Train Loss: 7692.6362 | Val Loss: 6004.4323 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 09 | Train Loss: 5872.5452 | Val Loss: 5917.9432 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 10 | Train Loss: 6531.7490 | Val Loss: 5709.2175 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:45,208] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 | Epoch 11 | Train Loss: 6547.1484 | Val Loss: 5862.5756 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 12 | Train Loss: 6225.2640 | Val Loss: 6667.7893 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 13 | Train Loss: 6532.1451 | Val Loss: 5824.7417 | Optimizer: RMSprop\n",
      "Trial 44 | Epoch 14 | Train Loss: 5963.5793 | Val Loss: 5639.3745 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 01 | Train Loss: 27861.4812 | Val Loss: 13655.8234 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 02 | Train Loss: 12125.0621 | Val Loss: 9906.6293 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 03 | Train Loss: 22317.7095 | Val Loss: 16245.0991 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 04 | Train Loss: 13911.2419 | Val Loss: 12838.9565 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 05 | Train Loss: 10799.7062 | Val Loss: 7669.0542 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 06 | Train Loss: 7692.3706 | Val Loss: 7059.2837 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 07 | Train Loss: 7120.0889 | Val Loss: 7419.5023 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 08 | Train Loss: 8939.0129 | Val Loss: 5953.5074 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 09 | Train Loss: 6944.5833 | Val Loss: 5700.0149 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 10 | Train Loss: 6510.5708 | Val Loss: 5678.0220 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:45,977] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 | Epoch 11 | Train Loss: 6654.9816 | Val Loss: 5693.1181 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 12 | Train Loss: 6736.6171 | Val Loss: 10525.8629 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 13 | Train Loss: 7462.4950 | Val Loss: 5737.3431 | Optimizer: RMSprop\n",
      "Trial 45 | Epoch 14 | Train Loss: 6357.7512 | Val Loss: 7132.5683 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:46,107] Trial 46 pruned. \n",
      "[I 2025-09-04 20:33:46,215] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 | Epoch 01 | Train Loss: 20914.9197 | Val Loss: 22328.3344 | Optimizer: Adam\n",
      "Trial 47 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:46,379] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 | Epoch 01 | Train Loss: 20776.9480 | Val Loss: 21585.0841 | Optimizer: AdamW\n",
      "Trial 49 | Epoch 01 | Train Loss: 19787.1138 | Val Loss: 17368.0385 | Optimizer: Adam\n",
      "Trial 49 | Epoch 02 | Train Loss: 12306.6725 | Val Loss: 12461.7078 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:46,602] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 | Epoch 03 | Train Loss: 10809.0979 | Val Loss: 12701.2400 | Optimizer: Adam\n",
      "Trial 50 | Epoch 01 | Train Loss: 18776.4123 | Val Loss: 16306.8491 | Optimizer: Adam\n",
      "Trial 50 | Epoch 02 | Train Loss: 12904.8482 | Val Loss: 10920.5918 | Optimizer: Adam\n",
      "Trial 50 | Epoch 03 | Train Loss: 11357.3353 | Val Loss: 10532.1292 | Optimizer: Adam\n",
      "Trial 50 | Epoch 04 | Train Loss: 10427.7349 | Val Loss: 10294.0882 | Optimizer: Adam\n",
      "Trial 50 | Epoch 05 | Train Loss: 10157.7906 | Val Loss: 8537.1441 | Optimizer: Adam\n",
      "Trial 50 | Epoch 06 | Train Loss: 9034.2364 | Val Loss: 7400.2513 | Optimizer: Adam\n",
      "Trial 50 | Epoch 07 | Train Loss: 8525.0255 | Val Loss: 6183.9227 | Optimizer: Adam\n",
      "Trial 50 | Epoch 08 | Train Loss: 7218.3947 | Val Loss: 5646.2806 | Optimizer: Adam\n",
      "Trial 50 | Epoch 09 | Train Loss: 7434.0483 | Val Loss: 6286.2373 | Optimizer: Adam\n",
      "Trial 50 | Epoch 10 | Train Loss: 6365.0510 | Val Loss: 5671.4051 | Optimizer: Adam\n",
      "Trial 50 | Epoch 11 | Train Loss: 6717.3703 | Val Loss: 6389.8425 | Optimizer: Adam\n",
      "Trial 50 | Epoch 12 | Train Loss: 6487.3654 | Val Loss: 5410.1971 | Optimizer: Adam\n",
      "Trial 50 | Epoch 13 | Train Loss: 6544.4421 | Val Loss: 5893.9403 | Optimizer: Adam\n",
      "Trial 50 | Epoch 14 | Train Loss: 6224.5050 | Val Loss: 5372.1605 | Optimizer: Adam\n",
      "Trial 50 | Epoch 15 | Train Loss: 5983.4354 | Val Loss: 5523.4918 | Optimizer: Adam\n",
      "Trial 50 | Epoch 16 | Train Loss: 5875.8098 | Val Loss: 5330.8035 | Optimizer: Adam\n",
      "Trial 50 | Epoch 17 | Train Loss: 5534.3266 | Val Loss: 5618.0600 | Optimizer: Adam\n",
      "Trial 50 | Epoch 18 | Train Loss: 6019.0464 | Val Loss: 5044.1526 | Optimizer: Adam\n",
      "Trial 50 | Epoch 19 | Train Loss: 6097.0027 | Val Loss: 6042.5384 | Optimizer: Adam\n",
      "Trial 50 | Epoch 20 | Train Loss: 5672.7294 | Val Loss: 5006.7204 | Optimizer: Adam\n",
      "Trial 50 | Epoch 21 | Train Loss: 5932.6565 | Val Loss: 6037.5956 | Optimizer: Adam\n",
      "Trial 50 | Epoch 22 | Train Loss: 5651.9786 | Val Loss: 5159.7853 | Optimizer: Adam\n",
      "Trial 50 | Epoch 23 | Train Loss: 5808.1131 | Val Loss: 5156.3305 | Optimizer: Adam\n",
      "Trial 50 | Epoch 24 | Train Loss: 5313.5733 | Val Loss: 5013.6099 | Optimizer: Adam\n",
      "Trial 50 | Epoch 25 | Train Loss: 5419.6310 | Val Loss: 5147.8296 | Optimizer: Adam\n",
      "Trial 50 | Epoch 26 | Train Loss: 5305.7326 | Val Loss: 5239.2453 | Optimizer: Adam\n",
      "Trial 50 | Epoch 27 | Train Loss: 5474.7728 | Val Loss: 4878.2036 | Optimizer: Adam\n",
      "Trial 50 | Epoch 28 | Train Loss: 5108.3292 | Val Loss: 5388.4983 | Optimizer: Adam\n",
      "Trial 50 | Epoch 29 | Train Loss: 5724.2030 | Val Loss: 4952.6093 | Optimizer: Adam\n",
      "Trial 50 | Epoch 30 | Train Loss: 5877.2375 | Val Loss: 4946.3332 | Optimizer: Adam\n",
      "Trial 50 | Epoch 31 | Train Loss: 5168.4524 | Val Loss: 5144.0668 | Optimizer: Adam\n",
      "Trial 50 | Epoch 32 | Train Loss: 5078.2956 | Val Loss: 4819.5921 | Optimizer: Adam\n",
      "Trial 50 | Epoch 33 | Train Loss: 5403.4390 | Val Loss: 5174.9972 | Optimizer: Adam\n",
      "Trial 50 | Epoch 34 | Train Loss: 5050.2986 | Val Loss: 4860.6577 | Optimizer: Adam\n",
      "Trial 50 | Epoch 35 | Train Loss: 4965.5840 | Val Loss: 5320.4822 | Optimizer: Adam\n",
      "Trial 50 | Epoch 36 | Train Loss: 4769.9597 | Val Loss: 5017.5453 | Optimizer: Adam\n",
      "Trial 50 | Epoch 37 | Train Loss: 4802.3253 | Val Loss: 5127.3195 | Optimizer: Adam\n",
      "Trial 50 | Epoch 38 | Train Loss: 4791.9394 | Val Loss: 4959.7022 | Optimizer: Adam\n",
      "Trial 50 | Epoch 39 | Train Loss: 4809.2590 | Val Loss: 6409.6687 | Optimizer: Adam\n",
      "Trial 50 | Epoch 40 | Train Loss: 5468.5671 | Val Loss: 4908.2981 | Optimizer: Adam\n",
      "Trial 50 | Epoch 41 | Train Loss: 5306.6458 | Val Loss: 4917.4994 | Optimizer: Adam\n",
      "Trial 50 | Epoch 42 | Train Loss: 5112.0492 | Val Loss: 5196.5008 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:48,757] Trial 50 finished with value: 4819.592084525835 and parameters: {'gnn_dim': 384, 'hidden_dim': 512, 'dropout_rate': 0.32975798640947857, 'lr': 0.0005747015618493944, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 5.567961602435076e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 - Early stopping triggered at epoch 42\n",
      "Trial 51 | Epoch 01 | Train Loss: 18547.1440 | Val Loss: 16187.6450 | Optimizer: Adam\n",
      "Trial 51 | Epoch 02 | Train Loss: 12732.3949 | Val Loss: 11114.3580 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:49,130] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 | Epoch 03 | Train Loss: 11337.4561 | Val Loss: 10673.2974 | Optimizer: Adam\n",
      "Trial 51 | Epoch 04 | Train Loss: 10701.4056 | Val Loss: 10234.7816 | Optimizer: Adam\n",
      "Trial 51 | Epoch 05 | Train Loss: 9902.6506 | Val Loss: 8784.4411 | Optimizer: Adam\n",
      "Trial 51 | Epoch 06 | Train Loss: 9487.2461 | Val Loss: 7608.7296 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:49,364] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 | Epoch 01 | Train Loss: 19475.8810 | Val Loss: 18463.1448 | Optimizer: Adam\n",
      "Trial 52 | Epoch 02 | Train Loss: 15381.0381 | Val Loss: 13607.1439 | Optimizer: Adam\n",
      "Trial 52 | Epoch 03 | Train Loss: 12026.7448 | Val Loss: 11222.5603 | Optimizer: Adam\n",
      "Trial 53 | Epoch 01 | Train Loss: 17419.9665 | Val Loss: 13235.3605 | Optimizer: Adam\n",
      "Trial 53 | Epoch 02 | Train Loss: 11412.9691 | Val Loss: 10503.7614 | Optimizer: Adam\n",
      "Trial 53 | Epoch 03 | Train Loss: 11431.4145 | Val Loss: 11139.9763 | Optimizer: Adam\n",
      "Trial 53 | Epoch 04 | Train Loss: 10388.6046 | Val Loss: 8479.5099 | Optimizer: Adam\n",
      "Trial 53 | Epoch 05 | Train Loss: 8504.6414 | Val Loss: 6046.2340 | Optimizer: Adam\n",
      "Trial 53 | Epoch 06 | Train Loss: 7162.9794 | Val Loss: 6587.8412 | Optimizer: Adam\n",
      "Trial 53 | Epoch 07 | Train Loss: 7487.4914 | Val Loss: 6244.2900 | Optimizer: Adam\n",
      "Trial 53 | Epoch 08 | Train Loss: 7188.7121 | Val Loss: 5754.4191 | Optimizer: Adam\n",
      "Trial 53 | Epoch 09 | Train Loss: 7164.2147 | Val Loss: 7335.0505 | Optimizer: Adam\n",
      "Trial 53 | Epoch 10 | Train Loss: 7418.3166 | Val Loss: 5549.0532 | Optimizer: Adam\n",
      "Trial 53 | Epoch 11 | Train Loss: 6281.1784 | Val Loss: 5591.3021 | Optimizer: Adam\n",
      "Trial 53 | Epoch 12 | Train Loss: 6043.4313 | Val Loss: 5213.0198 | Optimizer: Adam\n",
      "Trial 53 | Epoch 13 | Train Loss: 5774.6374 | Val Loss: 5453.7509 | Optimizer: Adam\n",
      "Trial 53 | Epoch 14 | Train Loss: 5476.5503 | Val Loss: 5103.2538 | Optimizer: Adam\n",
      "Trial 53 | Epoch 15 | Train Loss: 5818.0388 | Val Loss: 5240.7436 | Optimizer: Adam\n",
      "Trial 53 | Epoch 16 | Train Loss: 5555.4945 | Val Loss: 5524.0023 | Optimizer: Adam\n",
      "Trial 53 | Epoch 17 | Train Loss: 5477.7265 | Val Loss: 5331.4259 | Optimizer: Adam\n",
      "Trial 53 | Epoch 18 | Train Loss: 5554.7820 | Val Loss: 5418.7890 | Optimizer: Adam\n",
      "Trial 53 | Epoch 19 | Train Loss: 5364.0946 | Val Loss: 5289.1541 | Optimizer: Adam\n",
      "Trial 53 | Epoch 20 | Train Loss: 5402.6059 | Val Loss: 4918.8625 | Optimizer: Adam\n",
      "Trial 53 | Epoch 21 | Train Loss: 5694.1234 | Val Loss: 5033.2659 | Optimizer: Adam\n",
      "Trial 53 | Epoch 22 | Train Loss: 5497.3834 | Val Loss: 5195.5703 | Optimizer: Adam\n",
      "Trial 53 | Epoch 23 | Train Loss: 4933.0889 | Val Loss: 5768.0345 | Optimizer: Adam\n",
      "Trial 53 | Epoch 24 | Train Loss: 5031.6900 | Val Loss: 5195.2003 | Optimizer: Adam\n",
      "Trial 53 | Epoch 25 | Train Loss: 5171.0136 | Val Loss: 5436.4280 | Optimizer: Adam\n",
      "Trial 53 | Epoch 26 | Train Loss: 4894.8031 | Val Loss: 4861.6368 | Optimizer: Adam\n",
      "Trial 53 | Epoch 27 | Train Loss: 4814.2951 | Val Loss: 4957.9274 | Optimizer: Adam\n",
      "Trial 53 | Epoch 28 | Train Loss: 4700.7502 | Val Loss: 5573.6270 | Optimizer: Adam\n",
      "Trial 53 | Epoch 29 | Train Loss: 5013.4858 | Val Loss: 4947.5145 | Optimizer: Adam\n",
      "Trial 53 | Epoch 30 | Train Loss: 4814.6858 | Val Loss: 4970.6815 | Optimizer: Adam\n",
      "Trial 53 | Epoch 31 | Train Loss: 4855.1809 | Val Loss: 5183.3713 | Optimizer: Adam\n",
      "Trial 53 | Epoch 32 | Train Loss: 4880.4522 | Val Loss: 5513.0288 | Optimizer: Adam\n",
      "Trial 53 | Epoch 33 | Train Loss: 4933.7883 | Val Loss: 4971.5721 | Optimizer: Adam\n",
      "Trial 53 | Epoch 34 | Train Loss: 5506.3410 | Val Loss: 4920.4167 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:51,252] Trial 53 finished with value: 4861.636837194462 and parameters: {'gnn_dim': 384, 'hidden_dim': 512, 'dropout_rate': 0.3089079035570862, 'lr': 0.0008963791620382307, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 4.8494394579087605e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 | Epoch 35 | Train Loss: 5148.4224 | Val Loss: 5116.9359 | Optimizer: Adam\n",
      "Trial 53 | Epoch 36 | Train Loss: 4766.2482 | Val Loss: 5026.1005 | Optimizer: Adam\n",
      "Trial 53 - Early stopping triggered at epoch 36\n",
      "Trial 54 | Epoch 01 | Train Loss: 17374.6532 | Val Loss: 12417.8916 | Optimizer: Adam\n",
      "Trial 54 | Epoch 02 | Train Loss: 12049.3752 | Val Loss: 10897.0906 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:51,511] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 | Epoch 03 | Train Loss: 11106.5054 | Val Loss: 11922.5874 | Optimizer: Adam\n",
      "Trial 54 | Epoch 04 | Train Loss: 11789.5208 | Val Loss: 11553.0143 | Optimizer: Adam\n",
      "Trial 55 | Epoch 01 | Train Loss: 18164.9084 | Val Loss: 14146.5585 | Optimizer: Adam\n",
      "Trial 55 | Epoch 02 | Train Loss: 11617.7596 | Val Loss: 11260.2060 | Optimizer: Adam\n",
      "Trial 55 | Epoch 03 | Train Loss: 11571.2253 | Val Loss: 10797.5718 | Optimizer: Adam\n",
      "Trial 55 | Epoch 04 | Train Loss: 10631.6971 | Val Loss: 9398.0329 | Optimizer: Adam\n",
      "Trial 55 | Epoch 05 | Train Loss: 9007.9046 | Val Loss: 6511.9771 | Optimizer: Adam\n",
      "Trial 55 | Epoch 06 | Train Loss: 7755.2716 | Val Loss: 5678.8026 | Optimizer: Adam\n",
      "Trial 55 | Epoch 07 | Train Loss: 7779.8881 | Val Loss: 7868.8010 | Optimizer: Adam\n",
      "Trial 55 | Epoch 08 | Train Loss: 8158.3792 | Val Loss: 5561.2752 | Optimizer: Adam\n",
      "Trial 55 | Epoch 09 | Train Loss: 6749.9593 | Val Loss: 5918.6891 | Optimizer: Adam\n",
      "Trial 55 | Epoch 10 | Train Loss: 6401.1591 | Val Loss: 5582.3429 | Optimizer: Adam\n",
      "Trial 55 | Epoch 11 | Train Loss: 6435.4415 | Val Loss: 5433.4197 | Optimizer: Adam\n",
      "Trial 55 | Epoch 12 | Train Loss: 5977.9005 | Val Loss: 5369.9642 | Optimizer: Adam\n",
      "Trial 55 | Epoch 13 | Train Loss: 5920.5995 | Val Loss: 5834.6368 | Optimizer: Adam\n",
      "Trial 55 | Epoch 14 | Train Loss: 5975.9117 | Val Loss: 5163.2753 | Optimizer: Adam\n",
      "Trial 55 | Epoch 15 | Train Loss: 6108.7673 | Val Loss: 5424.1064 | Optimizer: Adam\n",
      "Trial 55 | Epoch 16 | Train Loss: 5793.9576 | Val Loss: 6226.1041 | Optimizer: Adam\n",
      "Trial 55 | Epoch 17 | Train Loss: 5695.8528 | Val Loss: 5312.9891 | Optimizer: Adam\n",
      "Trial 55 | Epoch 18 | Train Loss: 6686.0717 | Val Loss: 6148.3025 | Optimizer: Adam\n",
      "Trial 55 | Epoch 19 | Train Loss: 5587.1266 | Val Loss: 5058.2436 | Optimizer: Adam\n",
      "Trial 55 | Epoch 20 | Train Loss: 5585.0211 | Val Loss: 5083.0560 | Optimizer: Adam\n",
      "Trial 55 | Epoch 21 | Train Loss: 5504.2921 | Val Loss: 5284.2913 | Optimizer: Adam\n",
      "Trial 55 | Epoch 22 | Train Loss: 5302.4530 | Val Loss: 5056.2758 | Optimizer: Adam\n",
      "Trial 55 | Epoch 23 | Train Loss: 5793.7233 | Val Loss: 6755.2138 | Optimizer: Adam\n",
      "Trial 55 | Epoch 24 | Train Loss: 5342.0825 | Val Loss: 5086.4276 | Optimizer: Adam\n",
      "Trial 55 | Epoch 25 | Train Loss: 5742.7135 | Val Loss: 5390.9740 | Optimizer: Adam\n",
      "Trial 55 | Epoch 26 | Train Loss: 5404.3636 | Val Loss: 5140.9454 | Optimizer: Adam\n",
      "Trial 55 | Epoch 27 | Train Loss: 5305.7584 | Val Loss: 5409.6275 | Optimizer: Adam\n",
      "Trial 55 | Epoch 28 | Train Loss: 5094.0043 | Val Loss: 4919.8713 | Optimizer: Adam\n",
      "Trial 55 | Epoch 29 | Train Loss: 5153.1630 | Val Loss: 5500.7605 | Optimizer: Adam\n",
      "Trial 55 | Epoch 30 | Train Loss: 5170.5388 | Val Loss: 5133.7961 | Optimizer: Adam\n",
      "Trial 55 | Epoch 31 | Train Loss: 5012.4416 | Val Loss: 4990.1256 | Optimizer: Adam\n",
      "Trial 55 | Epoch 32 | Train Loss: 5014.6249 | Val Loss: 5949.9182 | Optimizer: Adam\n",
      "Trial 55 | Epoch 33 | Train Loss: 4818.7575 | Val Loss: 4921.9019 | Optimizer: Adam\n",
      "Trial 55 | Epoch 34 | Train Loss: 5149.4923 | Val Loss: 4925.2226 | Optimizer: Adam\n",
      "Trial 55 | Epoch 35 | Train Loss: 4593.8116 | Val Loss: 5103.0154 | Optimizer: Adam\n",
      "Trial 55 | Epoch 36 | Train Loss: 4708.1651 | Val Loss: 5111.7415 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:53,433] Trial 55 finished with value: 4919.87127262531 and parameters: {'gnn_dim': 384, 'hidden_dim': 512, 'dropout_rate': 0.3103758592941878, 'lr': 0.0007997078162739047, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 6.512503517476606e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 | Epoch 37 | Train Loss: 4814.5289 | Val Loss: 5229.0164 | Optimizer: Adam\n",
      "Trial 55 | Epoch 38 | Train Loss: 4626.3253 | Val Loss: 4930.8425 | Optimizer: Adam\n",
      "Trial 55 - Early stopping triggered at epoch 38\n",
      "Trial 56 | Epoch 01 | Train Loss: 19755.6595 | Val Loss: 18165.3553 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:53,616] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 | Epoch 02 | Train Loss: 14560.2054 | Val Loss: 11655.5638 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:53,934] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 | Epoch 01 | Train Loss: 20146.2244 | Val Loss: 19618.6790 | Optimizer: Adam\n",
      "Trial 58 | Epoch 01 | Train Loss: 18171.7138 | Val Loss: 14696.2367 | Optimizer: RMSprop\n",
      "Trial 58 | Epoch 02 | Train Loss: 11664.5294 | Val Loss: 9993.2075 | Optimizer: RMSprop\n",
      "Trial 58 | Epoch 03 | Train Loss: 9420.1654 | Val Loss: 8902.2804 | Optimizer: RMSprop\n",
      "Trial 58 | Epoch 04 | Train Loss: 8964.0627 | Val Loss: 8037.8236 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:54,490] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 | Epoch 05 | Train Loss: 8421.0290 | Val Loss: 7492.2324 | Optimizer: RMSprop\n",
      "Trial 58 | Epoch 06 | Train Loss: 7981.1986 | Val Loss: 7684.4601 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:54,792] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 | Epoch 01 | Train Loss: 20723.7636 | Val Loss: 21318.9183 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:55,232] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:55,364] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 | Epoch 01 | Train Loss: 21840.0497 | Val Loss: 23334.7652 | Optimizer: Adam\n",
      "Trial 62 | Epoch 01 | Train Loss: 18429.5908 | Val Loss: 13796.6149 | Optimizer: Adam\n",
      "Trial 62 | Epoch 02 | Train Loss: 12227.3548 | Val Loss: 11008.5488 | Optimizer: Adam\n",
      "Trial 62 | Epoch 03 | Train Loss: 11226.0987 | Val Loss: 11470.4880 | Optimizer: Adam\n",
      "Trial 62 | Epoch 04 | Train Loss: 10521.2963 | Val Loss: 8299.6031 | Optimizer: Adam\n",
      "Trial 62 | Epoch 05 | Train Loss: 8726.8705 | Val Loss: 6068.9805 | Optimizer: Adam\n",
      "Trial 62 | Epoch 06 | Train Loss: 8046.3479 | Val Loss: 8252.8094 | Optimizer: Adam\n",
      "Trial 62 | Epoch 07 | Train Loss: 8795.5277 | Val Loss: 5534.9176 | Optimizer: Adam\n",
      "Trial 62 | Epoch 08 | Train Loss: 7383.0148 | Val Loss: 6461.3457 | Optimizer: Adam\n",
      "Trial 62 | Epoch 09 | Train Loss: 7018.7849 | Val Loss: 5985.3614 | Optimizer: Adam\n",
      "Trial 62 | Epoch 10 | Train Loss: 6676.7753 | Val Loss: 5673.7314 | Optimizer: Adam\n",
      "Trial 62 | Epoch 11 | Train Loss: 6189.0784 | Val Loss: 5426.3552 | Optimizer: Adam\n",
      "Trial 62 | Epoch 12 | Train Loss: 6300.5678 | Val Loss: 5689.1380 | Optimizer: Adam\n",
      "Trial 62 | Epoch 13 | Train Loss: 6087.4123 | Val Loss: 5371.6999 | Optimizer: Adam\n",
      "Trial 62 | Epoch 14 | Train Loss: 5898.0073 | Val Loss: 5225.2958 | Optimizer: Adam\n",
      "Trial 62 | Epoch 15 | Train Loss: 6072.1219 | Val Loss: 5154.4698 | Optimizer: Adam\n",
      "Trial 62 | Epoch 16 | Train Loss: 6024.8196 | Val Loss: 5228.6223 | Optimizer: Adam\n",
      "Trial 62 | Epoch 17 | Train Loss: 5484.2587 | Val Loss: 4985.9272 | Optimizer: Adam\n",
      "Trial 62 | Epoch 18 | Train Loss: 5478.6380 | Val Loss: 5476.6898 | Optimizer: Adam\n",
      "Trial 62 | Epoch 19 | Train Loss: 5408.5712 | Val Loss: 5771.3498 | Optimizer: Adam\n",
      "Trial 62 | Epoch 20 | Train Loss: 5702.3305 | Val Loss: 5938.4828 | Optimizer: Adam\n",
      "Trial 62 | Epoch 21 | Train Loss: 6068.7440 | Val Loss: 6706.3547 | Optimizer: Adam\n",
      "Trial 62 | Epoch 22 | Train Loss: 7468.2531 | Val Loss: 5537.6107 | Optimizer: Adam\n",
      "Trial 62 | Epoch 23 | Train Loss: 6483.0185 | Val Loss: 6220.3480 | Optimizer: Adam\n",
      "Trial 62 | Epoch 24 | Train Loss: 6042.4076 | Val Loss: 5022.9152 | Optimizer: Adam\n",
      "Trial 62 | Epoch 25 | Train Loss: 5450.4360 | Val Loss: 5550.0400 | Optimizer: Adam\n",
      "Trial 62 | Epoch 26 | Train Loss: 5429.8190 | Val Loss: 4949.4186 | Optimizer: Adam\n",
      "Trial 62 | Epoch 27 | Train Loss: 5240.9367 | Val Loss: 5326.6351 | Optimizer: Adam\n",
      "Trial 62 | Epoch 28 | Train Loss: 4990.6233 | Val Loss: 4951.8846 | Optimizer: Adam\n",
      "Trial 62 | Epoch 29 | Train Loss: 5067.2769 | Val Loss: 5358.9812 | Optimizer: Adam\n",
      "Trial 62 | Epoch 30 | Train Loss: 5248.5910 | Val Loss: 5220.8345 | Optimizer: Adam\n",
      "Trial 62 | Epoch 31 | Train Loss: 5034.1822 | Val Loss: 5034.5576 | Optimizer: Adam\n",
      "Trial 62 | Epoch 32 | Train Loss: 5035.2582 | Val Loss: 5109.5765 | Optimizer: Adam\n",
      "Trial 62 | Epoch 33 | Train Loss: 4756.8323 | Val Loss: 5623.8565 | Optimizer: Adam\n",
      "Trial 62 | Epoch 34 | Train Loss: 5167.4935 | Val Loss: 4957.7401 | Optimizer: Adam\n",
      "Trial 62 | Epoch 35 | Train Loss: 4924.0619 | Val Loss: 5599.0258 | Optimizer: Adam\n",
      "Trial 62 | Epoch 36 | Train Loss: 4990.5819 | Val Loss: 4918.2799 | Optimizer: Adam\n",
      "Trial 62 | Epoch 37 | Train Loss: 5304.7623 | Val Loss: 4945.3156 | Optimizer: Adam\n",
      "Trial 62 | Epoch 38 | Train Loss: 4710.0154 | Val Loss: 5029.7541 | Optimizer: Adam\n",
      "Trial 62 | Epoch 39 | Train Loss: 4819.1646 | Val Loss: 4904.2504 | Optimizer: Adam\n",
      "Trial 62 | Epoch 40 | Train Loss: 4821.6672 | Val Loss: 5186.3464 | Optimizer: Adam\n",
      "Trial 62 | Epoch 41 | Train Loss: 4792.3112 | Val Loss: 4979.2150 | Optimizer: Adam\n",
      "Trial 62 | Epoch 42 | Train Loss: 4672.1181 | Val Loss: 4949.8744 | Optimizer: Adam\n",
      "Trial 62 | Epoch 43 | Train Loss: 4608.2112 | Val Loss: 5762.7824 | Optimizer: Adam\n",
      "Trial 62 | Epoch 44 | Train Loss: 5252.5816 | Val Loss: 5017.0971 | Optimizer: Adam\n",
      "Trial 62 | Epoch 45 | Train Loss: 5318.0914 | Val Loss: 5821.3973 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:57,986] Trial 62 finished with value: 4904.250406095297 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.3168074810507939, 'lr': 0.0008716967220131983, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.2526598945575168e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 | Epoch 46 | Train Loss: 4831.4300 | Val Loss: 5008.9786 | Optimizer: Adam\n",
      "Trial 62 | Epoch 47 | Train Loss: 4745.7836 | Val Loss: 5983.4720 | Optimizer: Adam\n",
      "Trial 62 | Epoch 48 | Train Loss: 4995.1440 | Val Loss: 4967.8810 | Optimizer: Adam\n",
      "Trial 62 | Epoch 49 | Train Loss: 4771.8450 | Val Loss: 5343.9041 | Optimizer: Adam\n",
      "Trial 62 - Early stopping triggered at epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:33:58,104] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 | Epoch 01 | Train Loss: 20335.0025 | Val Loss: 19661.0440 | Optimizer: Adam\n",
      "Trial 64 | Epoch 01 | Train Loss: 20584.8238 | Val Loss: 17242.1103 | Optimizer: Adam\n",
      "Trial 64 | Epoch 02 | Train Loss: 12226.5986 | Val Loss: 10807.1144 | Optimizer: Adam\n",
      "Trial 64 | Epoch 03 | Train Loss: 9752.9625 | Val Loss: 8039.6502 | Optimizer: Adam\n",
      "Trial 64 | Epoch 04 | Train Loss: 7930.0999 | Val Loss: 7122.6832 | Optimizer: Adam\n",
      "Trial 64 | Epoch 05 | Train Loss: 6989.9430 | Val Loss: 6066.7832 | Optimizer: Adam\n",
      "Trial 64 | Epoch 06 | Train Loss: 6969.7079 | Val Loss: 6375.4659 | Optimizer: Adam\n",
      "Trial 64 | Epoch 07 | Train Loss: 6865.2450 | Val Loss: 5963.2302 | Optimizer: Adam\n",
      "Trial 64 | Epoch 08 | Train Loss: 6969.3392 | Val Loss: 6224.3596 | Optimizer: Adam\n",
      "Trial 64 | Epoch 09 | Train Loss: 6662.6527 | Val Loss: 6259.2282 | Optimizer: Adam\n",
      "Trial 64 | Epoch 10 | Train Loss: 6607.9845 | Val Loss: 5390.0436 | Optimizer: Adam\n",
      "Trial 64 | Epoch 11 | Train Loss: 6092.9333 | Val Loss: 6079.2934 | Optimizer: Adam\n",
      "Trial 64 | Epoch 12 | Train Loss: 6298.3076 | Val Loss: 5757.2011 | Optimizer: Adam\n",
      "Trial 64 | Epoch 13 | Train Loss: 6224.3600 | Val Loss: 5634.5728 | Optimizer: Adam\n",
      "Trial 64 | Epoch 14 | Train Loss: 5694.2512 | Val Loss: 5239.5174 | Optimizer: Adam\n",
      "Trial 64 | Epoch 15 | Train Loss: 5991.7615 | Val Loss: 5185.6813 | Optimizer: Adam\n",
      "Trial 64 | Epoch 16 | Train Loss: 5742.3542 | Val Loss: 7703.8635 | Optimizer: Adam\n",
      "Trial 64 | Epoch 17 | Train Loss: 6462.5852 | Val Loss: 5594.5731 | Optimizer: Adam\n",
      "Trial 64 | Epoch 18 | Train Loss: 6407.5584 | Val Loss: 5404.4614 | Optimizer: Adam\n",
      "Trial 64 | Epoch 19 | Train Loss: 5724.4476 | Val Loss: 5268.7880 | Optimizer: Adam\n",
      "Trial 64 | Epoch 20 | Train Loss: 5964.6980 | Val Loss: 5318.5845 | Optimizer: Adam\n",
      "Trial 64 | Epoch 21 | Train Loss: 6380.8927 | Val Loss: 5357.4941 | Optimizer: Adam\n",
      "Trial 64 | Epoch 22 | Train Loss: 5653.1953 | Val Loss: 5766.3388 | Optimizer: Adam\n",
      "Trial 64 | Epoch 23 | Train Loss: 5426.7254 | Val Loss: 5489.7950 | Optimizer: Adam\n",
      "Trial 64 | Epoch 24 | Train Loss: 5458.3896 | Val Loss: 5154.6461 | Optimizer: Adam\n",
      "Trial 64 | Epoch 25 | Train Loss: 5255.5084 | Val Loss: 5804.3593 | Optimizer: Adam\n",
      "Trial 64 | Epoch 26 | Train Loss: 5426.8147 | Val Loss: 5923.4958 | Optimizer: Adam\n",
      "Trial 64 | Epoch 27 | Train Loss: 5376.3214 | Val Loss: 5310.1375 | Optimizer: Adam\n",
      "Trial 64 | Epoch 28 | Train Loss: 5278.7793 | Val Loss: 6092.5648 | Optimizer: Adam\n",
      "Trial 64 | Epoch 29 | Train Loss: 5324.9145 | Val Loss: 5106.1519 | Optimizer: Adam\n",
      "Trial 64 | Epoch 30 | Train Loss: 4913.4492 | Val Loss: 6038.9945 | Optimizer: Adam\n",
      "Trial 64 | Epoch 31 | Train Loss: 5254.8505 | Val Loss: 5373.7573 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:00,750] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 | Epoch 32 | Train Loss: 5456.0745 | Val Loss: 6082.5810 | Optimizer: Adam\n",
      "Trial 64 | Epoch 33 | Train Loss: 5211.8217 | Val Loss: 5400.1663 | Optimizer: Adam\n",
      "Trial 64 | Epoch 34 | Train Loss: 5174.6488 | Val Loss: 5145.5081 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:00,861] Trial 65 pruned. \n",
      "[I 2025-09-04 20:34:00,974] Trial 66 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 | Epoch 01 | Train Loss: 21993.1974 | Val Loss: 23768.8116 | Optimizer: AdamW\n",
      "Trial 66 | Epoch 01 | Train Loss: 20153.2969 | Val Loss: 20136.7978 | Optimizer: Adam\n",
      "Trial 67 | Epoch 01 | Train Loss: 18859.8984 | Val Loss: 15332.5807 | Optimizer: Adam\n",
      "Trial 67 | Epoch 02 | Train Loss: 12870.4333 | Val Loss: 10889.4115 | Optimizer: Adam\n",
      "Trial 67 | Epoch 03 | Train Loss: 10676.6172 | Val Loss: 10501.4185 | Optimizer: Adam\n",
      "Trial 67 | Epoch 04 | Train Loss: 10470.2676 | Val Loss: 9834.1070 | Optimizer: Adam\n",
      "Trial 67 | Epoch 05 | Train Loss: 9286.8065 | Val Loss: 8153.1170 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:01,323] Trial 67 pruned. \n",
      "[I 2025-09-04 20:34:01,437] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 | Epoch 06 | Train Loss: 8833.4582 | Val Loss: 8041.3544 | Optimizer: Adam\n",
      "Trial 68 | Epoch 01 | Train Loss: 20139.7218 | Val Loss: 19212.2431 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:01,553] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 | Epoch 01 | Train Loss: 19796.8392 | Val Loss: 19161.3156 | Optimizer: Adam\n",
      "Trial 70 | Epoch 01 | Train Loss: 478198.3479 | Val Loss: 10861.0138 | Optimizer: RMSprop\n",
      "Trial 70 | Epoch 02 | Train Loss: 21734.2374 | Val Loss: 16690.3976 | Optimizer: RMSprop\n",
      "Trial 70 | Epoch 03 | Train Loss: 12474.5599 | Val Loss: 16627.0403 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:01,800] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 | Epoch 04 | Train Loss: 12256.2589 | Val Loss: 10043.7501 | Optimizer: RMSprop\n",
      "Trial 71 | Epoch 01 | Train Loss: 18769.8907 | Val Loss: 15647.5909 | Optimizer: Adam\n",
      "Trial 71 | Epoch 02 | Train Loss: 11909.7994 | Val Loss: 10209.5628 | Optimizer: Adam\n",
      "Trial 71 | Epoch 03 | Train Loss: 10273.0890 | Val Loss: 10412.8935 | Optimizer: Adam\n",
      "Trial 71 | Epoch 04 | Train Loss: 9134.1209 | Val Loss: 7476.0273 | Optimizer: Adam\n",
      "Trial 71 | Epoch 05 | Train Loss: 7812.4762 | Val Loss: 7566.7983 | Optimizer: Adam\n",
      "Trial 71 | Epoch 06 | Train Loss: 7746.9618 | Val Loss: 5588.9434 | Optimizer: Adam\n",
      "Trial 71 | Epoch 07 | Train Loss: 7107.5083 | Val Loss: 5752.4888 | Optimizer: Adam\n",
      "Trial 71 | Epoch 08 | Train Loss: 6534.5494 | Val Loss: 5497.1784 | Optimizer: Adam\n",
      "Trial 71 | Epoch 09 | Train Loss: 6794.5440 | Val Loss: 5651.2733 | Optimizer: Adam\n",
      "Trial 71 | Epoch 10 | Train Loss: 6428.1620 | Val Loss: 6709.1950 | Optimizer: Adam\n",
      "Trial 71 | Epoch 11 | Train Loss: 6538.8408 | Val Loss: 5928.9512 | Optimizer: Adam\n",
      "Trial 71 | Epoch 12 | Train Loss: 7259.9977 | Val Loss: 5934.4974 | Optimizer: Adam\n",
      "Trial 71 | Epoch 13 | Train Loss: 6804.6275 | Val Loss: 6992.6639 | Optimizer: Adam\n",
      "Trial 71 | Epoch 14 | Train Loss: 7414.0972 | Val Loss: 5662.0297 | Optimizer: Adam\n",
      "Trial 71 | Epoch 15 | Train Loss: 6972.4808 | Val Loss: 6141.5303 | Optimizer: Adam\n",
      "Trial 71 | Epoch 16 | Train Loss: 6865.8528 | Val Loss: 5907.6690 | Optimizer: Adam\n",
      "Trial 71 | Epoch 17 | Train Loss: 6030.6083 | Val Loss: 5080.0344 | Optimizer: Adam\n",
      "Trial 71 | Epoch 18 | Train Loss: 5490.9755 | Val Loss: 5552.2531 | Optimizer: Adam\n",
      "Trial 71 | Epoch 19 | Train Loss: 6237.4743 | Val Loss: 5175.9675 | Optimizer: Adam\n",
      "Trial 71 | Epoch 20 | Train Loss: 5981.7259 | Val Loss: 5375.5191 | Optimizer: Adam\n",
      "Trial 71 | Epoch 21 | Train Loss: 5999.4229 | Val Loss: 5532.8406 | Optimizer: Adam\n",
      "Trial 71 | Epoch 22 | Train Loss: 6459.8086 | Val Loss: 5103.0461 | Optimizer: Adam\n",
      "Trial 71 | Epoch 23 | Train Loss: 5358.0514 | Val Loss: 5317.2927 | Optimizer: Adam\n",
      "Trial 71 | Epoch 24 | Train Loss: 5580.1177 | Val Loss: 5216.3788 | Optimizer: Adam\n",
      "Trial 71 | Epoch 25 | Train Loss: 5183.0276 | Val Loss: 5052.6172 | Optimizer: Adam\n",
      "Trial 71 | Epoch 26 | Train Loss: 5282.0302 | Val Loss: 5146.5663 | Optimizer: Adam\n",
      "Trial 71 | Epoch 27 | Train Loss: 5132.6991 | Val Loss: 5041.9452 | Optimizer: Adam\n",
      "Trial 71 | Epoch 28 | Train Loss: 4780.0014 | Val Loss: 5695.2700 | Optimizer: Adam\n",
      "Trial 71 | Epoch 29 | Train Loss: 5217.4427 | Val Loss: 4960.2500 | Optimizer: Adam\n",
      "Trial 71 | Epoch 30 | Train Loss: 5203.2378 | Val Loss: 5310.4662 | Optimizer: Adam\n",
      "Trial 71 | Epoch 31 | Train Loss: 5681.1578 | Val Loss: 5966.8558 | Optimizer: Adam\n",
      "Trial 71 | Epoch 32 | Train Loss: 5714.8277 | Val Loss: 4993.3844 | Optimizer: Adam\n",
      "Trial 71 | Epoch 33 | Train Loss: 5248.9709 | Val Loss: 5347.5604 | Optimizer: Adam\n",
      "Trial 71 | Epoch 34 | Train Loss: 5047.0498 | Val Loss: 5034.9471 | Optimizer: Adam\n",
      "Trial 71 | Epoch 35 | Train Loss: 5084.2587 | Val Loss: 4979.9322 | Optimizer: Adam\n",
      "Trial 71 | Epoch 36 | Train Loss: 4872.4341 | Val Loss: 4983.7019 | Optimizer: Adam\n",
      "Trial 71 | Epoch 37 | Train Loss: 4584.8525 | Val Loss: 5723.3067 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:03,844] Trial 71 finished with value: 4960.249961324257 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.31715704376324966, 'lr': 0.0008706712048981074, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.3359729540229494e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 | Epoch 38 | Train Loss: 4978.6551 | Val Loss: 5200.0131 | Optimizer: Adam\n",
      "Trial 71 | Epoch 39 | Train Loss: 4814.3595 | Val Loss: 5049.1275 | Optimizer: Adam\n",
      "Trial 71 - Early stopping triggered at epoch 39\n",
      "Trial 72 | Epoch 01 | Train Loss: 19754.5337 | Val Loss: 17895.0212 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:03,960] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 | Epoch 01 | Train Loss: 19377.8118 | Val Loss: 15440.4259 | Optimizer: Adam\n",
      "Trial 73 | Epoch 02 | Train Loss: 11904.1112 | Val Loss: 10558.2620 | Optimizer: Adam\n",
      "Trial 73 | Epoch 03 | Train Loss: 9683.4736 | Val Loss: 8261.2716 | Optimizer: Adam\n",
      "Trial 73 | Epoch 04 | Train Loss: 8592.9378 | Val Loss: 8363.8865 | Optimizer: Adam\n",
      "Trial 73 | Epoch 05 | Train Loss: 8494.7492 | Val Loss: 5762.2560 | Optimizer: Adam\n",
      "Trial 73 | Epoch 06 | Train Loss: 7913.5617 | Val Loss: 5482.0208 | Optimizer: Adam\n",
      "Trial 73 | Epoch 07 | Train Loss: 7757.3563 | Val Loss: 6951.5354 | Optimizer: Adam\n",
      "Trial 73 | Epoch 08 | Train Loss: 7004.9698 | Val Loss: 5650.6302 | Optimizer: Adam\n",
      "Trial 73 | Epoch 09 | Train Loss: 6568.2258 | Val Loss: 5836.3823 | Optimizer: Adam\n",
      "Trial 73 | Epoch 10 | Train Loss: 6523.9587 | Val Loss: 5562.0508 | Optimizer: Adam\n",
      "Trial 73 | Epoch 11 | Train Loss: 6342.1616 | Val Loss: 5411.5063 | Optimizer: Adam\n",
      "Trial 73 | Epoch 12 | Train Loss: 5829.5273 | Val Loss: 5555.9623 | Optimizer: Adam\n",
      "Trial 73 | Epoch 13 | Train Loss: 5880.4299 | Val Loss: 5354.0841 | Optimizer: Adam\n",
      "Trial 73 | Epoch 14 | Train Loss: 6094.2950 | Val Loss: 7219.0014 | Optimizer: Adam\n",
      "Trial 73 | Epoch 15 | Train Loss: 6342.4373 | Val Loss: 5434.9906 | Optimizer: Adam\n",
      "Trial 73 | Epoch 16 | Train Loss: 6658.4576 | Val Loss: 5694.2494 | Optimizer: Adam\n",
      "Trial 73 | Epoch 17 | Train Loss: 5885.2907 | Val Loss: 5615.6994 | Optimizer: Adam\n",
      "Trial 73 | Epoch 18 | Train Loss: 6272.3094 | Val Loss: 5414.2009 | Optimizer: Adam\n",
      "Trial 73 | Epoch 19 | Train Loss: 5669.7835 | Val Loss: 5425.2515 | Optimizer: Adam\n",
      "Trial 73 | Epoch 20 | Train Loss: 5542.3201 | Val Loss: 5247.8368 | Optimizer: Adam\n",
      "Trial 73 | Epoch 21 | Train Loss: 5686.6482 | Val Loss: 5197.0076 | Optimizer: Adam\n",
      "Trial 73 | Epoch 22 | Train Loss: 6268.4007 | Val Loss: 7368.1087 | Optimizer: Adam\n",
      "Trial 73 | Epoch 23 | Train Loss: 5926.3065 | Val Loss: 5392.8375 | Optimizer: Adam\n",
      "Trial 73 | Epoch 24 | Train Loss: 5851.4859 | Val Loss: 6025.9226 | Optimizer: Adam\n",
      "Trial 73 | Epoch 25 | Train Loss: 5141.9134 | Val Loss: 5170.7933 | Optimizer: Adam\n",
      "Trial 73 | Epoch 26 | Train Loss: 5547.5756 | Val Loss: 5737.4970 | Optimizer: Adam\n",
      "Trial 73 | Epoch 27 | Train Loss: 5091.4397 | Val Loss: 4980.6222 | Optimizer: Adam\n",
      "Trial 73 | Epoch 28 | Train Loss: 4804.6869 | Val Loss: 5790.6755 | Optimizer: Adam\n",
      "Trial 73 | Epoch 29 | Train Loss: 4726.4942 | Val Loss: 5219.8856 | Optimizer: Adam\n",
      "Trial 73 | Epoch 30 | Train Loss: 4926.4130 | Val Loss: 6428.0391 | Optimizer: Adam\n",
      "Trial 73 | Epoch 31 | Train Loss: 5378.1824 | Val Loss: 4957.7594 | Optimizer: Adam\n",
      "Trial 73 | Epoch 32 | Train Loss: 4867.0885 | Val Loss: 5312.9412 | Optimizer: Adam\n",
      "Trial 73 | Epoch 33 | Train Loss: 4802.1504 | Val Loss: 5039.3457 | Optimizer: Adam\n",
      "Trial 73 | Epoch 34 | Train Loss: 4873.8606 | Val Loss: 4975.7397 | Optimizer: Adam\n",
      "Trial 73 | Epoch 35 | Train Loss: 4578.8899 | Val Loss: 4878.1329 | Optimizer: Adam\n",
      "Trial 73 | Epoch 36 | Train Loss: 4992.6862 | Val Loss: 4913.9854 | Optimizer: Adam\n",
      "Trial 73 | Epoch 37 | Train Loss: 4719.1862 | Val Loss: 5026.4684 | Optimizer: Adam\n",
      "Trial 73 | Epoch 38 | Train Loss: 4714.4751 | Val Loss: 6344.6167 | Optimizer: Adam\n",
      "Trial 73 | Epoch 39 | Train Loss: 5190.4248 | Val Loss: 5079.7628 | Optimizer: Adam\n",
      "Trial 73 | Epoch 40 | Train Loss: 4584.9259 | Val Loss: 5437.2676 | Optimizer: Adam\n",
      "Trial 73 | Epoch 41 | Train Loss: 5733.3138 | Val Loss: 7314.6606 | Optimizer: Adam\n",
      "Trial 73 | Epoch 42 | Train Loss: 6099.3155 | Val Loss: 5291.7043 | Optimizer: Adam\n",
      "Trial 73 | Epoch 43 | Train Loss: 5478.0467 | Val Loss: 6204.3163 | Optimizer: Adam\n",
      "Trial 73 | Epoch 44 | Train Loss: 5155.9898 | Val Loss: 5261.6251 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:06,298] Trial 73 finished with value: 4878.132914023824 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.32262958802268354, 'lr': 0.0009973686660026174, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.983788747378193e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 | Epoch 45 | Train Loss: 5612.9800 | Val Loss: 5795.7689 | Optimizer: Adam\n",
      "Trial 73 - Early stopping triggered at epoch 45\n",
      "Trial 74 | Epoch 01 | Train Loss: 18825.2930 | Val Loss: 13665.5217 | Optimizer: Adam\n",
      "Trial 74 | Epoch 02 | Train Loss: 13359.8931 | Val Loss: 11798.1899 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:06,462] Trial 74 pruned. \n",
      "[I 2025-09-04 20:34:06,577] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 | Epoch 01 | Train Loss: 20505.3456 | Val Loss: 18659.1512 | Optimizer: Adam\n",
      "Trial 76 | Epoch 01 | Train Loss: 19046.9738 | Val Loss: 11284.7515 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:06,808] Trial 76 pruned. \n",
      "[I 2025-09-04 20:34:06,914] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 | Epoch 02 | Train Loss: 14410.6287 | Val Loss: 15251.9897 | Optimizer: Adam\n",
      "Trial 77 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:07,035] Trial 78 pruned. \n",
      "[I 2025-09-04 20:34:07,153] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 | Epoch 01 | Train Loss: 20139.4768 | Val Loss: 20516.0166 | Optimizer: AdamW\n",
      "Trial 79 | Epoch 01 | Train Loss: 21932.7697 | Val Loss: 23913.5387 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:07,323] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 | Epoch 01 | Train Loss: 23323.1727 | Val Loss: 15997.2267 | Optimizer: RMSprop\n",
      "Trial 80 | Epoch 02 | Train Loss: 12179.4036 | Val Loss: 12243.3731 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 01 | Train Loss: 18077.4201 | Val Loss: 14438.1696 | Optimizer: Adam\n",
      "Trial 81 | Epoch 02 | Train Loss: 12727.1889 | Val Loss: 10603.6033 | Optimizer: Adam\n",
      "Trial 81 | Epoch 03 | Train Loss: 10710.4517 | Val Loss: 10828.7516 | Optimizer: Adam\n",
      "Trial 81 | Epoch 04 | Train Loss: 9863.3009 | Val Loss: 8067.7900 | Optimizer: Adam\n",
      "Trial 81 | Epoch 05 | Train Loss: 8964.7110 | Val Loss: 7081.0733 | Optimizer: Adam\n",
      "Trial 81 | Epoch 06 | Train Loss: 7892.2289 | Val Loss: 5638.3898 | Optimizer: Adam\n",
      "Trial 81 | Epoch 07 | Train Loss: 7158.1765 | Val Loss: 5427.8301 | Optimizer: Adam\n",
      "Trial 81 | Epoch 08 | Train Loss: 6741.8720 | Val Loss: 5740.4525 | Optimizer: Adam\n",
      "Trial 81 | Epoch 09 | Train Loss: 6940.9314 | Val Loss: 6334.8249 | Optimizer: Adam\n",
      "Trial 81 | Epoch 10 | Train Loss: 6788.3250 | Val Loss: 5520.6765 | Optimizer: Adam\n",
      "Trial 81 | Epoch 11 | Train Loss: 6115.1671 | Val Loss: 5264.2794 | Optimizer: Adam\n",
      "Trial 81 | Epoch 12 | Train Loss: 5946.9917 | Val Loss: 6363.5425 | Optimizer: Adam\n",
      "Trial 81 | Epoch 13 | Train Loss: 5500.8972 | Val Loss: 6026.2603 | Optimizer: Adam\n",
      "Trial 81 | Epoch 14 | Train Loss: 6736.1188 | Val Loss: 6734.9040 | Optimizer: Adam\n",
      "Trial 81 | Epoch 15 | Train Loss: 6644.9881 | Val Loss: 5793.1703 | Optimizer: Adam\n",
      "Trial 81 | Epoch 16 | Train Loss: 6302.4315 | Val Loss: 5100.6950 | Optimizer: Adam\n",
      "Trial 81 | Epoch 17 | Train Loss: 5530.0909 | Val Loss: 5466.9085 | Optimizer: Adam\n",
      "Trial 81 | Epoch 18 | Train Loss: 5609.2517 | Val Loss: 5015.3584 | Optimizer: Adam\n",
      "Trial 81 | Epoch 19 | Train Loss: 5845.3518 | Val Loss: 7399.1680 | Optimizer: Adam\n",
      "Trial 81 | Epoch 20 | Train Loss: 6670.9719 | Val Loss: 5054.7055 | Optimizer: Adam\n",
      "Trial 81 | Epoch 21 | Train Loss: 5365.9802 | Val Loss: 6732.8128 | Optimizer: Adam\n",
      "Trial 81 | Epoch 22 | Train Loss: 5901.1081 | Val Loss: 5367.0523 | Optimizer: Adam\n",
      "Trial 81 | Epoch 23 | Train Loss: 5378.3633 | Val Loss: 5890.9953 | Optimizer: Adam\n",
      "Trial 81 | Epoch 24 | Train Loss: 5680.5041 | Val Loss: 4973.1738 | Optimizer: Adam\n",
      "Trial 81 | Epoch 25 | Train Loss: 5339.4561 | Val Loss: 5132.8046 | Optimizer: Adam\n",
      "Trial 81 | Epoch 26 | Train Loss: 5089.7642 | Val Loss: 5096.8098 | Optimizer: Adam\n",
      "Trial 81 | Epoch 27 | Train Loss: 5525.2309 | Val Loss: 5086.5286 | Optimizer: Adam\n",
      "Trial 81 | Epoch 28 | Train Loss: 6385.5692 | Val Loss: 6859.1161 | Optimizer: Adam\n",
      "Trial 81 | Epoch 29 | Train Loss: 5839.2872 | Val Loss: 4953.5191 | Optimizer: Adam\n",
      "Trial 81 | Epoch 30 | Train Loss: 5122.2199 | Val Loss: 5405.9400 | Optimizer: Adam\n",
      "Trial 81 | Epoch 31 | Train Loss: 4884.4620 | Val Loss: 4761.2515 | Optimizer: Adam\n",
      "Trial 81 | Epoch 32 | Train Loss: 5017.5576 | Val Loss: 5133.6820 | Optimizer: Adam\n",
      "Trial 81 | Epoch 33 | Train Loss: 4579.5800 | Val Loss: 5054.9369 | Optimizer: Adam\n",
      "Trial 81 | Epoch 34 | Train Loss: 5447.5736 | Val Loss: 4788.1610 | Optimizer: Adam\n",
      "Trial 81 | Epoch 35 | Train Loss: 4660.6392 | Val Loss: 4787.2240 | Optimizer: Adam\n",
      "Trial 81 | Epoch 36 | Train Loss: 4490.4272 | Val Loss: 4943.6522 | Optimizer: Adam\n",
      "Trial 81 | Epoch 37 | Train Loss: 4662.5203 | Val Loss: 4948.5819 | Optimizer: Adam\n",
      "Trial 81 | Epoch 38 | Train Loss: 4670.9992 | Val Loss: 5024.7156 | Optimizer: Adam\n",
      "Trial 81 | Epoch 39 | Train Loss: 4957.5486 | Val Loss: 4938.2118 | Optimizer: Adam\n",
      "Trial 81 | Epoch 40 | Train Loss: 4603.6043 | Val Loss: 5456.9153 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:09,488] Trial 81 finished with value: 4761.25146484375 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.313588677320361, 'lr': 0.000837632821313768, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.424402379741612e-05}. Best is trial 42 with value: 4722.913093189201.\n",
      "[I 2025-09-04 20:34:09,606] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 | Epoch 41 | Train Loss: 4950.4491 | Val Loss: 4946.4649 | Optimizer: Adam\n",
      "Trial 81 - Early stopping triggered at epoch 41\n",
      "Trial 82 | Epoch 01 | Train Loss: 20380.0025 | Val Loss: 18726.3468 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:09,722] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 | Epoch 01 | Train Loss: 19394.3478 | Val Loss: 18237.9091 | Optimizer: Adam\n",
      "Trial 84 | Epoch 01 | Train Loss: 18702.6600 | Val Loss: 15671.5027 | Optimizer: Adam\n",
      "Trial 84 | Epoch 02 | Train Loss: 13045.5690 | Val Loss: 10617.9394 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:10,044] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 | Epoch 03 | Train Loss: 10832.6041 | Val Loss: 10864.0322 | Optimizer: Adam\n",
      "Trial 84 | Epoch 04 | Train Loss: 9813.6070 | Val Loss: 8164.8048 | Optimizer: Adam\n",
      "Trial 84 | Epoch 05 | Train Loss: 9697.8438 | Val Loss: 9112.2679 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:10,162] Trial 85 pruned. \n",
      "[I 2025-09-04 20:34:10,281] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 | Epoch 01 | Train Loss: 20612.7509 | Val Loss: 18533.5420 | Optimizer: Adam\n",
      "Trial 86 | Epoch 01 | Train Loss: 20259.4412 | Val Loss: 19941.9455 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:10,396] Trial 87 pruned. \n",
      "[I 2025-09-04 20:34:10,518] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 | Epoch 01 | Train Loss: 19891.0477 | Val Loss: 19914.1908 | Optimizer: Adam\n",
      "Trial 88 | Epoch 01 | Train Loss: 20950.5002 | Val Loss: 22486.1619 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:10,681] Trial 89 pruned. \n",
      "[I 2025-09-04 20:34:10,796] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 | Epoch 01 | Train Loss: 21382.8814 | Val Loss: 22543.9992 | Optimizer: Adam\n",
      "Trial 90 | Epoch 01 | Train Loss: 18596.1395 | Val Loss: 16345.3691 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:10,919] Trial 91 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 | Epoch 01 | Train Loss: 19704.7488 | Val Loss: 17381.9444 | Optimizer: Adam\n",
      "Trial 92 | Epoch 01 | Train Loss: 19536.4770 | Val Loss: 15926.5099 | Optimizer: Adam\n",
      "Trial 92 | Epoch 02 | Train Loss: 12154.0031 | Val Loss: 10558.7710 | Optimizer: Adam\n",
      "Trial 92 | Epoch 03 | Train Loss: 10284.2173 | Val Loss: 9877.1671 | Optimizer: Adam\n",
      "Trial 92 | Epoch 04 | Train Loss: 9135.6520 | Val Loss: 7507.0662 | Optimizer: Adam\n",
      "Trial 92 | Epoch 05 | Train Loss: 7802.9799 | Val Loss: 6099.8865 | Optimizer: Adam\n",
      "Trial 92 | Epoch 06 | Train Loss: 7772.4444 | Val Loss: 6616.4162 | Optimizer: Adam\n",
      "Trial 92 | Epoch 07 | Train Loss: 7466.8183 | Val Loss: 6054.5609 | Optimizer: Adam\n",
      "Trial 92 | Epoch 08 | Train Loss: 7060.5214 | Val Loss: 5774.0953 | Optimizer: Adam\n",
      "Trial 92 | Epoch 09 | Train Loss: 6541.0081 | Val Loss: 6221.9192 | Optimizer: Adam\n",
      "Trial 92 | Epoch 10 | Train Loss: 6905.0358 | Val Loss: 5614.8660 | Optimizer: Adam\n",
      "Trial 92 | Epoch 11 | Train Loss: 6871.2449 | Val Loss: 5740.3328 | Optimizer: Adam\n",
      "Trial 92 | Epoch 12 | Train Loss: 6413.1729 | Val Loss: 5785.2695 | Optimizer: Adam\n",
      "Trial 92 | Epoch 13 | Train Loss: 6337.4262 | Val Loss: 5591.8560 | Optimizer: Adam\n",
      "Trial 92 | Epoch 14 | Train Loss: 6965.6640 | Val Loss: 8529.0582 | Optimizer: Adam\n",
      "Trial 92 | Epoch 15 | Train Loss: 7452.2285 | Val Loss: 5289.4799 | Optimizer: Adam\n",
      "Trial 92 | Epoch 16 | Train Loss: 6644.9186 | Val Loss: 6864.5041 | Optimizer: Adam\n",
      "Trial 92 | Epoch 17 | Train Loss: 6639.8466 | Val Loss: 5209.8626 | Optimizer: Adam\n",
      "Trial 92 | Epoch 18 | Train Loss: 6035.8995 | Val Loss: 5916.6042 | Optimizer: Adam\n",
      "Trial 92 | Epoch 19 | Train Loss: 6026.2855 | Val Loss: 5253.8078 | Optimizer: Adam\n",
      "Trial 92 | Epoch 20 | Train Loss: 5760.4084 | Val Loss: 5375.5772 | Optimizer: Adam\n",
      "Trial 92 | Epoch 21 | Train Loss: 5592.1486 | Val Loss: 5231.7841 | Optimizer: Adam\n",
      "Trial 92 | Epoch 22 | Train Loss: 5535.5009 | Val Loss: 5131.1931 | Optimizer: Adam\n",
      "Trial 92 | Epoch 23 | Train Loss: 5333.7878 | Val Loss: 5142.6372 | Optimizer: Adam\n",
      "Trial 92 | Epoch 24 | Train Loss: 5514.7334 | Val Loss: 5128.3281 | Optimizer: Adam\n",
      "Trial 92 | Epoch 25 | Train Loss: 5202.3779 | Val Loss: 5566.0206 | Optimizer: Adam\n",
      "Trial 92 | Epoch 26 | Train Loss: 5545.4388 | Val Loss: 5235.3954 | Optimizer: Adam\n",
      "Trial 92 | Epoch 27 | Train Loss: 6182.3392 | Val Loss: 7242.6653 | Optimizer: Adam\n",
      "Trial 92 | Epoch 28 | Train Loss: 5511.3965 | Val Loss: 5392.4052 | Optimizer: Adam\n",
      "Trial 92 | Epoch 29 | Train Loss: 5556.4223 | Val Loss: 6333.4755 | Optimizer: Adam\n",
      "Trial 92 | Epoch 30 | Train Loss: 5440.8404 | Val Loss: 5211.1062 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:12,745] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 | Epoch 31 | Train Loss: 5560.2442 | Val Loss: 6102.8879 | Optimizer: Adam\n",
      "Trial 92 | Epoch 32 | Train Loss: 5728.4526 | Val Loss: 5117.8193 | Optimizer: Adam\n",
      "Trial 92 | Epoch 33 | Train Loss: 5452.2920 | Val Loss: 5446.4337 | Optimizer: Adam\n",
      "Trial 92 | Epoch 34 | Train Loss: 5023.2962 | Val Loss: 5069.0758 | Optimizer: Adam\n",
      "Trial 93 | Epoch 01 | Train Loss: 19308.7562 | Val Loss: 15842.4214 | Optimizer: Adam\n",
      "Trial 93 | Epoch 02 | Train Loss: 11412.0431 | Val Loss: 10447.1157 | Optimizer: Adam\n",
      "Trial 93 | Epoch 03 | Train Loss: 10037.2560 | Val Loss: 9357.8299 | Optimizer: Adam\n",
      "Trial 93 | Epoch 04 | Train Loss: 8548.9460 | Val Loss: 6991.6138 | Optimizer: Adam\n",
      "Trial 93 | Epoch 05 | Train Loss: 8452.9742 | Val Loss: 5696.2383 | Optimizer: Adam\n",
      "Trial 93 | Epoch 06 | Train Loss: 7616.2415 | Val Loss: 6901.3151 | Optimizer: Adam\n",
      "Trial 93 | Epoch 07 | Train Loss: 6976.9598 | Val Loss: 5411.4240 | Optimizer: Adam\n",
      "Trial 93 | Epoch 08 | Train Loss: 6506.8212 | Val Loss: 6096.9366 | Optimizer: Adam\n",
      "Trial 93 | Epoch 09 | Train Loss: 6432.6445 | Val Loss: 5460.2335 | Optimizer: Adam\n",
      "Trial 93 | Epoch 10 | Train Loss: 6219.5002 | Val Loss: 6063.8503 | Optimizer: Adam\n",
      "Trial 93 | Epoch 11 | Train Loss: 6347.2545 | Val Loss: 5700.8506 | Optimizer: Adam\n",
      "Trial 93 | Epoch 12 | Train Loss: 6469.3563 | Val Loss: 5695.5541 | Optimizer: Adam\n",
      "Trial 93 | Epoch 13 | Train Loss: 6607.5468 | Val Loss: 6143.4200 | Optimizer: Adam\n",
      "Trial 93 | Epoch 14 | Train Loss: 6974.7894 | Val Loss: 7032.3258 | Optimizer: Adam\n",
      "Trial 93 | Epoch 15 | Train Loss: 6181.7007 | Val Loss: 5433.2071 | Optimizer: Adam\n",
      "Trial 93 | Epoch 16 | Train Loss: 5652.8331 | Val Loss: 6098.8784 | Optimizer: Adam\n",
      "Trial 93 | Epoch 17 | Train Loss: 6216.7373 | Val Loss: 5128.9004 | Optimizer: Adam\n",
      "Trial 93 | Epoch 18 | Train Loss: 5574.9175 | Val Loss: 5991.5916 | Optimizer: Adam\n",
      "Trial 93 | Epoch 19 | Train Loss: 5473.7063 | Val Loss: 5274.4107 | Optimizer: Adam\n",
      "Trial 93 | Epoch 20 | Train Loss: 5312.2181 | Val Loss: 5110.0204 | Optimizer: Adam\n",
      "Trial 93 | Epoch 21 | Train Loss: 5324.7613 | Val Loss: 5851.6955 | Optimizer: Adam\n",
      "Trial 93 | Epoch 22 | Train Loss: 5712.7316 | Val Loss: 5121.0814 | Optimizer: Adam\n",
      "Trial 93 | Epoch 23 | Train Loss: 5334.6752 | Val Loss: 5542.7256 | Optimizer: Adam\n",
      "Trial 93 | Epoch 24 | Train Loss: 5146.8641 | Val Loss: 5378.7763 | Optimizer: Adam\n",
      "Trial 93 | Epoch 25 | Train Loss: 5221.4736 | Val Loss: 5115.1138 | Optimizer: Adam\n",
      "Trial 93 | Epoch 26 | Train Loss: 4917.6947 | Val Loss: 5383.6168 | Optimizer: Adam\n",
      "Trial 93 | Epoch 27 | Train Loss: 5037.2323 | Val Loss: 5479.6200 | Optimizer: Adam\n",
      "Trial 93 | Epoch 28 | Train Loss: 5258.3850 | Val Loss: 5175.8881 | Optimizer: Adam\n",
      "Trial 93 | Epoch 29 | Train Loss: 5163.2079 | Val Loss: 5177.6808 | Optimizer: Adam\n",
      "Trial 93 | Epoch 30 | Train Loss: 5067.2184 | Val Loss: 5202.1213 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:14,349] Trial 93 finished with value: 5110.020430461015 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.31396994742758205, 'lr': 0.000890664867745442, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.1594511429733937e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 - Early stopping triggered at epoch 30\n",
      "Trial 94 | Epoch 01 | Train Loss: 18897.1850 | Val Loss: 14295.1721 | Optimizer: Adam\n",
      "Trial 94 | Epoch 02 | Train Loss: 11584.5025 | Val Loss: 10672.6093 | Optimizer: Adam\n",
      "Trial 94 | Epoch 03 | Train Loss: 10622.6790 | Val Loss: 9827.1141 | Optimizer: Adam\n",
      "Trial 94 | Epoch 04 | Train Loss: 8631.8243 | Val Loss: 6619.4291 | Optimizer: Adam\n",
      "Trial 94 | Epoch 05 | Train Loss: 7769.2751 | Val Loss: 5522.4048 | Optimizer: Adam\n",
      "Trial 94 | Epoch 06 | Train Loss: 8241.7804 | Val Loss: 8287.7625 | Optimizer: Adam\n",
      "Trial 94 | Epoch 07 | Train Loss: 7874.4423 | Val Loss: 6092.3476 | Optimizer: Adam\n",
      "Trial 94 | Epoch 08 | Train Loss: 7882.8292 | Val Loss: 7013.3535 | Optimizer: Adam\n",
      "Trial 94 | Epoch 09 | Train Loss: 7318.0685 | Val Loss: 5530.4196 | Optimizer: Adam\n",
      "Trial 94 | Epoch 10 | Train Loss: 6505.7655 | Val Loss: 6161.0082 | Optimizer: Adam\n",
      "Trial 94 | Epoch 11 | Train Loss: 6272.5421 | Val Loss: 5434.2955 | Optimizer: Adam\n",
      "Trial 94 | Epoch 12 | Train Loss: 6474.0335 | Val Loss: 5601.2885 | Optimizer: Adam\n",
      "Trial 94 | Epoch 13 | Train Loss: 5861.7110 | Val Loss: 5422.2738 | Optimizer: Adam\n",
      "Trial 94 | Epoch 14 | Train Loss: 6194.2374 | Val Loss: 5359.3683 | Optimizer: Adam\n",
      "Trial 94 | Epoch 15 | Train Loss: 5944.7692 | Val Loss: 7677.3680 | Optimizer: Adam\n",
      "Trial 94 | Epoch 16 | Train Loss: 6447.8379 | Val Loss: 5531.5119 | Optimizer: Adam\n",
      "Trial 94 | Epoch 17 | Train Loss: 6001.6063 | Val Loss: 6269.8801 | Optimizer: Adam\n",
      "Trial 94 | Epoch 18 | Train Loss: 5511.1656 | Val Loss: 5537.8233 | Optimizer: Adam\n",
      "Trial 94 | Epoch 19 | Train Loss: 5788.8905 | Val Loss: 6556.2431 | Optimizer: Adam\n",
      "Trial 94 | Epoch 20 | Train Loss: 5614.8353 | Val Loss: 5176.3825 | Optimizer: Adam\n",
      "Trial 94 | Epoch 21 | Train Loss: 5755.3596 | Val Loss: 5111.0121 | Optimizer: Adam\n",
      "Trial 94 | Epoch 22 | Train Loss: 5188.4635 | Val Loss: 5775.3338 | Optimizer: Adam\n",
      "Trial 94 | Epoch 23 | Train Loss: 5816.3072 | Val Loss: 5126.2005 | Optimizer: Adam\n",
      "Trial 94 | Epoch 24 | Train Loss: 5399.6347 | Val Loss: 5841.9984 | Optimizer: Adam\n",
      "Trial 94 | Epoch 25 | Train Loss: 5476.4340 | Val Loss: 5655.4283 | Optimizer: Adam\n",
      "Trial 94 | Epoch 26 | Train Loss: 5715.6970 | Val Loss: 5031.1635 | Optimizer: Adam\n",
      "Trial 94 | Epoch 27 | Train Loss: 5043.8721 | Val Loss: 5462.4792 | Optimizer: Adam\n",
      "Trial 94 | Epoch 28 | Train Loss: 5218.0026 | Val Loss: 5149.5050 | Optimizer: Adam\n",
      "Trial 94 | Epoch 29 | Train Loss: 5076.3428 | Val Loss: 5004.9608 | Optimizer: Adam\n",
      "Trial 94 | Epoch 30 | Train Loss: 4934.4164 | Val Loss: 5196.8868 | Optimizer: Adam\n",
      "Trial 94 | Epoch 31 | Train Loss: 5425.7518 | Val Loss: 5187.1765 | Optimizer: Adam\n",
      "Trial 94 | Epoch 32 | Train Loss: 4903.9764 | Val Loss: 5010.6634 | Optimizer: Adam\n",
      "Trial 94 | Epoch 33 | Train Loss: 4919.6896 | Val Loss: 5540.4271 | Optimizer: Adam\n",
      "Trial 94 | Epoch 34 | Train Loss: 5142.2589 | Val Loss: 4977.9706 | Optimizer: Adam\n",
      "Trial 94 | Epoch 35 | Train Loss: 4973.0488 | Val Loss: 5017.3371 | Optimizer: Adam\n",
      "Trial 94 | Epoch 36 | Train Loss: 4837.9682 | Val Loss: 5251.8408 | Optimizer: Adam\n",
      "Trial 94 | Epoch 37 | Train Loss: 4681.6400 | Val Loss: 5196.7046 | Optimizer: Adam\n",
      "Trial 94 | Epoch 38 | Train Loss: 5199.9824 | Val Loss: 5002.1609 | Optimizer: Adam\n",
      "Trial 94 | Epoch 39 | Train Loss: 4860.6632 | Val Loss: 4933.8691 | Optimizer: Adam\n",
      "Trial 94 | Epoch 40 | Train Loss: 4678.7813 | Val Loss: 5604.8912 | Optimizer: Adam\n",
      "Trial 94 | Epoch 41 | Train Loss: 5559.0756 | Val Loss: 6577.3901 | Optimizer: Adam\n",
      "Trial 94 | Epoch 42 | Train Loss: 6149.5539 | Val Loss: 4936.5268 | Optimizer: Adam\n",
      "Trial 94 | Epoch 43 | Train Loss: 5263.1068 | Val Loss: 5648.4031 | Optimizer: Adam\n",
      "Trial 94 | Epoch 44 | Train Loss: 4530.9297 | Val Loss: 5025.6980 | Optimizer: Adam\n",
      "Trial 94 | Epoch 45 | Train Loss: 4612.3716 | Val Loss: 5374.1050 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:16,931] Trial 94 finished with value: 4933.869116452661 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.33630838415593794, 'lr': 0.0009985704108281081, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 4.409764110043784e-06}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 | Epoch 46 | Train Loss: 4246.9332 | Val Loss: 5071.9034 | Optimizer: Adam\n",
      "Trial 94 | Epoch 47 | Train Loss: 4422.1098 | Val Loss: 5115.1937 | Optimizer: Adam\n",
      "Trial 94 | Epoch 48 | Train Loss: 4288.4776 | Val Loss: 5168.2380 | Optimizer: Adam\n",
      "Trial 94 | Epoch 49 | Train Loss: 4734.8627 | Val Loss: 5340.7177 | Optimizer: Adam\n",
      "Trial 94 - Early stopping triggered at epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:17,053] Trial 95 pruned. \n",
      "[I 2025-09-04 20:34:17,160] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 | Epoch 01 | Train Loss: 19725.5445 | Val Loss: 18148.1603 | Optimizer: Adam\n",
      "Trial 96 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 97 | Epoch 01 | Train Loss: 20418.8696 | Val Loss: 20398.6769 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:17,279] Trial 97 pruned. \n",
      "[I 2025-09-04 20:34:17,397] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 | Epoch 01 | Train Loss: 19905.1203 | Val Loss: 17591.7947 | Optimizer: AdamW\n",
      "Trial 99 | Epoch 01 | Train Loss: 194689.9473 | Val Loss: 14469.8312 | Optimizer: RMSprop\n",
      "Trial 99 | Epoch 02 | Train Loss: 11121.3762 | Val Loss: 10289.3812 | Optimizer: RMSprop\n",
      "Trial 99 | Epoch 03 | Train Loss: 10307.5067 | Val Loss: 10270.7283 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:17,648] Trial 99 pruned. \n",
      "[I 2025-09-04 20:34:17,771] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 | Epoch 04 | Train Loss: 10445.8673 | Val Loss: 11615.9596 | Optimizer: RMSprop\n",
      "Trial 100 | Epoch 01 | Train Loss: 21519.7626 | Val Loss: 22996.3619 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:18,032] Trial 101 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 | Epoch 01 | Train Loss: 18502.6418 | Val Loss: 14434.1215 | Optimizer: Adam\n",
      "Trial 101 | Epoch 02 | Train Loss: 12080.9472 | Val Loss: 10858.3752 | Optimizer: Adam\n",
      "Trial 101 | Epoch 03 | Train Loss: 11301.0745 | Val Loss: 11127.5006 | Optimizer: Adam\n",
      "Trial 101 | Epoch 04 | Train Loss: 10792.6038 | Val Loss: 10009.5952 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:18,290] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 | Epoch 01 | Train Loss: 17153.3094 | Val Loss: 12643.8374 | Optimizer: Adam\n",
      "Trial 102 | Epoch 02 | Train Loss: 11572.3852 | Val Loss: 10765.5680 | Optimizer: Adam\n",
      "Trial 102 | Epoch 03 | Train Loss: 11594.7506 | Val Loss: 11686.8177 | Optimizer: Adam\n",
      "Trial 102 | Epoch 04 | Train Loss: 11437.7897 | Val Loss: 10650.0725 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:18,455] Trial 103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 | Epoch 01 | Train Loss: 18977.8030 | Val Loss: 15144.7731 | Optimizer: Adam\n",
      "Trial 103 | Epoch 02 | Train Loss: 12338.8785 | Val Loss: 11415.0850 | Optimizer: Adam\n",
      "Trial 104 | Epoch 01 | Train Loss: 17421.1712 | Val Loss: 14224.9869 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:18,619] Trial 104 pruned. \n",
      "[I 2025-09-04 20:34:18,737] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 | Epoch 02 | Train Loss: 12575.9866 | Val Loss: 11279.1510 | Optimizer: Adam\n",
      "Trial 105 | Epoch 01 | Train Loss: 21628.7091 | Val Loss: 22500.3480 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:18,860] Trial 106 pruned. \n",
      "[I 2025-09-04 20:34:18,976] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 | Epoch 01 | Train Loss: 18953.8821 | Val Loss: 16792.2871 | Optimizer: Adam\n",
      "Trial 107 | Epoch 01 | Train Loss: 18731.7069 | Val Loss: 16050.7793 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:19,103] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 | Epoch 01 | Train Loss: 20151.0769 | Val Loss: 19030.2675 | Optimizer: Adam\n",
      "Trial 109 | Epoch 01 | Train Loss: 21397.9097 | Val Loss: 22843.6308 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:19,273] Trial 109 pruned. \n",
      "[I 2025-09-04 20:34:19,386] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 | Epoch 01 | Train Loss: 20670.1437 | Val Loss: 21327.4598 | Optimizer: Adam\n",
      "Trial 111 | Epoch 01 | Train Loss: 18355.9863 | Val Loss: 13236.3512 | Optimizer: Adam\n",
      "Trial 111 | Epoch 02 | Train Loss: 11047.6538 | Val Loss: 10049.5706 | Optimizer: Adam\n",
      "Trial 111 | Epoch 03 | Train Loss: 9643.4002 | Val Loss: 7991.6600 | Optimizer: Adam\n",
      "Trial 111 | Epoch 04 | Train Loss: 8453.5641 | Val Loss: 7655.7415 | Optimizer: Adam\n",
      "Trial 111 | Epoch 05 | Train Loss: 7512.2721 | Val Loss: 5683.1928 | Optimizer: Adam\n",
      "Trial 111 | Epoch 06 | Train Loss: 6971.1065 | Val Loss: 5560.7506 | Optimizer: Adam\n",
      "Trial 111 | Epoch 07 | Train Loss: 6513.9706 | Val Loss: 6224.6095 | Optimizer: Adam\n",
      "Trial 111 | Epoch 08 | Train Loss: 6552.4307 | Val Loss: 5501.1139 | Optimizer: Adam\n",
      "Trial 111 | Epoch 09 | Train Loss: 7046.8402 | Val Loss: 5391.5474 | Optimizer: Adam\n",
      "Trial 111 | Epoch 10 | Train Loss: 6332.4192 | Val Loss: 5818.4825 | Optimizer: Adam\n",
      "Trial 111 | Epoch 11 | Train Loss: 6377.3805 | Val Loss: 5461.2775 | Optimizer: Adam\n",
      "Trial 111 | Epoch 12 | Train Loss: 5715.7416 | Val Loss: 5209.7949 | Optimizer: Adam\n",
      "Trial 111 | Epoch 13 | Train Loss: 6204.2014 | Val Loss: 6814.1404 | Optimizer: Adam\n",
      "Trial 111 | Epoch 14 | Train Loss: 6754.8933 | Val Loss: 6596.9586 | Optimizer: Adam\n",
      "Trial 111 | Epoch 15 | Train Loss: 5824.6508 | Val Loss: 5719.5921 | Optimizer: Adam\n",
      "Trial 111 | Epoch 16 | Train Loss: 6136.6642 | Val Loss: 7086.7280 | Optimizer: Adam\n",
      "Trial 111 | Epoch 17 | Train Loss: 5919.2917 | Val Loss: 5253.2357 | Optimizer: Adam\n",
      "Trial 111 | Epoch 18 | Train Loss: 6064.4845 | Val Loss: 5851.4423 | Optimizer: Adam\n",
      "Trial 111 | Epoch 19 | Train Loss: 5943.7001 | Val Loss: 5396.8945 | Optimizer: Adam\n",
      "Trial 111 | Epoch 20 | Train Loss: 5614.4182 | Val Loss: 5024.2141 | Optimizer: Adam\n",
      "Trial 111 | Epoch 21 | Train Loss: 5283.7542 | Val Loss: 5311.4218 | Optimizer: Adam\n",
      "Trial 111 | Epoch 22 | Train Loss: 5472.8619 | Val Loss: 5001.6378 | Optimizer: Adam\n",
      "Trial 111 | Epoch 23 | Train Loss: 5175.9939 | Val Loss: 5188.6368 | Optimizer: Adam\n",
      "Trial 111 | Epoch 24 | Train Loss: 5255.9124 | Val Loss: 4956.6658 | Optimizer: Adam\n",
      "Trial 111 | Epoch 25 | Train Loss: 5396.6688 | Val Loss: 7058.2643 | Optimizer: Adam\n",
      "Trial 111 | Epoch 26 | Train Loss: 5402.0091 | Val Loss: 5249.6591 | Optimizer: Adam\n",
      "Trial 111 | Epoch 27 | Train Loss: 5517.5757 | Val Loss: 5617.2565 | Optimizer: Adam\n",
      "Trial 111 | Epoch 28 | Train Loss: 5147.0841 | Val Loss: 5024.9110 | Optimizer: Adam\n",
      "Trial 111 | Epoch 29 | Train Loss: 4591.9335 | Val Loss: 5152.9684 | Optimizer: Adam\n",
      "Trial 111 | Epoch 30 | Train Loss: 4963.5287 | Val Loss: 4953.0598 | Optimizer: Adam\n",
      "Trial 111 | Epoch 31 | Train Loss: 4808.1377 | Val Loss: 5484.8855 | Optimizer: Adam\n",
      "Trial 111 | Epoch 32 | Train Loss: 6037.5312 | Val Loss: 8501.8330 | Optimizer: Adam\n",
      "Trial 111 | Epoch 33 | Train Loss: 5979.2472 | Val Loss: 4945.0652 | Optimizer: Adam\n",
      "Trial 111 | Epoch 34 | Train Loss: 5187.2689 | Val Loss: 5356.1947 | Optimizer: Adam\n",
      "Trial 111 | Epoch 35 | Train Loss: 4871.5604 | Val Loss: 5038.5913 | Optimizer: Adam\n",
      "Trial 111 | Epoch 36 | Train Loss: 4874.7425 | Val Loss: 5094.3899 | Optimizer: Adam\n",
      "Trial 111 | Epoch 37 | Train Loss: 4758.7913 | Val Loss: 5253.4772 | Optimizer: Adam\n",
      "Trial 111 | Epoch 38 | Train Loss: 4539.1115 | Val Loss: 5099.4851 | Optimizer: Adam\n",
      "Trial 111 | Epoch 39 | Train Loss: 5109.0262 | Val Loss: 5899.5529 | Optimizer: Adam\n",
      "Trial 111 | Epoch 40 | Train Loss: 4791.8419 | Val Loss: 5122.4340 | Optimizer: Adam\n",
      "Trial 111 | Epoch 41 | Train Loss: 4718.9227 | Val Loss: 4918.0449 | Optimizer: Adam\n",
      "Trial 111 | Epoch 42 | Train Loss: 4084.6637 | Val Loss: 5377.8782 | Optimizer: Adam\n",
      "Trial 111 | Epoch 43 | Train Loss: 4497.6594 | Val Loss: 5433.9928 | Optimizer: Adam\n",
      "Trial 111 | Epoch 44 | Train Loss: 5077.6149 | Val Loss: 6838.6755 | Optimizer: Adam\n",
      "Trial 111 | Epoch 45 | Train Loss: 5138.7434 | Val Loss: 4974.8974 | Optimizer: Adam\n",
      "Trial 111 | Epoch 46 | Train Loss: 4604.4780 | Val Loss: 4973.2452 | Optimizer: Adam\n",
      "Trial 111 | Epoch 47 | Train Loss: 4489.4423 | Val Loss: 6246.9701 | Optimizer: Adam\n",
      "Trial 111 | Epoch 48 | Train Loss: 4780.8102 | Val Loss: 5282.2450 | Optimizer: Adam\n",
      "Trial 111 | Epoch 49 | Train Loss: 5132.9901 | Val Loss: 5795.6870 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:22,242] Trial 111 finished with value: 4918.04487836479 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.33586981232966556, 'lr': 0.0009888537178650305, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 5.165940823636908e-06}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 | Epoch 50 | Train Loss: 4570.1738 | Val Loss: 5410.1919 | Optimizer: Adam\n",
      "Trial 111 | Epoch 51 | Train Loss: 4689.5566 | Val Loss: 5150.5953 | Optimizer: Adam\n",
      "Trial 111 - Early stopping triggered at epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:22,578] Trial 112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 | Epoch 01 | Train Loss: 18542.2036 | Val Loss: 14188.7159 | Optimizer: Adam\n",
      "Trial 112 | Epoch 02 | Train Loss: 12994.5199 | Val Loss: 11840.6853 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:22,967] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 | Epoch 01 | Train Loss: 19092.3835 | Val Loss: 14675.5930 | Optimizer: Adam\n",
      "Trial 113 | Epoch 02 | Train Loss: 12054.2850 | Val Loss: 11061.7947 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:23,391] Trial 114 pruned. \n",
      "[I 2025-09-04 20:34:23,508] Trial 115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 | Epoch 01 | Train Loss: 19046.2341 | Val Loss: 16042.5906 | Optimizer: Adam\n",
      "Trial 115 | Epoch 01 | Train Loss: 20507.2240 | Val Loss: 19516.6465 | Optimizer: Adam\n",
      "Trial 116 | Epoch 01 | Train Loss: 18974.4825 | Val Loss: 15667.3882 | Optimizer: Adam\n",
      "Trial 116 | Epoch 02 | Train Loss: 12345.3856 | Val Loss: 10615.7158 | Optimizer: Adam\n",
      "Trial 116 | Epoch 03 | Train Loss: 10413.0529 | Val Loss: 10210.3126 | Optimizer: Adam\n",
      "Trial 116 | Epoch 04 | Train Loss: 9698.8368 | Val Loss: 7674.3976 | Optimizer: Adam\n",
      "Trial 116 | Epoch 05 | Train Loss: 7786.3564 | Val Loss: 6586.0815 | Optimizer: Adam\n",
      "Trial 116 | Epoch 06 | Train Loss: 7634.0725 | Val Loss: 5750.0921 | Optimizer: Adam\n",
      "Trial 116 | Epoch 07 | Train Loss: 6922.0131 | Val Loss: 5955.3166 | Optimizer: Adam\n",
      "Trial 116 | Epoch 08 | Train Loss: 7001.4697 | Val Loss: 6680.8410 | Optimizer: Adam\n",
      "Trial 116 | Epoch 09 | Train Loss: 6630.7218 | Val Loss: 5591.7758 | Optimizer: Adam\n",
      "Trial 116 | Epoch 10 | Train Loss: 6572.5858 | Val Loss: 6172.5922 | Optimizer: Adam\n",
      "Trial 116 | Epoch 11 | Train Loss: 6363.5811 | Val Loss: 5921.6961 | Optimizer: Adam\n",
      "Trial 116 | Epoch 12 | Train Loss: 6955.3329 | Val Loss: 5427.6909 | Optimizer: Adam\n",
      "Trial 116 | Epoch 13 | Train Loss: 6263.5317 | Val Loss: 5815.4205 | Optimizer: Adam\n",
      "Trial 116 | Epoch 14 | Train Loss: 5959.9559 | Val Loss: 5195.4301 | Optimizer: Adam\n",
      "Trial 116 | Epoch 15 | Train Loss: 5507.1226 | Val Loss: 5763.8719 | Optimizer: Adam\n",
      "Trial 116 | Epoch 16 | Train Loss: 5800.6105 | Val Loss: 5109.8174 | Optimizer: Adam\n",
      "Trial 116 | Epoch 17 | Train Loss: 5410.6694 | Val Loss: 5803.1847 | Optimizer: Adam\n",
      "Trial 116 | Epoch 18 | Train Loss: 5643.3764 | Val Loss: 5201.8883 | Optimizer: Adam\n",
      "Trial 116 | Epoch 19 | Train Loss: 5928.0643 | Val Loss: 5235.3949 | Optimizer: Adam\n",
      "Trial 116 | Epoch 20 | Train Loss: 5761.4785 | Val Loss: 6192.4891 | Optimizer: Adam\n",
      "Trial 116 | Epoch 21 | Train Loss: 5626.6199 | Val Loss: 5189.9797 | Optimizer: Adam\n",
      "Trial 116 | Epoch 22 | Train Loss: 5035.5243 | Val Loss: 5472.4939 | Optimizer: Adam\n",
      "Trial 116 | Epoch 23 | Train Loss: 5242.3243 | Val Loss: 5160.0765 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:24,888] Trial 116 finished with value: 5109.817445660582 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.30628162413744664, 'lr': 0.0007187731951512259, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.2057503379372012e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 | Epoch 24 | Train Loss: 5129.5875 | Val Loss: 5797.3586 | Optimizer: Adam\n",
      "Trial 116 | Epoch 25 | Train Loss: 5286.6081 | Val Loss: 5617.5973 | Optimizer: Adam\n",
      "Trial 116 | Epoch 26 | Train Loss: 5308.7087 | Val Loss: 5267.2947 | Optimizer: Adam\n",
      "Trial 116 - Early stopping triggered at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:24,991] Trial 117 pruned. \n",
      "[I 2025-09-04 20:34:25,103] Trial 118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 118 | Epoch 01 | Train Loss: 20451.5050 | Val Loss: 20084.0236 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:25,218] Trial 119 pruned. \n",
      "[I 2025-09-04 20:34:25,335] Trial 120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 | Epoch 01 | Train Loss: 21045.3157 | Val Loss: 21142.8502 | Optimizer: AdamW\n",
      "Trial 120 | Epoch 01 | Train Loss: 21212.0891 | Val Loss: 22867.3441 | Optimizer: Adam\n",
      "Trial 121 | Epoch 01 | Train Loss: 18913.6367 | Val Loss: 14381.3751 | Optimizer: Adam\n",
      "Trial 121 | Epoch 02 | Train Loss: 11129.3158 | Val Loss: 10674.0829 | Optimizer: Adam\n",
      "Trial 121 | Epoch 03 | Train Loss: 10152.2503 | Val Loss: 8291.4783 | Optimizer: Adam\n",
      "Trial 121 | Epoch 04 | Train Loss: 8114.2868 | Val Loss: 6640.9414 | Optimizer: Adam\n",
      "Trial 121 | Epoch 05 | Train Loss: 6937.7690 | Val Loss: 5503.1816 | Optimizer: Adam\n",
      "Trial 121 | Epoch 06 | Train Loss: 7304.4205 | Val Loss: 5578.8543 | Optimizer: Adam\n",
      "Trial 121 | Epoch 07 | Train Loss: 6921.4327 | Val Loss: 5538.0044 | Optimizer: Adam\n",
      "Trial 121 | Epoch 08 | Train Loss: 6400.9016 | Val Loss: 5619.5426 | Optimizer: Adam\n",
      "Trial 121 | Epoch 09 | Train Loss: 6203.3781 | Val Loss: 6025.3030 | Optimizer: Adam\n",
      "Trial 121 | Epoch 10 | Train Loss: 5988.0631 | Val Loss: 5370.7012 | Optimizer: Adam\n",
      "Trial 121 | Epoch 11 | Train Loss: 6627.5305 | Val Loss: 6451.0294 | Optimizer: Adam\n",
      "Trial 121 | Epoch 12 | Train Loss: 7578.4603 | Val Loss: 6179.5415 | Optimizer: Adam\n",
      "Trial 121 | Epoch 13 | Train Loss: 6048.7567 | Val Loss: 5830.6558 | Optimizer: Adam\n",
      "Trial 121 | Epoch 14 | Train Loss: 5764.0080 | Val Loss: 5322.0892 | Optimizer: Adam\n",
      "Trial 121 | Epoch 15 | Train Loss: 5983.3809 | Val Loss: 6367.5541 | Optimizer: Adam\n",
      "Trial 121 | Epoch 16 | Train Loss: 5877.7437 | Val Loss: 5130.9857 | Optimizer: Adam\n",
      "Trial 121 | Epoch 17 | Train Loss: 6533.7454 | Val Loss: 5264.4391 | Optimizer: Adam\n",
      "Trial 121 | Epoch 18 | Train Loss: 7007.2437 | Val Loss: 9025.9548 | Optimizer: Adam\n",
      "Trial 121 | Epoch 19 | Train Loss: 6824.4080 | Val Loss: 6057.8728 | Optimizer: Adam\n",
      "Trial 121 | Epoch 20 | Train Loss: 6099.6652 | Val Loss: 8522.3123 | Optimizer: Adam\n",
      "Trial 121 | Epoch 21 | Train Loss: 6793.7520 | Val Loss: 5200.9795 | Optimizer: Adam\n",
      "Trial 121 | Epoch 22 | Train Loss: 6130.8518 | Val Loss: 6631.2435 | Optimizer: Adam\n",
      "Trial 121 | Epoch 23 | Train Loss: 6163.0173 | Val Loss: 5122.8159 | Optimizer: Adam\n",
      "Trial 121 | Epoch 24 | Train Loss: 5286.1654 | Val Loss: 6178.3439 | Optimizer: Adam\n",
      "Trial 121 | Epoch 25 | Train Loss: 5744.7817 | Val Loss: 5103.6154 | Optimizer: Adam\n",
      "Trial 121 | Epoch 26 | Train Loss: 5457.0147 | Val Loss: 5476.8209 | Optimizer: Adam\n",
      "Trial 121 | Epoch 27 | Train Loss: 5268.1982 | Val Loss: 5020.3952 | Optimizer: Adam\n",
      "Trial 121 | Epoch 28 | Train Loss: 5023.0608 | Val Loss: 5144.4915 | Optimizer: Adam\n",
      "Trial 121 | Epoch 29 | Train Loss: 5086.2263 | Val Loss: 5294.0295 | Optimizer: Adam\n",
      "Trial 121 | Epoch 30 | Train Loss: 5172.3191 | Val Loss: 5030.4679 | Optimizer: Adam\n",
      "Trial 121 | Epoch 31 | Train Loss: 4984.3178 | Val Loss: 5198.8948 | Optimizer: Adam\n",
      "Trial 121 | Epoch 32 | Train Loss: 4810.6638 | Val Loss: 5164.1223 | Optimizer: Adam\n",
      "Trial 121 | Epoch 33 | Train Loss: 4954.9073 | Val Loss: 5290.3393 | Optimizer: Adam\n",
      "Trial 121 | Epoch 34 | Train Loss: 4784.1677 | Val Loss: 5798.2730 | Optimizer: Adam\n",
      "Trial 121 | Epoch 35 | Train Loss: 5218.3663 | Val Loss: 5074.6453 | Optimizer: Adam\n",
      "Trial 121 | Epoch 36 | Train Loss: 4870.4513 | Val Loss: 5031.1995 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:27,306] Trial 121 finished with value: 5020.395208075495 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.33607288351485465, 'lr': 0.0009877274792946965, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 5.081687941219335e-06}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 | Epoch 37 | Train Loss: 4675.6069 | Val Loss: 5322.4540 | Optimizer: Adam\n",
      "Trial 121 - Early stopping triggered at epoch 37\n",
      "Trial 122 | Epoch 01 | Train Loss: 18892.3027 | Val Loss: 15460.4625 | Optimizer: Adam\n",
      "Trial 122 | Epoch 02 | Train Loss: 12054.1331 | Val Loss: 10359.4282 | Optimizer: Adam\n",
      "Trial 122 | Epoch 03 | Train Loss: 10401.4784 | Val Loss: 8943.8694 | Optimizer: Adam\n",
      "Trial 122 | Epoch 04 | Train Loss: 8948.0145 | Val Loss: 7083.0188 | Optimizer: Adam\n",
      "Trial 122 | Epoch 05 | Train Loss: 7579.7716 | Val Loss: 6010.7037 | Optimizer: Adam\n",
      "Trial 122 | Epoch 06 | Train Loss: 7732.3718 | Val Loss: 7083.8038 | Optimizer: Adam\n",
      "Trial 122 | Epoch 07 | Train Loss: 7912.6193 | Val Loss: 6020.7030 | Optimizer: Adam\n",
      "Trial 122 | Epoch 08 | Train Loss: 7975.9545 | Val Loss: 8812.5762 | Optimizer: Adam\n",
      "Trial 122 | Epoch 09 | Train Loss: 8141.2549 | Val Loss: 5741.5152 | Optimizer: Adam\n",
      "Trial 122 | Epoch 10 | Train Loss: 7588.0085 | Val Loss: 6699.3930 | Optimizer: Adam\n",
      "Trial 122 | Epoch 11 | Train Loss: 7102.2425 | Val Loss: 5373.8869 | Optimizer: Adam\n",
      "Trial 122 | Epoch 12 | Train Loss: 6132.1561 | Val Loss: 5490.3695 | Optimizer: Adam\n",
      "Trial 122 | Epoch 13 | Train Loss: 5892.5281 | Val Loss: 5321.7857 | Optimizer: Adam\n",
      "Trial 122 | Epoch 14 | Train Loss: 6242.3796 | Val Loss: 5617.8490 | Optimizer: Adam\n",
      "Trial 122 | Epoch 15 | Train Loss: 5992.2034 | Val Loss: 5270.7644 | Optimizer: Adam\n",
      "Trial 122 | Epoch 16 | Train Loss: 5594.7291 | Val Loss: 5409.7723 | Optimizer: Adam\n",
      "Trial 122 | Epoch 17 | Train Loss: 5695.1379 | Val Loss: 5313.5422 | Optimizer: Adam\n",
      "Trial 122 | Epoch 18 | Train Loss: 6523.0912 | Val Loss: 5763.7198 | Optimizer: Adam\n",
      "Trial 122 | Epoch 19 | Train Loss: 5455.1581 | Val Loss: 5095.0839 | Optimizer: Adam\n",
      "Trial 122 | Epoch 20 | Train Loss: 5671.5492 | Val Loss: 5075.2844 | Optimizer: Adam\n",
      "Trial 122 | Epoch 21 | Train Loss: 6226.1851 | Val Loss: 7205.1673 | Optimizer: Adam\n",
      "Trial 122 | Epoch 22 | Train Loss: 6105.3469 | Val Loss: 5115.4167 | Optimizer: Adam\n",
      "Trial 122 | Epoch 23 | Train Loss: 6091.0257 | Val Loss: 5462.2025 | Optimizer: Adam\n",
      "Trial 122 | Epoch 24 | Train Loss: 5687.9175 | Val Loss: 5380.1354 | Optimizer: Adam\n",
      "Trial 122 | Epoch 25 | Train Loss: 5680.4224 | Val Loss: 5015.0843 | Optimizer: Adam\n",
      "Trial 122 | Epoch 26 | Train Loss: 5204.1817 | Val Loss: 5210.1729 | Optimizer: Adam\n",
      "Trial 122 | Epoch 27 | Train Loss: 5354.2801 | Val Loss: 5357.6428 | Optimizer: Adam\n",
      "Trial 122 | Epoch 28 | Train Loss: 6229.6520 | Val Loss: 7318.2031 | Optimizer: Adam\n",
      "Trial 122 | Epoch 29 | Train Loss: 5734.9208 | Val Loss: 5027.2963 | Optimizer: Adam\n",
      "Trial 122 | Epoch 30 | Train Loss: 5371.8784 | Val Loss: 5693.0290 | Optimizer: Adam\n",
      "Trial 122 | Epoch 31 | Train Loss: 4937.6635 | Val Loss: 4879.3292 | Optimizer: Adam\n",
      "Trial 122 | Epoch 32 | Train Loss: 5125.4766 | Val Loss: 5086.4310 | Optimizer: Adam\n",
      "Trial 122 | Epoch 33 | Train Loss: 5114.9637 | Val Loss: 5012.1112 | Optimizer: Adam\n",
      "Trial 122 | Epoch 34 | Train Loss: 4831.8951 | Val Loss: 5189.7367 | Optimizer: Adam\n",
      "Trial 122 | Epoch 35 | Train Loss: 5004.8880 | Val Loss: 5400.8024 | Optimizer: Adam\n",
      "Trial 122 | Epoch 36 | Train Loss: 5095.2632 | Val Loss: 5020.4682 | Optimizer: Adam\n",
      "Trial 122 | Epoch 37 | Train Loss: 4876.4904 | Val Loss: 4990.3428 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:29,486] Trial 122 finished with value: 4879.329203086324 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.34269453547106543, 'lr': 0.0008378511945473108, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 3.938549872592738e-06}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 | Epoch 38 | Train Loss: 4933.1909 | Val Loss: 4903.0084 | Optimizer: Adam\n",
      "Trial 122 | Epoch 39 | Train Loss: 5052.8626 | Val Loss: 4885.5371 | Optimizer: Adam\n",
      "Trial 122 | Epoch 40 | Train Loss: 4994.8472 | Val Loss: 5670.8591 | Optimizer: Adam\n",
      "Trial 122 | Epoch 41 | Train Loss: 4672.8173 | Val Loss: 4954.5248 | Optimizer: Adam\n",
      "Trial 122 - Early stopping triggered at epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:29,757] Trial 123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 | Epoch 01 | Train Loss: 19115.1295 | Val Loss: 15659.8536 | Optimizer: Adam\n",
      "Trial 123 | Epoch 02 | Train Loss: 12912.6646 | Val Loss: 10433.3089 | Optimizer: Adam\n",
      "Trial 123 | Epoch 03 | Train Loss: 10538.9077 | Val Loss: 11984.3936 | Optimizer: Adam\n",
      "Trial 123 | Epoch 04 | Train Loss: 10677.0401 | Val Loss: 9237.7342 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:29,874] Trial 124 pruned. \n",
      "[I 2025-09-04 20:34:29,992] Trial 125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 | Epoch 01 | Train Loss: 20020.0661 | Val Loss: 17174.3765 | Optimizer: Adam\n",
      "Trial 125 | Epoch 01 | Train Loss: 19627.1418 | Val Loss: 16193.7403 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:30,108] Trial 126 pruned. \n",
      "[I 2025-09-04 20:34:30,216] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 | Epoch 01 | Train Loss: 284401.5291 | Val Loss: 15844.0544 | Optimizer: RMSprop\n",
      "Trial 127 | Epoch 01 | Train Loss: 20602.4701 | Val Loss: 19346.3059 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:30,332] Trial 128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 | Epoch 01 | Train Loss: 20735.1083 | Val Loss: 20751.3401 | Optimizer: Adam\n",
      "Trial 129 | Epoch 01 | Train Loss: 20349.5939 | Val Loss: 17736.1147 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:30,490] Trial 129 pruned. \n",
      "[I 2025-09-04 20:34:30,608] Trial 130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 | Epoch 01 | Train Loss: 22372.6007 | Val Loss: 23998.3230 | Optimizer: Adam\n",
      "Trial 131 | Epoch 01 | Train Loss: 18994.7402 | Val Loss: 14583.4946 | Optimizer: Adam\n",
      "Trial 131 | Epoch 02 | Train Loss: 11553.9695 | Val Loss: 10377.6580 | Optimizer: Adam\n",
      "Trial 131 | Epoch 03 | Train Loss: 9611.7435 | Val Loss: 7896.6078 | Optimizer: Adam\n",
      "Trial 131 | Epoch 04 | Train Loss: 8332.3028 | Val Loss: 6509.1275 | Optimizer: Adam\n",
      "Trial 131 | Epoch 05 | Train Loss: 7387.7359 | Val Loss: 6109.9149 | Optimizer: Adam\n",
      "Trial 131 | Epoch 06 | Train Loss: 7842.9492 | Val Loss: 8411.5752 | Optimizer: Adam\n",
      "Trial 131 | Epoch 07 | Train Loss: 8348.2516 | Val Loss: 10183.6126 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:31,134] Trial 131 pruned. \n",
      "[I 2025-09-04 20:34:31,250] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 | Epoch 08 | Train Loss: 9687.2594 | Val Loss: 7015.0761 | Optimizer: Adam\n",
      "Trial 131 | Epoch 09 | Train Loss: 8328.3294 | Val Loss: 6329.0125 | Optimizer: Adam\n",
      "Trial 132 | Epoch 01 | Train Loss: 19663.7969 | Val Loss: 16495.7224 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:31,365] Trial 133 pruned. \n",
      "[I 2025-09-04 20:34:31,481] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 | Epoch 01 | Train Loss: 20011.9704 | Val Loss: 17913.9618 | Optimizer: Adam\n",
      "Trial 134 | Epoch 01 | Train Loss: 20548.4690 | Val Loss: 22076.4095 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:31,600] Trial 135 pruned. \n",
      "[I 2025-09-04 20:34:31,711] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 | Epoch 01 | Train Loss: 19685.1739 | Val Loss: 17803.3703 | Optimizer: Adam\n",
      "Trial 136 | Epoch 01 | Train Loss: 20705.2810 | Val Loss: 19658.1579 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:31,828] Trial 137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 | Epoch 01 | Train Loss: 237055.5977 | Val Loss: 232453.1301 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 01 | Train Loss: 17129.9311 | Val Loss: 13132.0762 | Optimizer: Adam\n",
      "Trial 138 | Epoch 02 | Train Loss: 12208.3260 | Val Loss: 10799.4406 | Optimizer: Adam\n",
      "Trial 138 | Epoch 03 | Train Loss: 10804.2373 | Val Loss: 10691.8777 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:32,078] Trial 138 pruned. \n",
      "[I 2025-09-04 20:34:32,197] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 | Epoch 04 | Train Loss: 10471.4370 | Val Loss: 8687.0065 | Optimizer: Adam\n",
      "Trial 139 | Epoch 01 | Train Loss: 20128.0591 | Val Loss: 18609.1380 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:32,298] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 141 | Epoch 01 | Train Loss: 62945.3405 | Val Loss: 13801.4445 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 02 | Train Loss: 11948.0325 | Val Loss: 9528.4436 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 03 | Train Loss: 10035.4276 | Val Loss: 8776.1243 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:32,549] Trial 141 pruned. \n",
      "[I 2025-09-04 20:34:32,704] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 | Epoch 04 | Train Loss: 8406.4017 | Val Loss: 8618.3185 | Optimizer: RMSprop\n",
      "Trial 142 | Epoch 01 | Train Loss: 15588.8860 | Val Loss: 11443.5904 | Optimizer: RMSprop\n",
      "Trial 142 | Epoch 02 | Train Loss: 13820.6890 | Val Loss: 11600.4300 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:32,817] Trial 143 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 | Epoch 01 | Train Loss: 22761.2323 | Val Loss: 23460.4282 | Optimizer: RMSprop\n",
      "Trial 144 | Epoch 01 | Train Loss: 18294.5881 | Val Loss: 14966.0106 | Optimizer: RMSprop\n",
      "Trial 144 | Epoch 02 | Train Loss: 16676.1339 | Val Loss: 16140.5251 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:32,977] Trial 144 pruned. \n",
      "[I 2025-09-04 20:34:33,093] Trial 145 pruned. \n",
      "[I 2025-09-04 20:34:33,213] Trial 146 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 | Epoch 01 | Train Loss: 19305.4417 | Val Loss: 16259.0040 | Optimizer: Adam\n",
      "Trial 146 | Epoch 01 | Train Loss: 20620.3422 | Val Loss: 19638.0383 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:33,331] Trial 147 pruned. \n",
      "[I 2025-09-04 20:34:33,460] Trial 148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 | Epoch 01 | Train Loss: 19033.9926 | Val Loss: 17286.8821 | Optimizer: Adam\n",
      "Trial 148 | Epoch 01 | Train Loss: 213237.3820 | Val Loss: 54885.1639 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:33,577] Trial 149 pruned. \n",
      "[I 2025-09-04 20:34:33,706] Trial 150 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 | Epoch 01 | Train Loss: 20341.0352 | Val Loss: 19383.2715 | Optimizer: Adam\n",
      "Trial 150 | Epoch 01 | Train Loss: 20416.2936 | Val Loss: 19129.6658 | Optimizer: Adam\n",
      "Trial 151 | Epoch 01 | Train Loss: 18966.1126 | Val Loss: 14741.7237 | Optimizer: Adam\n",
      "Trial 151 | Epoch 02 | Train Loss: 11111.2342 | Val Loss: 10006.6403 | Optimizer: Adam\n",
      "Trial 151 | Epoch 03 | Train Loss: 9882.4957 | Val Loss: 8418.1047 | Optimizer: Adam\n",
      "Trial 151 | Epoch 04 | Train Loss: 8237.6732 | Val Loss: 6763.3690 | Optimizer: Adam\n",
      "Trial 151 | Epoch 05 | Train Loss: 7119.5398 | Val Loss: 5520.4110 | Optimizer: Adam\n",
      "Trial 151 | Epoch 06 | Train Loss: 7671.0072 | Val Loss: 5532.1281 | Optimizer: Adam\n",
      "Trial 151 | Epoch 07 | Train Loss: 7814.4783 | Val Loss: 5642.8871 | Optimizer: Adam\n",
      "Trial 151 | Epoch 08 | Train Loss: 6911.9133 | Val Loss: 6167.9706 | Optimizer: Adam\n",
      "Trial 151 | Epoch 09 | Train Loss: 6460.0683 | Val Loss: 5526.3871 | Optimizer: Adam\n",
      "Trial 151 | Epoch 10 | Train Loss: 6467.7954 | Val Loss: 7653.0356 | Optimizer: Adam\n",
      "Trial 151 | Epoch 11 | Train Loss: 7253.9336 | Val Loss: 6276.7624 | Optimizer: Adam\n",
      "Trial 151 | Epoch 12 | Train Loss: 6950.3073 | Val Loss: 7447.1834 | Optimizer: Adam\n",
      "Trial 151 | Epoch 13 | Train Loss: 6887.8301 | Val Loss: 5402.8258 | Optimizer: Adam\n",
      "Trial 151 | Epoch 14 | Train Loss: 5892.4553 | Val Loss: 5491.7448 | Optimizer: Adam\n",
      "Trial 151 | Epoch 15 | Train Loss: 5910.9688 | Val Loss: 5391.3579 | Optimizer: Adam\n",
      "Trial 151 | Epoch 16 | Train Loss: 5862.8490 | Val Loss: 5256.2599 | Optimizer: Adam\n",
      "Trial 151 | Epoch 17 | Train Loss: 5882.9179 | Val Loss: 5057.9834 | Optimizer: Adam\n",
      "Trial 151 | Epoch 18 | Train Loss: 5541.9177 | Val Loss: 5300.6269 | Optimizer: Adam\n",
      "Trial 151 | Epoch 19 | Train Loss: 5885.3461 | Val Loss: 5297.4251 | Optimizer: Adam\n",
      "Trial 151 | Epoch 20 | Train Loss: 6266.5830 | Val Loss: 6068.9485 | Optimizer: Adam\n",
      "Trial 151 | Epoch 21 | Train Loss: 5555.0073 | Val Loss: 5153.4652 | Optimizer: Adam\n",
      "Trial 151 | Epoch 22 | Train Loss: 5763.7373 | Val Loss: 4991.0763 | Optimizer: Adam\n",
      "Trial 151 | Epoch 23 | Train Loss: 5605.1158 | Val Loss: 5884.7917 | Optimizer: Adam\n",
      "Trial 151 | Epoch 24 | Train Loss: 5228.6042 | Val Loss: 5021.2652 | Optimizer: Adam\n",
      "Trial 151 | Epoch 25 | Train Loss: 5089.6321 | Val Loss: 4943.9304 | Optimizer: Adam\n",
      "Trial 151 | Epoch 26 | Train Loss: 5205.1628 | Val Loss: 5339.1334 | Optimizer: Adam\n",
      "Trial 151 | Epoch 27 | Train Loss: 5085.2392 | Val Loss: 5022.5743 | Optimizer: Adam\n",
      "Trial 151 | Epoch 28 | Train Loss: 5094.5138 | Val Loss: 6268.9202 | Optimizer: Adam\n",
      "Trial 151 | Epoch 29 | Train Loss: 4991.4418 | Val Loss: 5036.8110 | Optimizer: Adam\n",
      "Trial 151 | Epoch 30 | Train Loss: 5499.0154 | Val Loss: 5105.2231 | Optimizer: Adam\n",
      "Trial 151 | Epoch 31 | Train Loss: 5188.5870 | Val Loss: 5227.1863 | Optimizer: Adam\n",
      "Trial 151 | Epoch 32 | Train Loss: 4929.1557 | Val Loss: 4943.0105 | Optimizer: Adam\n",
      "Trial 151 | Epoch 33 | Train Loss: 4581.9268 | Val Loss: 5157.7983 | Optimizer: Adam\n",
      "Trial 151 | Epoch 34 | Train Loss: 4769.3343 | Val Loss: 4934.6595 | Optimizer: Adam\n",
      "Trial 151 | Epoch 35 | Train Loss: 4451.0317 | Val Loss: 4907.4960 | Optimizer: Adam\n",
      "Trial 151 | Epoch 36 | Train Loss: 4955.6680 | Val Loss: 4944.6078 | Optimizer: Adam\n",
      "Trial 151 | Epoch 37 | Train Loss: 4583.9196 | Val Loss: 5472.4290 | Optimizer: Adam\n",
      "Trial 151 | Epoch 38 | Train Loss: 4854.0137 | Val Loss: 5290.3396 | Optimizer: Adam\n",
      "Trial 151 | Epoch 39 | Train Loss: 5014.8815 | Val Loss: 5235.5202 | Optimizer: Adam\n",
      "Trial 151 | Epoch 40 | Train Loss: 5094.5563 | Val Loss: 4773.1659 | Optimizer: Adam\n",
      "Trial 151 | Epoch 41 | Train Loss: 4461.4639 | Val Loss: 5343.8769 | Optimizer: Adam\n",
      "Trial 151 | Epoch 42 | Train Loss: 4494.4732 | Val Loss: 4959.2107 | Optimizer: Adam\n",
      "Trial 151 | Epoch 43 | Train Loss: 4425.1219 | Val Loss: 4827.2346 | Optimizer: Adam\n",
      "Trial 151 | Epoch 44 | Train Loss: 4618.4514 | Val Loss: 4863.3111 | Optimizer: Adam\n",
      "Trial 151 | Epoch 45 | Train Loss: 4421.2332 | Val Loss: 7083.9861 | Optimizer: Adam\n",
      "Trial 151 | Epoch 46 | Train Loss: 5317.2447 | Val Loss: 5210.9912 | Optimizer: Adam\n",
      "Trial 151 | Epoch 47 | Train Loss: 4861.5996 | Val Loss: 5728.7101 | Optimizer: Adam\n",
      "Trial 151 | Epoch 48 | Train Loss: 4845.4360 | Val Loss: 4863.1198 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:36,390] Trial 151 finished with value: 4773.165880259901 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.3169808017821424, 'lr': 0.0009165882903888204, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.811980243757698e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 151 | Epoch 49 | Train Loss: 4378.7122 | Val Loss: 4917.7918 | Optimizer: Adam\n",
      "Trial 151 | Epoch 50 | Train Loss: 4201.6819 | Val Loss: 5216.6559 | Optimizer: Adam\n",
      "Trial 151 - Early stopping triggered at epoch 50\n",
      "Trial 152 | Epoch 01 | Train Loss: 20150.2092 | Val Loss: 18270.4295 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:36,509] Trial 152 pruned. \n",
      "[I 2025-09-04 20:34:36,623] Trial 153 pruned. \n",
      "[I 2025-09-04 20:34:36,738] Trial 154 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 153 | Epoch 01 | Train Loss: 19151.8436 | Val Loss: 15790.3492 | Optimizer: Adam\n",
      "Trial 154 | Epoch 01 | Train Loss: 20687.4609 | Val Loss: 21599.2165 | Optimizer: Adam\n",
      "Trial 155 | Epoch 01 | Train Loss: 19398.4257 | Val Loss: 15568.9248 | Optimizer: Adam\n",
      "Trial 155 | Epoch 02 | Train Loss: 12036.7354 | Val Loss: 10169.7191 | Optimizer: Adam\n",
      "Trial 155 | Epoch 03 | Train Loss: 9906.1419 | Val Loss: 9639.8627 | Optimizer: Adam\n",
      "Trial 155 | Epoch 04 | Train Loss: 9085.6408 | Val Loss: 7300.9279 | Optimizer: Adam\n",
      "Trial 155 | Epoch 05 | Train Loss: 7728.4878 | Val Loss: 6468.0567 | Optimizer: Adam\n",
      "Trial 155 | Epoch 06 | Train Loss: 7376.4745 | Val Loss: 6857.5203 | Optimizer: Adam\n",
      "Trial 155 | Epoch 07 | Train Loss: 7686.5786 | Val Loss: 5671.8000 | Optimizer: Adam\n",
      "Trial 155 | Epoch 08 | Train Loss: 6924.0362 | Val Loss: 6634.1343 | Optimizer: Adam\n",
      "Trial 155 | Epoch 09 | Train Loss: 7420.6732 | Val Loss: 5669.1237 | Optimizer: Adam\n",
      "Trial 155 | Epoch 10 | Train Loss: 7001.1209 | Val Loss: 6026.0783 | Optimizer: Adam\n",
      "Trial 155 | Epoch 11 | Train Loss: 6444.6397 | Val Loss: 5546.5717 | Optimizer: Adam\n",
      "Trial 155 | Epoch 12 | Train Loss: 6571.9898 | Val Loss: 5721.1525 | Optimizer: Adam\n",
      "Trial 155 | Epoch 13 | Train Loss: 6710.3358 | Val Loss: 6334.7627 | Optimizer: Adam\n",
      "Trial 155 | Epoch 14 | Train Loss: 6571.8092 | Val Loss: 5201.9536 | Optimizer: Adam\n",
      "Trial 155 | Epoch 15 | Train Loss: 6258.3059 | Val Loss: 5403.9704 | Optimizer: Adam\n",
      "Trial 155 | Epoch 16 | Train Loss: 5819.5214 | Val Loss: 5284.0680 | Optimizer: Adam\n",
      "Trial 155 | Epoch 17 | Train Loss: 6325.1449 | Val Loss: 5322.2360 | Optimizer: Adam\n",
      "Trial 155 | Epoch 18 | Train Loss: 5623.7649 | Val Loss: 5415.0553 | Optimizer: Adam\n",
      "Trial 155 | Epoch 19 | Train Loss: 5697.2927 | Val Loss: 5025.7224 | Optimizer: Adam\n",
      "Trial 155 | Epoch 20 | Train Loss: 5332.4454 | Val Loss: 5165.6265 | Optimizer: Adam\n",
      "Trial 155 | Epoch 21 | Train Loss: 5733.0791 | Val Loss: 5088.3962 | Optimizer: Adam\n",
      "Trial 155 | Epoch 22 | Train Loss: 5800.9191 | Val Loss: 6563.4185 | Optimizer: Adam\n",
      "Trial 155 | Epoch 23 | Train Loss: 5801.4513 | Val Loss: 5160.9791 | Optimizer: Adam\n",
      "Trial 155 | Epoch 24 | Train Loss: 5816.0542 | Val Loss: 5971.2525 | Optimizer: Adam\n",
      "Trial 155 | Epoch 25 | Train Loss: 6151.1784 | Val Loss: 5507.4816 | Optimizer: Adam\n",
      "Trial 155 | Epoch 26 | Train Loss: 5540.3318 | Val Loss: 4998.7127 | Optimizer: Adam\n",
      "Trial 155 | Epoch 27 | Train Loss: 5359.8744 | Val Loss: 6195.3548 | Optimizer: Adam\n",
      "Trial 155 | Epoch 28 | Train Loss: 5230.1214 | Val Loss: 4941.2116 | Optimizer: Adam\n",
      "Trial 155 | Epoch 29 | Train Loss: 4853.4240 | Val Loss: 4978.4536 | Optimizer: Adam\n",
      "Trial 155 | Epoch 30 | Train Loss: 4956.7635 | Val Loss: 5373.0143 | Optimizer: Adam\n",
      "Trial 155 | Epoch 31 | Train Loss: 4683.7383 | Val Loss: 5336.4784 | Optimizer: Adam\n",
      "Trial 155 | Epoch 32 | Train Loss: 4975.5283 | Val Loss: 4881.0535 | Optimizer: Adam\n",
      "Trial 155 | Epoch 33 | Train Loss: 4869.7365 | Val Loss: 5066.3897 | Optimizer: Adam\n",
      "Trial 155 | Epoch 34 | Train Loss: 5810.0733 | Val Loss: 8058.0616 | Optimizer: Adam\n",
      "Trial 155 | Epoch 35 | Train Loss: 6298.3589 | Val Loss: 4872.3171 | Optimizer: Adam\n",
      "Trial 155 | Epoch 36 | Train Loss: 4554.9509 | Val Loss: 5217.4947 | Optimizer: Adam\n",
      "Trial 155 | Epoch 37 | Train Loss: 4884.5185 | Val Loss: 5030.3416 | Optimizer: Adam\n",
      "Trial 155 | Epoch 38 | Train Loss: 4786.1833 | Val Loss: 5177.3777 | Optimizer: Adam\n",
      "Trial 155 | Epoch 39 | Train Loss: 4768.2076 | Val Loss: 4882.8159 | Optimizer: Adam\n",
      "Trial 155 | Epoch 40 | Train Loss: 4801.8963 | Val Loss: 4913.2382 | Optimizer: Adam\n",
      "Trial 155 | Epoch 41 | Train Loss: 4911.3453 | Val Loss: 5782.3190 | Optimizer: Adam\n",
      "Trial 155 | Epoch 42 | Train Loss: 4632.0009 | Val Loss: 4840.7129 | Optimizer: Adam\n",
      "Trial 155 | Epoch 43 | Train Loss: 4351.6521 | Val Loss: 4873.2505 | Optimizer: Adam\n",
      "Trial 155 | Epoch 44 | Train Loss: 4828.8182 | Val Loss: 5486.5796 | Optimizer: Adam\n",
      "Trial 155 | Epoch 45 | Train Loss: 4898.7389 | Val Loss: 5234.4372 | Optimizer: Adam\n",
      "Trial 155 | Epoch 46 | Train Loss: 4453.3162 | Val Loss: 6434.8796 | Optimizer: Adam\n",
      "Trial 155 | Epoch 47 | Train Loss: 5299.5223 | Val Loss: 5046.5018 | Optimizer: Adam\n",
      "Trial 155 | Epoch 48 | Train Loss: 5274.8024 | Val Loss: 4916.8624 | Optimizer: Adam\n",
      "Trial 155 | Epoch 49 | Train Loss: 4339.1111 | Val Loss: 4982.8379 | Optimizer: Adam\n",
      "Trial 155 | Epoch 50 | Train Loss: 4570.5766 | Val Loss: 4877.1889 | Optimizer: Adam\n",
      "Trial 155 | Epoch 51 | Train Loss: 4384.1282 | Val Loss: 5147.8735 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:39,484] Trial 155 finished with value: 4840.712924466275 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.32693679783701846, 'lr': 0.0008136523898901495, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 7.169058629247296e-06}. Best is trial 42 with value: 4722.913093189201.\n",
      "[I 2025-09-04 20:34:39,602] Trial 156 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 155 | Epoch 52 | Train Loss: 4914.9490 | Val Loss: 4875.4573 | Optimizer: Adam\n",
      "Trial 155 - Early stopping triggered at epoch 52\n",
      "Trial 156 | Epoch 01 | Train Loss: 19402.5380 | Val Loss: 16573.9870 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:39,720] Trial 157 pruned. \n",
      "[I 2025-09-04 20:34:39,836] Trial 158 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 157 | Epoch 01 | Train Loss: 19826.8062 | Val Loss: 16911.3261 | Optimizer: Adam\n",
      "Trial 158 | Epoch 01 | Train Loss: 19113.2396 | Val Loss: 15915.9566 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:39,958] Trial 159 pruned. \n",
      "[I 2025-09-04 20:34:40,072] Trial 160 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 159 | Epoch 01 | Train Loss: 19819.9260 | Val Loss: 16200.0051 | Optimizer: Adam\n",
      "Trial 160 | Epoch 01 | Train Loss: 20079.6367 | Val Loss: 17644.6506 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:40,188] Trial 161 pruned. \n",
      "[I 2025-09-04 20:34:40,305] Trial 162 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 161 | Epoch 01 | Train Loss: 19412.8134 | Val Loss: 16711.9371 | Optimizer: Adam\n",
      "Trial 162 | Epoch 01 | Train Loss: 19764.7686 | Val Loss: 18226.5050 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:40,464] Trial 163 pruned. \n",
      "[I 2025-09-04 20:34:40,579] Trial 164 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 163 | Epoch 01 | Train Loss: 17410.6735 | Val Loss: 26584.8594 | Optimizer: Adam\n",
      "Trial 164 | Epoch 01 | Train Loss: 19041.2367 | Val Loss: 15830.3831 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:40,697] Trial 165 pruned. \n",
      "[I 2025-09-04 20:34:40,814] Trial 166 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165 | Epoch 01 | Train Loss: 764695.4653 | Val Loss: 81228.4760 | Optimizer: RMSprop\n",
      "Trial 166 | Epoch 01 | Train Loss: 20182.2562 | Val Loss: 19676.5653 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:40,925] Trial 167 pruned. \n",
      "[I 2025-09-04 20:34:41,044] Trial 168 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 167 | Epoch 01 | Train Loss: 19026.0937 | Val Loss: 16314.6059 | Optimizer: Adam\n",
      "Trial 168 | Epoch 01 | Train Loss: 20554.5027 | Val Loss: 20004.8614 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:41,236] Trial 169 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 169 | Epoch 01 | Train Loss: 18122.9912 | Val Loss: 11214.1875 | Optimizer: Adam\n",
      "Trial 169 | Epoch 02 | Train Loss: 11156.4682 | Val Loss: 11388.2484 | Optimizer: Adam\n",
      "Trial 170 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:41,338] Trial 170 pruned. \n",
      "[I 2025-09-04 20:34:41,471] Trial 171 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171 | Epoch 01 | Train Loss: 19295.3876 | Val Loss: 16742.4698 | Optimizer: Adam\n",
      "Trial 172 | Epoch 01 | Train Loss: 19080.1228 | Val Loss: 15115.8536 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:41,784] Trial 172 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 172 | Epoch 02 | Train Loss: 14534.7010 | Val Loss: 10356.7692 | Optimizer: Adam\n",
      "Trial 172 | Epoch 03 | Train Loss: 11944.4756 | Val Loss: 14392.9960 | Optimizer: Adam\n",
      "Trial 172 | Epoch 04 | Train Loss: 13435.2728 | Val Loss: 13824.1426 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:41,902] Trial 173 pruned. \n",
      "[I 2025-09-04 20:34:42,026] Trial 174 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 173 | Epoch 01 | Train Loss: 19503.1109 | Val Loss: 16851.5639 | Optimizer: Adam\n",
      "Trial 174 | Epoch 01 | Train Loss: 19037.6379 | Val Loss: 17406.9109 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:42,306] Trial 175 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 175 | Epoch 01 | Train Loss: 19106.4974 | Val Loss: 15280.0885 | Optimizer: Adam\n",
      "Trial 175 | Epoch 02 | Train Loss: 12165.4487 | Val Loss: 10566.2914 | Optimizer: Adam\n",
      "Trial 175 | Epoch 03 | Train Loss: 11209.5907 | Val Loss: 12311.6585 | Optimizer: Adam\n",
      "Trial 175 | Epoch 04 | Train Loss: 10508.9547 | Val Loss: 8547.6231 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:42,439] Trial 176 pruned. \n",
      "[I 2025-09-04 20:34:42,565] Trial 177 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 176 | Epoch 01 | Train Loss: 19893.3210 | Val Loss: 18166.0015 | Optimizer: Adam\n",
      "Trial 177 | Epoch 01 | Train Loss: 21287.7632 | Val Loss: 21287.8509 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:42,685] Trial 178 pruned. \n",
      "[I 2025-09-04 20:34:42,806] Trial 179 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 178 | Epoch 01 | Train Loss: 19454.1121 | Val Loss: 19176.6294 | Optimizer: RMSprop\n",
      "Trial 179 | Epoch 01 | Train Loss: 18971.0443 | Val Loss: 16289.2376 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:42,928] Trial 180 pruned. \n",
      "[I 2025-09-04 20:34:43,051] Trial 181 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180 | Epoch 01 | Train Loss: 20298.2360 | Val Loss: 20569.4350 | Optimizer: Adam\n",
      "Trial 181 | Epoch 01 | Train Loss: 21145.8335 | Val Loss: 21687.5605 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:43,172] Trial 182 pruned. \n",
      "[I 2025-09-04 20:34:43,291] Trial 183 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 182 | Epoch 01 | Train Loss: 20533.8511 | Val Loss: 20541.0235 | Optimizer: AdamW\n",
      "Trial 183 | Epoch 01 | Train Loss: 20722.3082 | Val Loss: 20810.9317 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:43,415] Trial 184 pruned. \n",
      "[I 2025-09-04 20:34:43,529] Trial 185 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 184 | Epoch 01 | Train Loss: 20484.8297 | Val Loss: 20494.9501 | Optimizer: Adam\n",
      "Trial 185 | Epoch 01 | Train Loss: 18945.5526 | Val Loss: 15821.9154 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:43,654] Trial 186 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 | Epoch 01 | Train Loss: 18638.8475 | Val Loss: 16420.1176 | Optimizer: Adam\n",
      "Trial 187 | Epoch 01 | Train Loss: 16759.2929 | Val Loss: 11214.6240 | Optimizer: Adam\n",
      "Trial 187 | Epoch 02 | Train Loss: 11011.9195 | Val Loss: 8193.3524 | Optimizer: Adam\n",
      "Trial 187 | Epoch 03 | Train Loss: 8276.0977 | Val Loss: 6200.3227 | Optimizer: Adam\n",
      "Trial 187 | Epoch 04 | Train Loss: 7695.0387 | Val Loss: 7889.4330 | Optimizer: Adam\n",
      "Trial 187 | Epoch 05 | Train Loss: 7110.6624 | Val Loss: 5557.8258 | Optimizer: Adam\n",
      "Trial 187 | Epoch 06 | Train Loss: 6578.2170 | Val Loss: 5578.5513 | Optimizer: Adam\n",
      "Trial 187 | Epoch 07 | Train Loss: 6634.4637 | Val Loss: 6299.5879 | Optimizer: Adam\n",
      "Trial 187 | Epoch 08 | Train Loss: 6792.2684 | Val Loss: 6293.0891 | Optimizer: Adam\n",
      "Trial 187 | Epoch 09 | Train Loss: 6216.4363 | Val Loss: 5515.3672 | Optimizer: Adam\n",
      "Trial 187 | Epoch 10 | Train Loss: 6246.9160 | Val Loss: 5345.6553 | Optimizer: Adam\n",
      "Trial 187 | Epoch 11 | Train Loss: 6224.2623 | Val Loss: 5218.4870 | Optimizer: Adam\n",
      "Trial 187 | Epoch 12 | Train Loss: 5786.5474 | Val Loss: 6457.8002 | Optimizer: Adam\n",
      "Trial 187 | Epoch 13 | Train Loss: 5404.1918 | Val Loss: 5391.1158 | Optimizer: Adam\n",
      "Trial 187 | Epoch 14 | Train Loss: 5509.4811 | Val Loss: 5063.6892 | Optimizer: Adam\n",
      "Trial 187 | Epoch 15 | Train Loss: 5168.8371 | Val Loss: 5220.5484 | Optimizer: Adam\n",
      "Trial 187 | Epoch 16 | Train Loss: 5405.1760 | Val Loss: 6982.7175 | Optimizer: Adam\n",
      "Trial 187 | Epoch 17 | Train Loss: 7187.6800 | Val Loss: 5323.4624 | Optimizer: Adam\n",
      "Trial 187 | Epoch 18 | Train Loss: 5951.9901 | Val Loss: 7102.2856 | Optimizer: Adam\n",
      "Trial 187 | Epoch 19 | Train Loss: 6191.6342 | Val Loss: 5069.3615 | Optimizer: Adam\n",
      "Trial 187 | Epoch 20 | Train Loss: 5513.4552 | Val Loss: 5400.6114 | Optimizer: Adam\n",
      "Trial 187 | Epoch 21 | Train Loss: 5317.6497 | Val Loss: 5348.0065 | Optimizer: Adam\n",
      "Trial 187 | Epoch 22 | Train Loss: 5076.3903 | Val Loss: 5962.1705 | Optimizer: Adam\n",
      "Trial 187 | Epoch 23 | Train Loss: 4920.5666 | Val Loss: 5020.6322 | Optimizer: Adam\n",
      "Trial 187 | Epoch 24 | Train Loss: 4916.7654 | Val Loss: 5609.9939 | Optimizer: Adam\n",
      "Trial 187 | Epoch 25 | Train Loss: 5513.2316 | Val Loss: 5452.2671 | Optimizer: Adam\n",
      "Trial 187 | Epoch 26 | Train Loss: 4608.9898 | Val Loss: 5141.1478 | Optimizer: Adam\n",
      "Trial 187 | Epoch 27 | Train Loss: 4827.1882 | Val Loss: 5045.9013 | Optimizer: Adam\n",
      "Trial 187 | Epoch 28 | Train Loss: 4783.1683 | Val Loss: 5877.6073 | Optimizer: Adam\n",
      "Trial 187 | Epoch 29 | Train Loss: 5349.0135 | Val Loss: 5066.2870 | Optimizer: Adam\n",
      "Trial 187 | Epoch 30 | Train Loss: 4345.9294 | Val Loss: 5555.8816 | Optimizer: Adam\n",
      "Trial 187 | Epoch 31 | Train Loss: 4619.8026 | Val Loss: 5159.7486 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:46,257] Trial 187 finished with value: 5020.632227529393 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33558082532697364, 'lr': 0.0009942065067803005, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.0557774058984523e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 187 | Epoch 32 | Train Loss: 4717.1621 | Val Loss: 5231.0409 | Optimizer: Adam\n",
      "Trial 187 | Epoch 33 | Train Loss: 4843.2333 | Val Loss: 5483.0950 | Optimizer: Adam\n",
      "Trial 187 - Early stopping triggered at epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:46,391] Trial 188 pruned. \n",
      "[I 2025-09-04 20:34:46,523] Trial 189 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 188 | Epoch 01 | Train Loss: 2541390.4860 | Val Loss: 18346.5174 | Optimizer: RMSprop\n",
      "Trial 189 | Epoch 01 | Train Loss: 21182.9049 | Val Loss: 21352.3813 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:46,661] Trial 190 pruned. \n",
      "[I 2025-09-04 20:34:46,793] Trial 191 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 190 | Epoch 01 | Train Loss: 20490.9512 | Val Loss: 19653.7428 | Optimizer: Adam\n",
      "Trial 191 | Epoch 01 | Train Loss: 19375.9425 | Val Loss: 16983.2204 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:46,929] Trial 192 pruned. \n",
      "[I 2025-09-04 20:34:47,065] Trial 193 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 192 | Epoch 01 | Train Loss: 19427.6919 | Val Loss: 18537.2486 | Optimizer: Adam\n",
      "Trial 193 | Epoch 01 | Train Loss: 21730.0944 | Val Loss: 23437.1426 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:47,359] Trial 194 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 194 | Epoch 01 | Train Loss: 19074.7473 | Val Loss: 15572.5210 | Optimizer: Adam\n",
      "Trial 194 | Epoch 02 | Train Loss: 12336.6699 | Val Loss: 10653.0587 | Optimizer: Adam\n",
      "Trial 194 | Epoch 03 | Train Loss: 11126.9795 | Val Loss: 11251.9902 | Optimizer: Adam\n",
      "Trial 194 | Epoch 04 | Train Loss: 10355.9804 | Val Loss: 8480.1777 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:47,505] Trial 195 pruned. \n",
      "[I 2025-09-04 20:34:47,640] Trial 196 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 195 | Epoch 01 | Train Loss: 19166.8351 | Val Loss: 16638.3398 | Optimizer: Adam\n",
      "Trial 196 | Epoch 01 | Train Loss: 21441.4533 | Val Loss: 22796.5176 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:47,865] Trial 197 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 197 | Epoch 01 | Train Loss: 17217.7306 | Val Loss: 11842.0176 | Optimizer: AdamW\n",
      "Trial 197 | Epoch 02 | Train Loss: 11569.9168 | Val Loss: 10687.2174 | Optimizer: AdamW\n",
      "Trial 197 | Epoch 03 | Train Loss: 10862.6824 | Val Loss: 10997.3678 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:48,001] Trial 198 pruned. \n",
      "[I 2025-09-04 20:34:48,143] Trial 199 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 198 | Epoch 01 | Train Loss: 19556.9630 | Val Loss: 18061.7180 | Optimizer: Adam\n",
      "Trial 199 | Epoch 01 | Train Loss: 19932.2001 | Val Loss: 17928.5879 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:48,280] Trial 200 pruned. \n",
      "[I 2025-09-04 20:34:48,425] Trial 201 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 | Epoch 01 | Train Loss: 19869.2430 | Val Loss: 18715.3042 | Optimizer: Adam\n",
      "Trial 201 | Epoch 01 | Train Loss: 19433.8358 | Val Loss: 16131.6660 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:48,675] Trial 202 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 202 | Epoch 01 | Train Loss: 19950.5503 | Val Loss: 17351.7079 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:49,047] Trial 203 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 203 | Epoch 01 | Train Loss: 19085.3814 | Val Loss: 14720.8040 | Optimizer: Adam\n",
      "Trial 203 | Epoch 02 | Train Loss: 12875.7807 | Val Loss: 11453.5434 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:49,398] Trial 204 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 204 | Epoch 01 | Train Loss: 19337.2564 | Val Loss: 16727.4663 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:49,836] Trial 205 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 205 | Epoch 01 | Train Loss: 19485.8655 | Val Loss: 16349.3636 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:49,980] Trial 206 pruned. \n",
      "[I 2025-09-04 20:34:50,105] Trial 207 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 206 | Epoch 01 | Train Loss: 20124.0875 | Val Loss: 17967.4078 | Optimizer: Adam\n",
      "Trial 207 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:50,239] Trial 208 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 208 | Epoch 01 | Train Loss: 19631.0385 | Val Loss: 17752.7527 | Optimizer: Adam\n",
      "Trial 209 | Epoch 01 | Train Loss: 18799.4244 | Val Loss: 15229.0185 | Optimizer: Adam\n",
      "Trial 209 | Epoch 02 | Train Loss: 11584.4001 | Val Loss: 10299.0275 | Optimizer: Adam\n",
      "Trial 209 | Epoch 03 | Train Loss: 10889.7403 | Val Loss: 11679.7728 | Optimizer: Adam\n",
      "Trial 209 | Epoch 04 | Train Loss: 10018.3287 | Val Loss: 8196.0423 | Optimizer: Adam\n",
      "Trial 209 | Epoch 05 | Train Loss: 9608.2909 | Val Loss: 7366.1107 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:50,636] Trial 209 pruned. \n",
      "[I 2025-09-04 20:34:50,767] Trial 210 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 210 | Epoch 01 | Train Loss: 21261.6101 | Val Loss: 22569.7645 | Optimizer: Adam\n",
      "Trial 211 | Epoch 01 | Train Loss: 17986.2215 | Val Loss: 12186.7960 | Optimizer: Adam\n",
      "Trial 211 | Epoch 02 | Train Loss: 12909.6708 | Val Loss: 11257.6071 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:50,949] Trial 211 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 212 | Epoch 01 | Train Loss: 19068.7488 | Val Loss: 10811.5270 | Optimizer: Adam\n",
      "Trial 212 | Epoch 02 | Train Loss: 9711.9903 | Val Loss: 8554.2727 | Optimizer: Adam\n",
      "Trial 212 | Epoch 03 | Train Loss: 8886.4348 | Val Loss: 6007.7560 | Optimizer: Adam\n",
      "Trial 212 | Epoch 04 | Train Loss: 7052.4412 | Val Loss: 6113.4715 | Optimizer: Adam\n",
      "Trial 212 | Epoch 05 | Train Loss: 7002.9090 | Val Loss: 7321.8049 | Optimizer: Adam\n",
      "Trial 212 | Epoch 06 | Train Loss: 7344.7504 | Val Loss: 6610.4736 | Optimizer: Adam\n",
      "Trial 212 | Epoch 07 | Train Loss: 6964.1907 | Val Loss: 6003.1100 | Optimizer: Adam\n",
      "Trial 212 | Epoch 08 | Train Loss: 6376.3691 | Val Loss: 7032.8843 | Optimizer: Adam\n",
      "Trial 212 | Epoch 09 | Train Loss: 6503.5283 | Val Loss: 5217.5709 | Optimizer: Adam\n",
      "Trial 212 | Epoch 10 | Train Loss: 6068.5834 | Val Loss: 5322.4529 | Optimizer: Adam\n",
      "Trial 212 | Epoch 11 | Train Loss: 5692.9313 | Val Loss: 5477.4834 | Optimizer: Adam\n",
      "Trial 212 | Epoch 12 | Train Loss: 6175.5525 | Val Loss: 6227.1678 | Optimizer: Adam\n",
      "Trial 212 | Epoch 13 | Train Loss: 5609.0280 | Val Loss: 5885.4044 | Optimizer: Adam\n",
      "Trial 212 | Epoch 14 | Train Loss: 5725.5933 | Val Loss: 6108.4024 | Optimizer: Adam\n",
      "Trial 212 | Epoch 15 | Train Loss: 6973.9953 | Val Loss: 6347.1077 | Optimizer: Adam\n",
      "Trial 212 | Epoch 16 | Train Loss: 6242.5101 | Val Loss: 6894.1729 | Optimizer: Adam\n",
      "Trial 212 | Epoch 17 | Train Loss: 5489.5400 | Val Loss: 6557.2581 | Optimizer: Adam\n",
      "Trial 212 | Epoch 18 | Train Loss: 6197.0041 | Val Loss: 5690.9208 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:52,508] Trial 212 finished with value: 5217.570936146349 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.3338708853694906, 'lr': 0.0009800915714122467, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.0594940625034082e-05}. Best is trial 42 with value: 4722.913093189201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 212 | Epoch 19 | Train Loss: 5879.0376 | Val Loss: 6331.3392 | Optimizer: Adam\n",
      "Trial 212 - Early stopping triggered at epoch 19\n",
      "Trial 213 | Epoch 01 | Train Loss: 17653.0924 | Val Loss: 21387.6511 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:52,668] Trial 213 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 214 | Epoch 01 | Train Loss: 18337.0351 | Val Loss: 10411.9864 | Optimizer: Adam\n",
      "Trial 214 | Epoch 02 | Train Loss: 9525.0681 | Val Loss: 7382.7927 | Optimizer: Adam\n",
      "Trial 214 | Epoch 03 | Train Loss: 8212.8910 | Val Loss: 6230.1491 | Optimizer: Adam\n",
      "Trial 214 | Epoch 04 | Train Loss: 8750.9526 | Val Loss: 9436.3320 | Optimizer: Adam\n",
      "Trial 214 | Epoch 05 | Train Loss: 6900.3755 | Val Loss: 7156.8175 | Optimizer: Adam\n",
      "Trial 214 | Epoch 06 | Train Loss: 7945.2623 | Val Loss: 6393.7456 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:53,291] Trial 214 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 214 | Epoch 07 | Train Loss: 6625.8399 | Val Loss: 6399.9278 | Optimizer: Adam\n",
      "Trial 215 | Epoch 01 | Train Loss: 18004.6270 | Val Loss: 13996.6994 | Optimizer: Adam\n",
      "Trial 215 | Epoch 02 | Train Loss: 11265.3186 | Val Loss: 10546.5921 | Optimizer: Adam\n",
      "Trial 215 | Epoch 03 | Train Loss: 9278.6844 | Val Loss: 7303.4898 | Optimizer: Adam\n",
      "Trial 215 | Epoch 04 | Train Loss: 7664.0923 | Val Loss: 6360.1140 | Optimizer: Adam\n",
      "Trial 215 | Epoch 05 | Train Loss: 7553.9265 | Val Loss: 5596.4169 | Optimizer: Adam\n",
      "Trial 215 | Epoch 06 | Train Loss: 7097.6230 | Val Loss: 6371.4381 | Optimizer: Adam\n",
      "Trial 215 | Epoch 07 | Train Loss: 6843.5745 | Val Loss: 5404.0874 | Optimizer: Adam\n",
      "Trial 215 | Epoch 08 | Train Loss: 6472.9561 | Val Loss: 5423.0708 | Optimizer: Adam\n",
      "Trial 215 | Epoch 09 | Train Loss: 6304.0336 | Val Loss: 6656.4824 | Optimizer: Adam\n",
      "Trial 215 | Epoch 10 | Train Loss: 5999.0358 | Val Loss: 5484.6841 | Optimizer: Adam\n",
      "Trial 215 | Epoch 11 | Train Loss: 6236.0894 | Val Loss: 5281.9011 | Optimizer: Adam\n",
      "Trial 215 | Epoch 12 | Train Loss: 6835.8894 | Val Loss: 6337.0641 | Optimizer: Adam\n",
      "Trial 215 | Epoch 13 | Train Loss: 6140.2102 | Val Loss: 5847.2407 | Optimizer: Adam\n",
      "Trial 215 | Epoch 14 | Train Loss: 5828.2867 | Val Loss: 5188.6415 | Optimizer: Adam\n",
      "Trial 215 | Epoch 15 | Train Loss: 5349.4070 | Val Loss: 5793.9938 | Optimizer: Adam\n",
      "Trial 215 | Epoch 16 | Train Loss: 5507.5557 | Val Loss: 5547.0084 | Optimizer: Adam\n",
      "Trial 215 | Epoch 17 | Train Loss: 5520.0302 | Val Loss: 5517.5746 | Optimizer: Adam\n",
      "Trial 215 | Epoch 18 | Train Loss: 5845.7817 | Val Loss: 6730.8751 | Optimizer: Adam\n",
      "Trial 215 | Epoch 19 | Train Loss: 5965.4421 | Val Loss: 5726.1868 | Optimizer: Adam\n",
      "Trial 215 | Epoch 20 | Train Loss: 5428.2466 | Val Loss: 5185.5755 | Optimizer: Adam\n",
      "Trial 215 | Epoch 21 | Train Loss: 5541.3202 | Val Loss: 5188.6731 | Optimizer: Adam\n",
      "Trial 215 | Epoch 22 | Train Loss: 6309.0871 | Val Loss: 7549.9943 | Optimizer: Adam\n",
      "Trial 215 | Epoch 23 | Train Loss: 5953.4030 | Val Loss: 5009.9138 | Optimizer: Adam\n",
      "Trial 215 | Epoch 24 | Train Loss: 5838.8302 | Val Loss: 5122.7183 | Optimizer: Adam\n",
      "Trial 215 | Epoch 25 | Train Loss: 5423.9617 | Val Loss: 5862.3340 | Optimizer: Adam\n",
      "Trial 215 | Epoch 26 | Train Loss: 5048.4435 | Val Loss: 5054.4300 | Optimizer: Adam\n",
      "Trial 215 | Epoch 27 | Train Loss: 5212.1636 | Val Loss: 5711.4171 | Optimizer: Adam\n",
      "Trial 215 | Epoch 28 | Train Loss: 5390.2186 | Val Loss: 5640.8937 | Optimizer: Adam\n",
      "Trial 215 | Epoch 29 | Train Loss: 5401.4818 | Val Loss: 5255.6720 | Optimizer: Adam\n",
      "Trial 215 | Epoch 30 | Train Loss: 5340.9790 | Val Loss: 5481.2606 | Optimizer: Adam\n",
      "Trial 215 | Epoch 31 | Train Loss: 4633.9154 | Val Loss: 5010.0656 | Optimizer: Adam\n",
      "Trial 215 | Epoch 32 | Train Loss: 4991.9233 | Val Loss: 5007.0971 | Optimizer: Adam\n",
      "Trial 215 | Epoch 33 | Train Loss: 5017.0875 | Val Loss: 6169.4051 | Optimizer: Adam\n",
      "Trial 215 | Epoch 34 | Train Loss: 5300.4333 | Val Loss: 5261.2615 | Optimizer: Adam\n",
      "Trial 215 | Epoch 35 | Train Loss: 4898.7899 | Val Loss: 5517.0357 | Optimizer: Adam\n",
      "Trial 215 | Epoch 36 | Train Loss: 5071.1704 | Val Loss: 5411.8556 | Optimizer: Adam\n",
      "Trial 215 | Epoch 37 | Train Loss: 4536.3269 | Val Loss: 5121.5111 | Optimizer: Adam\n",
      "Trial 215 | Epoch 38 | Train Loss: 4582.4848 | Val Loss: 5510.8563 | Optimizer: Adam\n",
      "Trial 215 | Epoch 39 | Train Loss: 4537.0480 | Val Loss: 5129.3395 | Optimizer: Adam\n",
      "Trial 215 | Epoch 40 | Train Loss: 4549.9458 | Val Loss: 5009.0407 | Optimizer: Adam\n",
      "Trial 215 | Epoch 41 | Train Loss: 4162.1595 | Val Loss: 5100.3427 | Optimizer: Adam\n",
      "Trial 215 | Epoch 42 | Train Loss: 4520.8626 | Val Loss: 4965.4880 | Optimizer: Adam\n",
      "Trial 215 | Epoch 43 | Train Loss: 4533.9381 | Val Loss: 5286.5607 | Optimizer: Adam\n",
      "Trial 215 | Epoch 44 | Train Loss: 4211.4166 | Val Loss: 5022.6012 | Optimizer: Adam\n",
      "Trial 215 | Epoch 45 | Train Loss: 4332.4933 | Val Loss: 5090.4173 | Optimizer: Adam\n",
      "Trial 215 | Epoch 46 | Train Loss: 4461.6859 | Val Loss: 5407.5665 | Optimizer: Adam\n",
      "Trial 215 | Epoch 47 | Train Loss: 4881.6487 | Val Loss: 5686.9077 | Optimizer: Adam\n",
      "Trial 215 | Epoch 48 | Train Loss: 4753.9367 | Val Loss: 4939.7253 | Optimizer: Adam\n",
      "Trial 215 | Epoch 49 | Train Loss: 4402.1652 | Val Loss: 5093.0737 | Optimizer: Adam\n",
      "Trial 215 | Epoch 50 | Train Loss: 4330.4363 | Val Loss: 4883.5164 | Optimizer: Adam\n",
      "Trial 215 | Epoch 51 | Train Loss: 4390.3125 | Val Loss: 4730.3042 | Optimizer: Adam\n",
      "Trial 215 | Epoch 52 | Train Loss: 4077.4297 | Val Loss: 4701.7155 | Optimizer: Adam\n",
      "Trial 215 | Epoch 53 | Train Loss: 4139.6987 | Val Loss: 4700.1826 | Optimizer: Adam\n",
      "Trial 215 | Epoch 54 | Train Loss: 3826.1568 | Val Loss: 4686.0541 | Optimizer: Adam\n",
      "Trial 215 | Epoch 55 | Train Loss: 3858.0478 | Val Loss: 4909.4437 | Optimizer: Adam\n",
      "Trial 215 | Epoch 56 | Train Loss: 3906.7431 | Val Loss: 5098.0929 | Optimizer: Adam\n",
      "Trial 215 | Epoch 57 | Train Loss: 3988.1983 | Val Loss: 5081.7206 | Optimizer: Adam\n",
      "Trial 215 | Epoch 58 | Train Loss: 4209.1091 | Val Loss: 5673.7111 | Optimizer: Adam\n",
      "Trial 215 | Epoch 59 | Train Loss: 4247.5502 | Val Loss: 5046.5691 | Optimizer: Adam\n",
      "Trial 215 | Epoch 60 | Train Loss: 3901.6339 | Val Loss: 4930.8801 | Optimizer: Adam\n",
      "Trial 215 | Epoch 61 | Train Loss: 4106.3013 | Val Loss: 5450.1217 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:58,181] Trial 215 finished with value: 4686.0540662708845 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33020326811762696, 'lr': 0.0008129951305863827, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.9949762628662353e-05}. Best is trial 215 with value: 4686.0540662708845.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 215 | Epoch 62 | Train Loss: 3993.3997 | Val Loss: 5084.8716 | Optimizer: Adam\n",
      "Trial 215 | Epoch 63 | Train Loss: 4097.9089 | Val Loss: 5114.7279 | Optimizer: Adam\n",
      "Trial 215 | Epoch 64 | Train Loss: 3804.6110 | Val Loss: 4691.5690 | Optimizer: Adam\n",
      "Trial 215 - Early stopping triggered at epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:58,344] Trial 216 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 216 | Epoch 01 | Train Loss: 810931522.1823 | Val Loss: 658125.3410 | Optimizer: RMSprop\n",
      "Trial 217 | Epoch 01 | Train Loss: 19319.6200 | Val Loss: 14098.2506 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:58,580] Trial 217 pruned. \n",
      "[I 2025-09-04 20:34:58,697] Trial 218 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 217 | Epoch 02 | Train Loss: 11761.3381 | Val Loss: 12728.6980 | Optimizer: Adam\n",
      "Trial 218 | Epoch 01 | Train Loss: 21207.1609 | Val Loss: 21872.5991 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:34:58,816] Trial 219 pruned. \n",
      "[I 2025-09-04 20:34:58,950] Trial 220 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 219 | Epoch 01 | Train Loss: 19180.5762 | Val Loss: 16613.5614 | Optimizer: Adam\n",
      "Trial 220 | Epoch 01 | Train Loss: 19680.3835 | Val Loss: 18465.1076 | Optimizer: Adam\n",
      "Trial 221 | Epoch 01 | Train Loss: 17801.1720 | Val Loss: 11117.2719 | Optimizer: Adam\n",
      "Trial 221 | Epoch 02 | Train Loss: 10578.7132 | Val Loss: 10230.4365 | Optimizer: Adam\n",
      "Trial 221 | Epoch 03 | Train Loss: 9781.9942 | Val Loss: 8847.4263 | Optimizer: Adam\n",
      "Trial 221 | Epoch 04 | Train Loss: 8277.8093 | Val Loss: 6639.3219 | Optimizer: Adam\n",
      "Trial 221 | Epoch 05 | Train Loss: 8236.8083 | Val Loss: 5723.6454 | Optimizer: Adam\n",
      "Trial 221 | Epoch 06 | Train Loss: 7173.2066 | Val Loss: 7111.9549 | Optimizer: Adam\n",
      "Trial 221 | Epoch 07 | Train Loss: 7218.9539 | Val Loss: 5682.6206 | Optimizer: Adam\n",
      "Trial 221 | Epoch 08 | Train Loss: 6666.0724 | Val Loss: 7109.8423 | Optimizer: Adam\n",
      "Trial 221 | Epoch 09 | Train Loss: 6789.3804 | Val Loss: 5719.5226 | Optimizer: Adam\n",
      "Trial 221 | Epoch 10 | Train Loss: 6550.6876 | Val Loss: 7037.2715 | Optimizer: Adam\n",
      "Trial 221 | Epoch 11 | Train Loss: 5913.8799 | Val Loss: 5320.1979 | Optimizer: Adam\n",
      "Trial 221 | Epoch 12 | Train Loss: 6038.2862 | Val Loss: 5374.6814 | Optimizer: Adam\n",
      "Trial 221 | Epoch 13 | Train Loss: 5432.8891 | Val Loss: 6251.9434 | Optimizer: Adam\n",
      "Trial 221 | Epoch 14 | Train Loss: 5712.7094 | Val Loss: 5168.4576 | Optimizer: Adam\n",
      "Trial 221 | Epoch 15 | Train Loss: 6707.1586 | Val Loss: 6169.9824 | Optimizer: Adam\n",
      "Trial 221 | Epoch 16 | Train Loss: 6278.3370 | Val Loss: 6384.9657 | Optimizer: Adam\n",
      "Trial 221 | Epoch 17 | Train Loss: 5504.1565 | Val Loss: 5245.2271 | Optimizer: Adam\n",
      "Trial 221 | Epoch 18 | Train Loss: 5438.4158 | Val Loss: 5178.8313 | Optimizer: Adam\n",
      "Trial 221 | Epoch 19 | Train Loss: 5909.9211 | Val Loss: 6735.2562 | Optimizer: Adam\n",
      "Trial 221 | Epoch 20 | Train Loss: 5788.7323 | Val Loss: 5162.4890 | Optimizer: Adam\n",
      "Trial 221 | Epoch 21 | Train Loss: 5061.1469 | Val Loss: 5256.1899 | Optimizer: Adam\n",
      "Trial 221 | Epoch 22 | Train Loss: 5106.5741 | Val Loss: 5211.9947 | Optimizer: Adam\n",
      "Trial 221 | Epoch 23 | Train Loss: 4661.3969 | Val Loss: 5441.7437 | Optimizer: Adam\n",
      "Trial 221 | Epoch 24 | Train Loss: 4713.2182 | Val Loss: 5268.1328 | Optimizer: Adam\n",
      "Trial 221 | Epoch 25 | Train Loss: 4908.7050 | Val Loss: 5166.2686 | Optimizer: Adam\n",
      "Trial 221 | Epoch 26 | Train Loss: 4732.2888 | Val Loss: 5255.5244 | Optimizer: Adam\n",
      "Trial 221 | Epoch 27 | Train Loss: 4798.3952 | Val Loss: 6418.0677 | Optimizer: Adam\n",
      "Trial 221 | Epoch 28 | Train Loss: 4532.1914 | Val Loss: 5632.2338 | Optimizer: Adam\n",
      "Trial 221 | Epoch 29 | Train Loss: 5272.6157 | Val Loss: 5157.4784 | Optimizer: Adam\n",
      "Trial 221 | Epoch 30 | Train Loss: 5293.8630 | Val Loss: 5670.5840 | Optimizer: Adam\n",
      "Trial 221 | Epoch 31 | Train Loss: 4806.0809 | Val Loss: 5132.2256 | Optimizer: Adam\n",
      "Trial 221 | Epoch 32 | Train Loss: 4688.5925 | Val Loss: 4991.8554 | Optimizer: Adam\n",
      "Trial 221 | Epoch 33 | Train Loss: 4736.4870 | Val Loss: 4952.7394 | Optimizer: Adam\n",
      "Trial 221 | Epoch 34 | Train Loss: 4582.5490 | Val Loss: 5630.4601 | Optimizer: Adam\n",
      "Trial 221 | Epoch 35 | Train Loss: 4950.3312 | Val Loss: 5195.6613 | Optimizer: Adam\n",
      "Trial 221 | Epoch 36 | Train Loss: 4735.3471 | Val Loss: 7040.7760 | Optimizer: Adam\n",
      "Trial 221 | Epoch 37 | Train Loss: 5580.1735 | Val Loss: 5124.0543 | Optimizer: Adam\n",
      "Trial 221 | Epoch 38 | Train Loss: 5424.8210 | Val Loss: 5123.4000 | Optimizer: Adam\n",
      "Trial 221 | Epoch 39 | Train Loss: 5275.6989 | Val Loss: 6307.1888 | Optimizer: Adam\n",
      "Trial 221 | Epoch 40 | Train Loss: 5183.6075 | Val Loss: 5256.1703 | Optimizer: Adam\n",
      "Trial 221 | Epoch 41 | Train Loss: 4746.6071 | Val Loss: 5531.5765 | Optimizer: Adam\n",
      "Trial 221 | Epoch 42 | Train Loss: 4762.9931 | Val Loss: 5028.9631 | Optimizer: Adam\n",
      "Trial 221 | Epoch 43 | Train Loss: 4611.4618 | Val Loss: 4881.6687 | Optimizer: Adam\n",
      "Trial 221 | Epoch 44 | Train Loss: 4159.4766 | Val Loss: 4812.3279 | Optimizer: Adam\n",
      "Trial 221 | Epoch 45 | Train Loss: 4122.0758 | Val Loss: 5823.9920 | Optimizer: Adam\n",
      "Trial 221 | Epoch 46 | Train Loss: 4128.4433 | Val Loss: 5113.0421 | Optimizer: Adam\n",
      "Trial 221 | Epoch 47 | Train Loss: 3964.2815 | Val Loss: 5177.8925 | Optimizer: Adam\n",
      "Trial 221 | Epoch 48 | Train Loss: 4384.4117 | Val Loss: 5039.1855 | Optimizer: Adam\n",
      "Trial 221 | Epoch 49 | Train Loss: 3915.0646 | Val Loss: 4670.1515 | Optimizer: Adam\n",
      "Trial 221 | Epoch 50 | Train Loss: 3845.6481 | Val Loss: 5027.3911 | Optimizer: Adam\n",
      "Trial 221 | Epoch 51 | Train Loss: 4046.6456 | Val Loss: 4668.5931 | Optimizer: Adam\n",
      "Trial 221 | Epoch 52 | Train Loss: 3866.3741 | Val Loss: 4739.5062 | Optimizer: Adam\n",
      "Trial 221 | Epoch 53 | Train Loss: 4033.0980 | Val Loss: 4796.1872 | Optimizer: Adam\n",
      "Trial 221 | Epoch 54 | Train Loss: 3700.3423 | Val Loss: 5128.5539 | Optimizer: Adam\n",
      "Trial 221 | Epoch 55 | Train Loss: 3862.8836 | Val Loss: 5001.2904 | Optimizer: Adam\n",
      "Trial 221 | Epoch 56 | Train Loss: 3929.2691 | Val Loss: 5913.1016 | Optimizer: Adam\n",
      "Trial 221 | Epoch 57 | Train Loss: 4188.0201 | Val Loss: 5149.9406 | Optimizer: Adam\n",
      "Trial 221 | Epoch 58 | Train Loss: 3969.8535 | Val Loss: 5141.4849 | Optimizer: Adam\n",
      "Trial 221 | Epoch 59 | Train Loss: 4019.3546 | Val Loss: 4879.8443 | Optimizer: Adam\n",
      "Trial 221 | Epoch 60 | Train Loss: 3609.8407 | Val Loss: 5038.7596 | Optimizer: Adam\n",
      "Trial 221 | Epoch 61 | Train Loss: 3642.8413 | Val Loss: 4651.3844 | Optimizer: Adam\n",
      "Trial 221 | Epoch 62 | Train Loss: 3745.3250 | Val Loss: 5244.0607 | Optimizer: Adam\n",
      "Trial 221 | Epoch 63 | Train Loss: 3476.9499 | Val Loss: 5182.8466 | Optimizer: Adam\n",
      "Trial 221 | Epoch 64 | Train Loss: 3670.4521 | Val Loss: 4533.8839 | Optimizer: Adam\n",
      "Trial 221 | Epoch 65 | Train Loss: 3450.4823 | Val Loss: 5075.1918 | Optimizer: Adam\n",
      "Trial 221 | Epoch 66 | Train Loss: 3610.4606 | Val Loss: 4458.5617 | Optimizer: Adam\n",
      "Trial 221 | Epoch 67 | Train Loss: 3393.5808 | Val Loss: 4819.9053 | Optimizer: Adam\n",
      "Trial 221 | Epoch 68 | Train Loss: 3385.2412 | Val Loss: 5540.1347 | Optimizer: Adam\n",
      "Trial 221 | Epoch 69 | Train Loss: 4236.3115 | Val Loss: 5051.4239 | Optimizer: Adam\n",
      "Trial 221 | Epoch 70 | Train Loss: 3801.8141 | Val Loss: 5173.9375 | Optimizer: Adam\n",
      "Trial 221 | Epoch 71 | Train Loss: 3965.5635 | Val Loss: 5105.5396 | Optimizer: Adam\n",
      "Trial 221 | Epoch 72 | Train Loss: 3709.6135 | Val Loss: 5022.7887 | Optimizer: Adam\n",
      "Trial 221 | Epoch 73 | Train Loss: 3852.3946 | Val Loss: 5362.2401 | Optimizer: Adam\n",
      "Trial 221 | Epoch 74 | Train Loss: 3670.2608 | Val Loss: 4494.6304 | Optimizer: Adam\n",
      "Trial 221 | Epoch 75 | Train Loss: 3228.6157 | Val Loss: 4249.4237 | Optimizer: Adam\n",
      "Trial 221 | Epoch 76 | Train Loss: 3281.3485 | Val Loss: 5458.0469 | Optimizer: Adam\n",
      "Trial 221 | Epoch 77 | Train Loss: 3936.4099 | Val Loss: 4628.9553 | Optimizer: Adam\n",
      "Trial 221 | Epoch 78 | Train Loss: 3215.6221 | Val Loss: 4357.7627 | Optimizer: Adam\n",
      "Trial 221 | Epoch 79 | Train Loss: 3166.8878 | Val Loss: 4543.4782 | Optimizer: Adam\n",
      "Trial 221 | Epoch 80 | Train Loss: 3535.1424 | Val Loss: 4718.8558 | Optimizer: Adam\n",
      "Trial 221 | Epoch 81 | Train Loss: 3149.4253 | Val Loss: 4871.0091 | Optimizer: Adam\n",
      "Trial 221 | Epoch 82 | Train Loss: 3244.6939 | Val Loss: 5435.8045 | Optimizer: Adam\n",
      "Trial 221 | Epoch 83 | Train Loss: 3928.7159 | Val Loss: 4583.5515 | Optimizer: Adam\n",
      "Trial 221 | Epoch 84 | Train Loss: 3337.6443 | Val Loss: 4686.6845 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:05,450] Trial 221 finished with value: 4249.423654084158 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33402122608313956, 'lr': 0.0009940158933486353, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 7.475313105245206e-05}. Best is trial 221 with value: 4249.423654084158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 221 | Epoch 85 | Train Loss: 3114.3228 | Val Loss: 4591.2244 | Optimizer: Adam\n",
      "Trial 221 - Early stopping triggered at epoch 85\n",
      "Trial 222 | Epoch 01 | Train Loss: 17446.1304 | Val Loss: 21071.4944 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:05,614] Trial 222 pruned. \n",
      "[I 2025-09-04 20:35:05,850] Trial 223 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 223 | Epoch 01 | Train Loss: 18766.7515 | Val Loss: 11358.2679 | Optimizer: Adam\n",
      "Trial 223 | Epoch 02 | Train Loss: 11788.8193 | Val Loss: 11147.1399 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:06,010] Trial 224 pruned. \n",
      "[I 2025-09-04 20:35:06,168] Trial 225 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 224 | Epoch 01 | Train Loss: 18253.5920 | Val Loss: 15681.5676 | Optimizer: Adam\n",
      "Trial 225 | Epoch 01 | Train Loss: 21137.0268 | Val Loss: 21877.2894 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:06,329] Trial 226 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 226 | Epoch 01 | Train Loss: 17678.9413 | Val Loss: 13313.2021 | Optimizer: AdamW\n",
      "Trial 226 | Epoch 02 | Train Loss: 11827.1628 | Val Loss: 10917.8737 | Optimizer: AdamW\n",
      "Trial 227 | Epoch 01 | Train Loss: 18744.5738 | Val Loss: 14247.4427 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:06,499] Trial 227 pruned. \n",
      "[I 2025-09-04 20:35:06,619] Trial 228 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 227 | Epoch 02 | Train Loss: 12957.8511 | Val Loss: 11571.9246 | Optimizer: Adam\n",
      "Trial 228 | Epoch 01 | Train Loss: 19478.8589 | Val Loss: 16816.0683 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:06,779] Trial 229 pruned. \n",
      "[I 2025-09-04 20:35:06,897] Trial 230 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 229 | Epoch 01 | Train Loss: 646755868.5656 | Val Loss: 3465153.9257 | Optimizer: RMSprop\n",
      "Trial 230 | Epoch 01 | Train Loss: 21413.2633 | Val Loss: 22604.5659 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:07,059] Trial 231 pruned. \n",
      "[I 2025-09-04 20:35:07,219] Trial 232 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 231 | Epoch 01 | Train Loss: 17468.7209 | Val Loss: 27884.4407 | Optimizer: Adam\n",
      "Trial 232 | Epoch 01 | Train Loss: 17075.5842 | Val Loss: 31988.7913 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:07,462] Trial 233 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 233 | Epoch 01 | Train Loss: 18578.6161 | Val Loss: 11208.0142 | Optimizer: Adam\n",
      "Trial 233 | Epoch 02 | Train Loss: 12048.7042 | Val Loss: 11991.7403 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:07,628] Trial 234 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 234 | Epoch 01 | Train Loss: 20693.2237 | Val Loss: 21139.3630 | Optimizer: Adam\n",
      "Trial 235 | Epoch 01 | Train Loss: 16861.8436 | Val Loss: 10874.5025 | Optimizer: Adam\n",
      "Trial 235 | Epoch 02 | Train Loss: 10409.9979 | Val Loss: 8405.6490 | Optimizer: Adam\n",
      "Trial 235 | Epoch 03 | Train Loss: 8441.9370 | Val Loss: 6969.0034 | Optimizer: Adam\n",
      "Trial 235 | Epoch 04 | Train Loss: 8451.1343 | Val Loss: 9822.9014 | Optimizer: Adam\n",
      "Trial 235 | Epoch 05 | Train Loss: 8758.4190 | Val Loss: 6070.8705 | Optimizer: Adam\n",
      "Trial 235 | Epoch 06 | Train Loss: 7202.5401 | Val Loss: 6222.3120 | Optimizer: Adam\n",
      "Trial 235 | Epoch 07 | Train Loss: 7147.1607 | Val Loss: 7125.5221 | Optimizer: Adam\n",
      "Trial 235 | Epoch 08 | Train Loss: 6925.2810 | Val Loss: 5242.8357 | Optimizer: Adam\n",
      "Trial 235 | Epoch 09 | Train Loss: 6083.1304 | Val Loss: 6777.2101 | Optimizer: Adam\n",
      "Trial 235 | Epoch 10 | Train Loss: 6767.3727 | Val Loss: 7532.3261 | Optimizer: Adam\n",
      "Trial 235 | Epoch 11 | Train Loss: 7024.3686 | Val Loss: 5831.5232 | Optimizer: Adam\n",
      "Trial 235 | Epoch 12 | Train Loss: 6003.6109 | Val Loss: 6542.4323 | Optimizer: Adam\n",
      "Trial 235 | Epoch 13 | Train Loss: 5774.3171 | Val Loss: 5243.4325 | Optimizer: Adam\n",
      "Trial 235 | Epoch 14 | Train Loss: 5709.3405 | Val Loss: 5527.2560 | Optimizer: Adam\n",
      "Trial 235 | Epoch 15 | Train Loss: 5444.3436 | Val Loss: 5227.0750 | Optimizer: Adam\n",
      "Trial 235 | Epoch 16 | Train Loss: 5421.9754 | Val Loss: 5518.5488 | Optimizer: Adam\n",
      "Trial 235 | Epoch 17 | Train Loss: 5435.7178 | Val Loss: 5789.6951 | Optimizer: Adam\n",
      "Trial 235 | Epoch 18 | Train Loss: 5582.0473 | Val Loss: 5534.1449 | Optimizer: Adam\n",
      "Trial 235 | Epoch 19 | Train Loss: 6023.4563 | Val Loss: 6077.4268 | Optimizer: Adam\n",
      "Trial 235 | Epoch 20 | Train Loss: 5161.6926 | Val Loss: 5239.1369 | Optimizer: Adam\n",
      "Trial 235 | Epoch 21 | Train Loss: 5089.6425 | Val Loss: 6917.0261 | Optimizer: Adam\n",
      "Trial 235 | Epoch 22 | Train Loss: 5370.7608 | Val Loss: 5776.1168 | Optimizer: Adam\n",
      "Trial 235 | Epoch 23 | Train Loss: 6362.0410 | Val Loss: 5048.0720 | Optimizer: Adam\n",
      "Trial 235 | Epoch 24 | Train Loss: 5242.9616 | Val Loss: 5235.5351 | Optimizer: Adam\n",
      "Trial 235 | Epoch 25 | Train Loss: 4897.5559 | Val Loss: 5022.7992 | Optimizer: Adam\n",
      "Trial 235 | Epoch 26 | Train Loss: 4756.7617 | Val Loss: 5421.0792 | Optimizer: Adam\n",
      "Trial 235 | Epoch 27 | Train Loss: 4738.8946 | Val Loss: 5104.4683 | Optimizer: Adam\n",
      "Trial 235 | Epoch 28 | Train Loss: 5060.0577 | Val Loss: 5055.3119 | Optimizer: Adam\n",
      "Trial 235 | Epoch 29 | Train Loss: 4800.2998 | Val Loss: 5815.7871 | Optimizer: Adam\n",
      "Trial 235 | Epoch 30 | Train Loss: 4536.0965 | Val Loss: 4970.4412 | Optimizer: Adam\n",
      "Trial 235 | Epoch 31 | Train Loss: 4935.8289 | Val Loss: 5462.8851 | Optimizer: Adam\n",
      "Trial 235 | Epoch 32 | Train Loss: 4871.4165 | Val Loss: 5879.2221 | Optimizer: Adam\n",
      "Trial 235 | Epoch 33 | Train Loss: 4800.2263 | Val Loss: 5318.3585 | Optimizer: Adam\n",
      "Trial 235 | Epoch 34 | Train Loss: 4828.9725 | Val Loss: 5793.5530 | Optimizer: Adam\n",
      "Trial 235 | Epoch 35 | Train Loss: 5179.5517 | Val Loss: 5942.5576 | Optimizer: Adam\n",
      "Trial 235 | Epoch 36 | Train Loss: 4434.3956 | Val Loss: 5035.7370 | Optimizer: Adam\n",
      "Trial 235 | Epoch 37 | Train Loss: 5503.5973 | Val Loss: 5526.0179 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:10,737] Trial 235 finished with value: 4970.441208036819 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.3310738410663764, 'lr': 0.0009963203851917164, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 6.734863342773612e-05}. Best is trial 221 with value: 4249.423654084158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 235 | Epoch 38 | Train Loss: 5466.5322 | Val Loss: 6662.5712 | Optimizer: Adam\n",
      "Trial 235 | Epoch 39 | Train Loss: 5377.8320 | Val Loss: 5191.5543 | Optimizer: Adam\n",
      "Trial 235 | Epoch 40 | Train Loss: 4950.7388 | Val Loss: 5844.8600 | Optimizer: Adam\n",
      "Trial 235 - Early stopping triggered at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:10,864] Trial 236 pruned. \n",
      "[I 2025-09-04 20:35:10,984] Trial 237 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 236 | Epoch 01 | Train Loss: 19755.0854 | Val Loss: 18257.0429 | Optimizer: Adam\n",
      "Trial 237 | Epoch 01 | Train Loss: 20706.6110 | Val Loss: 22248.6379 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:11,106] Trial 238 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 238 | Epoch 01 | Train Loss: 20213.6695 | Val Loss: 19060.1966 | Optimizer: Adam\n",
      "Trial 239 | Epoch 01 | Train Loss: 18072.1806 | Val Loss: 14265.4323 | Optimizer: Adam\n",
      "Trial 239 | Epoch 02 | Train Loss: 11675.1971 | Val Loss: 10309.0825 | Optimizer: Adam\n",
      "Trial 239 | Epoch 03 | Train Loss: 9933.6055 | Val Loss: 9773.6327 | Optimizer: Adam\n",
      "Trial 239 | Epoch 04 | Train Loss: 9502.1728 | Val Loss: 6840.6066 | Optimizer: Adam\n",
      "Trial 239 | Epoch 05 | Train Loss: 7444.7595 | Val Loss: 5730.8862 | Optimizer: Adam\n",
      "Trial 239 | Epoch 06 | Train Loss: 7608.0290 | Val Loss: 5589.2593 | Optimizer: Adam\n",
      "Trial 239 | Epoch 07 | Train Loss: 7266.9819 | Val Loss: 6533.0907 | Optimizer: Adam\n",
      "Trial 239 | Epoch 08 | Train Loss: 6318.4107 | Val Loss: 6111.8148 | Optimizer: Adam\n",
      "Trial 239 | Epoch 09 | Train Loss: 6534.1498 | Val Loss: 7862.2546 | Optimizer: Adam\n",
      "Trial 239 | Epoch 10 | Train Loss: 7007.2589 | Val Loss: 6509.5582 | Optimizer: Adam\n",
      "Trial 239 | Epoch 11 | Train Loss: 6897.9552 | Val Loss: 6671.3157 | Optimizer: Adam\n",
      "Trial 239 | Epoch 12 | Train Loss: 6534.2989 | Val Loss: 5388.6473 | Optimizer: Adam\n",
      "Trial 239 | Epoch 13 | Train Loss: 6175.7162 | Val Loss: 5510.1968 | Optimizer: Adam\n",
      "Trial 239 | Epoch 14 | Train Loss: 5637.9403 | Val Loss: 5405.2863 | Optimizer: Adam\n",
      "Trial 239 | Epoch 15 | Train Loss: 5595.5484 | Val Loss: 5542.0040 | Optimizer: Adam\n",
      "Trial 239 | Epoch 16 | Train Loss: 5812.6295 | Val Loss: 5867.5088 | Optimizer: Adam\n",
      "Trial 239 | Epoch 17 | Train Loss: 5622.4950 | Val Loss: 5084.1013 | Optimizer: Adam\n",
      "Trial 239 | Epoch 18 | Train Loss: 5511.4281 | Val Loss: 5243.8143 | Optimizer: Adam\n",
      "Trial 239 | Epoch 19 | Train Loss: 5406.1325 | Val Loss: 5290.4518 | Optimizer: Adam\n",
      "Trial 239 | Epoch 20 | Train Loss: 5427.8303 | Val Loss: 5503.0264 | Optimizer: Adam\n",
      "Trial 239 | Epoch 21 | Train Loss: 5308.7616 | Val Loss: 5055.0675 | Optimizer: Adam\n",
      "Trial 239 | Epoch 22 | Train Loss: 5932.6511 | Val Loss: 5021.2114 | Optimizer: Adam\n",
      "Trial 239 | Epoch 23 | Train Loss: 5572.8036 | Val Loss: 5222.3435 | Optimizer: Adam\n",
      "Trial 239 | Epoch 24 | Train Loss: 5080.6049 | Val Loss: 5389.2279 | Optimizer: Adam\n",
      "Trial 239 | Epoch 25 | Train Loss: 4855.5497 | Val Loss: 5053.6633 | Optimizer: Adam\n",
      "Trial 239 | Epoch 26 | Train Loss: 5065.7752 | Val Loss: 5513.0996 | Optimizer: Adam\n",
      "Trial 239 | Epoch 27 | Train Loss: 5154.5438 | Val Loss: 5624.4267 | Optimizer: Adam\n",
      "Trial 239 | Epoch 28 | Train Loss: 4870.9369 | Val Loss: 5054.3425 | Optimizer: Adam\n",
      "Trial 239 | Epoch 29 | Train Loss: 4903.7514 | Val Loss: 5004.8005 | Optimizer: Adam\n",
      "Trial 239 | Epoch 30 | Train Loss: 4782.1478 | Val Loss: 5538.5047 | Optimizer: Adam\n",
      "Trial 239 | Epoch 31 | Train Loss: 4957.0036 | Val Loss: 4984.2529 | Optimizer: Adam\n",
      "Trial 239 | Epoch 32 | Train Loss: 5330.2211 | Val Loss: 4930.2992 | Optimizer: Adam\n",
      "Trial 239 | Epoch 33 | Train Loss: 4834.0174 | Val Loss: 5041.9220 | Optimizer: Adam\n",
      "Trial 239 | Epoch 34 | Train Loss: 5035.0119 | Val Loss: 4937.2591 | Optimizer: Adam\n",
      "Trial 239 | Epoch 35 | Train Loss: 4975.2457 | Val Loss: 4961.7412 | Optimizer: Adam\n",
      "Trial 239 | Epoch 36 | Train Loss: 4761.8485 | Val Loss: 5514.7027 | Optimizer: Adam\n",
      "Trial 239 | Epoch 37 | Train Loss: 4704.7919 | Val Loss: 4983.3481 | Optimizer: Adam\n",
      "Trial 239 | Epoch 38 | Train Loss: 4568.6704 | Val Loss: 4898.3163 | Optimizer: Adam\n",
      "Trial 239 | Epoch 39 | Train Loss: 4531.6259 | Val Loss: 5573.6040 | Optimizer: Adam\n",
      "Trial 239 | Epoch 40 | Train Loss: 4718.9069 | Val Loss: 4962.9610 | Optimizer: Adam\n",
      "Trial 239 | Epoch 41 | Train Loss: 4691.2401 | Val Loss: 5465.9274 | Optimizer: Adam\n",
      "Trial 239 | Epoch 42 | Train Loss: 4875.6266 | Val Loss: 5473.4326 | Optimizer: Adam\n",
      "Trial 239 | Epoch 43 | Train Loss: 4882.0063 | Val Loss: 6255.7566 | Optimizer: Adam\n",
      "Trial 239 | Epoch 44 | Train Loss: 4718.7850 | Val Loss: 4834.1003 | Optimizer: Adam\n",
      "Trial 239 | Epoch 45 | Train Loss: 4712.1891 | Val Loss: 4909.4247 | Optimizer: Adam\n",
      "Trial 239 | Epoch 46 | Train Loss: 4453.5426 | Val Loss: 4860.3307 | Optimizer: Adam\n",
      "Trial 239 | Epoch 47 | Train Loss: 4356.7022 | Val Loss: 4941.7483 | Optimizer: Adam\n",
      "Trial 239 | Epoch 48 | Train Loss: 4812.9313 | Val Loss: 5693.5190 | Optimizer: Adam\n",
      "Trial 239 | Epoch 49 | Train Loss: 4595.8146 | Val Loss: 4868.4330 | Optimizer: Adam\n",
      "Trial 239 | Epoch 50 | Train Loss: 4398.9737 | Val Loss: 4955.4121 | Optimizer: Adam\n",
      "Trial 239 | Epoch 51 | Train Loss: 4489.5141 | Val Loss: 4977.0381 | Optimizer: Adam\n",
      "Trial 239 | Epoch 52 | Train Loss: 4372.4514 | Val Loss: 5012.3611 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:13,954] Trial 239 finished with value: 4834.100324876237 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.27769335292670594, 'lr': 0.0007744282300946191, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 8.725816765018418e-05}. Best is trial 221 with value: 4249.423654084158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 239 | Epoch 53 | Train Loss: 4361.0565 | Val Loss: 4969.6693 | Optimizer: Adam\n",
      "Trial 239 | Epoch 54 | Train Loss: 4323.2331 | Val Loss: 4842.2311 | Optimizer: Adam\n",
      "Trial 239 - Early stopping triggered at epoch 54\n",
      "Trial 240 | Epoch 01 | Train Loss: 18872.9935 | Val Loss: 15801.9989 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:14,074] Trial 240 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 241 | Epoch 01 | Train Loss: 18576.4067 | Val Loss: 14387.9737 | Optimizer: Adam\n",
      "Trial 241 | Epoch 02 | Train Loss: 11462.8060 | Val Loss: 10268.2964 | Optimizer: Adam\n",
      "Trial 241 | Epoch 03 | Train Loss: 10302.7053 | Val Loss: 10162.4294 | Optimizer: Adam\n",
      "Trial 241 | Epoch 04 | Train Loss: 9953.9498 | Val Loss: 7884.8948 | Optimizer: Adam\n",
      "Trial 241 | Epoch 05 | Train Loss: 8372.3008 | Val Loss: 6671.4077 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:14,406] Trial 241 pruned. \n",
      "[I 2025-09-04 20:35:14,533] Trial 242 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 242 | Epoch 01 | Train Loss: 21726.0836 | Val Loss: 23485.4161 | Optimizer: Adam\n",
      "Trial 243 | Epoch 01 | Train Loss: 18701.6586 | Val Loss: 13458.0199 | Optimizer: Adam\n",
      "Trial 243 | Epoch 02 | Train Loss: 12179.0952 | Val Loss: 10901.8345 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:14,722] Trial 243 pruned. \n",
      "[I 2025-09-04 20:35:14,894] Trial 244 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 244 | Epoch 01 | Train Loss: 18467.7402 | Val Loss: 14095.6324 | Optimizer: Adam\n",
      "Trial 244 | Epoch 02 | Train Loss: 12066.8744 | Val Loss: 10630.2409 | Optimizer: Adam\n",
      "Trial 245 | Epoch 01 | Train Loss: 18483.3783 | Val Loss: 13909.7517 | Optimizer: Adam\n",
      "Trial 245 | Epoch 02 | Train Loss: 11012.4106 | Val Loss: 10310.3615 | Optimizer: Adam\n",
      "Trial 245 | Epoch 03 | Train Loss: 10464.6402 | Val Loss: 8904.6333 | Optimizer: Adam\n",
      "Trial 245 | Epoch 04 | Train Loss: 8790.3407 | Val Loss: 6345.8861 | Optimizer: Adam\n",
      "Trial 245 | Epoch 05 | Train Loss: 7468.0031 | Val Loss: 6013.5527 | Optimizer: Adam\n",
      "Trial 245 | Epoch 06 | Train Loss: 7086.8901 | Val Loss: 6131.8674 | Optimizer: Adam\n",
      "Trial 245 | Epoch 07 | Train Loss: 6840.1430 | Val Loss: 5626.2244 | Optimizer: Adam\n",
      "Trial 245 | Epoch 08 | Train Loss: 6781.9460 | Val Loss: 7750.6851 | Optimizer: Adam\n",
      "Trial 245 | Epoch 09 | Train Loss: 7789.6112 | Val Loss: 5478.6922 | Optimizer: Adam\n",
      "Trial 245 | Epoch 10 | Train Loss: 7179.1102 | Val Loss: 5944.2315 | Optimizer: Adam\n",
      "Trial 245 | Epoch 11 | Train Loss: 7089.0888 | Val Loss: 6525.7695 | Optimizer: Adam\n",
      "Trial 245 | Epoch 12 | Train Loss: 6787.7715 | Val Loss: 5286.9032 | Optimizer: Adam\n",
      "Trial 245 | Epoch 13 | Train Loss: 6457.3566 | Val Loss: 6018.7194 | Optimizer: Adam\n",
      "Trial 245 | Epoch 14 | Train Loss: 5866.9775 | Val Loss: 5250.6975 | Optimizer: Adam\n",
      "Trial 245 | Epoch 15 | Train Loss: 5879.1238 | Val Loss: 6034.5187 | Optimizer: Adam\n",
      "Trial 245 | Epoch 16 | Train Loss: 6141.0698 | Val Loss: 5325.5630 | Optimizer: Adam\n",
      "Trial 245 | Epoch 17 | Train Loss: 6043.1414 | Val Loss: 5880.9210 | Optimizer: Adam\n",
      "Trial 245 | Epoch 18 | Train Loss: 6050.4093 | Val Loss: 6515.0880 | Optimizer: Adam\n",
      "Trial 245 | Epoch 19 | Train Loss: 6940.3776 | Val Loss: 5168.8325 | Optimizer: Adam\n",
      "Trial 245 | Epoch 20 | Train Loss: 6172.4313 | Val Loss: 6518.6250 | Optimizer: Adam\n",
      "Trial 245 | Epoch 21 | Train Loss: 6099.9697 | Val Loss: 5076.3557 | Optimizer: Adam\n",
      "Trial 245 | Epoch 22 | Train Loss: 5342.8513 | Val Loss: 5356.4132 | Optimizer: Adam\n",
      "Trial 245 | Epoch 23 | Train Loss: 5365.7623 | Val Loss: 5159.3694 | Optimizer: Adam\n",
      "Trial 245 | Epoch 24 | Train Loss: 5625.6680 | Val Loss: 5067.8129 | Optimizer: Adam\n",
      "Trial 245 | Epoch 25 | Train Loss: 5356.1431 | Val Loss: 5790.1929 | Optimizer: Adam\n",
      "Trial 245 | Epoch 26 | Train Loss: 5344.1840 | Val Loss: 4997.7575 | Optimizer: Adam\n",
      "Trial 245 | Epoch 27 | Train Loss: 5452.5330 | Val Loss: 5205.3072 | Optimizer: Adam\n",
      "Trial 245 | Epoch 28 | Train Loss: 5473.3696 | Val Loss: 5093.4196 | Optimizer: Adam\n",
      "Trial 245 | Epoch 29 | Train Loss: 4796.0784 | Val Loss: 5880.2376 | Optimizer: Adam\n",
      "Trial 245 | Epoch 30 | Train Loss: 4938.0718 | Val Loss: 5131.9318 | Optimizer: Adam\n",
      "Trial 245 | Epoch 31 | Train Loss: 6048.3566 | Val Loss: 5134.2313 | Optimizer: Adam\n",
      "Trial 245 | Epoch 32 | Train Loss: 5533.7552 | Val Loss: 5688.3376 | Optimizer: Adam\n",
      "Trial 245 | Epoch 33 | Train Loss: 5342.9052 | Val Loss: 4972.2239 | Optimizer: Adam\n",
      "Trial 245 | Epoch 34 | Train Loss: 4893.8659 | Val Loss: 5361.0458 | Optimizer: Adam\n",
      "Trial 245 | Epoch 35 | Train Loss: 5183.0585 | Val Loss: 4880.3284 | Optimizer: Adam\n",
      "Trial 245 | Epoch 36 | Train Loss: 5375.9601 | Val Loss: 5109.9982 | Optimizer: Adam\n",
      "Trial 245 | Epoch 37 | Train Loss: 4971.2997 | Val Loss: 5089.8255 | Optimizer: Adam\n",
      "Trial 245 | Epoch 38 | Train Loss: 5170.6710 | Val Loss: 4956.4225 | Optimizer: Adam\n",
      "Trial 245 | Epoch 39 | Train Loss: 4736.7451 | Val Loss: 5860.8728 | Optimizer: Adam\n",
      "Trial 245 | Epoch 40 | Train Loss: 5186.5168 | Val Loss: 5568.6636 | Optimizer: Adam\n",
      "Trial 245 | Epoch 41 | Train Loss: 5593.7900 | Val Loss: 7363.1860 | Optimizer: Adam\n",
      "Trial 245 | Epoch 42 | Train Loss: 5423.8131 | Val Loss: 5298.3948 | Optimizer: Adam\n",
      "Trial 245 | Epoch 43 | Train Loss: 4895.9247 | Val Loss: 6397.8438 | Optimizer: Adam\n",
      "Trial 245 | Epoch 44 | Train Loss: 5017.0183 | Val Loss: 5237.0067 | Optimizer: Adam\n",
      "Trial 245 | Epoch 45 | Train Loss: 5044.9279 | Val Loss: 5503.8696 | Optimizer: Adam\n",
      "Trial 245 - Early stopping triggered at epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:17,307] Trial 245 finished with value: 4880.328376392326 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.39719222032435736, 'lr': 0.0009129166051325231, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.4616445620770948e-06}. Best is trial 221 with value: 4249.423654084158.\n",
      "[I 2025-09-04 20:35:17,433] Trial 246 pruned. \n",
      "[I 2025-09-04 20:35:17,547] Trial 247 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 246 | Epoch 01 | Train Loss: 19248.7376 | Val Loss: 17026.4867 | Optimizer: Adam\n",
      "Trial 247 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 248 | Epoch 01 | Train Loss: 97670.8019 | Val Loss: 11831.7981 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 02 | Train Loss: 10640.8689 | Val Loss: 8900.0453 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 03 | Train Loss: 9450.1817 | Val Loss: 6424.0591 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 04 | Train Loss: 7090.4199 | Val Loss: 6051.7666 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 05 | Train Loss: 8950.4416 | Val Loss: 6544.6747 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 06 | Train Loss: 6936.3326 | Val Loss: 6663.7421 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 07 | Train Loss: 6740.0690 | Val Loss: 5800.3527 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 08 | Train Loss: 7152.7514 | Val Loss: 6983.3238 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 09 | Train Loss: 6930.2242 | Val Loss: 5723.2469 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:18,187] Trial 248 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 248 | Epoch 10 | Train Loss: 6645.7698 | Val Loss: 6378.9493 | Optimizer: RMSprop\n",
      "Trial 248 | Epoch 11 | Train Loss: 6313.6426 | Val Loss: 6514.5720 | Optimizer: RMSprop\n",
      "Trial 249 | Epoch 01 | Train Loss: 17486.1801 | Val Loss: 14113.3814 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:18,355] Trial 249 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 249 | Epoch 02 | Train Loss: 12291.3455 | Val Loss: 10713.7303 | Optimizer: Adam\n",
      "Trial 250 | Epoch 01 | Train Loss: 20394.7717 | Val Loss: 15239.7906 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:18,610] Trial 250 pruned. \n",
      "[I 2025-09-04 20:35:18,745] Trial 251 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 250 | Epoch 02 | Train Loss: 12993.2285 | Val Loss: 13476.1566 | Optimizer: AdamW\n",
      "Trial 251 | Epoch 01 | Train Loss: 19402.2967 | Val Loss: 17595.0966 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:18,884] Trial 252 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 252 | Epoch 01 | Train Loss: 19409.4193 | Val Loss: 17218.1586 | Optimizer: Adam\n",
      "Trial 253 | Epoch 01 | Train Loss: 18895.8027 | Val Loss: 14936.8592 | Optimizer: Adam\n",
      "Trial 253 | Epoch 02 | Train Loss: 11527.4222 | Val Loss: 10890.3517 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:19,071] Trial 253 pruned. \n",
      "[I 2025-09-04 20:35:19,202] Trial 254 pruned. \n",
      "[I 2025-09-04 20:35:19,340] Trial 255 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 | Epoch 01 | Train Loss: 19145.1364 | Val Loss: 16306.8194 | Optimizer: Adam\n",
      "Trial 255 | Epoch 01 | Train Loss: 19071.1405 | Val Loss: 15667.4816 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:19,535] Trial 256 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 256 | Epoch 01 | Train Loss: 18269.3722 | Val Loss: 14933.9982 | Optimizer: Adam\n",
      "Trial 256 | Epoch 02 | Train Loss: 12596.8705 | Val Loss: 10694.0545 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:19,717] Trial 257 pruned. \n",
      "[I 2025-09-04 20:35:19,855] Trial 258 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 257 | Epoch 01 | Train Loss: 7352953302.2690 | Val Loss: 426685.1467 | Optimizer: RMSprop\n",
      "Trial 258 | Epoch 01 | Train Loss: 21153.1633 | Val Loss: 21273.1105 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:20,054] Trial 259 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 259 | Epoch 01 | Train Loss: 17734.3962 | Val Loss: 14200.2724 | Optimizer: Adam\n",
      "Trial 259 | Epoch 02 | Train Loss: 10881.3858 | Val Loss: 10788.4766 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:20,311] Trial 260 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 260 | Epoch 01 | Train Loss: 18423.9602 | Val Loss: 15806.8412 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:20,576] Trial 261 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 261 | Epoch 01 | Train Loss: 19434.0931 | Val Loss: 16891.7178 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:20,985] Trial 262 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 262 | Epoch 01 | Train Loss: 19458.3972 | Val Loss: 14452.0788 | Optimizer: AdamW\n",
      "Trial 262 | Epoch 02 | Train Loss: 11731.9057 | Val Loss: 11465.4079 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:21,428] Trial 263 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 263 | Epoch 01 | Train Loss: 20640.1612 | Val Loss: 20875.9070 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:21,571] Trial 264 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 264 | Epoch 01 | Train Loss: 21376.8016 | Val Loss: 23100.8571 | Optimizer: Adam\n",
      "Trial 265 | Epoch 01 | Train Loss: 18150.9163 | Val Loss: 11212.8753 | Optimizer: Adam\n",
      "Trial 265 | Epoch 02 | Train Loss: 9930.5543 | Val Loss: 8672.1658 | Optimizer: Adam\n",
      "Trial 265 | Epoch 03 | Train Loss: 8918.2958 | Val Loss: 7438.4698 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:22,136] Trial 265 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 265 | Epoch 04 | Train Loss: 8862.5399 | Val Loss: 7568.0455 | Optimizer: Adam\n",
      "Trial 265 | Epoch 05 | Train Loss: 8236.5546 | Val Loss: 7494.6061 | Optimizer: Adam\n",
      "Trial 266 | Epoch 01 | Train Loss: 51877.7200 | Val Loss: 13533.7268 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:22,310] Trial 266 pruned. \n",
      "[I 2025-09-04 20:35:22,428] Trial 267 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 266 | Epoch 02 | Train Loss: 11053.9422 | Val Loss: 11891.6714 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 01 | Train Loss: 20942.7412 | Val Loss: 21546.6794 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:22,605] Trial 268 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 268 | Epoch 01 | Train Loss: 18310.2923 | Val Loss: 14943.0315 | Optimizer: Adam\n",
      "Trial 268 | Epoch 02 | Train Loss: 12359.4444 | Val Loss: 11419.5706 | Optimizer: Adam\n",
      "Trial 269 | Epoch 01 | Train Loss: 19435.5094 | Val Loss: 16174.7279 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:22,726] Trial 269 pruned. \n",
      "[I 2025-09-04 20:35:22,843] Trial 270 pruned. \n",
      "[I 2025-09-04 20:35:23,004] Trial 271 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 270 | Epoch 01 | Train Loss: 20530.5742 | Val Loss: 20241.5435 | Optimizer: Adam\n",
      "Trial 271 | Epoch 01 | Train Loss: 17595.2778 | Val Loss: 26211.7356 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:23,111] Trial 272 pruned. \n",
      "[I 2025-09-04 20:35:23,227] Trial 273 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 272 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 273 | Epoch 01 | Train Loss: 19662.5615 | Val Loss: 19551.9568 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:23,399] Trial 274 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 274 | Epoch 01 | Train Loss: 17348.0419 | Val Loss: 13490.3021 | Optimizer: Adam\n",
      "Trial 274 | Epoch 02 | Train Loss: 11548.8529 | Val Loss: 10823.6044 | Optimizer: Adam\n",
      "Trial 275 | Epoch 01 | Train Loss: 1640970.6244 | Val Loss: 10672.7984 | Optimizer: RMSprop\n",
      "Trial 275 | Epoch 02 | Train Loss: 14962.0757 | Val Loss: 13242.2054 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:23,569] Trial 275 pruned. \n",
      "[I 2025-09-04 20:35:23,684] Trial 276 pruned. \n",
      "[I 2025-09-04 20:35:23,806] Trial 277 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 276 | Epoch 01 | Train Loss: 19582.2856 | Val Loss: 18382.8791 | Optimizer: Adam\n",
      "Trial 277 | Epoch 01 | Train Loss: 19494.1337 | Val Loss: 16910.1537 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:23,977] Trial 278 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 278 | Epoch 01 | Train Loss: 19363.2723 | Val Loss: 15463.2181 | Optimizer: Adam\n",
      "Trial 279 | Epoch 01 | Train Loss: 18959.3711 | Val Loss: 15119.2307 | Optimizer: Adam\n",
      "Trial 279 | Epoch 02 | Train Loss: 11899.6584 | Val Loss: 10445.6018 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:24,208] Trial 279 pruned. \n",
      "[I 2025-09-04 20:35:24,336] Trial 280 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 279 | Epoch 03 | Train Loss: 10572.2181 | Val Loss: 10122.4160 | Optimizer: Adam\n",
      "Trial 280 | Epoch 01 | Train Loss: 19956.7760 | Val Loss: 17639.3935 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:24,456] Trial 281 pruned. \n",
      "[I 2025-09-04 20:35:24,576] Trial 282 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 281 | Epoch 01 | Train Loss: 19018.3061 | Val Loss: 16408.0000 | Optimizer: Adam\n",
      "Trial 282 | Epoch 01 | Train Loss: 20770.2943 | Val Loss: 21653.2876 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:24,696] Trial 283 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 283 | Epoch 01 | Train Loss: 19526.7273 | Val Loss: 16509.9087 | Optimizer: Adam\n",
      "Trial 284 | Epoch 01 | Train Loss: 20245.4328 | Val Loss: 17717.8951 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:24,868] Trial 284 pruned. \n",
      "[I 2025-09-04 20:35:24,992] Trial 285 pruned. \n",
      "[I 2025-09-04 20:35:25,113] Trial 286 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 285 | Epoch 01 | Train Loss: 11144889.5209 | Val Loss: 31963.9876 | Optimizer: RMSprop\n",
      "Trial 286 | Epoch 01 | Train Loss: 21403.0770 | Val Loss: 23100.2999 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:25,239] Trial 287 pruned. \n",
      "[I 2025-09-04 20:35:25,363] Trial 288 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 287 | Epoch 01 | Train Loss: 19593.3025 | Val Loss: 19526.8618 | Optimizer: Adam\n",
      "Trial 288 | Epoch 01 | Train Loss: 19778.7304 | Val Loss: 15667.1882 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:25,486] Trial 289 pruned. \n",
      "[I 2025-09-04 20:35:25,603] Trial 290 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 289 | Epoch 01 | Train Loss: 21663.2477 | Val Loss: 23408.0146 | Optimizer: AdamW\n",
      "Trial 290 | Epoch 01 | Train Loss: 19104.0633 | Val Loss: 16508.3832 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:25,726] Trial 291 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 291 | Epoch 01 | Train Loss: 19469.4989 | Val Loss: 16893.3591 | Optimizer: Adam\n",
      "Trial 292 | Epoch 01 | Train Loss: 17895.2821 | Val Loss: 12899.1027 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:25,976] Trial 292 pruned. \n",
      "[I 2025-09-04 20:35:26,099] Trial 293 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 292 | Epoch 02 | Train Loss: 10936.7703 | Val Loss: 12644.8381 | Optimizer: Adam\n",
      "Trial 293 | Epoch 01 | Train Loss: 21097.4675 | Val Loss: 20535.4777 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:26,223] Trial 294 pruned. \n",
      "[I 2025-09-04 20:35:26,341] Trial 295 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 294 | Epoch 01 | Train Loss: 253871.9464 | Val Loss: 15549.5691 | Optimizer: RMSprop\n",
      "Trial 295 | Epoch 01 | Train Loss: 18681.4944 | Val Loss: 15437.0194 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:26,515] Trial 296 pruned. \n",
      "[I 2025-09-04 20:35:26,622] Trial 297 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 296 | Epoch 01 | Train Loss: 19694.7097 | Val Loss: 14959.2562 | Optimizer: Adam\n",
      "Trial 296 | Epoch 02 | Train Loss: 12953.5174 | Val Loss: 11348.8220 | Optimizer: Adam\n",
      "Trial 297 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:26,873] Trial 298 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 298 | Epoch 01 | Train Loss: 18705.7945 | Val Loss: 11841.7587 | Optimizer: Adam\n",
      "Trial 298 | Epoch 02 | Train Loss: 12837.4494 | Val Loss: 12816.6937 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:26,999] Trial 299 pruned. \n",
      "[I 2025-09-04 20:35:27,116] Trial 300 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 299 | Epoch 01 | Train Loss: 19520.8700 | Val Loss: 15917.5274 | Optimizer: Adam\n",
      "Trial 300 | Epoch 01 | Train Loss: 19651.0042 | Val Loss: 17466.3900 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:27,240] Trial 301 pruned. \n",
      "[I 2025-09-04 20:35:27,364] Trial 302 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 301 | Epoch 01 | Train Loss: 18686.8293 | Val Loss: 16147.4111 | Optimizer: Adam\n",
      "Trial 302 | Epoch 01 | Train Loss: 19041.7477 | Val Loss: 15737.7686 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:27,485] Trial 303 pruned. \n",
      "[I 2025-09-04 20:35:27,602] Trial 304 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 303 | Epoch 01 | Train Loss: 1841129.0433 | Val Loss: 24684.5141 | Optimizer: RMSprop\n",
      "Trial 304 | Epoch 01 | Train Loss: 20298.1575 | Val Loss: 18671.5852 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:27,763] Trial 305 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 305 | Epoch 01 | Train Loss: 19779.8881 | Val Loss: 17661.6870 | Optimizer: Adam\n",
      "Trial 306 | Epoch 01 | Train Loss: 18143.7492 | Val Loss: 13070.5745 | Optimizer: Adam\n",
      "Trial 306 | Epoch 02 | Train Loss: 12487.1477 | Val Loss: 11013.1279 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:27,937] Trial 306 pruned. \n",
      "[I 2025-09-04 20:35:28,065] Trial 307 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 307 | Epoch 01 | Train Loss: 19275.9953 | Val Loss: 16229.6561 | Optimizer: Adam\n",
      "Trial 308 | Epoch 01 | Train Loss: 19153.7374 | Val Loss: 14396.9847 | Optimizer: Adam\n",
      "Trial 308 | Epoch 02 | Train Loss: 13001.7845 | Val Loss: 11842.1877 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:28,236] Trial 308 pruned. \n",
      "[I 2025-09-04 20:35:28,359] Trial 309 pruned. \n",
      "[I 2025-09-04 20:35:28,483] Trial 310 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 309 | Epoch 01 | Train Loss: 19133.5924 | Val Loss: 15714.8362 | Optimizer: Adam\n",
      "Trial 310 | Epoch 01 | Train Loss: 19658.1710 | Val Loss: 17547.0900 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:28,649] Trial 311 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 311 | Epoch 01 | Train Loss: 21356.3182 | Val Loss: 22859.6614 | Optimizer: Adam\n",
      "Trial 312 | Epoch 01 | Train Loss: 58733.0618 | Val Loss: 12586.8682 | Optimizer: RMSprop\n",
      "Trial 312 | Epoch 02 | Train Loss: 11478.5566 | Val Loss: 9792.0853 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:28,996] Trial 312 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 312 | Epoch 03 | Train Loss: 9500.9151 | Val Loss: 12212.0591 | Optimizer: RMSprop\n",
      "Trial 312 | Epoch 04 | Train Loss: 8723.7040 | Val Loss: 8013.1783 | Optimizer: RMSprop\n",
      "Trial 312 | Epoch 05 | Train Loss: 8846.0437 | Val Loss: 7315.6788 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:29,178] Trial 313 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 313 | Epoch 01 | Train Loss: 17920.0561 | Val Loss: 12446.1935 | Optimizer: Adam\n",
      "Trial 313 | Epoch 02 | Train Loss: 11395.0561 | Val Loss: 10834.6443 | Optimizer: Adam\n",
      "Trial 314 | Epoch 01 | Train Loss: 19288.8203 | Val Loss: 17103.7979 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:29,298] Trial 314 pruned. \n",
      "[I 2025-09-04 20:35:29,426] Trial 315 pruned. \n",
      "[I 2025-09-04 20:35:29,551] Trial 316 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 315 | Epoch 01 | Train Loss: 19734.4126 | Val Loss: 18912.5736 | Optimizer: Adam\n",
      "Trial 316 | Epoch 01 | Train Loss: 20850.3346 | Val Loss: 20830.2802 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:29,680] Trial 317 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 317 | Epoch 01 | Train Loss: 19710.3323 | Val Loss: 17963.9270 | Optimizer: Adam\n",
      "Trial 318 | Epoch 01 | Train Loss: 17772.2593 | Val Loss: 15621.0108 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:29,850] Trial 318 pruned. \n",
      "[I 2025-09-04 20:35:29,971] Trial 319 pruned. \n",
      "[I 2025-09-04 20:35:30,105] Trial 320 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 319 | Epoch 01 | Train Loss: 21661.3241 | Val Loss: 22829.2117 | Optimizer: Adam\n",
      "Trial 320 | Epoch 01 | Train Loss: 20411.6878 | Val Loss: 19734.5537 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:30,299] Trial 321 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 321 | Epoch 01 | Train Loss: 222816.5962 | Val Loss: 13666.1303 | Optimizer: RMSprop\n",
      "Trial 321 | Epoch 02 | Train Loss: 12579.5354 | Val Loss: 11443.7784 | Optimizer: RMSprop\n",
      "Trial 322 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:30,415] Trial 322 pruned. \n",
      "[I 2025-09-04 20:35:30,598] Trial 323 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 323 | Epoch 01 | Train Loss: 18122.5048 | Val Loss: 11478.7369 | Optimizer: Adam\n",
      "Trial 323 | Epoch 02 | Train Loss: 11528.0682 | Val Loss: 11707.9675 | Optimizer: Adam\n",
      "Trial 324 | Epoch 01 | Train Loss: 19772.6178 | Val Loss: 16931.1746 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:30,740] Trial 324 pruned. \n",
      "[I 2025-09-04 20:35:30,931] Trial 325 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 325 | Epoch 01 | Train Loss: 20905.8331 | Val Loss: 20846.5193 | Optimizer: Adam\n",
      "Trial 326 | Epoch 01 | Train Loss: 18645.3219 | Val Loss: 14870.3571 | Optimizer: Adam\n",
      "Trial 326 | Epoch 02 | Train Loss: 12405.5796 | Val Loss: 10592.3624 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:31,203] Trial 326 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 326 | Epoch 03 | Train Loss: 10801.6358 | Val Loss: 11934.2032 | Optimizer: Adam\n",
      "Trial 327 | Epoch 01 | Train Loss: 18091.9376 | Val Loss: 13956.9628 | Optimizer: Adam\n",
      "Trial 327 | Epoch 02 | Train Loss: 11704.8972 | Val Loss: 10699.8665 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:31,402] Trial 327 pruned. \n",
      "[I 2025-09-04 20:35:31,558] Trial 328 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 328 | Epoch 01 | Train Loss: 20576.2648 | Val Loss: 20117.0074 | Optimizer: Adam\n",
      "Trial 329 | Epoch 01 | Train Loss: 21061.7297 | Val Loss: 21333.4998 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:31,712] Trial 329 pruned. \n",
      "[I 2025-09-04 20:35:32,000] Trial 330 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 330 | Epoch 01 | Train Loss: 18312.5154 | Val Loss: 13888.0699 | Optimizer: Adam\n",
      "Trial 330 | Epoch 02 | Train Loss: 11203.9309 | Val Loss: 10394.5798 | Optimizer: Adam\n",
      "Trial 330 | Epoch 03 | Train Loss: 10480.8702 | Val Loss: 10567.5259 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:32,314] Trial 331 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 331 | Epoch 01 | Train Loss: 20137.6465 | Val Loss: 13672.4805 | Optimizer: Adam\n",
      "Trial 331 | Epoch 02 | Train Loss: 10848.6806 | Val Loss: 11084.4152 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:32,589] Trial 332 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 332 | Epoch 01 | Train Loss: 21704.4731 | Val Loss: 13641.5406 | Optimizer: RMSprop\n",
      "Trial 332 | Epoch 02 | Train Loss: 11647.1915 | Val Loss: 10497.4106 | Optimizer: RMSprop\n",
      "Trial 332 | Epoch 03 | Train Loss: 11057.6195 | Val Loss: 9461.4468 | Optimizer: RMSprop\n",
      "Trial 332 | Epoch 04 | Train Loss: 9373.2799 | Val Loss: 8139.8345 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:32,733] Trial 333 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 333 | Epoch 01 | Train Loss: 18866.0576 | Val Loss: 16117.4715 | Optimizer: Adam\n",
      "Trial 334 | Epoch 01 | Train Loss: 18705.0402 | Val Loss: 14874.5700 | Optimizer: Adam\n",
      "Trial 334 | Epoch 02 | Train Loss: 11331.7382 | Val Loss: 10413.4792 | Optimizer: Adam\n",
      "Trial 334 | Epoch 03 | Train Loss: 10172.8032 | Val Loss: 8736.2259 | Optimizer: Adam\n",
      "Trial 334 | Epoch 04 | Train Loss: 8407.1228 | Val Loss: 6865.2543 | Optimizer: Adam\n",
      "Trial 334 | Epoch 05 | Train Loss: 7593.1378 | Val Loss: 5465.4688 | Optimizer: Adam\n",
      "Trial 334 | Epoch 06 | Train Loss: 7177.8570 | Val Loss: 6002.4402 | Optimizer: Adam\n",
      "Trial 334 | Epoch 07 | Train Loss: 7047.4461 | Val Loss: 6981.1199 | Optimizer: Adam\n",
      "Trial 334 | Epoch 08 | Train Loss: 6735.0018 | Val Loss: 5822.9602 | Optimizer: Adam\n",
      "Trial 334 | Epoch 09 | Train Loss: 6787.3647 | Val Loss: 7540.8081 | Optimizer: Adam\n",
      "Trial 334 | Epoch 10 | Train Loss: 6917.0320 | Val Loss: 6027.8853 | Optimizer: Adam\n",
      "Trial 334 | Epoch 11 | Train Loss: 6500.9668 | Val Loss: 6382.2716 | Optimizer: Adam\n",
      "Trial 334 | Epoch 12 | Train Loss: 6191.7771 | Val Loss: 5266.0969 | Optimizer: Adam\n",
      "Trial 334 | Epoch 13 | Train Loss: 5661.9368 | Val Loss: 6076.7342 | Optimizer: Adam\n",
      "Trial 334 | Epoch 14 | Train Loss: 5817.9058 | Val Loss: 5247.1409 | Optimizer: Adam\n",
      "Trial 334 | Epoch 15 | Train Loss: 5869.9610 | Val Loss: 5510.0023 | Optimizer: Adam\n",
      "Trial 334 | Epoch 16 | Train Loss: 5778.4942 | Val Loss: 6308.7662 | Optimizer: Adam\n",
      "Trial 334 | Epoch 17 | Train Loss: 6335.3281 | Val Loss: 5171.3142 | Optimizer: Adam\n",
      "Trial 334 | Epoch 18 | Train Loss: 5770.3395 | Val Loss: 5197.4716 | Optimizer: Adam\n",
      "Trial 334 | Epoch 19 | Train Loss: 5416.1057 | Val Loss: 6151.7753 | Optimizer: Adam\n",
      "Trial 334 | Epoch 20 | Train Loss: 5399.1138 | Val Loss: 5436.4640 | Optimizer: Adam\n",
      "Trial 334 | Epoch 21 | Train Loss: 6200.6987 | Val Loss: 5473.3883 | Optimizer: Adam\n",
      "Trial 334 | Epoch 22 | Train Loss: 5646.4699 | Val Loss: 5623.8664 | Optimizer: Adam\n",
      "Trial 334 | Epoch 23 | Train Loss: 5602.4704 | Val Loss: 7284.1418 | Optimizer: Adam\n",
      "Trial 334 | Epoch 24 | Train Loss: 6973.2951 | Val Loss: 5444.4917 | Optimizer: Adam\n",
      "Trial 334 | Epoch 25 | Train Loss: 5992.6225 | Val Loss: 7552.4384 | Optimizer: Adam\n",
      "Trial 334 | Epoch 26 | Train Loss: 6689.4139 | Val Loss: 5026.4375 | Optimizer: Adam\n",
      "Trial 334 | Epoch 27 | Train Loss: 5628.6408 | Val Loss: 6411.8289 | Optimizer: Adam\n",
      "Trial 334 | Epoch 28 | Train Loss: 5978.8012 | Val Loss: 5020.8497 | Optimizer: Adam\n",
      "Trial 334 | Epoch 29 | Train Loss: 5200.4675 | Val Loss: 5651.9546 | Optimizer: Adam\n",
      "Trial 334 | Epoch 30 | Train Loss: 5267.2459 | Val Loss: 4957.8142 | Optimizer: Adam\n",
      "Trial 334 | Epoch 31 | Train Loss: 4937.3667 | Val Loss: 5126.3722 | Optimizer: Adam\n",
      "Trial 334 | Epoch 32 | Train Loss: 4986.5363 | Val Loss: 5076.4942 | Optimizer: Adam\n",
      "Trial 334 | Epoch 33 | Train Loss: 5193.2429 | Val Loss: 5016.9403 | Optimizer: Adam\n",
      "Trial 334 | Epoch 34 | Train Loss: 5165.7547 | Val Loss: 5092.9094 | Optimizer: Adam\n",
      "Trial 334 | Epoch 35 | Train Loss: 5102.8187 | Val Loss: 5139.8528 | Optimizer: Adam\n",
      "Trial 334 | Epoch 36 | Train Loss: 4642.0623 | Val Loss: 5333.6356 | Optimizer: Adam\n",
      "Trial 334 | Epoch 37 | Train Loss: 5398.1487 | Val Loss: 6910.6920 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:35,128] Trial 334 finished with value: 4957.81423073948 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.2868119265997926, 'lr': 0.0008522813862297137, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 4.9946955277409905e-06}. Best is trial 221 with value: 4249.423654084158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 334 | Epoch 38 | Train Loss: 5612.4191 | Val Loss: 5023.4347 | Optimizer: Adam\n",
      "Trial 334 | Epoch 39 | Train Loss: 5334.6770 | Val Loss: 5182.0584 | Optimizer: Adam\n",
      "Trial 334 | Epoch 40 | Train Loss: 5326.6944 | Val Loss: 5642.5102 | Optimizer: Adam\n",
      "Trial 334 - Early stopping triggered at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:35,268] Trial 335 pruned. \n",
      "[I 2025-09-04 20:35:35,404] Trial 336 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 335 | Epoch 01 | Train Loss: 19328.3006 | Val Loss: 15942.8429 | Optimizer: Adam\n",
      "Trial 336 | Epoch 01 | Train Loss: 19448.5280 | Val Loss: 15856.0336 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:35,539] Trial 337 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 337 | Epoch 01 | Train Loss: 20952.9368 | Val Loss: 21867.9854 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:35,782] Trial 338 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 338 | Epoch 01 | Train Loss: 20026.1213 | Val Loss: 16906.2174 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:36,201] Trial 339 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 339 | Epoch 01 | Train Loss: 19235.0097 | Val Loss: 11539.5738 | Optimizer: Adam\n",
      "Trial 339 | Epoch 02 | Train Loss: 14132.2470 | Val Loss: 16195.5272 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:36,585] Trial 340 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 340 | Epoch 01 | Train Loss: 18404.1941 | Val Loss: 13913.5645 | Optimizer: Adam\n",
      "Trial 340 | Epoch 02 | Train Loss: 12640.2830 | Val Loss: 11269.4477 | Optimizer: Adam\n",
      "Trial 341 | Epoch 01 | Train Loss: 107965.9051 | Val Loss: 9610.2575 | Optimizer: RMSprop\n",
      "Trial 341 | Epoch 02 | Train Loss: 51518.6682 | Val Loss: 13236.3948 | Optimizer: RMSprop\n",
      "Trial 341 | Epoch 03 | Train Loss: 12148.2209 | Val Loss: 7692.0583 | Optimizer: RMSprop\n",
      "Trial 341 | Epoch 04 | Train Loss: 9363.9900 | Val Loss: 7711.1998 | Optimizer: RMSprop\n",
      "Trial 341 | Epoch 05 | Train Loss: 7501.2783 | Val Loss: 6430.1023 | Optimizer: RMSprop\n",
      "Trial 341 | Epoch 06 | Train Loss: 6976.3883 | Val Loss: 6401.5633 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:37,350] Trial 341 pruned. \n",
      "[I 2025-09-04 20:35:37,462] Trial 342 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 341 | Epoch 07 | Train Loss: 8609.4319 | Val Loss: 7015.4189 | Optimizer: RMSprop\n",
      "Trial 342 | Epoch 01 | Train Loss: 19648.9333 | Val Loss: 17522.7031 | Optimizer: Adam\n",
      "Trial 343 | Epoch 01 | Train Loss: 18951.8885 | Val Loss: 14608.1682 | Optimizer: Adam\n",
      "Trial 343 | Epoch 02 | Train Loss: 10642.6378 | Val Loss: 10052.6486 | Optimizer: Adam\n",
      "Trial 343 | Epoch 03 | Train Loss: 9497.8011 | Val Loss: 8627.6077 | Optimizer: Adam\n",
      "Trial 343 | Epoch 04 | Train Loss: 8609.7481 | Val Loss: 6764.8873 | Optimizer: Adam\n",
      "Trial 343 | Epoch 05 | Train Loss: 7328.0948 | Val Loss: 6106.5075 | Optimizer: Adam\n",
      "Trial 343 | Epoch 06 | Train Loss: 7643.6763 | Val Loss: 5436.4359 | Optimizer: Adam\n",
      "Trial 343 | Epoch 07 | Train Loss: 6763.3790 | Val Loss: 6064.0347 | Optimizer: Adam\n",
      "Trial 343 | Epoch 08 | Train Loss: 6769.4500 | Val Loss: 5747.5116 | Optimizer: Adam\n",
      "Trial 343 | Epoch 09 | Train Loss: 6570.0638 | Val Loss: 5394.7232 | Optimizer: Adam\n",
      "Trial 343 | Epoch 10 | Train Loss: 6418.4072 | Val Loss: 5509.9580 | Optimizer: Adam\n",
      "Trial 343 | Epoch 11 | Train Loss: 6132.9988 | Val Loss: 5897.4487 | Optimizer: Adam\n",
      "Trial 343 | Epoch 12 | Train Loss: 6051.9184 | Val Loss: 5547.9376 | Optimizer: Adam\n",
      "Trial 343 | Epoch 13 | Train Loss: 6304.7334 | Val Loss: 5292.4586 | Optimizer: Adam\n",
      "Trial 343 | Epoch 14 | Train Loss: 5956.9559 | Val Loss: 5734.3355 | Optimizer: Adam\n",
      "Trial 343 | Epoch 15 | Train Loss: 5772.9514 | Val Loss: 5583.4891 | Optimizer: Adam\n",
      "Trial 343 | Epoch 16 | Train Loss: 5645.0658 | Val Loss: 5078.8336 | Optimizer: Adam\n",
      "Trial 343 | Epoch 17 | Train Loss: 5451.8743 | Val Loss: 5054.3230 | Optimizer: Adam\n",
      "Trial 343 | Epoch 18 | Train Loss: 5613.5013 | Val Loss: 5902.3306 | Optimizer: Adam\n",
      "Trial 343 | Epoch 19 | Train Loss: 5687.6049 | Val Loss: 6879.5040 | Optimizer: Adam\n",
      "Trial 343 | Epoch 20 | Train Loss: 6400.2001 | Val Loss: 5322.2224 | Optimizer: Adam\n",
      "Trial 343 | Epoch 21 | Train Loss: 6642.9017 | Val Loss: 6016.8943 | Optimizer: Adam\n",
      "Trial 343 | Epoch 22 | Train Loss: 5795.2873 | Val Loss: 5565.9450 | Optimizer: Adam\n",
      "Trial 343 | Epoch 23 | Train Loss: 6784.3649 | Val Loss: 5058.9145 | Optimizer: Adam\n",
      "Trial 343 | Epoch 24 | Train Loss: 6591.9271 | Val Loss: 7056.5822 | Optimizer: Adam\n",
      "Trial 343 | Epoch 25 | Train Loss: 6047.3949 | Val Loss: 5021.4417 | Optimizer: Adam\n",
      "Trial 343 | Epoch 26 | Train Loss: 5349.8592 | Val Loss: 6042.1635 | Optimizer: Adam\n",
      "Trial 343 | Epoch 27 | Train Loss: 5708.7064 | Val Loss: 5101.2890 | Optimizer: Adam\n",
      "Trial 343 | Epoch 28 | Train Loss: 5615.0100 | Val Loss: 5526.7045 | Optimizer: Adam\n",
      "Trial 343 | Epoch 29 | Train Loss: 4934.4046 | Val Loss: 5022.4605 | Optimizer: Adam\n",
      "Trial 343 | Epoch 30 | Train Loss: 4979.0360 | Val Loss: 5136.6935 | Optimizer: Adam\n",
      "Trial 343 | Epoch 31 | Train Loss: 5129.6756 | Val Loss: 5274.7819 | Optimizer: Adam\n",
      "Trial 343 | Epoch 32 | Train Loss: 5154.9909 | Val Loss: 5988.9649 | Optimizer: Adam\n",
      "Trial 343 | Epoch 33 | Train Loss: 5263.0968 | Val Loss: 5251.7439 | Optimizer: Adam\n",
      "Trial 343 | Epoch 34 | Train Loss: 5260.0648 | Val Loss: 5406.3246 | Optimizer: Adam\n",
      "Trial 343 | Epoch 35 | Train Loss: 4816.7749 | Val Loss: 5108.2006 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:39,306] Trial 343 finished with value: 5021.441693900835 and parameters: {'gnn_dim': 512, 'hidden_dim': 384, 'dropout_rate': 0.3208273463190895, 'lr': 0.000920336120486832, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.938460113981291e-05}. Best is trial 221 with value: 4249.423654084158.\n",
      "[I 2025-09-04 20:35:39,427] Trial 344 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 343 - Early stopping triggered at epoch 35\n",
      "Trial 344 | Epoch 01 | Train Loss: 21435.0413 | Val Loss: 23246.5191 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:39,590] Trial 345 pruned. \n",
      "[I 2025-09-04 20:35:39,712] Trial 346 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 345 | Epoch 01 | Train Loss: 20101.8522 | Val Loss: 17566.9896 | Optimizer: Adam\n",
      "Trial 346 | Epoch 01 | Train Loss: 21113.4813 | Val Loss: 22734.5914 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:39,817] Trial 347 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 347 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 348 | Epoch 01 | Train Loss: 17157.3199 | Val Loss: 12168.0193 | Optimizer: Adam\n",
      "Trial 348 | Epoch 02 | Train Loss: 12227.9009 | Val Loss: 10925.3739 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:39,993] Trial 348 pruned. \n",
      "[I 2025-09-04 20:35:40,169] Trial 349 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 349 | Epoch 01 | Train Loss: 18753.1490 | Val Loss: 14814.1120 | Optimizer: Adam\n",
      "Trial 349 | Epoch 02 | Train Loss: 12498.6290 | Val Loss: 10853.5840 | Optimizer: Adam\n",
      "Trial 350 | Epoch 01 | Train Loss: 19045.0306 | Val Loss: 16356.5349 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:40,290] Trial 350 pruned. \n",
      "[I 2025-09-04 20:35:40,407] Trial 351 pruned. \n",
      "[I 2025-09-04 20:35:40,530] Trial 352 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 351 | Epoch 01 | Train Loss: 701587.9767 | Val Loss: 61781.7773 | Optimizer: RMSprop\n",
      "Trial 352 | Epoch 01 | Train Loss: 18817.9006 | Val Loss: 15923.0342 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:40,707] Trial 353 pruned. \n",
      "[I 2025-09-04 20:35:40,831] Trial 354 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 353 | Epoch 01 | Train Loss: 21503.7284 | Val Loss: 21927.9374 | Optimizer: Adam\n",
      "Trial 354 | Epoch 01 | Train Loss: 19364.1926 | Val Loss: 15466.3540 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:41,061] Trial 355 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 355 | Epoch 01 | Train Loss: 18234.6396 | Val Loss: 14215.4093 | Optimizer: Adam\n",
      "Trial 355 | Epoch 02 | Train Loss: 12366.8359 | Val Loss: 10493.9948 | Optimizer: Adam\n",
      "Trial 355 | Epoch 03 | Train Loss: 10742.3624 | Val Loss: 11057.3926 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:41,175] Trial 356 pruned. \n",
      "[I 2025-09-04 20:35:41,300] Trial 357 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 356 | Epoch 01 | Train Loss: 19690.7434 | Val Loss: 18153.9370 | Optimizer: Adam\n",
      "Trial 357 | Epoch 01 | Train Loss: 19393.1573 | Val Loss: 16448.8647 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:41,423] Trial 358 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 358 | Epoch 01 | Train Loss: 19652.9641 | Val Loss: 18341.4778 | Optimizer: Adam\n",
      "Trial 359 | Epoch 01 | Train Loss: 20661.1683 | Val Loss: 19802.3607 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:41,591] Trial 359 pruned. \n",
      "[I 2025-09-04 20:35:41,716] Trial 360 pruned. \n",
      "[I 2025-09-04 20:35:41,836] Trial 361 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 360 | Epoch 01 | Train Loss: 9975283.4369 | Val Loss: 172165.8373 | Optimizer: RMSprop\n",
      "Trial 361 | Epoch 01 | Train Loss: 21005.2190 | Val Loss: 22108.9173 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:42,075] Trial 362 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 362 | Epoch 01 | Train Loss: 17475.9597 | Val Loss: 14457.7914 | Optimizer: Adam\n",
      "Trial 362 | Epoch 02 | Train Loss: 11757.8874 | Val Loss: 10532.8473 | Optimizer: Adam\n",
      "Trial 362 | Epoch 03 | Train Loss: 10589.8241 | Val Loss: 11486.8578 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:42,202] Trial 363 pruned. \n",
      "[I 2025-09-04 20:35:42,330] Trial 364 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 363 | Epoch 01 | Train Loss: 19015.5096 | Val Loss: 15942.0626 | Optimizer: Adam\n",
      "Trial 364 | Epoch 01 | Train Loss: 20577.8593 | Val Loss: 20476.2387 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:42,450] Trial 365 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 365 | Epoch 01 | Train Loss: 20368.2331 | Val Loss: 19666.0689 | Optimizer: Adam\n",
      "Trial 366 | Epoch 01 | Train Loss: 18472.6971 | Val Loss: 11969.3355 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:42,696] Trial 366 pruned. \n",
      "[I 2025-09-04 20:35:42,821] Trial 367 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 366 | Epoch 02 | Train Loss: 13803.9936 | Val Loss: 15920.2018 | Optimizer: Adam\n",
      "Trial 367 | Epoch 01 | Train Loss: 20650.3800 | Val Loss: 19451.0179 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:42,943] Trial 368 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 368 | Epoch 01 | Train Loss: 5793560.8675 | Val Loss: 58124.8335 | Optimizer: RMSprop\n",
      "Trial 369 | Epoch 01 | Train Loss: 17609.9860 | Val Loss: 11850.3638 | Optimizer: Adam\n",
      "Trial 369 | Epoch 02 | Train Loss: 14035.5548 | Val Loss: 10973.6800 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:43,119] Trial 369 pruned. \n",
      "[I 2025-09-04 20:35:43,235] Trial 370 pruned. \n",
      "[I 2025-09-04 20:35:43,352] Trial 371 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 370 | Epoch 01 | Train Loss: 19157.1749 | Val Loss: 16606.9969 | Optimizer: Adam\n",
      "Trial 371 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 372 | Epoch 01 | Train Loss: 17820.2841 | Val Loss: 12995.6204 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 02 | Train Loss: 11886.1671 | Val Loss: 10513.2633 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 03 | Train Loss: 9319.9105 | Val Loss: 7426.8642 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 04 | Train Loss: 8328.2263 | Val Loss: 5888.5783 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 05 | Train Loss: 7517.9136 | Val Loss: 6827.2726 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 06 | Train Loss: 7367.6123 | Val Loss: 6147.1344 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 07 | Train Loss: 7099.5825 | Val Loss: 5653.6473 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 08 | Train Loss: 6290.1405 | Val Loss: 5421.9761 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 09 | Train Loss: 6224.6830 | Val Loss: 5842.4505 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 10 | Train Loss: 6025.4577 | Val Loss: 5393.7413 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 11 | Train Loss: 6493.9540 | Val Loss: 5311.6463 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 12 | Train Loss: 5941.1242 | Val Loss: 6774.1533 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 13 | Train Loss: 6710.0204 | Val Loss: 6846.6817 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 14 | Train Loss: 6069.4162 | Val Loss: 5418.7395 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 15 | Train Loss: 5572.0296 | Val Loss: 5173.8972 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 16 | Train Loss: 5250.5283 | Val Loss: 5762.3805 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 17 | Train Loss: 5287.9463 | Val Loss: 5397.6791 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 18 | Train Loss: 5104.3299 | Val Loss: 5372.5948 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 19 | Train Loss: 5652.2164 | Val Loss: 5299.1111 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 20 | Train Loss: 4994.0644 | Val Loss: 5571.4499 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 21 | Train Loss: 4813.8414 | Val Loss: 5150.8950 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 22 | Train Loss: 5793.6723 | Val Loss: 5329.2148 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 23 | Train Loss: 5252.9879 | Val Loss: 5321.4983 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 24 | Train Loss: 5071.2894 | Val Loss: 5570.0922 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 25 | Train Loss: 4996.5206 | Val Loss: 5477.4639 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 26 | Train Loss: 5076.4979 | Val Loss: 5542.9345 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 27 | Train Loss: 5187.4349 | Val Loss: 5396.3554 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 28 | Train Loss: 4840.5651 | Val Loss: 5580.7635 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 29 | Train Loss: 4533.3888 | Val Loss: 5107.0290 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 30 | Train Loss: 5037.8023 | Val Loss: 5307.5040 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 31 | Train Loss: 5020.1162 | Val Loss: 7999.6284 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 32 | Train Loss: 6274.7631 | Val Loss: 6063.4756 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 33 | Train Loss: 5705.5780 | Val Loss: 5803.6884 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 34 | Train Loss: 5147.2275 | Val Loss: 5666.7922 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 35 | Train Loss: 5053.6879 | Val Loss: 5229.3091 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 36 | Train Loss: 4480.5915 | Val Loss: 5448.6588 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:46,387] Trial 372 finished with value: 5107.029045482674 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33808175396315826, 'lr': 0.0008559518199889417, 'activation': 'Swish', 'optimizer': 'AdamW', 'weight_decay': 6.850562838407049e-06}. Best is trial 221 with value: 4249.423654084158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 372 | Epoch 37 | Train Loss: 5179.8517 | Val Loss: 5454.0453 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 38 | Train Loss: 5221.6319 | Val Loss: 6873.4815 | Optimizer: AdamW\n",
      "Trial 372 | Epoch 39 | Train Loss: 5250.8530 | Val Loss: 6098.5938 | Optimizer: AdamW\n",
      "Trial 372 - Early stopping triggered at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:46,515] Trial 373 pruned. \n",
      "[I 2025-09-04 20:35:46,631] Trial 374 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 373 | Epoch 01 | Train Loss: 21074.3973 | Val Loss: 22666.5698 | Optimizer: Adam\n",
      "Trial 374 | Epoch 01 | Train Loss: 19712.7406 | Val Loss: 18192.6454 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:46,758] Trial 375 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 375 | Epoch 01 | Train Loss: 21416.9455 | Val Loss: 23171.0167 | Optimizer: Adam\n",
      "Trial 376 | Epoch 01 | Train Loss: 18204.4337 | Val Loss: 13454.8630 | Optimizer: Adam\n",
      "Trial 376 | Epoch 02 | Train Loss: 12348.8018 | Val Loss: 11278.3431 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:46,936] Trial 376 pruned. \n",
      "[I 2025-09-04 20:35:47,063] Trial 377 pruned. \n",
      "[I 2025-09-04 20:35:47,182] Trial 378 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 377 | Epoch 01 | Train Loss: 19266.0428 | Val Loss: 17216.2001 | Optimizer: Adam\n",
      "Trial 378 | Epoch 01 | Train Loss: 18914.2117 | Val Loss: 16008.2824 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:47,309] Trial 379 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 379 | Epoch 01 | Train Loss: 19736.8421 | Val Loss: 18646.5059 | Optimizer: RMSprop\n",
      "Trial 380 | Epoch 01 | Train Loss: 19367.8216 | Val Loss: 11631.2995 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:47,551] Trial 380 pruned. \n",
      "[I 2025-09-04 20:35:47,679] Trial 381 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 380 | Epoch 02 | Train Loss: 14921.9288 | Val Loss: 15654.8627 | Optimizer: Adam\n",
      "Trial 381 | Epoch 01 | Train Loss: 19596.5480 | Val Loss: 15965.8664 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:47,804] Trial 382 pruned. \n",
      "[I 2025-09-04 20:35:47,925] Trial 383 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 382 | Epoch 01 | Train Loss: 20611.9267 | Val Loss: 19692.1711 | Optimizer: Adam\n",
      "Trial 383 | Epoch 01 | Train Loss: 19984.8108 | Val Loss: 18418.4393 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:48,056] Trial 384 pruned. \n",
      "[I 2025-09-04 20:35:48,193] Trial 385 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 384 | Epoch 01 | Train Loss: 19158.7118 | Val Loss: 15587.1392 | Optimizer: AdamW\n",
      "Trial 385 | Epoch 01 | Train Loss: 20140.9543 | Val Loss: 19193.5117 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:48,385] Trial 386 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 386 | Epoch 01 | Train Loss: 20830.8437 | Val Loss: 21049.7663 | Optimizer: Adam\n",
      "Trial 387 | Epoch 01 | Train Loss: 18673.7857 | Val Loss: 14693.8187 | Optimizer: Adam\n",
      "Trial 387 | Epoch 02 | Train Loss: 11625.4773 | Val Loss: 10763.8570 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:48,593] Trial 387 pruned. \n",
      "[I 2025-09-04 20:35:48,764] Trial 388 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 388 | Epoch 01 | Train Loss: 34328.1991 | Val Loss: 13467.3427 | Optimizer: RMSprop\n",
      "Trial 388 | Epoch 02 | Train Loss: 16676.3448 | Val Loss: 10867.2017 | Optimizer: RMSprop\n",
      "Trial 389 | Epoch 01 | Train Loss: 18550.4223 | Val Loss: 12629.1780 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:48,949] Trial 389 pruned. \n",
      "[I 2025-09-04 20:35:49,081] Trial 390 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 389 | Epoch 02 | Train Loss: 11121.0623 | Val Loss: 11153.8593 | Optimizer: Adam\n",
      "Trial 390 | Epoch 01 | Train Loss: 19298.0680 | Val Loss: 17231.0397 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:49,213] Trial 391 pruned. \n",
      "[I 2025-09-04 20:35:49,337] Trial 392 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 391 | Epoch 01 | Train Loss: 20370.5242 | Val Loss: 18817.5659 | Optimizer: Adam\n",
      "Trial 392 | Epoch 01 | Train Loss: 19181.8561 | Val Loss: 17242.1944 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:49,516] Trial 393 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 393 | Epoch 01 | Train Loss: 20339.3507 | Val Loss: 19845.3675 | Optimizer: Adam\n",
      "Trial 394 | Epoch 01 | Train Loss: 17860.2726 | Val Loss: 13608.5940 | Optimizer: Adam\n",
      "Trial 394 | Epoch 02 | Train Loss: 10900.4521 | Val Loss: 10081.7172 | Optimizer: Adam\n",
      "Trial 394 | Epoch 03 | Train Loss: 10437.2949 | Val Loss: 9219.6240 | Optimizer: Adam\n",
      "Trial 394 | Epoch 04 | Train Loss: 9027.0992 | Val Loss: 6867.7981 | Optimizer: Adam\n",
      "Trial 394 | Epoch 05 | Train Loss: 8111.5485 | Val Loss: 5602.5012 | Optimizer: Adam\n",
      "Trial 394 | Epoch 06 | Train Loss: 7323.8980 | Val Loss: 5906.1626 | Optimizer: Adam\n",
      "Trial 394 | Epoch 07 | Train Loss: 6746.4300 | Val Loss: 5410.0826 | Optimizer: Adam\n",
      "Trial 394 | Epoch 08 | Train Loss: 6616.7494 | Val Loss: 5395.4796 | Optimizer: Adam\n",
      "Trial 394 | Epoch 09 | Train Loss: 6329.6802 | Val Loss: 6937.0925 | Optimizer: Adam\n",
      "Trial 394 | Epoch 10 | Train Loss: 6690.9340 | Val Loss: 5399.7156 | Optimizer: Adam\n",
      "Trial 394 | Epoch 11 | Train Loss: 6455.5440 | Val Loss: 5427.4452 | Optimizer: Adam\n",
      "Trial 394 | Epoch 12 | Train Loss: 5693.4780 | Val Loss: 5314.5629 | Optimizer: Adam\n",
      "Trial 394 | Epoch 13 | Train Loss: 5906.8773 | Val Loss: 5354.9741 | Optimizer: Adam\n",
      "Trial 394 | Epoch 14 | Train Loss: 5582.4843 | Val Loss: 5790.8772 | Optimizer: Adam\n",
      "Trial 394 | Epoch 15 | Train Loss: 5760.7579 | Val Loss: 6345.6943 | Optimizer: Adam\n",
      "Trial 394 | Epoch 16 | Train Loss: 6530.6131 | Val Loss: 6889.3046 | Optimizer: Adam\n",
      "Trial 394 | Epoch 17 | Train Loss: 5862.5508 | Val Loss: 5348.7791 | Optimizer: Adam\n",
      "Trial 394 | Epoch 18 | Train Loss: 6104.9727 | Val Loss: 5100.4854 | Optimizer: Adam\n",
      "Trial 394 | Epoch 19 | Train Loss: 6204.5791 | Val Loss: 6835.5440 | Optimizer: Adam\n",
      "Trial 394 | Epoch 20 | Train Loss: 6082.5673 | Val Loss: 5304.6888 | Optimizer: Adam\n",
      "Trial 394 | Epoch 21 | Train Loss: 5725.5471 | Val Loss: 6622.4509 | Optimizer: Adam\n",
      "Trial 394 | Epoch 22 | Train Loss: 5817.6009 | Val Loss: 5015.2278 | Optimizer: Adam\n",
      "Trial 394 | Epoch 23 | Train Loss: 5252.4327 | Val Loss: 5374.2201 | Optimizer: Adam\n",
      "Trial 394 | Epoch 24 | Train Loss: 5428.2134 | Val Loss: 5430.5218 | Optimizer: Adam\n",
      "Trial 394 | Epoch 25 | Train Loss: 5219.2308 | Val Loss: 5009.4354 | Optimizer: Adam\n",
      "Trial 394 | Epoch 26 | Train Loss: 5213.0834 | Val Loss: 5971.9266 | Optimizer: Adam\n",
      "Trial 394 | Epoch 27 | Train Loss: 4925.3524 | Val Loss: 5007.3234 | Optimizer: Adam\n",
      "Trial 394 | Epoch 28 | Train Loss: 5052.0312 | Val Loss: 5632.0965 | Optimizer: Adam\n",
      "Trial 394 | Epoch 29 | Train Loss: 5057.7637 | Val Loss: 5038.3183 | Optimizer: Adam\n",
      "Trial 394 | Epoch 30 | Train Loss: 4689.1586 | Val Loss: 5545.3015 | Optimizer: Adam\n",
      "Trial 394 | Epoch 31 | Train Loss: 5145.1716 | Val Loss: 5398.5843 | Optimizer: Adam\n",
      "Trial 394 | Epoch 32 | Train Loss: 5294.3469 | Val Loss: 5065.7198 | Optimizer: Adam\n",
      "Trial 394 | Epoch 33 | Train Loss: 4794.9599 | Val Loss: 4951.4701 | Optimizer: Adam\n",
      "Trial 394 | Epoch 34 | Train Loss: 4954.9738 | Val Loss: 5870.2664 | Optimizer: Adam\n",
      "Trial 394 | Epoch 35 | Train Loss: 4964.1462 | Val Loss: 5028.8886 | Optimizer: Adam\n",
      "Trial 394 | Epoch 36 | Train Loss: 4987.4351 | Val Loss: 5009.0304 | Optimizer: Adam\n",
      "Trial 394 | Epoch 37 | Train Loss: 4866.1619 | Val Loss: 5400.6374 | Optimizer: Adam\n",
      "Trial 394 | Epoch 38 | Train Loss: 4830.0088 | Val Loss: 5009.0830 | Optimizer: Adam\n",
      "Trial 394 | Epoch 39 | Train Loss: 4490.8981 | Val Loss: 5315.2758 | Optimizer: Adam\n",
      "Trial 394 | Epoch 40 | Train Loss: 4549.1858 | Val Loss: 4876.0757 | Optimizer: Adam\n",
      "Trial 394 | Epoch 41 | Train Loss: 4459.4214 | Val Loss: 4925.2577 | Optimizer: Adam\n",
      "Trial 394 | Epoch 42 | Train Loss: 4086.6967 | Val Loss: 5787.6739 | Optimizer: Adam\n",
      "Trial 394 | Epoch 43 | Train Loss: 4935.2512 | Val Loss: 4876.2930 | Optimizer: Adam\n",
      "Trial 394 | Epoch 44 | Train Loss: 4702.0692 | Val Loss: 4797.8169 | Optimizer: Adam\n",
      "Trial 394 | Epoch 45 | Train Loss: 5090.2518 | Val Loss: 6916.9085 | Optimizer: Adam\n",
      "Trial 394 | Epoch 46 | Train Loss: 5329.4759 | Val Loss: 5046.4955 | Optimizer: Adam\n",
      "Trial 394 | Epoch 47 | Train Loss: 4442.3813 | Val Loss: 6041.3744 | Optimizer: Adam\n",
      "Trial 394 | Epoch 48 | Train Loss: 4902.7929 | Val Loss: 5034.3642 | Optimizer: Adam\n",
      "Trial 394 | Epoch 49 | Train Loss: 4550.6277 | Val Loss: 4906.5516 | Optimizer: Adam\n",
      "Trial 394 | Epoch 50 | Train Loss: 4519.1701 | Val Loss: 5445.0807 | Optimizer: Adam\n",
      "Trial 394 | Epoch 51 | Train Loss: 4627.1694 | Val Loss: 4939.2056 | Optimizer: Adam\n",
      "Trial 394 | Epoch 52 | Train Loss: 4784.0181 | Val Loss: 5243.9740 | Optimizer: Adam\n",
      "Trial 394 | Epoch 53 | Train Loss: 4324.5351 | Val Loss: 4975.9903 | Optimizer: Adam\n",
      "Trial 394 | Epoch 54 | Train Loss: 4492.1594 | Val Loss: 4788.2006 | Optimizer: Adam\n",
      "Trial 394 | Epoch 55 | Train Loss: 4333.2932 | Val Loss: 5095.9785 | Optimizer: Adam\n",
      "Trial 394 | Epoch 56 | Train Loss: 4167.6336 | Val Loss: 4858.3029 | Optimizer: Adam\n",
      "Trial 394 | Epoch 57 | Train Loss: 4136.5864 | Val Loss: 4887.9381 | Optimizer: Adam\n",
      "Trial 394 | Epoch 58 | Train Loss: 4316.8151 | Val Loss: 5079.7176 | Optimizer: Adam\n",
      "Trial 394 | Epoch 59 | Train Loss: 4296.0587 | Val Loss: 4844.0133 | Optimizer: Adam\n",
      "Trial 394 | Epoch 60 | Train Loss: 3978.2904 | Val Loss: 5195.6524 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:52,938] Trial 394 finished with value: 4788.200620745668 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.2520264002619727, 'lr': 0.0008135832220916303, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.4712274010837464e-05}. Best is trial 221 with value: 4249.423654084158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 394 | Epoch 61 | Train Loss: 4324.6513 | Val Loss: 5049.9887 | Optimizer: Adam\n",
      "Trial 394 | Epoch 62 | Train Loss: 4429.3104 | Val Loss: 4854.9375 | Optimizer: Adam\n",
      "Trial 394 | Epoch 63 | Train Loss: 4046.8889 | Val Loss: 5339.5127 | Optimizer: Adam\n",
      "Trial 394 | Epoch 64 | Train Loss: 4313.3451 | Val Loss: 5060.8941 | Optimizer: Adam\n",
      "Trial 394 - Early stopping triggered at epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:53,076] Trial 395 pruned. \n",
      "[I 2025-09-04 20:35:53,208] Trial 396 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 395 | Epoch 01 | Train Loss: 18929.3486 | Val Loss: 15103.7570 | Optimizer: Adam\n",
      "Trial 396 | Epoch 01 | Train Loss: 19329.5415 | Val Loss: 16373.0681 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:53,399] Trial 397 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 397 | Epoch 01 | Train Loss: 18171.0367 | Val Loss: 13023.3015 | Optimizer: Adam\n",
      "Trial 397 | Epoch 02 | Train Loss: 11807.6587 | Val Loss: 10796.2171 | Optimizer: Adam\n",
      "Trial 398 | Epoch 01 | Train Loss: 18197.0452 | Val Loss: 14849.9131 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:53,525] Trial 398 pruned. \n",
      "[I 2025-09-04 20:35:53,663] Trial 399 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 399 | Epoch 01 | Train Loss: 19266.1021 | Val Loss: 16682.0955 | Optimizer: Adam\n",
      "Trial 400 | Epoch 01 | Train Loss: 18957.6178 | Val Loss: 13699.4673 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:53,918] Trial 400 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 400 | Epoch 02 | Train Loss: 11962.4380 | Val Loss: 12691.1211 | Optimizer: Adam\n",
      "Trial 401 | Epoch 01 | Train Loss: 18839.0906 | Val Loss: 14078.4430 | Optimizer: Adam\n",
      "Trial 401 | Epoch 02 | Train Loss: 12348.9476 | Val Loss: 11277.0792 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:54,109] Trial 401 pruned. \n",
      "[I 2025-09-04 20:35:54,229] Trial 402 pruned. \n",
      "[I 2025-09-04 20:35:54,356] Trial 403 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 402 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 403 | Epoch 01 | Train Loss: 21099.8605 | Val Loss: 21469.6895 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:54,488] Trial 404 pruned. \n",
      "[I 2025-09-04 20:35:54,624] Trial 405 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 404 | Epoch 01 | Train Loss: 20729.8425 | Val Loss: 20201.1165 | Optimizer: Adam\n",
      "Trial 405 | Epoch 01 | Train Loss: 236210.5991 | Val Loss: 162385.4203 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:54,812] Trial 406 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 406 | Epoch 01 | Train Loss: 17569.4359 | Val Loss: 13503.8369 | Optimizer: Adam\n",
      "Trial 406 | Epoch 02 | Train Loss: 11735.4642 | Val Loss: 10756.9110 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:55,063] Trial 407 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 407 | Epoch 01 | Train Loss: 18044.2811 | Val Loss: 13640.0002 | Optimizer: Adam\n",
      "Trial 407 | Epoch 02 | Train Loss: 12688.0239 | Val Loss: 12955.7217 | Optimizer: Adam\n",
      "Trial 408 | Epoch 01 | Train Loss: 18918.0588 | Val Loss: 15966.8374 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:55,184] Trial 408 pruned. \n",
      "[I 2025-09-04 20:35:55,312] Trial 409 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 409 | Epoch 01 | Train Loss: 20140.1096 | Val Loss: 19027.6168 | Optimizer: Adam\n",
      "Trial 410 | Epoch 01 | Train Loss: 18468.2958 | Val Loss: 13428.7532 | Optimizer: Adam\n",
      "Trial 410 | Epoch 02 | Train Loss: 11823.3085 | Val Loss: 11479.4512 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:55,494] Trial 410 pruned. \n",
      "[I 2025-09-04 20:35:55,620] Trial 411 pruned. \n",
      "[I 2025-09-04 20:35:55,744] Trial 412 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 411 | Epoch 01 | Train Loss: 19012.4616 | Val Loss: 16174.9650 | Optimizer: Adam\n",
      "Trial 412 | Epoch 01 | Train Loss: 18518.1252 | Val Loss: 15161.2327 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:55,875] Trial 413 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 413 | Epoch 01 | Train Loss: 19146.4659 | Val Loss: 15481.4427 | Optimizer: Adam\n",
      "Trial 414 | Epoch 01 | Train Loss: 703896439.6670 | Val Loss: 29844993804.6733 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:56,046] Trial 414 pruned. \n",
      "[I 2025-09-04 20:35:56,178] Trial 415 pruned. \n",
      "[I 2025-09-04 20:35:56,306] Trial 416 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 415 | Epoch 01 | Train Loss: 19917.3398 | Val Loss: 18348.4812 | Optimizer: Adam\n",
      "Trial 416 | Epoch 01 | Train Loss: 21586.0012 | Val Loss: 23179.8789 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:56,479] Trial 417 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 417 | Epoch 01 | Train Loss: 18688.0065 | Val Loss: 14535.2483 | Optimizer: Adam\n",
      "Trial 417 | Epoch 02 | Train Loss: 12908.8159 | Val Loss: 10606.6252 | Optimizer: Adam\n",
      "Trial 418 | Epoch 01 | Train Loss: 19802.9488 | Val Loss: 19037.3976 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:56,608] Trial 418 pruned. \n",
      "[I 2025-09-04 20:35:56,740] Trial 419 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 419 | Epoch 01 | Train Loss: 19259.0210 | Val Loss: 16528.8912 | Optimizer: Adam\n",
      "Trial 420 | Epoch 01 | Train Loss: 21627.9764 | Val Loss: 23514.0038 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:56,913] Trial 420 pruned. \n",
      "[I 2025-09-04 20:35:57,040] Trial 421 pruned. \n",
      "[I 2025-09-04 20:35:57,178] Trial 422 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 421 | Epoch 01 | Train Loss: 80456.8671 | Val Loss: 18449.1610 | Optimizer: RMSprop\n",
      "Trial 422 | Epoch 01 | Train Loss: 19290.5015 | Val Loss: 15761.5862 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:57,313] Trial 423 pruned. \n",
      "[I 2025-09-04 20:35:57,457] Trial 424 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 423 | Epoch 01 | Train Loss: 19580.0654 | Val Loss: 16515.7253 | Optimizer: Adam\n",
      "Trial 424 | Epoch 01 | Train Loss: 18752.8307 | Val Loss: 15958.8207 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:57,601] Trial 425 pruned. \n",
      "[I 2025-09-04 20:35:57,735] Trial 426 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 425 | Epoch 01 | Train Loss: 19884.7024 | Val Loss: 18091.8467 | Optimizer: Adam\n",
      "Trial 426 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:58,054] Trial 427 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 427 | Epoch 01 | Train Loss: 19389.0900 | Val Loss: 12143.5305 | Optimizer: Adam\n",
      "Trial 427 | Epoch 02 | Train Loss: 13224.5253 | Val Loss: 13936.4455 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:58,255] Trial 428 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 428 | Epoch 01 | Train Loss: 17742.6041 | Val Loss: 13319.6663 | Optimizer: Adam\n",
      "Trial 428 | Epoch 02 | Train Loss: 11399.8707 | Val Loss: 10582.2438 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:58,461] Trial 429 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 429 | Epoch 01 | Train Loss: 20630.0212 | Val Loss: 22294.2065 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:58,718] Trial 430 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 430 | Epoch 01 | Train Loss: 21415.8646 | Val Loss: 23399.3440 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:58,993] Trial 431 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 431 | Epoch 01 | Train Loss: 29319329.2313 | Val Loss: 31492.6737 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:59,330] Trial 432 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 432 | Epoch 01 | Train Loss: 19381.4077 | Val Loss: 17022.5626 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:35:59,872] Trial 433 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 433 | Epoch 01 | Train Loss: 17933.6734 | Val Loss: 13472.8610 | Optimizer: Adam\n",
      "Trial 433 | Epoch 02 | Train Loss: 11797.1035 | Val Loss: 10489.3899 | Optimizer: Adam\n",
      "Trial 433 | Epoch 03 | Train Loss: 10875.4897 | Val Loss: 11722.4952 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:00,046] Trial 434 pruned. \n",
      "[I 2025-09-04 20:36:00,161] Trial 435 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 434 | Epoch 01 | Train Loss: 20984.5161 | Val Loss: 22177.7900 | Optimizer: Adam\n",
      "Trial 435 | Epoch 01 | Train Loss: 20138.9747 | Val Loss: 20022.8241 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:00,343] Trial 436 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 436 | Epoch 01 | Train Loss: 19042.2466 | Val Loss: 14288.3048 | Optimizer: Adam\n",
      "Trial 436 | Epoch 02 | Train Loss: 12972.0876 | Val Loss: 11723.8465 | Optimizer: Adam\n",
      "Trial 437 | Epoch 01 | Train Loss: 19541.2688 | Val Loss: 17728.8193 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:00,477] Trial 437 pruned. \n",
      "[I 2025-09-04 20:36:00,608] Trial 438 pruned. \n",
      "[I 2025-09-04 20:36:00,729] Trial 439 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 438 | Epoch 01 | Train Loss: 18851.2600 | Val Loss: 15385.5363 | Optimizer: Adam\n",
      "Trial 439 | Epoch 01 | Train Loss: 39704.0505 | Val Loss: 14998.8276 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:00,859] Trial 440 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 440 | Epoch 01 | Train Loss: 18648.9324 | Val Loss: 16008.3112 | Optimizer: Adam\n",
      "Trial 441 | Epoch 01 | Train Loss: 18099.4408 | Val Loss: 19483.9197 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:01,033] Trial 441 pruned. \n",
      "[I 2025-09-04 20:36:01,170] Trial 442 pruned. \n",
      "[I 2025-09-04 20:36:01,306] Trial 443 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 442 | Epoch 01 | Train Loss: 19157.5596 | Val Loss: 16369.1400 | Optimizer: Adam\n",
      "Trial 443 | Epoch 01 | Train Loss: 18967.8583 | Val Loss: 14932.6299 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:01,434] Trial 444 pruned. \n",
      "[I 2025-09-04 20:36:01,572] Trial 445 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 444 | Epoch 01 | Train Loss: 20402.9820 | Val Loss: 18325.6501 | Optimizer: Adam\n",
      "Trial 445 | Epoch 01 | Train Loss: 20061.4656 | Val Loss: 18394.6755 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:01,774] Trial 446 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 446 | Epoch 01 | Train Loss: 18424.9197 | Val Loss: 14423.3912 | Optimizer: Adam\n",
      "Trial 446 | Epoch 02 | Train Loss: 12908.1579 | Val Loss: 10635.6342 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:01,970] Trial 447 pruned. \n",
      "[I 2025-09-04 20:36:02,106] Trial 448 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 447 | Epoch 01 | Train Loss: 20325.0845 | Val Loss: 15925.7036 | Optimizer: Adam\n",
      "Trial 448 | Epoch 01 | Train Loss: 5319058.0110 | Val Loss: 20749.1114 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:02,275] Trial 449 pruned. \n",
      "[I 2025-09-04 20:36:02,389] Trial 450 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 449 | Epoch 01 | Train Loss: 18202.5000 | Val Loss: 14428.0144 | Optimizer: Adam\n",
      "Trial 449 | Epoch 02 | Train Loss: 12048.6979 | Val Loss: 11153.0218 | Optimizer: Adam\n",
      "Trial 450 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:02,528] Trial 451 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 451 | Epoch 01 | Train Loss: 19829.7185 | Val Loss: 15931.1745 | Optimizer: Adam\n",
      "Trial 452 | Epoch 01 | Train Loss: 18321.9224 | Val Loss: 12660.7714 | Optimizer: Adam\n",
      "Trial 452 | Epoch 02 | Train Loss: 11506.3137 | Val Loss: 10990.7985 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:02,708] Trial 452 pruned. \n",
      "[I 2025-09-04 20:36:02,830] Trial 453 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 453 | Epoch 01 | Train Loss: 19859.2310 | Val Loss: 18899.7185 | Optimizer: Adam\n",
      "Trial 454 | Epoch 01 | Train Loss: 18251.3465 | Val Loss: 15250.5499 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:03,006] Trial 454 pruned. \n",
      "[I 2025-09-04 20:36:03,136] Trial 455 pruned. \n",
      "[I 2025-09-04 20:36:03,263] Trial 456 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 455 | Epoch 01 | Train Loss: 19849.1446 | Val Loss: 18389.9367 | Optimizer: Adam\n",
      "Trial 456 | Epoch 01 | Train Loss: 19430.5149 | Val Loss: 17601.7528 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:03,391] Trial 457 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 457 | Epoch 01 | Train Loss: 872086.7963 | Val Loss: 131557.5065 | Optimizer: RMSprop\n",
      "Trial 458 | Epoch 01 | Train Loss: 18826.4021 | Val Loss: 14694.2430 | Optimizer: Adam\n",
      "Trial 458 | Epoch 02 | Train Loss: 12852.1021 | Val Loss: 10706.8711 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:03,561] Trial 458 pruned. \n",
      "[I 2025-09-04 20:36:03,690] Trial 459 pruned. \n",
      "[I 2025-09-04 20:36:03,815] Trial 460 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 459 | Epoch 01 | Train Loss: 20269.2525 | Val Loss: 18879.8728 | Optimizer: Adam\n",
      "Trial 460 | Epoch 01 | Train Loss: 18759.8212 | Val Loss: 15453.7836 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:04,114] Trial 461 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 461 | Epoch 01 | Train Loss: 19164.4363 | Val Loss: 12932.9583 | Optimizer: Adam\n",
      "Trial 461 | Epoch 02 | Train Loss: 11564.1851 | Val Loss: 12805.2835 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:04,288] Trial 462 pruned. \n",
      "[I 2025-09-04 20:36:04,405] Trial 463 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 462 | Epoch 01 | Train Loss: 18548.1534 | Val Loss: 13622.6252 | Optimizer: Adam\n",
      "Trial 462 | Epoch 02 | Train Loss: 12996.2833 | Val Loss: 11526.0143 | Optimizer: Adam\n",
      "Trial 463 | Epoch 01 | Train Loss: 19439.3468 | Val Loss: 17814.4420 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:04,534] Trial 464 pruned. \n",
      "[I 2025-09-04 20:36:04,659] Trial 465 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 464 | Epoch 01 | Train Loss: 19404.8296 | Val Loss: 15928.2668 | Optimizer: Adam\n",
      "Trial 465 | Epoch 01 | Train Loss: 19607.2243 | Val Loss: 15587.2540 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:04,916] Trial 466 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 466 | Epoch 01 | Train Loss: 3307318.1757 | Val Loss: 11646.5132 | Optimizer: RMSprop\n",
      "Trial 466 | Epoch 02 | Train Loss: 10069.0673 | Val Loss: 9338.5794 | Optimizer: RMSprop\n",
      "Trial 466 | Epoch 03 | Train Loss: 10088.4850 | Val Loss: 9413.1234 | Optimizer: RMSprop\n",
      "Trial 466 | Epoch 04 | Train Loss: 9281.1436 | Val Loss: 8440.2633 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:05,041] Trial 467 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 467 | Epoch 01 | Train Loss: 20083.6813 | Val Loss: 16781.8441 | Optimizer: Adam\n",
      "Trial 468 | Epoch 01 | Train Loss: 21073.7901 | Val Loss: 22472.5734 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:05,219] Trial 468 pruned. \n",
      "[I 2025-09-04 20:36:05,380] Trial 469 pruned. \n",
      "[I 2025-09-04 20:36:05,506] Trial 470 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 469 | Epoch 01 | Train Loss: 21110.7289 | Val Loss: 21833.6335 | Optimizer: Adam\n",
      "Trial 470 | Epoch 01 | Train Loss: 20289.9496 | Val Loss: 19963.4711 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:05,672] Trial 471 pruned. \n",
      "[I 2025-09-04 20:36:05,782] Trial 472 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 471 | Epoch 01 | Train Loss: 17537.2070 | Val Loss: 12578.6664 | Optimizer: Adam\n",
      "Trial 471 | Epoch 02 | Train Loss: 12298.0718 | Val Loss: 10812.2043 | Optimizer: Adam\n",
      "Trial 472 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:05,929] Trial 473 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 473 | Epoch 01 | Train Loss: 18865.7396 | Val Loss: 15160.4602 | Optimizer: Adam\n",
      "Trial 474 | Epoch 01 | Train Loss: 21096.1636 | Val Loss: 22386.2022 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:06,127] Trial 474 pruned. \n",
      "[I 2025-09-04 20:36:06,265] Trial 475 pruned. \n",
      "[I 2025-09-04 20:36:06,394] Trial 476 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 475 | Epoch 01 | Train Loss: 36644.9576 | Val Loss: 20187.8316 | Optimizer: RMSprop\n",
      "Trial 476 | Epoch 01 | Train Loss: 19763.2062 | Val Loss: 18030.8317 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:06,606] Trial 477 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 477 | Epoch 01 | Train Loss: 16795.7956 | Val Loss: 11544.4235 | Optimizer: Adam\n",
      "Trial 477 | Epoch 02 | Train Loss: 12158.7077 | Val Loss: 11569.4998 | Optimizer: Adam\n",
      "Trial 478 | Epoch 01 | Train Loss: 19476.6138 | Val Loss: 18499.4220 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:06,748] Trial 478 pruned. \n",
      "[I 2025-09-04 20:36:06,889] Trial 479 pruned. \n",
      "[I 2025-09-04 20:36:07,021] Trial 480 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 479 | Epoch 01 | Train Loss: 21708.6806 | Val Loss: 23407.1463 | Optimizer: Adam\n",
      "Trial 480 | Epoch 01 | Train Loss: 19397.9228 | Val Loss: 16252.1437 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:07,326] Trial 481 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 481 | Epoch 01 | Train Loss: 19317.2519 | Val Loss: 11834.8328 | Optimizer: Adam\n",
      "Trial 481 | Epoch 02 | Train Loss: 12715.8042 | Val Loss: 13949.6765 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:07,460] Trial 482 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 482 | Epoch 01 | Train Loss: 19883.3975 | Val Loss: 18199.5819 | Optimizer: Adam\n",
      "Trial 483 | Epoch 01 | Train Loss: 18741.9036 | Val Loss: 14040.2588 | Optimizer: Adam\n",
      "Trial 483 | Epoch 02 | Train Loss: 11380.6302 | Val Loss: 10400.5754 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:07,693] Trial 483 pruned. \n",
      "[I 2025-09-04 20:36:07,823] Trial 484 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 483 | Epoch 03 | Train Loss: 10379.7281 | Val Loss: 10006.2230 | Optimizer: Adam\n",
      "Trial 484 | Epoch 01 | Train Loss: 1252632.1483 | Val Loss: 36998.9511 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:07,945] Trial 485 pruned. \n",
      "[I 2025-09-04 20:36:08,076] Trial 486 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 485 | Epoch 01 | Train Loss: 18389.7767 | Val Loss: 16014.9848 | Optimizer: Adam\n",
      "Trial 486 | Epoch 01 | Train Loss: 19509.0375 | Val Loss: 15623.7081 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:08,205] Trial 487 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 487 | Epoch 01 | Train Loss: 18768.7078 | Val Loss: 14871.7887 | Optimizer: Adam\n",
      "Trial 488 | Epoch 01 | Train Loss: 20035.7323 | Val Loss: 15858.2837 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:08,374] Trial 488 pruned. \n",
      "[I 2025-09-04 20:36:08,504] Trial 489 pruned. \n",
      "[I 2025-09-04 20:36:08,630] Trial 490 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 489 | Epoch 01 | Train Loss: 20560.9169 | Val Loss: 20459.4926 | Optimizer: Adam\n",
      "Trial 490 | Epoch 01 | Train Loss: 21056.0320 | Val Loss: 21864.5906 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:08,762] Trial 491 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 491 | Epoch 01 | Train Loss: 21300.0610 | Val Loss: 21983.4394 | Optimizer: Adam\n",
      "Trial 492 | Epoch 01 | Train Loss: 77920.9543 | Val Loss: 14727.8385 | Optimizer: RMSprop\n",
      "Trial 492 | Epoch 02 | Train Loss: 11178.4241 | Val Loss: 8439.7723 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:09,096] Trial 492 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 492 | Epoch 03 | Train Loss: 8832.1855 | Val Loss: 9634.3849 | Optimizer: RMSprop\n",
      "Trial 492 | Epoch 04 | Train Loss: 8109.6631 | Val Loss: 6650.4762 | Optimizer: RMSprop\n",
      "Trial 492 | Epoch 05 | Train Loss: 7440.4774 | Val Loss: 6882.8250 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:09,283] Trial 493 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 493 | Epoch 01 | Train Loss: 17308.3831 | Val Loss: 12116.6147 | Optimizer: Adam\n",
      "Trial 493 | Epoch 02 | Train Loss: 12640.7111 | Val Loss: 11516.6889 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:09,544] Trial 494 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 494 | Epoch 01 | Train Loss: 20045.8096 | Val Loss: 13654.0815 | Optimizer: Adam\n",
      "Trial 494 | Epoch 02 | Train Loss: 11043.2513 | Val Loss: 13690.9196 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:09,733] Trial 495 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 495 | Epoch 01 | Train Loss: 18215.6809 | Val Loss: 13682.0238 | Optimizer: Adam\n",
      "Trial 495 | Epoch 02 | Train Loss: 11817.4289 | Val Loss: 10769.4536 | Optimizer: Adam\n",
      "Trial 496 | Epoch 01 | Train Loss: 21507.5969 | Val Loss: 23153.5264 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:09,878] Trial 496 pruned. \n",
      "[I 2025-09-04 20:36:10,023] Trial 497 pruned. \n",
      "[I 2025-09-04 20:36:10,169] Trial 498 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 497 | Epoch 01 | Train Loss: 20764.7208 | Val Loss: 20514.1548 | Optimizer: Adam\n",
      "Trial 498 | Epoch 01 | Train Loss: 19803.6913 | Val Loss: 17647.6809 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:36:10,298] Trial 499 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 499 | Epoch 01 | NaN loss detected so pruning trial\n",
      "{'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33402122608313956, 'lr': 0.0009940158933486353, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 7.475313105245206e-05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          8,
          11,
          14,
          16,
          17,
          20,
          25,
          31,
          35,
          41,
          42,
          50,
          53,
          55,
          62,
          71,
          73,
          81,
          93,
          94,
          111,
          116,
          121,
          122,
          151,
          155,
          187,
          212,
          215,
          221,
          235,
          239,
          245,
          334,
          343,
          372,
          394
         ],
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          5066.432979772587,
          4884.735221031869,
          4884.735221031869,
          4884.735221031869,
          4884.735221031869,
          4884.735221031869,
          4884.735221031869,
          4884.735221031869,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4846.0888671875,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4722.913093189201,
          4686.0540662708845,
          4686.0540662708845,
          4686.0540662708845,
          4686.0540662708845,
          4686.0540662708845,
          4686.0540662708845,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158,
          4249.423654084158
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "gnn_dim (CategoricalDistribution): 0.0048116942373506565<extra></extra>",
          "hidden_dim (CategoricalDistribution): 0.0193241791842472<extra></extra>",
          "weight_decay (FloatDistribution): 0.02492463441912253<extra></extra>",
          "dropout_rate (FloatDistribution): 0.031182159216136995<extra></extra>",
          "activation (CategoricalDistribution): 0.15885744242965927<extra></extra>",
          "lr (FloatDistribution): 0.3534557232577235<extra></extra>",
          "optimizer (CategoricalDistribution): 0.4074441672557598<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "0.02",
          "0.02",
          "0.03",
          "0.16",
          "0.35",
          "0.41"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0048116942373506565,
          0.0193241791842472,
          0.02492463441912253,
          0.031182159216136995,
          0.15885744242965927,
          0.3534557232577235,
          0.4074441672557598
         ],
         "y": [
          "gnn_dim",
          "hidden_dim",
          "weight_decay",
          "dropout_rate",
          "activation",
          "lr",
          "optimizer"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial0",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          24309.167175897277,
          23994.160059560643,
          23684.720664449258,
          23385.009959003713,
          23090.70387917698,
          22797.887550278465,
          22505.90683013614,
          22203.44848391089,
          21891.576519956685,
          21563.091120049507,
          21221.834525835395,
          20872.669651144803,
          20520.4864634901,
          20155.0743541151,
          19768.688505569306,
          19362.1463490099,
          18922.30600247525,
          18448.66868425124,
          17915.74948754641,
          17322.772267558787,
          16652.79389696782,
          15907.985999381188,
          15087.260577815594,
          14207.06745049505,
          13302.681911355197,
          12473.803546565594,
          11775.537873220916,
          11293.798402691831,
          11052.672049040842,
          10920.380898050742,
          10782.977597076115,
          10655.494701423268,
          10537.910049891709,
          10440.884224164603,
          10340.055789758664,
          10225.092183632425,
          10087.676516089108,
          9943.086266243812,
          9811.301284034653,
          9695.302618347772,
          9584.016301825495,
          9466.1826171875,
          9332.222153465347,
          9230.975170173268,
          9118.524839495669,
          8996.56258702042,
          8878.326481280941,
          8779.69282758354,
          8639.887279548268,
          8536.228941058169,
          8416.20891669245,
          8315.886820273825,
          8189.247539255879,
          8072.2685546875,
          7993.479032913057,
          7913.249772780013,
          7836.524554262067,
          7729.620499110458,
          7654.384929996906,
          7586.703637453589,
          7490.012066831683,
          7412.159958036819,
          7366.160625193379,
          7306.7715568920175,
          7274.207422841893,
          7240.938278349319,
          7233.943417388614,
          7164.220577428837,
          7108.840680112933,
          7064.66552734375,
          7041.682211092203,
          7008.015731358292,
          7017.932979772587,
          7027.350566599629,
          6980.517002823329,
          6940.714626198948,
          6910.334912592822,
          6881.246843092513,
          6837.270232247834,
          6836.001232789295,
          6837.062495165532,
          6808.924374419864,
          6792.754670095916,
          6798.449890741027,
          6772.900777382426,
          6761.9945177134905,
          6713.045356977104,
          6648.609481358292,
          6623.38445621906,
          6617.007343556621,
          6584.655988938737,
          6625.814607827971,
          6619.5697130259905,
          6600.734529702971,
          6532.308337523205,
          6484.439167891399,
          6458.3331190052595,
          6473.681360225866,
          6477.651014271349
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          22035.82841506807,
          21343.63205832302,
          20591.365447091583,
          19650.21904006807,
          18435.816019492573,
          16935.16101678527,
          15237.55257967203,
          13750.529035813737,
          12400.60629060953,
          11519.387221534653,
          11062.321540454826,
          10786.25570467203,
          10548.382358060026,
          10368.560672571164,
          10206.908464186263,
          10052.513855584777,
          9919.948561262376,
          9743.058738784035,
          9632.679126701732,
          9455.589099241955,
          9365.777401763615,
          9220.952138768564,
          9046.496142094678,
          8950.131487855817,
          8798.933361695545,
          8664.256197787747,
          8562.947903774753,
          8423.826065516709,
          8303.454038714419,
          8142.142418587562,
          7941.567518177599,
          7879.028890779703,
          7783.820244817451,
          7762.802652189047,
          7641.886254641089,
          7555.57470703125,
          7490.964737391708,
          7394.845084313119,
          7351.018535349629,
          7265.956059521968,
          7227.606774056312,
          7274.995803681931,
          7183.315627900681,
          7175.395749535891,
          7106.5488377939355,
          7095.568045134592,
          7053.770609336324,
          7021.680180615718,
          7021.557288443688,
          6973.958442914604,
          6992.193340037129,
          6993.600977529393,
          6913.161708114171,
          6933.390895730198,
          6905.8661384204825,
          6879.41011273979,
          6795.182791228342,
          6792.557868579826,
          6789.770324102723,
          6782.2045995126855,
          6761.044269221844,
          6797.536901492884,
          6784.793282990408,
          6751.887037824877,
          6710.594334970607,
          6707.336976910582,
          6626.605314047029,
          6666.127842667079,
          6637.833554107364,
          6684.956069190904,
          6656.035306118502,
          6656.72931331219,
          6560.835603921721,
          6600.695573561263,
          6522.2794080677595,
          6486.194524481745,
          6611.870958384901,
          6492.160059560643,
          6495.111632696473,
          6449.6395565826115,
          6480.179247563428,
          6497.4737246673885,
          6496.909348893873,
          6426.402015006188,
          6434.656172648515,
          6466.032163714418,
          6430.351905747215,
          6483.251986966275,
          6403.004075456373,
          6393.004650758045,
          6354.933811301052,
          6283.174620977723,
          6341.306616452661,
          6292.261264310025,
          6372.412766862623,
          6320.906834970607,
          6251.136767094678,
          6201.081407603651,
          6176.655341120049
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial2",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          20821.857015779704,
          17460.64424118193,
          11086.316464263615,
          10528.134214495669,
          10457.742728960397,
          9364.206712175124,
          7958.889029625619,
          7461.894482905322,
          7597.039579788057,
          6198.295922609839,
          6265.861482827971,
          5571.210067295792,
          5967.077660891089,
          5587.617670946782,
          5898.489813776299,
          6685.742820815285,
          5597.247442566522,
          6833.208375232054,
          5530.851697865099,
          5594.908072594369,
          5971.3309628326115,
          5337.4306543935645,
          5565.144081644493,
          5288.143235612623,
          5490.0975643951115,
          5457.518201771349,
          5487.567740563119,
          5105.842628403465,
          5363.073836827042,
          5161.180378828899,
          5066.432979772587,
          6126.677400796721,
          5089.496717396349,
          5200.8769434560645,
          5158.181287708849,
          5301.071709661201,
          5160.171812151918,
          5192.6358533802595,
          5102.484036587252,
          5158.26433903156,
          5188.993860225866
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial3",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "y": [
          23701.087987314357,
          11416.88718285891,
          22964.49793084777,
          23531.458578279704,
          23480.772431930694,
          23431.03664526609,
          23394.94438428218,
          23375.73302134901,
          23357.830290841583,
          23340.01877707302,
          23322.77312809406,
          23305.127185179455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial4",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          22499.79975634282,
          21774.788830445545,
          20995.70163598391,
          20076.881690903465,
          18806.398534189357,
          16841.404190516707,
          13810.801129331683,
          11053.754747447401,
          11195.304697168936,
          10394.484578047648,
          10384.970248685026,
          9835.221196240718,
          9270.091806543936,
          8702.214099241955,
          8173.025791885829,
          7813.728172377785,
          7687.607673267326,
          7288.272925046411,
          7080.807177250928,
          7053.3306775990095,
          6955.524878171411,
          6788.097404857674,
          6684.835884320854,
          6461.142834351795,
          6351.329024211015,
          6068.440642404084,
          6071.912873220916,
          5762.548252823329,
          5676.28191715656,
          5588.036195660582,
          5779.283846109221,
          5634.2921033802595,
          5603.774476910582,
          5859.865514774134,
          5990.889986850248,
          5645.032695505879,
          5699.870624806621,
          5712.776579904084,
          5573.323430731745,
          5699.215854153775,
          5493.312475827661,
          5529.096515315594,
          5569.9969977954825,
          5430.585076964728,
          5346.682868579826,
          5411.591564820545,
          5521.713707650062,
          5303.446748336943,
          5275.5570177134905,
          5336.441923538057,
          5454.827955793627,
          5279.723985728651,
          5233.00754660427,
          5372.87042659344,
          5291.614277150371,
          5090.704792891399,
          5543.712324992265,
          5488.629868309096,
          5137.231846573329,
          5445.2373046875,
          5221.159184521968,
          5098.424843363243,
          5570.4618222076115,
          5110.486139580755,
          5042.959598352413,
          5332.834197091584,
          5183.150066715656,
          5028.1165058400375,
          5141.691319229579,
          5143.939989750928,
          5259.466859723082,
          5176.9317131420175,
          5074.815995320235,
          5083.690453859839,
          5028.017911703279,
          5171.9196269724625,
          4996.458336556312,
          5318.884325688428,
          4971.021721263924,
          5142.0768535349625,
          4955.83478206219,
          5148.70676535427,
          5597.916228341584,
          5009.403523360149,
          5182.451007503094,
          5064.400086053527,
          4976.908420676052,
          5290.0869043935645,
          4884.735221031869,
          5186.637086169554,
          5114.841845219678,
          4901.161471225248,
          5251.153252629951,
          5003.300795753404,
          5155.361598855198,
          4953.66384011448,
          4913.088494933478,
          5000.8569239248145,
          5131.5078221689355
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial5",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22512.61896658416
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial6",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23147.74296101485
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial7",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60
         ],
         "y": [
          13247.20905205755,
          10872.791518409653,
          9473.493811881188,
          8720.474793084777,
          7851.288830445545,
          7265.374105623453,
          7014.547401956993,
          7810.563452390161,
          6790.021102452042,
          6780.491317295792,
          6528.855594446163,
          7043.498897741337,
          6702.365461594987,
          6150.876779084158,
          5898.5855604115095,
          6126.058680770421,
          5847.489852452042,
          6113.787733021349,
          5821.815100943688,
          5708.085802134901,
          5703.017926206683,
          5671.349657719678,
          5692.116829749381,
          5577.508953434406,
          5731.153151106127,
          6136.3222559560645,
          6449.200814124381,
          5610.055794593131,
          5658.742617767636,
          5456.7954198251855,
          6224.423272161201,
          5610.895962252475,
          5698.765325262995,
          5661.176008469987,
          5886.363377939357,
          5281.874709931931,
          5891.675118927908,
          5434.657584313119,
          5249.031946163366,
          5611.512187693379,
          5243.947159266708,
          5755.6531269337875,
          5264.841995088181,
          5206.131787592822,
          5390.814109877785,
          5213.807230430074,
          5171.988358601485,
          6264.102026608911,
          5334.207398669554,
          5153.819055538366,
          5425.6895449798885,
          5158.249753442141,
          5357.10746538521,
          5316.444930577042,
          5260.875062848082,
          5331.7870175201115,
          6437.205024945854,
          5368.332625889542,
          6584.173223816522,
          5183.996214611696
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial9",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23172.13356667698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial10",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23666.75570467203
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial11",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76
         ],
         "y": [
          21486.335434715347,
          19131.56025680693,
          15272.714118579826,
          11269.980323715965,
          10481.95667349938,
          10934.543577892946,
          9727.453250696164,
          8319.334777227723,
          7673.242641939975,
          7702.601934754022,
          6536.449354115099,
          6504.674229385829,
          5784.614910465656,
          5601.163757928527,
          5683.18332785427,
          5581.276091622834,
          5584.915285620359,
          5678.238257077661,
          5576.778436339728,
          5792.035692875928,
          5611.6752204517325,
          5736.191788172958,
          5444.5272712329825,
          5400.321545289295,
          5574.221892404084,
          5296.431993541151,
          5358.041876160272,
          5258.450910813737,
          5297.785286780631,
          5282.299543626237,
          5278.933308516399,
          5363.211981745049,
          5236.616960280013,
          5034.6308497060645,
          5550.7818494740095,
          5255.104946627475,
          5231.476891243812,
          5018.735037322092,
          5187.640789371906,
          5016.382092164295,
          5178.592260983911,
          5610.909015315594,
          4962.883774559096,
          5231.0449122060645,
          5081.812127745978,
          5364.168848623143,
          5033.206895884901,
          5161.523297300433,
          5279.796812151918,
          4951.553872892172,
          5438.2583104501855,
          4965.784020150062,
          5060.976335280013,
          5043.871059908725,
          4923.964147586634,
          5144.036940168627,
          5184.033710744121,
          4923.806633373299,
          5919.048233485458,
          5278.61958539604,
          5901.0527247060645,
          5039.001435836943,
          5487.44722211479,
          4956.941880027846,
          5183.526666924505,
          4846.0888671875,
          5292.4926854501855,
          4848.67827825263,
          5098.367385713181,
          4864.116496171101,
          4912.131821434096,
          4852.6674079517325,
          4991.649240021658,
          4906.112662438119,
          4851.424961807704,
          5349.623506149443
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial12",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22138.790918935643
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial13",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22592.37091970916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial14",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68
         ],
         "y": [
          20356.333326887376,
          15322.164284885519,
          11845.79086092203,
          11102.017520111385,
          9777.00239789604,
          8101.3998104888615,
          7615.9942324798885,
          7399.476378790223,
          5821.942793742265,
          6376.375106358292,
          5566.313592589728,
          6014.978317411819,
          5777.034363397277,
          5636.362918664913,
          5535.393955948329,
          5529.357165648205,
          5542.705107131807,
          5422.617990021658,
          5432.953289371906,
          5758.867593595297,
          5234.336251740408,
          5441.18035465656,
          5173.059227065285,
          5338.146136293317,
          5410.088930035582,
          5587.3362324025375,
          5312.71293413521,
          5128.895121055074,
          6993.8813379873145,
          5304.702346650681,
          6424.960647431931,
          5373.806664797339,
          5965.130322749072,
          5123.314844716893,
          5743.6088963876855,
          5052.526062616027,
          5201.252199682859,
          5170.518424156869,
          5468.412162554146,
          4992.977693765471,
          5332.952554532797,
          4984.767969716893,
          5485.500062848082,
          5008.381376663057,
          5015.8831074025375,
          5152.873530321782,
          5049.925147934715,
          6517.511259475557,
          5064.724933284344,
          5966.865205368193,
          4911.214065400681,
          4939.924297068379,
          4951.88405495823,
          5321.091144221844,
          5392.763961943069,
          4882.569505143873,
          5313.316749497215,
          4873.60986328125,
          5246.5352287670175,
          5024.16304242729,
          5078.746586865718,
          4918.220857827971,
          5134.448919012995,
          5011.909295714728,
          4952.672827390161,
          5464.434773360149,
          4976.410678372525,
          5198.868836053527
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial15",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          18247.925800587873,
          14238.923847462871,
          11399.460995513615,
          9661.097540222772,
          8089.353675162438,
          7970.885621325804,
          7565.673702428837,
          7004.086300085087,
          7122.698981861076,
          6754.483345258354,
          8024.949252591275,
          7551.8474628712875,
          6316.408551206683,
          7499.094107750619
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial16",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43
         ],
         "y": [
          18596.671855662127,
          10448.002823329209,
          10992.772828357054,
          8109.43967551052,
          8140.0062364634905,
          6103.601504486386,
          6773.386931466584,
          6044.405911587252,
          6804.1211856048885,
          5852.85622292698,
          6035.822217280322,
          5442.680920289295,
          6566.903890779703,
          5651.256502359221,
          6093.047087716584,
          5343.701017172029,
          5605.2323493579825,
          5314.179445776609,
          5373.902309908725,
          6366.122287863552,
          5169.009992844987,
          5492.833955368193,
          5282.897093517946,
          5198.7113339263615,
          6226.678696434096,
          5115.5760606822405,
          5437.381603883045,
          5307.314051864171,
          5902.073430731745,
          5153.797111888924,
          5136.496407990408,
          5359.098816522277,
          5087.837315323329,
          5340.635099203279,
          5567.572686223701,
          5149.419530283107,
          5240.309164217203,
          5660.904142172029,
          5124.447294631807,
          5137.709748220916,
          5733.665551516089,
          5310.411645266089,
          5422.936286548576
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial17",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51
         ],
         "y": [
          20551.397644647277,
          15308.717541383045,
          11992.817711556312,
          10551.920134591584,
          9587.708994043936,
          7715.469509011448,
          7776.244430693069,
          6998.5405370126855,
          5938.163090771968,
          6196.947318804146,
          5495.2161152150375,
          5874.60085183323,
          5719.932713876857,
          5943.2505994740095,
          5519.149215849319,
          5757.170153929455,
          5602.608055190285,
          5734.477263497834,
          5440.017732827971,
          5437.92356222927,
          5564.495175201114,
          5200.147605971535,
          6109.2104588876855,
          5288.5814317759905,
          5422.796768641708,
          6148.198416228342,
          5153.85284846844,
          5972.586121209777,
          5365.500725170174,
          5147.083916692451,
          5586.992554919554,
          5187.798378519493,
          5567.929121867265,
          5048.575925317141,
          5119.093198870668,
          5250.734254138304,
          5095.768796410891,
          5726.285001547029,
          5054.070447865099,
          5547.449658686572,
          4976.4566154857675,
          5234.396919477104,
          4986.083206025681,
          5190.288027923886,
          5051.852481048886,
          5405.845069809715,
          5103.943436726485,
          5106.901932820235,
          5178.832214959777,
          5005.053227490718,
          5053.423987662438
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial18",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          2677134581771031
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial19",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          21025.77268332302,
          16475.924620977723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial20",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          15961.64482131807,
          10400.312084235768,
          8939.21815052599,
          6951.928430538366,
          5474.022620474938,
          5588.662085202661,
          6039.618280089728,
          8396.152309908724,
          5710.495416924505,
          6354.534948367884,
          5849.997573097154,
          5303.8291934173885,
          5878.929905051052,
          5293.425138265779,
          5456.7934473623145,
          5166.774863668007,
          5220.792992922339,
          6130.759649597772,
          5482.0064201732675,
          5505.916740795174,
          6322.652348584468,
          5207.926656288676,
          5750.636883121906,
          5107.397784846844,
          5053.204797725866,
          5105.699049543627,
          5427.505888381807,
          5988.775342280322,
          5203.731348623143,
          5150.032564975248,
          7126.92409402073,
          5067.661563080136,
          5871.153470181002,
          5060.988044361076,
          5074.823295366646
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial21",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22424.12033957302
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial22",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22799.51982131807
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial23",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21565.17394415223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial24",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23213.284344059404
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial25",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52
         ],
         "y": [
          18581.219542852723,
          11100.699383121906,
          11078.41346302599,
          10964.98031404703,
          8120.223444268255,
          6995.356633856745,
          6029.350315207302,
          5786.01096457302,
          5487.8007715810645,
          7059.506676400062,
          6259.201872872834,
          5690.886191793007,
          6289.939704517326,
          5446.655727877475,
          6261.323701461943,
          5312.448116491337,
          5548.219069074877,
          5451.662757193688,
          5498.893984955136,
          5273.9161074798885,
          6597.156013111076,
          5291.103433439047,
          5675.302270266089,
          5110.788637066832,
          5412.439332263304,
          5119.199827892946,
          5075.8558845142325,
          7196.193601098391,
          5139.317856590346,
          5546.781380530631,
          5220.814946240718,
          5316.559531636757,
          5395.971036703279,
          5026.382657797029,
          5201.558898321473,
          5078.461614325495,
          5138.730918355507,
          5055.8135490795175,
          6004.2691541615095,
          5116.069572826424,
          5584.799862701114,
          4899.978186881188,
          5131.673199644183,
          4981.655660194926,
          4992.958002978032,
          5202.003413134282,
          5020.722873801052,
          5041.307916924505,
          4956.284672803218,
          5024.884852645421,
          5680.760026686263,
          5050.970176168007
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial26",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21434.971805383662
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial27",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial28",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          20654.01108060025,
          16215.29891514542
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial29",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22953.77272199876
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial30",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          16945.92021194307,
          11245.365785504331,
          10667.949315439357,
          11346.674263227103,
          11124.9072265625
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial31",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          16625.68086711015,
          10841.569055538366,
          11653.148698561263,
          9471.337329826732,
          7798.360902691832,
          7131.112149984529,
          5750.841327931621,
          6271.554092860458,
          5816.700886641399,
          6237.003147238552,
          5625.999129795792,
          5338.438394376547,
          5579.833515431621,
          5212.212885790532,
          5275.006057588181,
          5320.78901898979,
          5130.070530051052,
          7230.530399133663,
          5471.746079246596,
          5609.570931311881,
          5212.41277653156,
          5081.558269840656,
          5794.279625618812,
          5067.771078279703,
          4991.117936842513,
          5138.637018487005,
          5184.288414681312,
          5185.123554494121,
          5108.725832495359,
          5113.006811765161,
          5731.141635403775,
          5079.8296623607675,
          5124.179639155322,
          5935.827428836634,
          5139.64235573948
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial32",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          19578.95057240099,
          11595.869488706683,
          10605.637772663986,
          12421.85788598391,
          10280.835512066831
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial33",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          19735.83214727723,
          15111.67862391708,
          11436.822488010519,
          10069.177521658416,
          10447.707891785272
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial34",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21565.814453125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial35",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          13795.212320157798,
          17541.86650100557,
          9830.939714186263,
          7108.569021697092,
          11531.844233446782,
          5997.5639551748145,
          6174.281975170174,
          6084.163637066832,
          5624.861632696473,
          7826.545371480507,
          5717.603878210087,
          6708.354216622834,
          6825.302748878404,
          5260.655437809406,
          5347.408125773515,
          7103.593102181312,
          6477.470359877785,
          5218.048151299505,
          5299.74724918781,
          6468.647161200495,
          5457.061924698329,
          5188.034387569616,
          5216.969069074877,
          5114.586899559096,
          6080.929252397896,
          5360.706755685334,
          5160.461445119121,
          5889.538371171101,
          5756.067247447401,
          5718.482784460087,
          4950.2066348236385,
          5561.591091042698,
          5146.587822942451,
          5031.249376353651,
          5425.554958230198,
          5341.425844098082,
          7120.909991878094,
          5095.384707611386,
          5197.03715288521,
          5580.000696163366,
          6759.892075340346
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial36",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21995.857769956685
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial37",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial38",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23825.84765625
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial39",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          20176.0623646349,
          16573.75066715656
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial40",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20848.76067450495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial41",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26
         ],
         "y": [
          14468.859578047648,
          8430.733214727723,
          11173.768796410892,
          6989.271648746906,
          8489.015475131497,
          7554.567909769493,
          11259.765673344678,
          5817.152633818069,
          6793.04620784344,
          6219.639822478342,
          5659.848178372525,
          6543.181543935643,
          5318.204285272277,
          9803.039845683787,
          5159.02508121906,
          5128.944872563428,
          5205.290662708849,
          5339.083636293317,
          6031.835420211943,
          5919.293186301052,
          5248.386887956373,
          6580.424335744121,
          5874.105309212562,
          7513.002934521968,
          7538.107881149443,
          5200.354289139851
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial42",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46
         ],
         "y": [
          15041.513111076732,
          14316.379215655941,
          7828.85844194771,
          8196.650671024134,
          6107.045511680074,
          6623.316870358911,
          10049.043384514232,
          7070.669762337562,
          11280.404625618812,
          6079.751590539913,
          5427.648640547649,
          5962.147248220916,
          6239.267321898205,
          5287.423480043317,
          7635.581049853032,
          5320.692508508663,
          5596.346650680693,
          5222.71750754177,
          5229.6964824412125,
          5136.212368502475,
          5022.447821588799,
          8461.077675394492,
          5318.539381574877,
          5080.601746209777,
          5073.18550336479,
          5410.910103070854,
          5633.457645227413,
          5169.0908106435645,
          5696.852746944616,
          4995.861458655631,
          5259.894028465346,
          6711.890262414913,
          5691.357663598391,
          8495.631168780941,
          5051.321530785891,
          4722.913093189201,
          4895.140658841275,
          5521.894207340656,
          6838.304498955755,
          6011.871698058478,
          7016.060155283107,
          5022.324494314666,
          6369.686581451114,
          4954.259262840346,
          5345.467188466893,
          4870.980239112779
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial43",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          53618.24350247525
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial44",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          15418.769357209158,
          9936.139319693688,
          8967.169090346535,
          8709.928836633664,
          6508.834337291151,
          6095.2782091197405,
          11103.133818069307,
          6004.432278774752,
          5917.943175665223,
          5709.217473700495,
          5862.575625580136,
          6667.789275216584,
          5824.741704053218,
          5639.374497215346
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial45",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          13655.823387221535,
          9906.629293007425,
          16245.099087252474,
          12838.956509127474,
          7669.054175046411,
          7059.283676902846,
          7419.50226253094,
          5953.507382232364,
          5700.01487082302,
          5678.021958152846,
          5693.118062538676,
          10525.86292349938,
          5737.343102181312,
          7132.568277189047
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial46",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22328.33440980817
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial47",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial48",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21585.0841197401
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial49",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          17368.038540377474,
          12461.707804764852,
          12701.239963644803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial50",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42
         ],
         "y": [
          16306.849125928218,
          10920.591758199258,
          10532.129176980197,
          10294.08824837562,
          8537.144076810026,
          7400.25128596844,
          6183.922706528465,
          5646.280631188119,
          6286.237324025371,
          5671.405113900062,
          6389.84246403156,
          5410.197110922029,
          5893.940323329208,
          5372.160470490408,
          5523.491766901299,
          5330.8035175587875,
          5618.060000580136,
          5044.152585473391,
          6042.53835183323,
          5006.720369546721,
          6037.595567759901,
          5159.785320621906,
          5156.330469716893,
          5013.609926129332,
          5147.829560836943,
          5239.245334738552,
          4878.203637453589,
          5388.498336943069,
          4952.6092831451115,
          4946.33323019802,
          5144.0667833384905,
          4819.592084525835,
          5174.997191174196,
          4860.6577051748145,
          5320.482175317141,
          5017.545289294554,
          5127.319495474938,
          4959.702235457921,
          6409.6686504099625,
          4908.298102954826,
          4917.499366684715,
          5196.500821859529
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial51",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          16187.645034034653,
          11114.358031017946,
          10673.297397122526,
          10234.781598081683,
          8784.44111618193,
          7608.729617883663
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial52",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          18463.14482131807,
          13607.143854424505,
          11222.56025680693
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial53",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "y": [
          13235.360535272277,
          10503.761399675124,
          11139.976320776608,
          8479.509871983291,
          6046.233988242574,
          6587.841202235458,
          6244.290014890161,
          5754.419051670792,
          7335.050505685334,
          5549.053208152846,
          5591.302139735458,
          5213.019835821473,
          5453.750908879951,
          5103.253799891708,
          5240.743618502475,
          5524.002257696473,
          5331.425911780631,
          5418.7889899829825,
          5289.154050317141,
          4918.862512569616,
          5033.265900564666,
          5195.5703125,
          5768.034518100248,
          5195.200292001857,
          5436.427985767326,
          4861.636837194462,
          4957.927371789913,
          5573.626972462871,
          4947.514527575804,
          4970.681483504796,
          5183.371258121906,
          5513.028794090346,
          4971.572101253094,
          4920.416721457302,
          5116.935909460087,
          5026.100537592822
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial54",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          12417.891611231436,
          10897.090559251237,
          11922.58735883354,
          11553.01427134901
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial55",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
         ],
         "y": [
          14146.558516398514,
          11260.206006342822,
          10797.571811185026,
          9398.032884050124,
          6511.977084622525,
          5678.8026231822405,
          7868.801042311263,
          5561.275163405013,
          5918.689129215656,
          5582.342889464728,
          5433.419670482674,
          5369.9641620900375,
          5834.636786432549,
          5163.275289101176,
          5424.106411471225,
          6226.104105430074,
          5312.989132116337,
          6148.302453975866,
          5058.243628171411,
          5083.0560411509905,
          5284.2913105275375,
          5056.275782216893,
          6755.213780167079,
          5086.427628016708,
          5390.973976059715,
          5140.94535601021,
          5409.627518757735,
          4919.87127262531,
          5500.760495629641,
          5133.796086981745,
          4990.125642984221,
          5949.9181621287125,
          4921.901949740873,
          4925.222641746596,
          5103.0154316212875,
          5111.741544515779,
          5229.016427521658,
          4930.842468866027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial56",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          18165.355285040223,
          11655.563795637376
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial57",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19618.679030012376
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial58",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          14696.236666537747,
          9993.20747602104,
          8902.28042814047,
          8037.823624110458,
          7492.232407371596,
          7684.460144647277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial59",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21318.918336169554
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial60",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial61",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23334.765238242573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial62",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          13796.614924969059,
          11008.548828125,
          11470.487952506188,
          8299.603080522897,
          6068.980488087871,
          8252.809391437191,
          5534.917640006188,
          6461.345664449257,
          5985.361444152228,
          5673.731392133354,
          5426.355222192141,
          5689.137995049505,
          5371.69988590656,
          5225.295763072401,
          5154.469750734839,
          5228.622316870359,
          4985.927159073329,
          5476.689752862005,
          5771.349764077971,
          5938.482779625619,
          6706.354724241955,
          5537.6107286509905,
          6220.348043007426,
          5022.915246944616,
          5550.039990717822,
          4949.418640741027,
          5326.635084699877,
          4951.884552908416,
          5358.981198754641,
          5220.8344823251855,
          5034.557593015161,
          5109.576539294554,
          5623.856512995049,
          4957.740079672029,
          5599.025762879022,
          4918.279930190285,
          4945.315555383663,
          5029.754138304455,
          4904.250406095297,
          5186.346360612623,
          4979.214969446163,
          4949.874434367265,
          5762.78240543781,
          5017.097109955136,
          5821.397301400062,
          5008.9786268177595,
          5983.471955252166,
          4967.8809705677595,
          5343.904079323948
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial63",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19661.043974319306
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial64",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34
         ],
         "y": [
          17242.11026454208,
          10807.11441251547,
          8039.650192411819,
          7122.683226330446,
          6066.7832127939355,
          6375.465946008663,
          5963.230231861076,
          6224.359645730198,
          6259.228157874381,
          5390.043577892946,
          6079.293389348701,
          5757.201051013304,
          5634.57279741646,
          5239.517423422029,
          5185.681268370978,
          7703.863542311263,
          5594.573135829208,
          5404.461445119121,
          5268.787960241337,
          5318.584496828589,
          5357.4940681079825,
          5766.338843015161,
          5489.794989557549,
          5154.646092783107,
          5804.3592831451115,
          5923.495837523205,
          5310.137497099319,
          6092.564835047958,
          5106.151903813428,
          6038.994512879022,
          5373.75732421875,
          6082.580987004951,
          5400.166329865408,
          5145.508097733601
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial65",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23768.81157178218
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial66",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20136.79780321782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial67",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          15332.580725943688,
          10889.411519569925,
          10501.41848120359,
          9834.10695776609,
          8153.116974783416,
          8041.354405167079
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial68",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19212.243057704207
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial69",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19161.315613397277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial70",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10861.013845915842,
          16690.397557626857,
          16627.040271116955,
          10043.750145034035
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial71",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
         ],
         "y": [
          15647.590946008664,
          10209.562770730197,
          10412.893477336014,
          7476.027276067451,
          7566.798315671411,
          5588.943398050743,
          5752.488837213799,
          5497.178430538366,
          5651.273316638304,
          6709.195032100866,
          5928.951191212871,
          5934.497384552908,
          6992.663927134901,
          5662.02974164604,
          6141.5302831064355,
          5907.668983988243,
          5080.034387569616,
          5552.253132735149,
          5175.967454362623,
          5375.519139658107,
          5532.840622099319,
          5103.046067643873,
          5317.292654509592,
          5216.378780553837,
          5052.617168162129,
          5146.566328898515,
          5041.9452399829825,
          5695.269971186572,
          4960.249961324257,
          5310.4661974009905,
          5966.855787824877,
          4993.384441715656,
          5347.5604356822405,
          5034.947139928837,
          4979.9322014232675,
          4983.701858369431,
          5723.306698638614,
          5200.013115911201,
          5049.127528426671
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial72",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17895.021165300124
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial73",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "y": [
          15440.425858601486,
          10558.261999149134,
          8261.271590733291,
          8363.886486695545,
          5762.256004409035,
          5482.020768873763,
          6951.535383469987,
          5650.630221225248,
          5836.382275874072,
          5562.05082476021,
          5411.506299311572,
          5555.962320157797,
          5354.084134243502,
          7219.001358485458,
          5434.990567953279,
          5694.249352181312,
          5615.699358949567,
          5414.200852800123,
          5425.251542195235,
          5247.836778697401,
          5197.00763362469,
          7368.10870784344,
          5392.837465191832,
          6025.922609839109,
          5170.793336169554,
          5737.497017133354,
          4980.622171836324,
          5790.675520188737,
          5219.885621325804,
          6428.03910601021,
          4957.759359529703,
          5312.941232209158,
          5039.345688621596,
          4975.739697749072,
          4878.132914023824,
          4913.9854240795175,
          5026.468416421721,
          6344.616660543007,
          5079.7627678295175,
          5437.267611966275,
          7314.660557510829,
          5291.704319113552,
          6204.316285388304,
          5261.625125696163,
          5795.768868927908
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial74",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13665.521726098392,
          11798.189946240718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial75",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18659.151241491338
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial76",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11284.751450340347,
          15251.989654238861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial77",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial78",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20516.016591893564
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial79",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23913.538656404704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial80",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          15997.226688196164,
          12243.373085550742
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial81",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          14438.169554455446,
          10603.603312577352,
          10828.75157603651,
          8067.7900390625,
          7081.073309870049,
          5638.3897596302595,
          5427.830140973082,
          5740.452462677908,
          6334.824914913366,
          5520.676477413366,
          5264.279364557549,
          6363.542514310025,
          6026.260340926671,
          6734.903997137995,
          5793.170284460087,
          5100.694959583849,
          5466.908502862005,
          5015.358417775371,
          7399.168021929146,
          5054.705484220297,
          6732.81276589573,
          5367.052275100557,
          5890.99533957302,
          4973.173774945854,
          5132.804634320854,
          5096.80979269802,
          5086.528557201424,
          6859.116109413676,
          4953.519144492574,
          5405.9399510751855,
          4761.25146484375,
          5133.682027382426,
          5054.936944036201,
          4788.161011950804,
          4787.2240099009905,
          4943.65216487469,
          4948.581891050433,
          5024.715568920174,
          4938.211788366337,
          5456.91526144802,
          4946.464877591275
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial82",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18726.346805383662
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial83",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18237.90906366027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial84",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          15671.502707301981,
          10617.939395111385,
          10864.0322265625,
          8164.804818030631,
          9112.267877862005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial85",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18533.541982518564
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial86",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19941.94546720297
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial87",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19914.19082611386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial88",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22486.161896658417
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial89",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22543.999207147277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial90",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16345.36907294245
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial91",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17381.94442295792
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial92",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34
         ],
         "y": [
          15926.509891321164,
          10558.770962252474,
          9877.167069538986,
          7507.066198367884,
          6099.886510867884,
          6616.416165493502,
          6054.560948135829,
          5774.095321202042,
          6221.91921120823,
          5614.86598855198,
          5740.33278542698,
          5785.269511912129,
          5591.8559667001855,
          8529.05819248917,
          5289.479898282797,
          6864.504065787438,
          5209.862556079826,
          5916.604245629641,
          5253.807786393873,
          5375.577216120049,
          5231.784145846225,
          5131.193103148205,
          5142.637158686572,
          5128.328086324257,
          5566.020560991646,
          5235.395420792079,
          7242.66530495823,
          5392.405215423886,
          6333.475547261757,
          5211.106184251237,
          6102.8878886912125,
          5117.819321434096,
          5446.433651763614,
          5069.0757754486385
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial93",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "y": [
          15842.42143022896,
          10447.115669477103,
          9357.829855739481,
          6991.613750193379,
          5696.238252243193,
          6901.315105778156,
          5411.423968324567,
          6096.936620126857,
          5460.233528968131,
          6063.850271697092,
          5700.850590771968,
          5695.554097694926,
          6143.419999226485,
          7032.3257947865095,
          5433.207094098082,
          6098.878369624072,
          5128.900414797339,
          5991.591632503094,
          5274.41068804146,
          5110.020430461015,
          5851.695457534035,
          5121.081397934715,
          5542.7255859375,
          5378.776251160272,
          5115.113803372525,
          5383.616752397896,
          5479.6200059947405,
          5175.888082069926,
          5177.680809096535,
          5202.121335473391
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial94",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          14295.172058709777,
          10672.60928797958,
          9827.114093440594,
          6619.429121867265,
          5522.40482866646,
          8287.762506768255,
          6092.347588567451,
          7013.353476949257,
          5530.419617303527,
          6161.008199257426,
          5434.295516514542,
          5601.288458191522,
          5422.273838760829,
          5359.368309096535,
          7677.368048035272,
          5531.511887956373,
          6269.880066522277,
          5537.823319538985,
          6556.243115717822,
          5176.382536935334,
          5111.012066831683,
          5775.333795830755,
          5126.200451539295,
          5841.998414294554,
          5655.428251663057,
          5031.163487198329,
          5462.479192450495,
          5149.505003674196,
          5004.960797300433,
          5196.886834777228,
          5187.176487082302,
          5010.66335183323,
          5540.427096225248,
          4977.970635442451,
          5017.337063931002,
          5251.840771967822,
          5196.704618850557,
          5002.160857247834,
          4933.869116452661,
          5604.891166460396,
          6577.390107711943,
          4936.526807124072,
          5648.403122099319,
          5025.698014967513,
          5374.10502397896,
          5071.90336382271,
          5115.1937364634905,
          5168.237996016399,
          5340.717744430693
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial95",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18148.160281946162
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial96",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial97",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20398.676941522277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial98",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17591.794651144803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial99",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          14469.83120939047,
          10289.381178449876,
          10270.728312577352,
          11615.959632193688
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial100",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22996.361888923268
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial101",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          14434.121509514232,
          10858.375183709777,
          11127.500551129331,
          10009.595229347153
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial102",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          12643.837407178218,
          10765.568020962253,
          11686.817701887376,
          10650.072459003713
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial103",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          15144.77307974938,
          11415.085009282178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial104",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14224.986898592202,
          11279.151028774753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial105",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22500.34796565594
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial106",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16792.287119043936
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial107",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16050.779267868193
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial108",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19030.267500773516
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial109",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22843.630840037127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial110",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21327.45975788985
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial111",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51
         ],
         "y": [
          13236.351175742575,
          10049.570621905941,
          7991.65997737469,
          7655.741467164295,
          5683.1927792388615,
          5560.750647818688,
          6224.609505530631,
          5501.1138807240095,
          5391.547411625928,
          5818.482479888614,
          5461.277498452971,
          5209.794863861386,
          6814.140378442141,
          6596.958641127785,
          5719.592057936263,
          7086.727998336943,
          5253.235738319926,
          5851.442257116337,
          5396.894492574257,
          5024.214118579826,
          5311.421841158725,
          5001.637758160582,
          5188.6367912670175,
          4956.665827080755,
          7058.264300355817,
          5249.659141011757,
          5617.2564588490095,
          5024.911011950804,
          5152.968430925123,
          4953.059758856745,
          5484.88547629177,
          8501.833017481436,
          4945.065216970916,
          5356.194727529393,
          5038.59130859375,
          5094.389880491955,
          5253.477215153156,
          5099.485105004641,
          5899.552908415842,
          5122.433995010829,
          4918.04487836479,
          5377.878214921101,
          5433.992835318688,
          6838.675467009592,
          4974.897441599629,
          4973.245170366646,
          6246.9701423267325,
          5282.245020498143,
          5795.687031056621,
          5410.191913869121,
          5150.5953066986385
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial112",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14188.715868657178,
          11840.685285813737
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial113",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14675.593015160892,
          11061.794660813737
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial114",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16042.590597926981
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial115",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19516.646523050742
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial116",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26
         ],
         "y": [
          15667.388188428218,
          10615.715810643564,
          10210.312625696164,
          7674.397591468131,
          6586.081480120668,
          5750.092140122215,
          5955.316618966584,
          6680.841033029084,
          5591.775811223701,
          6172.592164294554,
          5921.696105352723,
          5427.690864789604,
          5815.4204826732675,
          5195.43013227104,
          5763.871934947401,
          5109.817445660582,
          5803.184671836324,
          5201.888304455446,
          5235.394859993812,
          6192.489083771658,
          5189.97967106281,
          5472.493855391399,
          5160.076452274134,
          5797.358572478342,
          5617.597264658107,
          5267.29465597927
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial117",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial118",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20084.02359220297
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial119",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21142.85020884901
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial120",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22867.344117419554
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial121",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37
         ],
         "y": [
          14381.375116027228,
          10674.08292079208,
          8291.478341584158,
          6640.941367574257,
          5503.181587445854,
          5578.854337484529,
          5538.0044042001855,
          5619.542567489171,
          6025.303005105198,
          5370.701171875,
          6451.029432240099,
          6179.541484568379,
          5830.6557520498145,
          5322.089157255569,
          6367.554121867265,
          5130.985733485458,
          5264.439071202042,
          9025.954836401608,
          6057.872795482674,
          8522.312253442142,
          5200.979530863243,
          6631.243536316522,
          5122.815942141089,
          6178.343870861696,
          5103.615389077971,
          5476.820926477413,
          5020.395208075495,
          5144.49152034344,
          5294.029524094987,
          5030.467896716429,
          5198.8948261525375,
          5164.122316870359,
          5290.339258779393,
          5798.272968556621,
          5074.645333771658,
          5031.19952815594,
          5322.453995204208
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial122",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          15460.462542543317,
          10359.428237159653,
          8943.869353341584,
          7083.018757735149,
          6010.703709970607,
          7083.803807626857,
          6020.7030331451115,
          8812.57621538521,
          5741.515233408107,
          6699.392969716893,
          5373.886868618502,
          5490.369488706683,
          5321.785707379332,
          5617.848971225248,
          5270.76438254177,
          5409.772311068998,
          5313.542151724938,
          5763.719779741646,
          5095.0838731822405,
          5075.284431079826,
          7205.167272586634,
          5115.416658609221,
          5462.202462677908,
          5380.135423112623,
          5015.084284112005,
          5210.172919245049,
          5357.642790841584,
          7318.2031346689355,
          5027.296256188119,
          5693.028992303527,
          4879.329203086324,
          5086.4309589650375,
          5012.111212097772,
          5189.736676206683,
          5400.802395962252,
          5020.4681698638615,
          4990.342787940904,
          4903.008387801671,
          4885.537085202661,
          5670.859055925123,
          4954.524834661201
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial123",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          15659.853621983291,
          10433.308854811263,
          11984.393632038986,
          9237.734162283416
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial124",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17174.37648901609
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial125",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16193.74030205755
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial126",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15844.054407100866
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial127",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19346.305944461634
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial128",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20751.34013381807
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial129",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17736.114673576732
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial130",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23998.322961788366
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial131",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          14583.494624071782,
          10377.658019415223,
          7896.607794129022,
          6509.127460744121,
          6109.914923035272,
          8411.575233988242,
          10183.612633431312,
          7015.076147702661,
          6329.012482595916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial132",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16495.722375850866
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial133",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17913.961836711016
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial134",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22076.409537438118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial135",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17803.370349241955
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial136",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19658.157932394803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial137",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          232453.130105198
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial138",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          13132.076200881807,
          10799.44058439047,
          10691.877716970916,
          8687.006497524753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial139",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18609.137975711634
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial140",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial141",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          13801.444461633664,
          9528.443552753713,
          8776.124294167697,
          8618.318465733291
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial142",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11443.590414217202,
          11600.429967899134
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial143",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23460.428179146038
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial144",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14966.010635829209,
          16140.525052212253
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial145",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16259.003954594678
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial146",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19638.038269647277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial147",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17286.882106667697
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial148",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          54885.16394647277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial149",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19383.271503712873
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial150",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19129.66584158416
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial151",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          14741.723652150371,
          10006.64033493193,
          8418.104685566213,
          6763.369034266708,
          5520.411002281869,
          5532.128137569616,
          5642.887076500619,
          6167.970572594369,
          5526.387057162748,
          7653.03560102104,
          6276.762448754641,
          7447.183356861076,
          5402.8257561107675,
          5491.744827119431,
          5391.357929494121,
          5256.259852645421,
          5057.983374265161,
          5300.626924118193,
          5297.425147934715,
          6068.948532255569,
          5153.465201500619,
          4991.076287902228,
          5884.791731126237,
          5021.26518022896,
          4943.930436842513,
          5339.133363629332,
          5022.574257425743,
          6268.920236115408,
          5036.811030321782,
          5105.223139696782,
          5227.186315555384,
          4943.010471457302,
          5157.7983301748145,
          4934.659450417698,
          4907.495963219369,
          4944.607769956683,
          5472.428952660891,
          5290.339587523205,
          5235.520154896349,
          4773.165880259901,
          5343.876885442451,
          4959.2107441212875,
          4827.234573213181,
          4863.3111463490095,
          7083.986081567141,
          5210.991191599629,
          5728.710105971535,
          4863.119846457302,
          4917.791832650062,
          5216.655906752785
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial152",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18270.429523128096
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial153",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15790.349154935026
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial154",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21599.21650680693
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial155",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52
         ],
         "y": [
          15568.9248046875,
          10169.719059405941,
          9639.862672107054,
          7300.927889077971,
          6468.056698638614,
          6857.520348275062,
          5671.799973893873,
          6634.134258005879,
          5669.123689859221,
          6026.078279702971,
          5546.571724164604,
          5721.152546797649,
          6334.76265180229,
          5201.953642288057,
          5403.970374381188,
          5284.067967783107,
          5322.236004215656,
          5415.055277305074,
          5025.722380685334,
          5165.626460009282,
          5088.396165300123,
          6563.41845703125,
          5160.9791150990095,
          5971.252499419864,
          5507.4816386912125,
          4998.71271174969,
          6195.35480159344,
          4941.211590153156,
          4978.453550433168,
          5373.014261680074,
          5336.478428604579,
          4881.053527227723,
          5066.3897209545175,
          8058.061624961324,
          4872.317107247834,
          5217.494667581993,
          5030.341608330755,
          5177.377745977723,
          4882.815937306621,
          4913.238228070854,
          5782.318968517946,
          4840.712924466275,
          4873.250512453589,
          5486.579604347154,
          5234.437238938737,
          6434.87961691677,
          5046.501779084158,
          4916.862449721535,
          4982.837885790532,
          4877.188863319926,
          5147.873506149443,
          4875.457330987005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial156",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16573.98704362624
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial157",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16911.326113861385
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial158",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15915.956644492575
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial159",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16200.005066522277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial160",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17644.65061301052
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial161",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16711.937064897895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial162",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18226.50495049505
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial163",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26584.859355662127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial164",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15830.383141243812
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial165",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          81228.4760210396
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial166",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19676.565284653465
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial167",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16314.605855507425
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial168",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20004.86144415223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial169",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11214.187538675742,
          11388.248365949876
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial170",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial171",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16742.469784576115
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial172",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          15115.853621983291,
          10356.769163830446,
          14392.996016398514,
          13824.142607131807
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial173",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16851.56387298886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial174",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17406.910920095917
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial175",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          15280.088519105817,
          10566.29139271349,
          12311.658531868812,
          8547.623056543936
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial176",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18166.001518022895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial177",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21287.850866336634
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial178",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19176.629389696784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial179",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16289.237623762376
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial180",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20569.435024752474
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial181",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21687.560469523516
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial182",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20541.023456837873
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial183",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20810.931698638615
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial184",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20494.95014696782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial185",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15821.915387144183
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial186",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16420.117622602105
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial187",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
         ],
         "y": [
          11214.62395575495,
          8193.35242786974,
          6200.3226813892325,
          7889.433008779393,
          5557.825785117574,
          5578.551293703589,
          6299.587861618193,
          6293.089113745359,
          5515.367226175743,
          5345.655287940904,
          5218.487024288366,
          6457.800152769183,
          5391.115843517946,
          5063.689153387995,
          5220.548359181621,
          6982.717541383045,
          5323.4624120126855,
          7102.2855526763615,
          5069.361487662438,
          5400.611352297339,
          5348.006454014542,
          5962.170492342203,
          5020.632227529393,
          5609.99387472927,
          5452.267051168007,
          5141.147828357054,
          5045.901299504951,
          5877.607325185643,
          5066.286969175433,
          5555.881637724319,
          5159.748573831993,
          5231.040918935643,
          5483.094987623763
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial188",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18346.5174427599
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial189",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21352.381342821784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial190",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19653.74282564975
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial191",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16983.22044206374
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial192",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18537.248568997526
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial193",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23437.142636138615
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial194",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          15572.521029935026,
          10653.058719446164,
          11251.990234375,
          8480.17766669245
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial195",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16638.339805074258
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial196",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22796.517578125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial197",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11842.017607131807,
          10687.217377011139,
          10997.367796642946
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial198",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18061.71803449876
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial199",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17928.587861618194
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial200",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18715.304204053216
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial201",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16131.665957611385
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial202",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17351.707911123143
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial203",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14720.804030012376,
          11453.543384514232
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial204",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16727.466255414605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial205",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16349.363551980197
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial206",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17967.40782603651
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial207",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial208",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17752.75267829517
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial209",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          15229.018496673885,
          10299.027479115099,
          11679.772799350247,
          8196.042262917697,
          7366.110699644183
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial210",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22569.764464727723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial211",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12186.796043471535,
          11257.60706412438
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial212",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          10811.527044012995,
          8554.272717164295,
          6007.756023746906,
          6113.471534653465,
          7321.80486637531,
          6610.473608640161,
          6003.110027653156,
          7032.884291847154,
          5217.570936146349,
          5322.452854269802,
          5477.483393603032,
          6227.167756033416,
          5885.404374226485,
          6108.402440439357,
          6347.107697439666,
          6894.172899907178,
          6557.258126740408,
          5690.920777575804,
          6331.339205600248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial213",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21387.65114480198
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial214",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          10411.986405476486,
          7382.792712523205,
          6230.149133663366,
          9436.331982905322,
          7156.817532681002,
          6393.745644144493,
          6399.927763381807
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial215",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64
         ],
         "y": [
          13996.699354115099,
          10546.592125618812,
          7303.489765431621,
          6360.113953241027,
          5596.416929339418,
          6371.438109142946,
          5404.087421681621,
          5423.070771774443,
          6656.482417040532,
          5484.684120706993,
          5281.901115795174,
          6337.064129215656,
          5847.240708152846,
          5188.641524211015,
          5793.993768370978,
          5547.008426477413,
          5517.574620010829,
          6730.875101523824,
          5726.186837677908,
          5185.575466042698,
          5188.673064279084,
          7549.994266321163,
          5009.913791769802,
          5122.718314897896,
          5862.333969871596,
          5054.430045250619,
          5711.4171033802595,
          5640.893656211324,
          5255.671962020421,
          5481.260587484529,
          5010.065550549196,
          5007.09712445854,
          6169.405065555384,
          5261.261457688737,
          5517.035692875928,
          5411.855618618502,
          5121.511128944926,
          5510.856300278465,
          5129.339544012995,
          5009.040735225866,
          5100.342691251547,
          4965.487952506188,
          5286.560696743502,
          5022.601175742574,
          5090.417349938119,
          5407.566502939357,
          5686.907739016089,
          4939.725286200495,
          5093.073691793007,
          4883.51642268719,
          4730.304218556621,
          4701.715457727413,
          4700.182583346225,
          4686.0540662708845,
          4909.443731629022,
          5098.092918471535,
          5081.720645111386,
          5673.711092202971,
          5046.569089379641,
          4930.880134204826,
          5450.121727065285,
          5084.871635210396,
          5114.727867806312,
          4691.569002359221
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial216",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          658125.3409653465
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial217",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14098.250560798268,
          12728.698039139852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial218",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21872.599067914605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial219",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16613.561359065596
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial220",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18465.10757657797
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial221",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85
         ],
         "y": [
          11117.271900139232,
          10230.436494430693,
          8847.426274365718,
          6639.3218691986385,
          5723.645357943998,
          7111.95485573948,
          5682.620629641089,
          7109.842251314975,
          5719.522562461324,
          7037.271508547339,
          5320.197874767946,
          5374.681360225866,
          6251.943359375,
          5168.457645227413,
          6169.982388033725,
          6384.965704285272,
          5245.227074953589,
          5178.831330252166,
          6735.256217125619,
          5162.489025758045,
          5256.18994140625,
          5211.994691754332,
          5441.743666847154,
          5268.132831837871,
          5166.268583694307,
          5255.524394724629,
          6418.067726059715,
          5632.233751353651,
          5157.478365756498,
          5670.5839747060645,
          5132.225590771968,
          4991.855415570854,
          4952.739373839728,
          5630.460067295792,
          5195.661321356745,
          7040.776048112623,
          5124.0543104115095,
          5123.399955522896,
          6307.188829478651,
          5256.170274791151,
          5531.576471612005,
          5028.963122679455,
          4881.6686504099625,
          4812.327866355971,
          5823.991984452351,
          5113.042098545792,
          5177.89253461479,
          5039.1854550201115,
          4670.151483214728,
          5027.391098777846,
          4668.593121519183,
          4739.506178449877,
          4796.187195428527,
          5128.553865640471,
          5001.290420985458,
          5913.101567334468,
          5149.940565052599,
          5141.484887453589,
          4879.8443301361385,
          5038.7595722462875,
          4651.384354695235,
          5244.060711246906,
          5182.846645846225,
          4533.883863996752,
          5075.191807510829,
          4458.561687809406,
          4819.905302444307,
          5540.13472211479,
          5051.423924814357,
          5173.937507251701,
          5105.539603960396,
          5022.788733756188,
          5362.240132851176,
          4494.63041460396,
          4249.423654084158,
          5458.046928179146,
          4628.955295676052,
          4357.762741239944,
          4543.47824972927,
          4718.855753983601,
          4871.009132309715,
          5435.804503790223,
          4583.551477413366,
          4686.684512298886,
          4591.2244159962875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial222",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21071.49443069307
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial223",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11358.267945544554,
          11147.139948174505
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial224",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15681.567566522277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial225",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21877.289449257427
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial226",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13313.20206141708,
          10917.873723700495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial227",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14247.442692218441,
          11571.924582301981
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial228",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16816.068253016707
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial229",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          3465153.925742574
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial230",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22604.565884127474
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial231",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          27884.440710086634
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial232",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          31988.791344368812
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial233",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11208.014223004331,
          11991.740331064357
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial234",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21139.36297184406
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial235",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          10874.502533261139,
          8405.64896929146,
          6969.003379293007,
          9822.901386525371,
          6070.870470103651,
          6222.312016553218,
          7125.522093517946,
          5242.835748955755,
          6777.21013981281,
          7532.326113861386,
          5831.523234452351,
          6542.432331953899,
          5243.4325059947405,
          5527.255989905631,
          5227.074982595916,
          5518.548832959468,
          5789.695080445545,
          5534.144884166151,
          6077.426806157178,
          5239.136878287438,
          6917.026115795174,
          5776.116795908107,
          5048.072009398205,
          5235.5350643951115,
          5022.799229385829,
          5421.079169245049,
          5104.468300394493,
          5055.311924698329,
          5815.787056195854,
          4970.441208036819,
          5462.885113706683,
          5879.222148630879,
          5318.358480623453,
          5793.553019608601,
          5942.5576171875,
          5035.737048460705,
          5526.017863358601,
          6662.57124555229,
          5191.554315245978,
          5844.860008315285
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial236",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18257.042891398516
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial237",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22248.63789836015
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial238",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19060.19662747525
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial239",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54
         ],
         "y": [
          14265.432278774753,
          10309.082514696782,
          9773.632667465965,
          6840.6066386912125,
          5730.886177289604,
          5589.259296681621,
          6533.090660775062,
          6111.814767365408,
          7862.254645923576,
          6509.558182820235,
          6671.315748762377,
          5388.647262724319,
          5510.196753171411,
          5405.286258508663,
          5542.004002939357,
          5867.5087793935645,
          5084.1012675974625,
          5243.814327428837,
          5290.451776183478,
          5503.026372021968,
          5055.067537515471,
          5021.21142578125,
          5222.343513111076,
          5389.227853302908,
          5053.663298654084,
          5513.0996190439355,
          5624.426709467822,
          5054.342526879641,
          5004.8004863474625,
          5538.504670095916,
          4984.252866839418,
          4930.299176206683,
          5041.922005530631,
          4937.259059792698,
          4961.741152923886,
          5514.7027479115095,
          4983.348130027846,
          4898.316299891708,
          5573.6039942373145,
          4962.9610486927595,
          5465.927434637995,
          5473.432602684096,
          6255.75657004177,
          4834.100324876237,
          4909.4247128326115,
          4860.330663095607,
          4941.748264426052,
          5693.519004293007,
          4868.433008779393,
          4955.4121190439355,
          4977.038119778775,
          5012.361076732674,
          4969.669317566522,
          4842.231131072092
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial240",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15801.998926748143
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial241",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          14387.973661819307,
          10268.296372215347,
          10162.42939743193,
          7884.894811649134,
          6671.407651995668
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial242",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23485.416092976484
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial243",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13458.019937345298,
          10901.83449682859
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial244",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14095.63236772896,
          10630.24092086943
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial245",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "y": [
          13909.751711401608,
          10310.36148282797,
          8904.63325727104,
          6345.886133779393,
          6013.552666692451,
          6131.867395382116,
          5626.224420830755,
          7750.685077931621,
          5478.692242612933,
          5944.231512995049,
          6525.769492574257,
          5286.903160775062,
          6018.719446163366,
          5250.69753152073,
          6034.518719059406,
          5325.562968943379,
          5880.920985457921,
          6515.087992148824,
          5168.83247602104,
          6518.6249903310645,
          5076.355676632116,
          5356.413201964728,
          5159.369401686263,
          5067.812886757426,
          5790.192885597154,
          4997.757512762995,
          5205.307211092203,
          5093.419554455446,
          5880.237643100248,
          5131.931814665842,
          5134.2312519337875,
          5688.337590887995,
          4972.2239277150375,
          5361.0458065826115,
          4880.328376392326,
          5109.9981580677595,
          5089.825548228651,
          4956.4224551361385,
          5860.872785813737,
          5568.663588722154,
          7363.186015818379,
          5298.39475363552,
          6397.843827351485,
          5237.006705406869,
          5503.8695563892325
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial246",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17026.48666653775
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial247",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial248",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "y": [
          11831.798073948019,
          8900.045260287747,
          6424.059062693379,
          6051.766640238243,
          6544.674722501547,
          6663.742090810643,
          5800.3527324412125,
          6983.323783647896,
          5723.2468769337875,
          6378.949349280631,
          6514.572009398205
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial249",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14113.38139116646,
          10713.730265702352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial250",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          15239.79055151609,
          13476.156617419554
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial251",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17595.096573329207
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial252",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17218.158618889232
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial253",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14936.859200959158,
          10890.351746209777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial254",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16306.819355275371
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial255",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15667.481551670791
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial256",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14933.998153233291,
          10694.054503790223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial257",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          426685.14665841585
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial258",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21273.110535272277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial259",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14200.272412592822,
          10788.47664952042
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial260",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15806.841216738861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial261",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16891.71784112005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial262",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14452.078772818688,
          11465.407932394803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial263",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20875.907042852723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial264",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23100.85711246906
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial265",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          11212.875261061263,
          8672.165793239481,
          7438.469823251857,
          7568.045545521349,
          7494.606140741027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial266",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13533.726794554455,
          11891.671420560026
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial267",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21546.679358756188
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial268",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14943.031530399134,
          11419.570612237005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial269",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16174.727925819925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial270",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20241.543490872526
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial271",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26211.73561262376
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial272",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial273",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19551.95677985767
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial274",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13490.302076887376,
          10823.604443842822
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial275",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10672.798393022897,
          13242.205426206683
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial276",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18382.87906095297
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial277",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16910.15374574567
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial278",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15463.218082843441
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial279",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          15119.230700804455,
          10445.601755878713,
          10122.416034962871
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial280",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17639.393535349627
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial281",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16407.999970993194
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial282",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21653.287592821784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial283",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16509.908725247526
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial284",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17717.895072710395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial285",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          31963.987623762376
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial286",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23100.29987237005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial287",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19526.861830909653
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial288",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15667.188244508045
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial289",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23408.01456141708
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial290",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16508.38323793317
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial291",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16893.359142945545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial292",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12899.102703434406,
          12644.838113010519
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial293",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20535.477684096535
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial294",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15549.569123220916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial295",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15437.01944422958
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial296",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14959.256246132425,
          11348.822004563737
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial297",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial298",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11841.758653697401,
          12816.693746132425
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial299",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15917.527401763615
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial300",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17466.389967512376
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial301",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16147.411074798885
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial302",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15737.7685546875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial303",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24684.514058632427
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial304",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18671.58522199876
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial305",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17661.686968208538
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial306",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13070.57450881807,
          11013.12786200495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial307",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16229.656066290223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial308",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14396.98473275062,
          11842.187674040842
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial309",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15714.836179223392
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial310",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17547.08995977723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial311",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22859.66135519802
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial312",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          12586.868222076115,
          9792.085347694925,
          12212.05905785891,
          8013.178271000928,
          7315.678812461324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial313",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12446.193494740099,
          10834.644328202352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial314",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17103.7978515625
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial315",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18912.573599938118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial316",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20830.28022509282
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial317",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17963.927028542697
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial318",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15621.010790532178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial319",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22829.211730352723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial320",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19734.55366259282
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial321",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13666.13034692141,
          11443.778436339728
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial322",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial323",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11478.73694693688,
          11707.967454362624
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial324",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16931.174640315596
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial325",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20846.519318533417
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial326",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14870.357102800124,
          10592.362430383664,
          11934.203173344678
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial327",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13956.962842280322,
          10699.866452660892
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial328",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20117.007425742573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial329",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21333.49982595916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial330",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          13888.069906404702,
          10394.579836401608,
          10567.525941754331
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial331",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13672.480459081064,
          11084.415203434406
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial332",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          13641.540561185026,
          10497.410591352103,
          9461.446772509282,
          8139.834487159654
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial333",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16117.47152498453
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial334",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40
         ],
         "y": [
          14874.570041769803,
          10413.479163443688,
          8736.225885674505,
          6865.254336517636,
          5465.4687596689355,
          6002.440245977723,
          6981.119860960705,
          5822.960173654084,
          7540.808076461943,
          6027.885302250928,
          6382.271610071163,
          5266.096935914295,
          6076.734205793627,
          5247.140871557859,
          5510.002257696473,
          6308.766166460396,
          5171.314182394802,
          5197.471621673886,
          6151.775303604579,
          5436.463983214728,
          5473.388304455446,
          5623.866413985149,
          7284.1417949412125,
          5444.491665377475,
          7552.438408879951,
          5026.4375096689355,
          6411.828855004641,
          5020.849749574567,
          5651.954570505879,
          4957.81423073948,
          5126.372210512067,
          5076.494227645421,
          5016.940323329208,
          5092.909440748763,
          5139.852819461634,
          5333.635606822401,
          6910.691962213799,
          5023.434710512067,
          5182.058448715965,
          5642.510249071782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial335",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15942.842937809406
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial336",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15856.033551206683
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial337",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21867.985361231436
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial338",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16906.21743502475
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial339",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11539.57384166151,
          16195.527247060643
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial340",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13913.564472462871,
          11269.447662051361
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial341",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          9610.257532100866,
          13236.394763304455,
          7692.058318185334,
          7711.199803720607,
          6430.102282835705,
          6401.563346031869,
          7015.418930809096
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial342",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17522.703125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial343",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          14608.168181466584,
          10052.648563196164,
          8627.607663598392,
          6764.887289217203,
          6106.50754660427,
          5436.435861115408,
          6064.034663134282,
          5747.511612391708,
          5394.723192875928,
          5509.957954633354,
          5897.44868695854,
          5547.937577351485,
          5292.458554107364,
          5734.335516901299,
          5583.489107943998,
          5078.833645962252,
          5054.323039139851,
          5902.330571240718,
          6879.503988435953,
          5322.222400023205,
          6016.894347540223,
          5565.944974087252,
          5058.914531443379,
          7056.582214959777,
          5021.441693900835,
          6042.163487198329,
          5101.289047996596,
          5526.704483485458,
          5022.460463722154,
          5136.69353825031,
          5274.781946163366,
          5988.964877591275,
          5251.743865060334,
          5406.3245958384905,
          5108.200630414604
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial344",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23246.519086478962
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial345",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17566.989615563118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial346",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22734.591352103962
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial347",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial348",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12168.019270188737,
          10925.373888072401
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial349",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14814.112043626237,
          10853.583994043936
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial350",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16356.534933864481
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial351",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          61781.777305074254
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial352",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15923.034208694307
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial353",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21927.937403310643
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial354",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15466.353989402847
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial355",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14215.409324721535,
          10493.994778774753,
          11057.392568456064
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial356",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18153.937045560026
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial357",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16448.864702583538
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial358",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18341.47776144802
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial359",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19802.36072865099
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial360",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          172165.83725247523
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial361",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22108.91733060025
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial362",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14457.791402382425,
          10532.847259823639,
          11486.857827970298
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial363",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15942.062635365099
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial364",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20476.238726021038
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial365",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19666.068862159653
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial366",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11969.335512066831,
          15920.201810024753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial367",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19451.01786819307
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial368",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          58124.83350092822
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial369",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11850.363842048268,
          10973.680016243812
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial370",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16606.996925278465
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial371",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial372",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
         ],
         "y": [
          12995.62040725557,
          10513.263275448639,
          7426.864170792079,
          5888.578270034035,
          6827.272562461324,
          6147.1343691986385,
          5653.647286896658,
          5421.9761467357675,
          5842.45046120823,
          5393.741307626857,
          5311.64630549969,
          6774.153305809096,
          6846.681742148824,
          5418.739470529084,
          5173.897161200495,
          5762.380525796721,
          5397.6791073638615,
          5372.594779741646,
          5299.111052560334,
          5571.449943920174,
          5150.894971186572,
          5329.214848584468,
          5321.498264426052,
          5570.092222308168,
          5477.463901028775,
          5542.934468788676,
          5396.355439743193,
          5580.763526840965,
          5107.029045482674,
          5307.504007773824,
          7999.6284082998145,
          6063.475552096225,
          5803.688394376547,
          5666.7921855662125,
          5229.309106203589,
          5448.658778426671,
          5454.045260287748,
          6873.481503326114,
          6098.593832185953
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial373",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22666.569771039605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial374",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18192.64544012995
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial375",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23171.016746596535
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial376",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13454.863029857674,
          11278.343073174505
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial377",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17216.20014696782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial378",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16008.282352258664
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial379",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18646.505859375
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial380",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11631.299504950495,
          15654.86268177599
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial381",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15965.866433323019
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial382",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19692.171082147277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial383",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18418.439259746287
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial384",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15587.139213335397
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial385",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19193.51171875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial386",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21049.76626314975
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial387",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14693.818688118812,
          10763.85697710396
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial388",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13467.34270575495,
          10867.201664990718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial389",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12629.178014774134,
          11153.859326655322
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial390",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17231.039690980815
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial391",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18817.565884127474
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial392",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17242.194355275373
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial393",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19845.36747756807
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial394",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64
         ],
         "y": [
          13608.593991723392,
          10081.717193301361,
          9219.623975092822,
          6867.798083616955,
          5602.50115543781,
          5906.162573483911,
          5410.082625889542,
          5395.479569538985,
          6937.092497872834,
          5399.71564143719,
          5427.4452399829825,
          5314.562935102104,
          5354.974053411201,
          5790.877151338181,
          6345.694268254951,
          6889.304585976176,
          5348.779079323948,
          5100.485438582921,
          6835.544003326114,
          5304.688814975248,
          6622.450886641399,
          5015.227809792698,
          5374.220113319926,
          5430.521817953279,
          5009.435387337562,
          5971.926641785272,
          5007.323358214728,
          5632.096495977723,
          5038.318291692451,
          5545.30149191677,
          5398.584269608601,
          5065.71977007271,
          4951.470139909498,
          5870.26637917698,
          5028.888642868193,
          5009.030399133663,
          5400.637356899752,
          5009.083046488243,
          5315.2757677134905,
          4876.0756932626855,
          4925.257744817451,
          5787.673857131807,
          4876.29296875,
          4797.816875193379,
          6916.908459351795,
          5046.495465269183,
          6041.3744392017325,
          5034.364228805693,
          4906.551607943998,
          5445.080696936881,
          4939.205595413057,
          5243.973951887377,
          4975.990268216275,
          4788.200620745668,
          5095.978462445854,
          4858.302884243502,
          4887.9380994740095,
          5079.717633237933,
          4844.013318958849,
          5195.652363087871,
          5049.988682510829,
          4854.937538675743,
          5339.512690478032,
          5060.894129989171
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial395",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15103.757029316213
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial396",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16373.068146658416
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial397",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13023.301496751237,
          10796.217125618812
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial398",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14849.913134282178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial399",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16682.095538753096
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial400",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13699.467338335397,
          12691.121113087871
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial401",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14078.442991955446,
          11277.079159576115
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial402",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial403",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21469.689549814357
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial404",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20201.116491336634
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial405",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          162385.4203279703
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial406",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13503.836923731436,
          10756.91097810953
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial407",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13640.000174040842,
          12955.72174737005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial408",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15966.83742651609
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial409",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19027.616839418315
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial410",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13428.753161741955,
          11479.451162206064
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial411",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16174.96499845297
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial412",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15161.232721612005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial413",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15481.44274056312
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial414",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          29844993804.673267
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial415",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18348.48118425124
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial416",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23179.878867574258
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial417",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14535.248269260519,
          10606.62515470297
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial418",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19037.397605971535
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial419",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16528.891185798268
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial420",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23514.003848236385
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial421",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18449.160968440596
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial422",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15761.586208230197
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial423",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16515.72529586943
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial424",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15958.820708926361
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial425",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18091.84674737005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial426",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial427",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12143.530476485148,
          13936.445486540842
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial428",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13319.666315362005,
          10582.243821550124
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial429",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22294.206509127474
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial430",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23399.343982054455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial431",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          31492.67371209777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial432",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17022.562577351484
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial433",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          13472.861009050124,
          10489.389861154084,
          11722.495223545791
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial434",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22177.790048731436
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial435",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20022.824122060643
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial436",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14288.30477452042,
          11723.846515315594
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial437",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17728.819306930694
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial438",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15385.536335860148
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial439",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14998.827573870669
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial440",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16008.311223700495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial441",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19483.919651144803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial442",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16369.14000618812
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial443",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14932.629911819307
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial444",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18325.65005221225
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial445",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18394.675549195545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial446",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14423.391176129331,
          10635.634243502474
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial447",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15925.70358910891
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial448",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20749.111424814357
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial449",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14428.014406714108,
          11153.021784112005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial450",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial451",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15931.174485612624
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial452",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12660.77139735458,
          10990.798499381188
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial453",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18899.71849860767
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial454",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15250.549911045791
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial455",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18389.936707147277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial456",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17601.752765315596
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial457",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          131557.50649752477
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial458",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          14694.242990021658,
          10706.871142094678
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial459",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18879.87275680693
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial460",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15453.783599551361
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial461",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12932.958288211634,
          12805.283473855197
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial462",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13622.625222385519,
          11526.014339031559
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial463",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17814.441967048268
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial464",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15928.266843285892
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial465",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15587.253954594678
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial466",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          11646.513246441831,
          9338.579381961634,
          9413.123356280941,
          8440.263333462253
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial467",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16781.84414642636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial468",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22472.573367883662
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial469",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21833.633508663366
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial470",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19963.47112855817
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial471",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12578.66637337562,
          10812.204323948019
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial472",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial473",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15160.460163985148
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial474",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22386.20221612005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial475",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20187.831625154704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial476",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18030.83172184406
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial477",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11544.423499381188,
          11569.499825959158
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial478",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18499.4220103651
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial479",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23407.146252320545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial480",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16252.143738397277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial481",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11834.832843440594,
          13949.676458075495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial482",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18199.58187654703
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial483",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14040.258760055693,
          10400.575446704826,
          10006.223004331683
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial484",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          36998.95111386139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial485",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16014.984761757425
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial486",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15623.708133508664
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial487",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14871.788666073639
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial488",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15858.283696240718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial489",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20459.492574257427
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial490",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21864.59059792698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial491",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21983.439433787127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial492",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          14727.83850943688,
          8439.772315903465,
          9634.384881652228,
          6650.476248259592,
          6882.824987430384
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial493",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12116.61472192141,
          11516.688872988861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial494",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13654.081489789603,
          13690.91963180693
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial495",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13682.02381458849,
          10769.453627784653
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial496",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23153.52643487005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial497",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20514.154799659653
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial498",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17647.680857441213
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial499",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Intermediate Values Plot"
        },
        "xaxis": {
         "title": {
          "text": "Step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Intermediate Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            11416.88718285891,
            11416.88718285891
           ],
           "values": [
            11416.88718285891
           ]
          },
          {
           "label": "activation",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "ReLU"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "dropout_rate",
           "range": [
            0.27004144501157257,
            0.27004144501157257
           ],
           "values": [
            0.27004144501157257
           ]
          },
          {
           "label": "gnn_dim",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "384"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "hidden_dim",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "256"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "lr",
           "range": [
            -4.792347686804845,
            -4.792347686804845
           ],
           "ticktext": [
            "1.61e-05"
           ],
           "tickvals": [
            -4.792347686804845
           ],
           "values": [
            -4.792347686804845
           ]
          },
          {
           "label": "momentum",
           "range": [
            -0.09267913506752211,
            -0.09267913506752211
           ],
           "ticktext": [
            "0.808"
           ],
           "tickvals": [
            -0.09267913506752211
           ],
           "values": [
            -0.09267913506752211
           ]
          },
          {
           "label": "optimizer",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "SGD"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "weight_decay",
           "range": [
            -4.598636491127117,
            -4.598636491127117
           ],
           "ticktext": [
            "2.52e-05"
           ],
           "tickvals": [
            -4.598636491127117
           ],
           "values": [
            -4.598636491127117
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           11416.88718285891
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": true,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "ReLU",
          "Swish",
          "Swish",
          "ReLU",
          "Swish",
          "GELU",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish"
         ],
         "xaxis": "x",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.3114341269529591,
          0.279674211400994,
          0.2954992251671889,
          0.27004144501157257,
          0.2855393115752087,
          0.38647214299409266,
          0.29301594324415503,
          0.3187463467127898,
          0.3256627759126541,
          0.35855691959411123,
          0.3959820471173325,
          0.33494778058802105,
          0.3418458742399081,
          0.2795496735999456,
          0.2761721195674439,
          0.26438482774499983,
          0.32975798640947857,
          0.3089079035570862,
          0.3103758592941878,
          0.3168074810507939,
          0.31715704376324966,
          0.32262958802268354,
          0.313588677320361,
          0.31396994742758205,
          0.33630838415593794,
          0.33586981232966556,
          0.30628162413744664,
          0.33607288351485465,
          0.34269453547106543,
          0.3169808017821424,
          0.32693679783701846,
          0.33558082532697364,
          0.3338708853694906,
          0.33020326811762696,
          0.33402122608313956,
          0.3310738410663764,
          0.27769335292670594,
          0.39719222032435736,
          0.2868119265997926,
          0.3208273463190895,
          0.33808175396315826,
          0.2520264002619727
         ],
         "xaxis": "x2",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          384,
          384,
          512,
          384,
          512,
          512,
          512,
          512,
          1024,
          512,
          512,
          512,
          512,
          384,
          384,
          384,
          384,
          384,
          384,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          1024,
          1024,
          1024,
          1024,
          1024,
          512,
          512,
          512,
          512,
          1024,
          512
         ],
         "xaxis": "x3",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          512,
          256,
          384,
          256,
          384,
          512,
          384,
          384,
          384,
          384,
          384,
          384,
          384,
          256,
          256,
          256,
          512,
          512,
          512,
          384,
          384,
          384,
          384,
          384,
          384,
          384,
          512,
          384,
          384,
          384,
          384,
          512,
          512,
          512,
          512,
          512,
          512,
          384,
          384,
          384,
          512,
          512
         ],
         "xaxis": "x4",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.00002259564567566569,
          0.000026204602506041883,
          0.000359806924945697,
          0.000016130666533531174,
          0.00010785040998541331,
          0.00008184948648838637,
          0.0002714126951500106,
          0.000438907245775387,
          0.0004879332577688947,
          0.000437006768112207,
          0.0008955535563152082,
          0.0005964304841631316,
          0.0007189770870424607,
          0.0006474066450772411,
          0.0005955154334385722,
          0.0006367169549716812,
          0.0005747015618493944,
          0.0008963791620382307,
          0.0007997078162739047,
          0.0008716967220131983,
          0.0008706712048981074,
          0.0009973686660026174,
          0.000837632821313768,
          0.000890664867745442,
          0.0009985704108281081,
          0.0009888537178650305,
          0.0007187731951512259,
          0.0009877274792946965,
          0.0008378511945473108,
          0.0009165882903888204,
          0.0008136523898901495,
          0.0009942065067803005,
          0.0009800915714122467,
          0.0008129951305863827,
          0.0009940158933486353,
          0.0009963203851917164,
          0.0007744282300946191,
          0.0009129166051325231,
          0.0008522813862297137,
          0.000920336120486832,
          0.0008559518199889417,
          0.0008135832220916303
         ],
         "xaxis": "x5",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": [
           3
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8078316510437843
         ],
         "xaxis": "x6",
         "y": [
          11416.88718285891
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "Adam",
          "RMSprop",
          "Adam",
          "SGD",
          "Adam",
          "RMSprop",
          "Adam",
          "Adam",
          "Adam",
          "AdamW",
          "Adam",
          "Adam",
          "Adam",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "AdamW",
          "Adam"
         ],
         "xaxis": "x7",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           8,
           11,
           14,
           16,
           17,
           20,
           25,
           31,
           35,
           41,
           42,
           50,
           53,
           55,
           62,
           71,
           73,
           81,
           93,
           94,
           111,
           116,
           121,
           122,
           151,
           155,
           187,
           212,
           215,
           221,
           235,
           239,
           245,
           334,
           343,
           372,
           394
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.0000016988711084377392,
          0.000009585616350224761,
          0.00009784632875052921,
          0.000025197851309764388,
          0.00006181383857104351,
          0.000014045095239369073,
          0.00009667669781987394,
          0.00008136665679414679,
          0.000001006692826269477,
          0.00003014555325100063,
          0.000042481757087975294,
          0.00003216413359805328,
          0.00003231936509665378,
          0.000008610469228489611,
          0.000007685258288063121,
          0.000005193545641666849,
          0.00005567961602435076,
          0.000048494394579087605,
          0.00006512503517476606,
          0.000022526598945575168,
          0.000023359729540229494,
          0.00001983788747378193,
          0.00002424402379741612,
          0.000021594511429733937,
          0.000004409764110043784,
          0.000005165940823636908,
          0.000012057503379372012,
          0.000005081687941219335,
          0.000003938549872592738,
          0.00001811980243757698,
          0.000007169058629247296,
          0.000010557774058984523,
          0.000010594940625034082,
          0.000029949762628662353,
          0.00007475313105245206,
          0.00006734863342773612,
          0.00008725816765018418,
          0.0000014616445620770948,
          0.0000049946955277409905,
          0.00001938460113981291,
          0.000006850562838407049,
          0.000024712274010837464
         ],
         "xaxis": "x8",
         "y": [
          6458.3331190052595,
          6176.655341120049,
          5066.432979772587,
          11416.88718285891,
          4884.735221031869,
          5153.819055538366,
          4846.0888671875,
          4873.60986328125,
          5087.837315323329,
          4976.4566154857675,
          5053.204797725866,
          4899.978186881188,
          4991.117936842513,
          4950.2066348236385,
          5128.944872563428,
          4722.913093189201,
          4819.592084525835,
          4861.636837194462,
          4919.87127262531,
          4904.250406095297,
          4960.249961324257,
          4878.132914023824,
          4761.25146484375,
          5110.020430461015,
          4933.869116452661,
          4918.04487836479,
          5109.817445660582,
          5020.395208075495,
          4879.329203086324,
          4773.165880259901,
          4840.712924466275,
          5020.632227529393,
          5217.570936146349,
          4686.0540662708845,
          4249.423654084158,
          4970.441208036819,
          4834.100324876237,
          4880.328376392326,
          4957.81423073948,
          5021.441693900835,
          5107.029045482674,
          4788.200620745668
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 2400,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "ReLU",
          "GELU",
          "Swish"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          0.103125
         ],
         "title": {
          "text": "activation"
         },
         "type": "category"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.128125,
          0.23124999999999998
         ],
         "title": {
          "text": "dropout_rate"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "categoryarray": [
          384,
          512,
          1024
         ],
         "categoryorder": "array",
         "domain": [
          0.25625,
          0.359375
         ],
         "title": {
          "text": "gnn_dim"
         },
         "type": "category"
        },
        "xaxis4": {
         "anchor": "y4",
         "categoryarray": [
          256,
          384,
          512
         ],
         "categoryorder": "array",
         "domain": [
          0.38437499999999997,
          0.48749999999999993
         ],
         "title": {
          "text": "hidden_dim"
         },
         "type": "category"
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.5125,
          0.615625
         ],
         "title": {
          "text": "lr"
         },
         "type": "log"
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.640625,
          0.74375
         ],
         "title": {
          "text": "momentum"
         },
         "type": "log"
        },
        "xaxis7": {
         "anchor": "y7",
         "categoryarray": [
          "Adam",
          "AdamW",
          "SGD",
          "RMSprop"
         ],
         "categoryorder": "array",
         "domain": [
          0.76875,
          0.8718750000000001
         ],
         "title": {
          "text": "optimizer"
         },
         "type": "category"
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.8968750000000001,
          1
         ],
         "title": {
          "text": "weight_decay"
         },
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # hyperparameter search space\n",
    "    gnn_dim = trial.suggest_categorical(\"gnn_dim\", [384, 512, 1024])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [256, 384, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.25, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 8e-6, 1e-3, log=True)\n",
    "    activation = trial.suggest_categorical(\"activation\", ['ReLU', 'GELU', 'Swish'])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"SGD\", \"RMSprop\"])\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.8, 0.99, log=True) if optimizer_name == \"SGD\" else None\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
    "\n",
    "    # Corrected Data Splitting for Polymer Data \n",
    "    # Split the full data_list into train, validation, and test sets.\n",
    "    # Note: `data_list` should be created in a previous cell.\n",
    "    train_val_set, test_set = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "    train_set, val_set = train_test_split(train_val_set, test_size=0.25, random_state=42)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    valid_loader = DataLoader(val_set, batch_size=64)\n",
    "    \n",
    "    # model instantiation\n",
    "    # The rdkit_dim is dynamically taken from the pre-processed features.\n",
    "    model = HybridGNN(\n",
    "        gnn_dim=gnn_dim,\n",
    "        rdkit_dim=rdkit_features.shape[1],\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=activation\n",
    "    )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # optimizer instantiation\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer '{optimizer_name}' not supported\")\n",
    "\n",
    "    # training loop with NaN check and early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, 100):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch)\n",
    "            loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "\n",
    "            if torch.isnan(loss).any():\n",
    "                print(f\"Trial {trial.number} | Epoch {epoch:02d} | NaN loss detected so pruning trial\")\n",
    "                trial.report(float('inf'), epoch)\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch.num_graphs\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch)\n",
    "                val_loss += F.mse_loss(pred, batch.y.view(-1, 1)).item() * batch.num_graphs\n",
    "        val_loss /= len(valid_loader.dataset)\n",
    "\n",
    "        # logging, reporting, pruning, early stopping\n",
    "        print(f\"Trial {trial.number} | Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Optimizer: {optimizer_name}\")\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Trial {trial.number} - Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    study_name = \"final_2d_gnn_study_Tg_4\"\n",
    "    storage_name = f\"sqlite:///{study_name}.db\"\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "    def save_study_callback(study, trial):\n",
    "        pass\n",
    "\n",
    "    study.optimize(objective, n_trials=500, callbacks=[save_study_callback])\n",
    "    print(study.best_params)\n",
    "    joblib.dump(study, f\"{study_name}_final.pkl\")\n",
    "    \n",
    "    # final plots\n",
    "    vis = optuna.visualization\n",
    "    fig = vis.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "    fig_params = vis.plot_param_importances(study)\n",
    "    fig_params.show()\n",
    "    fig_intermediate = vis.plot_intermediate_values(study)\n",
    "    fig_intermediate.show()\n",
    "    fig_parallel_coordinate = vis.plot_parallel_coordinate(study)\n",
    "    fig_parallel_coordinate.show()\n",
    "    fig_slice = vis.plot_slice(study)\n",
    "    fig_slice.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b2e9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33402122608313956, 'lr': 0.0009940158933486353, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 7.475313105245206e-05}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad23af4",
   "metadata": {},
   "source": [
    "# Step 9: Retrain with best prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdff0035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 21904.7777 | Val Loss: 23462.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning:\n",
      "\n",
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 21218.4752 | Val Loss: 22052.3681\n",
      "Epoch 03 | Train Loss: 19390.1681 | Val Loss: 19183.9435\n",
      "Epoch 04 | Train Loss: 15083.8185 | Val Loss: 11912.9191\n",
      "Epoch 05 | Train Loss: 13905.1284 | Val Loss: 10586.8118\n",
      "Epoch 06 | Train Loss: 9808.4535 | Val Loss: 7770.5857\n",
      "Epoch 07 | Train Loss: 8421.7568 | Val Loss: 7533.6802\n",
      "Epoch 08 | Train Loss: 7659.5119 | Val Loss: 5644.4122\n",
      "Epoch 09 | Train Loss: 6533.8564 | Val Loss: 7839.1318\n",
      "Epoch 10 | Train Loss: 7922.8050 | Val Loss: 8400.7356\n",
      "Epoch 11 | Train Loss: 8104.2209 | Val Loss: 8396.5517\n",
      "Epoch 12 | Train Loss: 9887.7695 | Val Loss: 12065.4202\n",
      "Epoch 13 | Train Loss: 10193.6392 | Val Loss: 7041.4121\n",
      "Epoch 14 | Train Loss: 6643.3078 | Val Loss: 5164.5083\n",
      "Epoch 15 | Train Loss: 5863.7779 | Val Loss: 5212.3601\n",
      "Epoch 16 | Train Loss: 5343.4172 | Val Loss: 5501.9270\n",
      "Epoch 17 | Train Loss: 5467.5845 | Val Loss: 6618.9851\n",
      "Epoch 18 | Train Loss: 5748.7740 | Val Loss: 5387.0696\n",
      "Epoch 19 | Train Loss: 5471.7613 | Val Loss: 6467.6667\n",
      "Epoch 20 | Train Loss: 5882.9432 | Val Loss: 5844.9318\n",
      "Epoch 21 | Train Loss: 5131.0074 | Val Loss: 5619.8744\n",
      "Epoch 22 | Train Loss: 5886.5633 | Val Loss: 5061.8085\n",
      "Epoch 23 | Train Loss: 4841.6066 | Val Loss: 4945.1219\n",
      "Epoch 24 | Train Loss: 4893.5778 | Val Loss: 6663.7352\n",
      "Epoch 25 | Train Loss: 5214.5517 | Val Loss: 5307.9142\n",
      "Epoch 26 | Train Loss: 4857.1449 | Val Loss: 6329.0034\n",
      "Epoch 27 | Train Loss: 4693.6095 | Val Loss: 5286.3176\n",
      "Epoch 28 | Train Loss: 4808.1430 | Val Loss: 5012.3030\n",
      "Epoch 29 | Train Loss: 4524.9343 | Val Loss: 5308.9905\n",
      "Epoch 30 | Train Loss: 4521.9726 | Val Loss: 5205.2529\n",
      "Epoch 31 | Train Loss: 4930.6534 | Val Loss: 4986.0218\n",
      "Epoch 32 | Train Loss: 4659.9689 | Val Loss: 5044.3174\n",
      "Epoch 33 | Train Loss: 4740.4042 | Val Loss: 5143.6448\n",
      "Early stopping triggered at epoch 33\n",
      "\n",
      "Final Test Set Evaluation:\n",
      "         MAE       RMSE  r_squared\n",
      "0  44.350979  59.360771   0.717006\n",
      "Final Test Loss: 3523.7009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_31444\\639511179.py:104: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The best_params dictionary is available from your Optuna study\n",
    "best_params = study.best_params\n",
    "\n",
    "# Use the same train/val/test sets as the Optuna objective function.\n",
    "# You need to make sure `data_list` is available in this scope.\n",
    "train_val_set, test_set = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "train_set, val_set = train_test_split(train_val_set, test_size=0.25, random_state=42)\n",
    " \n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=64)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "\n",
    "# reinitialize model\n",
    "model = HybridGNN(\n",
    "    gnn_dim=best_params['gnn_dim'],\n",
    "    rdkit_dim=rdkit_features.shape[1],\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    activation=best_params['activation']\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# instantiate Optimizer based on Optuna's choice\n",
    "optimizer_name = best_params['optimizer']\n",
    "lr = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "\n",
    "if optimizer_name == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "elif optimizer_name == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "elif optimizer_name == \"SGD\":\n",
    "    momentum = best_params['momentum']\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "elif optimizer_name == \"RMSprop\":\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "else:\n",
    "    raise ValueError(f\"Optimizer '{optimizer_name}' not supported.\")\n",
    "\n",
    "num_epochs = 100\n",
    "total_steps = num_epochs * len(train_loader)\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "# early stopping training loop w loss tracking and plotting\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            preds.append(pred.cpu())\n",
    "            targets.append(batch.y.view(-1, 1).cpu())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return avg_loss, preds, targets\n",
    "\n",
    "for epoch in range(1, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_loss, val_preds, val_targets = evaluate(model, valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_hybridgnn.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# load best model and final evaluation on the TEST set\n",
    "model.load_state_dict(torch.load(\"best_hybridgnn.pt\"))\n",
    "model.eval()\n",
    "final_test_loss, test_preds, test_targets = evaluate(model, test_loader)\n",
    "metrics = regression_metrics(test_targets.numpy(), test_preds.numpy())\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])\n",
    "print(f\"Final Test Loss: {final_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef0f88",
   "metadata": {},
   "source": [
    "# Step 10: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9437faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting training and validation loss \n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c13e8b",
   "metadata": {},
   "source": [
    "| Model Type             | Featurization        |   MAE |  RMSE |   R² | Notes             |\n",
    "|------------------------|----------------------|-------|-------|------|-------------------|\n",
    "| Hybrid GNN (Tuned)| OGB smiles2graph + RDKit descriptors | 0.159 | 0.234 | 0.965 | Best   |\n",
    "| Hybrid GNN (Untuned) | OGB smiles2graph + RDKit descriptors | 0.223 | 0.308 | 0.939 | 2nd best|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130ba5c",
   "metadata": {},
   "source": [
    "# Step 11: Evaluate on test-dev and save the predictions to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68eba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2298/2298 [00:22<00:00, 102.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with molecule IDs saved to 'hybridgnn_testdev_predictions_with_ids.csv'\n"
     ]
    }
   ],
   "source": [
    "# map subset back to original dataset indices\n",
    "test_indices = split_idx['test-dev']\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "all_preds = []\n",
    "all_ids = [] # store original molecule indices\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader, desc=\"Predicting\")):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "\n",
    "# stack predictions\n",
    "all_preds = np.vstack(all_preds)\n",
    "\n",
    "# match predictions to original indices\n",
    "submission_df = pd.DataFrame({'mol_index': test_indices,  # original indices\n",
    "                              'prediction': all_preds.flatten()  # flatten to 1D\n",
    "                              })\n",
    "\n",
    "# sort by original molecule ID \n",
    "submission_df = submission_df.sort_values('mol_index').reset_index(drop=True)\n",
    "\n",
    "# save to CSV\n",
    "submission_df.to_csv(\"hybridgnn_testdev_predictions_with_ids.csv\", index=False)\n",
    "print(\"Predictions with molecule IDs saved to 'hybridgnn_testdev_predictions_with_ids.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f673460",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cce6e",
   "metadata": {},
   "source": [
    "## Model Performance Summary\n",
    "\n",
    "All baseline models were initially trained and evaluated on a 5,000 molecule subset of the full dataset. Below is a comparison of results across different featurization strategies and model types:\n",
    "\n",
    "### 2D Baseline Models\n",
    "\n",
    "| Model Type    | Featurization      | MAE   | RMSE  | R²    | Notes                                 |\n",
    "| ------------- | ------------------ | ----- | ----- | ----- | ------------------------------------- |\n",
    "| MLP (Tuned)   | RDKit Fingerprints | 0.426 | 0.574 | 0.798 | Strong performance across all metrics |\n",
    "| KRR (Tuned)   | RDKit Fingerprints | 0.454 | 0.593 | 0.784 | Good overall, slightly lower R²       |\n",
    "| RF (Tuned)    | RDKit Fingerprints | 0.423 | 0.583 | 0.791 | Best MAE, very competitive overall    |\n",
    "| MLP (Tuned)   | Coulomb Matrix     | 0.636 | 0.819 | 0.588 | Significantly weaker performance      |\n",
    "| MLP (Untuned) | RDKit Fingerprints | 0.467 | 0.609 | 0.772 | Solid untuned baseline                |\n",
    "| KRR (Untuned) | RDKit Fingerprints | 0.519 | 0.668 | 0.726 | Notable drop from tuned version       |\n",
    "| RF (Untuned)  | RDKit Fingerprints | 0.426 | 0.587 | 0.788 | Surprisingly close to tuned RF        |\n",
    "| MLP (Untuned) | Coulomb Matrix     | 0.663 | 0.847 | 0.559 | Consistently underperforms            |\n",
    "\n",
    "### Graph Neural Network Models (ChemML)\n",
    "\n",
    "| Model Type    | Featurization               | MAE   | RMSE  | R²    | Notes                                |\n",
    "| ------------- | --------------------------- | ----- | ----- | ----- | ------------------------------------ |\n",
    "| GNN (Tuned)   | `tensorise_molecules` Graph | 0.302 | 0.411 | 0.900 | Best results from ChemML experiments |\n",
    "| GNN (Untuned) | `tensorise_molecules` Graph | 0.400 | 0.519 | 0.841 | Strong but less optimized            |\n",
    "\n",
    "### Final Hybrid GNN Model Trained on Full Dataset (OGB-Compatible)\n",
    "\n",
    "| Model Type           | Featurization                          | MAE   | RMSE  | R²    | Notes                              |\n",
    "| -------------------- | -------------------------------------- | ----- | ----- | ----- | ---------------------------------- |\n",
    "| Hybrid GNN (Tuned)   | OGB `smiles2graph` + RDKit descriptors | 0.159 | 0.234 | 0.965 | State-of-the-art level performance |\n",
    "| Hybrid GNN (Untuned) | OGB `smiles2graph` + RDKit descriptors | 0.223 | 0.308 | 0.939 | Still very strong pre-tuning       |\n",
    "\n",
    "---\n",
    "\n",
    "## Model Error Analysis\n",
    "\n",
    "I performed qualitative evaluation by comparing predicted vs. true HOMO–LUMO gaps for both randomly selected and poorly predicted molecules. The worst performing molecules often showed rare or complex structures likely underrepresented in the training set. This highlights the importance of structural diversity and potentially more expressive 3D information to improve generalization.\n",
    "\n",
    "## Next Steps: Integrating 3D Molecular Information\n",
    "\n",
    "To push performance even further and overcome limitations of 2D graphs and hand crafted descriptors, my next step will involve:\n",
    "\n",
    "* Using **3D molecular geometries** \n",
    "* Incorporating **interatomic distances**, angles, and **spatial encoding** (SchNet, DimeNet, or SE(3)-equivariant models)\n",
    "* Comparing results against the current best MAE (\\~0.159)\n",
    "\n",
    "This direction aligns with trends in molecular property prediction where 3D aware models often outperform purely 2D approaches, especially for quantum properties like HOMO–LUMO gaps.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
