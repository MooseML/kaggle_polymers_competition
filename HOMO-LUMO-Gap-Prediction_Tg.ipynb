{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61979795",
   "metadata": {},
   "source": [
    "# HOMO-LUMO Gap Predictions\n",
    "\n",
    "### Problem Statement & Motivation\n",
    "\n",
    "Accurately predicting quantum chemical properties like the HOMO–LUMO energy gap is essential for advancing materials science, drug discovery, and electronic design. The HOMO–LUMO gap is particularly informative for assessing molecular reactivity and stability. While Density Functional Theory (DFT) provides precise estimates, its high computational cost makes it impractical for large-scale screening of molecular libraries. This notebook explores machine learning alternatives that are fast, scalable, and interpretable, offering solutions that are accessible even on modest hardware.\n",
    "\n",
    "### Related Work & Key Gap\n",
    "\n",
    "Past work has shown that:\n",
    "\n",
    "* DFT is accurate but computationally intensive\n",
    "* ML models like kernel methods and GNNs show promise, but often require large models and expensive hardware\n",
    "\n",
    "Key Gap: A need for lightweight, high-performing models that can run locally and integrate with user-friendly tools for deployment in research or education.\n",
    "\n",
    "### Methodology & Evaluation\n",
    "\n",
    "This notebook:\n",
    "\n",
    "* Benchmarks a variety of 2D-based models using RDKit descriptors, Coulomb matrices, and graph neural networks (GNNs) on a 5k molecule subset\n",
    "* Progresses to a hybrid GNN architecture combining OGB-standard graphs with SMILES-derived cheminformatics features\n",
    "* Achieves **MAE = 0.159 eV**\n",
    "* Visualizes results using parity plots, error inspection, and predicted-vs-true comparisons\n",
    "* Evaluates both random and high-error cases to better understand model behavior\n",
    "\n",
    "| Metric   | Best Model (Hybrid GNN) |\n",
    "| -------- | ----------------------- |\n",
    "| **MAE**  | 0.159 eV                |\n",
    "| **RMSE** | 0.234 eV                |\n",
    "| **R²**   | 0.965                   |\n",
    "\n",
    "\n",
    "### Deployment & Accessibility\n",
    "\n",
    "To make the model practically useful, an **interactive web app** was developed:\n",
    "\n",
    "**Live App**: [HOMO–LUMO Gap Predictor on Hugging Face](https://huggingface.co/spaces/MooseML/homo-lumo-gap-predictor)\n",
    "\n",
    "Features:\n",
    "\n",
    "* **SMILES input** for any organic molecule\n",
    "* **Real-time prediction** of the HOMO–LUMO gap\n",
    "* **Molecular visualization**\n",
    "* Simple **CSV logging** for result tracking\n",
    "\n",
    "GitHub Repository: [MooseML/homo-lumo-gap-models](https://github.com/MooseML/homo-lumo-gap-models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a8192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ace_tools_open as tools\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import pickle\n",
    "import joblib\n",
    "import os \n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, Module, Sequential, Dropout\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# OGB dataset \n",
    "from ogb.lsc import PygPCQM4Mv2Dataset, PCQM4Mv2Dataset\n",
    "from ogb.utils import smiles2graph\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "# RDKit\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "\n",
    "# ChemML\n",
    "from chemml.chem import Molecule, RDKitFingerprint, CoulombMatrix, tensorise_molecules\n",
    "from chemml.models import MLP, NeuralGraphHidden, NeuralGraphOutput\n",
    "from chemml.utils import regression_metrics\n",
    "\n",
    "# SKlearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589db70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Built with CUDA: True\n",
      "CUDA available: True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Device: /physical_device:GPU:0\n",
      "Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"CUDA available:\", tf.test.is_built_with_gpu_support())\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# list all GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# check compute capability if GPU available\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(f\"Device: {gpu.name}\")\n",
    "        print(f\"Compute Capability: {details.get('compute_capability')}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b585ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: data\n",
      "LMDB directory: data\\processed_chunks\n",
      "Train LMDB: data\\processed_chunks\\polymer_train3d_dist.lmdb\n",
      "Test LMDB: data\\processed_chunks\\polymer_test3d_dist.lmdb\n",
      "LMDBs already exist.\n"
     ]
    }
   ],
   "source": [
    "# Paths - Fixed for Kaggle environment\n",
    "if os.path.exists('/kaggle'):\n",
    "    DATA_ROOT = '/kaggle/input/neurips-open-polymer-prediction-2025'\n",
    "    CHUNK_DIR = '/kaggle/working/processed_chunks'  # Writable directory\n",
    "    BACKBONE_PATH = '/kaggle/input/polymer/best_gnn_transformer_hybrid.pt'\n",
    "else:\n",
    "    DATA_ROOT = 'data'\n",
    "    CHUNK_DIR = os.path.join(DATA_ROOT, 'processed_chunks')\n",
    "    BACKBONE_PATH = 'best_gnn_transformer_hybrid.pt'\n",
    "\n",
    "TRAIN_LMDB = os.path.join(CHUNK_DIR, 'polymer_train3d_dist.lmdb')\n",
    "TEST_LMDB = os.path.join(CHUNK_DIR, 'polymer_test3d_dist.lmdb')\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"LMDB directory: {CHUNK_DIR}\")\n",
    "print(f\"Train LMDB: {TRAIN_LMDB}\")\n",
    "print(f\"Test LMDB: {TEST_LMDB}\")\n",
    "\n",
    "# Create LMDBs if they don't exist\n",
    "if not os.path.exists(TRAIN_LMDB) or not os.path.exists(TEST_LMDB):\n",
    "    print('Building LMDBs...')\n",
    "    os.makedirs(CHUNK_DIR, exist_ok=True)\n",
    "    # Run the LMDB builders\n",
    "    !python build_polymer_lmdb_fixed.py train\n",
    "    !python build_polymer_lmdb_fixed.py test\n",
    "    print('LMDB creation complete.')\n",
    "else:\n",
    "    print('LMDBs already exist.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c34b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV with shape: (7973, 6)\n",
      "                                                 SMILES  Tg       FFV  \\\n",
      "7560  *C=Cc1ccc2c3ccc(*)cc3n(-c3ccc(OCCCCCCCCCC)c(OC... NaN  0.386695   \n",
      "1405                  *CC(=O)NCCCCCCNC(=O)Cc1ccc(O*)cc1 NaN  0.335504   \n",
      "5196                              *CC(*)c1ccccc1C(=O)NC NaN  0.355580   \n",
      "2087  *c1ccc2c(c1)C(=O)N(c1ccc(Oc3ccc(N4C(=O)c5ccc(-... NaN  0.401573   \n",
      "3337                    *CC(*)OC(=O)c1ccc(-c2ccccc2)cc1 NaN  0.353609   \n",
      "\n",
      "            Tc  Density  Rg  \n",
      "7560       NaN      NaN NaN  \n",
      "1405       NaN      NaN NaN  \n",
      "5196  0.183667      NaN NaN  \n",
      "2087       NaN      NaN NaN  \n",
      "3337       NaN      NaN NaN  \n"
     ]
    }
   ],
   "source": [
    "# /path/to/your_script.py\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_path = os.path.join(DATA_ROOT, 'train.csv')\n",
    "train_df   = pd.read_csv(train_path)\n",
    "\n",
    "#  Keep only the columns we care about \n",
    "target_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "train_df   = train_df[target_cols]        # drops id and any other columns\n",
    "\n",
    "#  Sample a subset (optional) \n",
    "n = len(train_df)\n",
    "subset_size = n                         # change to whatever you need\n",
    "subset_df   = train_df.sample(subset_size, random_state=42)\n",
    "\n",
    "#  Save the subset as a CSV \n",
    "subset_path = os.path.join(DATA_ROOT, 'train_subset.csv')\n",
    "subset_df.to_csv(subset_path, index=False)\n",
    "\n",
    "print(f\"Saved CSV with shape: {subset_df.shape}\")\n",
    "print(subset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f5f955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAEsASwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiioLu8tdPtXur25htreP78szhEXtyTwKAJ6KjguIbq3juLeWOaGRQySRsGVgehBHBFSUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABUc88VtA888qRRINzySMFVR6knpXIeK/G91pGu2vhvQ9Gl1TXbuA3CRlxHDFHkrvdj2yDx7deRXAa39kfUki8c6zceJ9aLZh8M6IreRG3owHJx6sQcdjQB2N38SpdXupNO8C6TJrt0p2vetmOyhP+1IfvfQdexrj7+LSLvX7e08Z6xd+L9caQBdG0lG+y2mTgkqpH3R3Y5x1FdHaeFPFfie1jg1i4i8LaCoxHo2jkCUr6SSgYH0UYOegruNA8M6L4XsRaaNp0FpFxuKL8z+7MeWP1NAHGS+Dte8DyteeBJ/tOnZLzaBeSkofXyHPKN7Hj68Cui8LeOtJ8UtJax+bZatBxcabeL5c8R7/KfvD3HtnFdPXNeKfA+j+K1jmuUkttRg5ttRtW8ueEjphh1HseKAOlorzWPxX4i8ByJaeNoTf6RkJFr9pEfl9PPjHKn/aH68mvQrG/s9Tso7ywuobq2lGUmhcOrfQigCxRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHn6fvf2gZW7Q+GQv4m5z/Kut0nw7o+hNcNpem21o9xI0kzxoAzsTk5PXGT06DtXJaV+9+OniB/+eOkW8f5sWr0CgAooooAKKKKAOX1vxBNa+N/D3hwW0E1rq0V01yZASVEaAgAdMEkg5BrC+DFtFbeD78QLthbVroxpnhVDBQB6D5al1n978cPDKf88dMupPzIWj4L/P8ADOzuP+e9xcyZ9czOP6UAegUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB5/4Z/e/GTx0/8Azxg0+P8AOItXoFeSprP/AAh/xK8WnXPM0uHXjbjTtVkiL2wZIioDNwAQSDg46HJAwTpWfjrVfCs0Nh48gT7NKQttr9mu62mz08wD/Vsfy/AZoA9IoqOCeK5gSeCVJYZFDJJGwZWB6EEdRUlABRRRQB5zqcu345Rt/wA+3heWb6ZnxVz4NxeT8JtBX1jkb85XP9ab4k0WWw8Ra54wuLu3jsx4eexRWYhg4YvnnjB6dc5q78LAg+GHh9UZWAtRnac4OTkfUGgDr6KKKACiiigAoorNvde0+wuGt5nmaVFDyLDbyS+Wp6FtinaPrSbS3LhTnUdoK78jSoqOCaK5gjngkWSKRQyOpyGB6EGpKZLTTswooooEFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFe/sLTVLKWyv7aK5tpRteKVAysPcGvOLzwdrng2Gb/hF1XWvD0gP2jw7ftu2qevku2f++T+pr0+igDxTw5LLbtPefDa8b90xa/8I6qxRomz83l55Q5+q56njFeh+FfHeleKXls0Wax1e3H+k6bdrsmiPfg/eHuPUZxmk8U+A9K8Tyx3u6XT9Yg5t9Ts22TRkdMkfeHsffGK4t/EXjDw94it9DvfDmna14luIGSw1aJ1hE0IOW80EZXGASAQD29SAes3FxDaW8lxczRwwxjc8kjBVUepJ4Argbr4k3GtXUmn+A9JfWrhTte/kzHZQn3c/f8AoOvYmmwfDi81+4jvvHurvq0incmm22YrKE/7o5c+5/HNd9a2tvZW0dtaQRQQRjakUSBVUegA4FAHB2nw1k1e7j1Lx1qr67dId0dkuY7KA/7MY+99W69xSX/gG/8AD17Lq/w/vE0+Zzvn0mbJs7n6L/yzb3HH05r0OigDjvDXxBstYvzo2q2sui+IE+/p92cb/eJujj6c/hzXY1ieJfCejeLbAWur2iy7OYplO2WFvVGHIP6eua406n4q+G4I1rzvEXhmPpqMa/6XaL/01X+NR/e69SewoA9Norh7/wCLHhSC1t2068bWby6Gbex05DLM59Cv8H/AsH2qvZ2HjfxZMZ9emj8P6Q64XTrN99y44/1kvRfoPU5FJ3toVBRckpOy7m/rHjLTdLufsMIk1DUm4WztF3vn/a7L+P5VDZ3dzpd9qM93pd6TfvHcx+RH5pB8pFMTFeAQVPJ4561raRoWmaFbeRptnHAp+8wGWf8A3mPJ/GtGs1Gb1kzslXw8E4Uotp7tvV6p7LRbefqclpWt2nh2LT9D1ffZ3Dxb1kkXEO5mJ8sP0yuQPT3rretVr/T7PVLN7S+t47iB/vI4yPr7H3rjLu08ReB4DPocM2u6Qpy2nO/7+Fe5iY/eA/u//roXNF23QVHQrxdS/LPdp7P07Pyf39DvKKwvDHjDRfF1m0+lXW6SPie2kGyaBvR0PI+vT3qzrviPR/DNibzWdQgs4exkb5nPoqjlj7AGtThNSsfxD4q0TwrZ/atZ1CG1Q/cRjl5D6Ko5b8BXH/8ACSeMvG3yeFtO/sPSX/5i+qR/vXHrFD/Itwfatjw98ONF0S8/tO6M2r60xy+o6i3myA/7APCD0xz70AYsPxcEV2s+s+F9W0jQJjtt9VuUJUnjG9AuUB7HJ/nj0W2uYL22jubWaOeCVQySxsGVh6gjg0s8ENzBJBcRJLDIpV45FDKwPUEHqK88ufA+seELmXUvAFyqwOxefQbp828p7+UT/q2/T6AYoA9HorlPC/j7TPEdw+mzRy6ZrkPE+mXg2yqe5X++vuO3OBXV0AFFMmmit4XmnlSKJBud3YKqj1JPSuBu/iVJq11Jp3gXSpNeu0O2S8J8uzgP+1IfvfQdexoA7u6u7axtZLq7nit7eJd0ksrhVUepJ4FV9J1rTNesheaTfW95b7ivmQuGAI7H0Psa4u2+G9xrdzHqHjzVn1qdTujsIsx2UJ9kHL/U9e4NSar8NxZXrax4Hu00DVAPnhjT/RLkD+GSMcD6gcemeaAO+orhtD+IinUk0HxZZHQtcPCLI2be694pOhz6E55xya7mgAooooAKK5LxH8RNE0C7GnRmbVNYbhNN09PNmJ/2scL+PPsap6NbeO9b1i21XW7mDQ9OhbemkW2JpJRjGJpDx36L+hFAHc0UUUAFFFFABRRRQAV5/qf73466Cn/PHR7iT83C16BXn7fvf2gkHaHwyT+JucfyoA9AooooAKKKKACuX+I8vk/DbxG3rp8y/mpH9a6iuU+JcIuPhzrcJkMYkgCFgucZYDpxSbSV2XTpyqTUIK7bsvmcL4W0PTtK+JHhGOxsoLaRvDZubgxIFMjsFUs3qa9lrz7TdNEfxXsJfMyLXwwkGzb384c5z6DpXoNCknsFSnOm0pK19QooopkBRRRQByHif4fafr14urWNxLo+vRf6vUrPhz7OvAcex+mcVD4f+GmlaVdpqmrTza9rY63+oHeVP+whJCAdupHrXa0UAFFFFABRRRQBz/ijwZo3i63RdRgZbmHm3vIG2TwN2KuPfnByPauS/tD4leFJF0g6TF4qjk+W01MSiBkHpOMHp65GfUnp6bRQB53D8O9Q8RzJeePtYbUtp3JpVpmKziPuPvSEep/Wu9tLO20+1jtbO3it7eMYSKJAqqPYDgVPRQAUUUUAZuueH9K8S6a+n6xZRXds38LjlT6qeqn3FcL9n8W/Dfm0Nx4n8MJ1gY5vbNf9k/8ALRR6dfoBmvTKKAODm+L/AISNhBNYXU+pXlxxDp9pCz3DN/dKfw/j+Gap/wBmeOvG/wA2r3Z8LaM//LlYybryVfR5eifQfQiu5tdD0mx1CfULTTLOC9uM+dcRQKskmTk7mAyeeav0AYvhzwlofhS0Nvo2nxW+4fvJcbpJPdnPJraoooAKKKKACiiigAooooAK8/0/978eNYf/AJ46HDH+chaul8R+L9C8J2on1jUI4C3+rhHzSyH0VByf5V5ppvi6XSfHeo+Lte8P6rpehavDDbW93PFnydnQyquSgbPH9ewB7NRUNpd219ax3VpPFPbyrujliYMrD1BHWpqACiiigArk/iUSPAOoqOrmJR+Mq11lYXihUubS001raK4kvrlY41mLbFKgyFjtIJwEPGRk4rOqrwa7nXgJcmKpzf2Wn8lq/wAjOsQD8UtRx0i0yKP83zXXVzmlxNbeK7xb2O3e/ntUkF1AHQSRqSu0ozNtIOOQec10dFJWT9WVjpKU422UYr10CiiitDiCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKiubmGzt3uLiVY4kBZmY8AVLVa/sLbU7KSzvIhLbyY3oejAHOD7UAUda8UaL4esftmqajBBEc7AWyzkdlUck/SuV/tnxj4y+XQ7I+H9Jfg6hfpm4kU944ug9i35100HhDQLfUbfUV0yF7y3gWCKaQF2RVzjGe/J+br71t0Acn4c+Heh+Hro6gyS6lrD8yalqD+bMT6gnhfw/M11M0MVxC8M0aSROpV0dQVYHqCD1FPooA85u/A2reFLqXU/h/dJCjsXn0O6Ym1m9fLP/LNv06dBxWz4X8f6d4hun0y6hl0nXYv9dpl58sg90PR19x25xXW1geKPBujeLrVI9StyJ4uYLuE7J4G7FHHI55x09qAN+ivONK1nxP4S8W6V4U8QSx6xZamZFsNUU7JxsXcVlX+IgY5985PQej0AFUNU03+0YoCk7W9xbyiaCZVDbWAI5B6ghiCPer9FJpNWZUJyhLmjuZlhpc0F/LqF7di6u5IxECkXloiAk4Vck8k5JJPatOiihJLRDqVJVHzSCiiimQFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAef+Kv3vxh8Ax9ok1CQ/jCAK9ArhdWVZfjP4dBUFodNuZAeeMkLXdUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAcbNY3cnxktr37NN9ji0Nk+0bD5fmGb7u7puxzjriuyrJi0Py/Ekusfa5j5kYjMG99ox0P3sd34xj5hwCCTrUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAaV0lEQVR4nO3de1TT5/0H8A8x3IKCCihg1Yowb0iV1nvVUtnWOqz1km7zd7K160669hzToztdaN1k3ZwntetOzuZpG1h3Ds4zj7E9bujmbGT1rmhbb3iriihCUVERCCCQPL8/njXNIiDk9vkmfb/+kiR88yHmnc+T5/skT4QQggCAj4q7AIBvOoQQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZgpJYRNTU0LFiwYNmzY2LFjKyoquMsBCB7+EN67d+9Pf/rTmDFjtm/fXltbe/78+ZkzZ5aUlHDXBRAkEUIIrvvu6OjYtGnTm2++WVlZSUQZGRm5ubmHDx8+deoUEc2dO7e4uDgzM5OrPIAgERwcDofVanUFbMKECVar1el0ymutVmtycjIRxcbGmkymzs5OliIBgiPYIXQ6naWlpdnZ2TJ+Y8eOLSkpuT9mt2/f1uv18jaTJ0/+7LPPglwnQNAENYQ2my0nJ0dGa+TIkRaLpaOjw3Xt3r176+vr3W//r3/9a8SIEUQUGRlpNBrb2tqCWS1AcAQphDabbcqUKTJ+w4cPN5vN7okqLy/Pz88nooKCAo9ftNvtRqNRpVIRUUZGxieffBKcggGCJuAh3Ldv3xNPPCHjl5ycbDKZWltbXdceP378mWeekdcmJCSsW7euy4McOHBg/PjxRBQREaHX6xsbGwNdNkDQBDCEhw4dkv2NiBITE00mk91ud1175swZnU4nW1xcXJzBYLh+/XoPR2tvbzeZTFFRUUSUlpa2devWwFUOEEwBCeHJkye1Wq2M34ABA4xGY0NDg+vay5cv6/X6fv36EVFUVJRer6+tre39kadNmyaPrNVqb9y4EYj6AYLJzyGsqKjQarURERFE1L9/f6PRePv2bde1V69e1ev1arVazrXo9fpr16719S4cDofFYunfvz8RDRo0yGKx+PUvAAg2v4Xw7NmzOp1O9jeNRmMwGOrq6lzXXr9+3Wg0xsTEEJFKpdJqtRcvXvTl7iorK7/zne/Ilvj0009XVVX5/BcA8PBDCKuqqlz97f7h5c2bN41GY2xsrCt+58+f9/1OJavVmpSUJGOP0/oQonwKYXl5+U9/+tPo6Gg5vNTpdJWVla5rGxsbTSZTfHy8nNXMz88/duyYr/Xep66uTqfTyZY4Y8aM06dP+/0uAALK+xAWFxfLp75arX7++efd49fU1GQymQYOHChvkJeX9+mnn/qj2m5t3759+PDhOK0Pocj7EA4aNIiIUlNTz54967rQbrebzeahQ4fK+M2aNWvPnj3+qPPBGhoaDAaDPOeRlZV1+PDh4NwvgI+8D2FCQgIRlZWVyR/v3btnsVhSU1Nl/GbOnOm6Kph2794t14WrVKrJkyfjHAYon/chlHmrqamRPxYUFMj4TZs2befOnX4qzxutra2rV6+Wp0mWLVvGWAlAb3j/ecL4+Pimpqa7d+/KqZfa2tqlS5e+/vrrCxYs8O6A/qXT6TZu3JicnHzjxg3uWgB64uUn64UQdrs9IiIiLi5OXpKWlnbw4EGFJJCIZs+eTUQTJkzgLgTgAbwMod1udzqdGo1Gnp1Xgra2tqlTp7pWq8oZmvT0dNaiAB5M7d2vNTc3E5FcO6YQjY2NR48elefu6asKBwwYwFoUwIN52QmbmppIYU9xj9TJChX1MgHQJS9DqMBO6FGS3W4nhVUI0CWfOqGinuIezVmBvRqgSz51QkU9xT06oQJ7NUCXwmc4ik4IISrcJmbQCSHkoBMCMEMnBGDmUyd0rVlTAo/UKXD+FqBLYT47qqgKAboU5u8JFVUhQJfC8z1hR0dHe3u7Wq2W3+8GoGTh2QkV+BoB0J3w7IQKfI0A6E64dUJZkgJfIwC6Ez4LuN2nQxX4GgHQnfA5RYFOCCEqfIaj6IQQorwJYWdnZ1tbm1qtljtMKIHT6WxtbVWpVBqNhtAJIaR4E0JlviEUQsTFxcmvG0UnhBDiTQjvf4rLRuS3ovoOH6GA0OWfTrh+/fqsrKxdu3b5ra4+6nLhqKLWlwN0x5sQXr58mYg6Ozvlj0KIzZs3y1079Xp9Q0ODH+vrJY/Wp8DJW4DueBPCc+fOEdGVK1dqamqIKCIiYs+ePSaTKTo6uri4eNy4cR9++KGfy3yQ6OjoqVOnPvLII/JHBb5rBeiWF/tXVFdXR0ZGElFSUlJpaanr8gsXLuTm5srD5ufnV1dX+2e/jL77wQ9+QER/+9vfuAp4gI4OUV0tbt/mrgMUwZtO+NBDD23ZsmX48OH19fXPPPPMggULamtriSgjI6OsrMxiscTHx2/fvn3ixIlFRUXC2w1nfCGHxErshA4HrVpFiYn06KOUmkqPPkqHD3PXBNy8jq/T6bRYLPJ918CBAy0Wi9PplFfV1tYuWrRIHn/OnDnnzp3zzytGL9y6dauwsDA2Nnbo0KGzZ89m7MZde+MNkZ4uTpwQQoiODlFYKOLjxZUr3GUBJ5/2rBdC1NTULFy4UOZt7ty5X3zxhesqq9U6ZMgQIoqNjTWZTJ2dnT7eV88aGhpWr14t92mLiIiQnyQcOHBgUVGR69WBWUeH6N9ffPTR/1w4dar41a+YCgJF8DWEktVqTU5OJiKNRuOet9u3b+v1ehnRSZMmBWjn+ubmZpPJJLfvJqK8vLwjR47U1tYuWbJEXvL444+77+nN5uJFQSRu3vyfC197TSxezFQQKIJ/QiiEuHXrlitvkydP/uyzz1xX7dixY+TIkUSkVquNRmNra6u/7lTu0Z2SkiLvd9asWZ988on7DUpLS4cNG0ZEMTExhYWF9+7d89dde6O8XBAJjxrWrhVz5jAVBIrgtxBK//znP0eMGEFEkZGRRqOxra1NXm63241Go9zMcPTo0b5vZ9/e3m6xWGTAiGj69Onu87Tu7ty5o9fr5XK27OzsI0eO+HjX3qurE0Ti8uX/ufCVV8SPfsRTDyiDn0Movsqb3KMzMzPTvTUdPHhQbp0bERGh1+vv3r3rxfHb29tLSkpGjx4t4zdx4kSr1frA39q9e3dmZqbsxgaDQa41DZKrV4XBIAoLhRAiPV2sXfv1VS0tIjVVvP++EELU1gavpB69++67cXFx0dHRs2bNamxs5C4n/Pk/hNKBAwfGjRvnypvr/7K9vV2e1iei1NTUjzxmKXrkcDisVqvMEhGNHz/earX2ftKlpaXF1Y3T09N37drV57+qr2prxfLlIjpaEImEBNHcLP7+d6HRCJNJHD8ubDYxd67IyRFtbeLkSREdLfR6wfqk//jjj6dNm+Y+eT5mzJi9e/cylvRNEKgQiq/yFhUVRURpaWlbt251XVVRUTF9+nT535yfn19TU9PzoZxOZ2lpqWtBzKhRoywWi3fTrZ9//nlOTo58ddDpdLdu3fLiIA9WXy+MRqHRCCKhUgmtVrjO0+zZI559VowbJ6ZOFatWCTkcsFiEWi2IxMMPi507A1JSjw4cOPDkk0/KhzcpKenFF180m83y9S6wD5RXbt68+c4777g/o0JaAEMonTx5curUqfJ/V6vV3rhxQ17ucDjMZrM8n56YmLhv377ujmCz2WRsiGjkyJEWi6Wjo8OXkty7cUpKypYtW3w5mqfGRmEyiYQEQSSIRF6eOHasV7944oSYMuW/v6XVek6iBszhw4fz8/Plwzt48ODCwkLX2wRfhi0BIqfi5Cs7EeXk5NTX13MX5auAh1AI4XA4LBaLzNugQYMsFovrqsuXL3/3u99NSkq62dVzzmazuQL80EMPmc1m10yP7y5cuPDEE0+4uvG1a9d8PWJTkzCZxKBBX8fv6NG+HaGjQ5jNIi5OEIkhQ0RJia8l9ejUqVNarVZOWfXv399oNN65c+f+m/V12BIg7e3tRUVFctqPiKKiomTlKSkpH374IUtJ/hKMEEqVlZXf/va35SP49NNPX3FbJnLlviUj+/fvdy1DTU5ONplMLS0tfi+ph0U/fWK32zt//3uRlPR1/A4e9L6sS5dEXt5/DzV/vrh61ftDdePMmTM6nU5OnsXFxRmNxp5Hm/56oLzjMRcwYcKEzZs3OxyOiooK1xCad62yh5qaGoPB8OWXX/by9sELoWS1WhMTE+8/re/iPjpKTEwsLCwM9ARdTU3Ns88+K+9xzpw558+f7/3vytFRWlra6TlzBJGYMUP4Zb7H6RQlJSIxURCJ+HhhNguHww+HFeLy5ct6vV7OTkVFRen1+t4/V+SwRT5QHqujAkTOBWRnZ8s7HTt2bElJiftzxul0lpSUDB48mIgSEhLMZrPDTw+Ud27evGk0GuXXvrz66qu9/K1gh1AIUVdXp9Pp5MM6c+bM06dPy8tPnjzpGh0NGDDAaDQ2NDQErSrXop9eLrJrb29///33hw8fLv+QF596Svz7336uqaZGLFokW+Kp73/fxyW4V65c0ev1arWaiCIjI/V6vXcjcKvVmpSU1MPLqL/0fi6gtrZ28eLF8pZcq6MaGxtNJpNr1WR+fv6xXs4FsIRQ2rZtm3wGR0ZGvvjii4sWLXK9OVm1atVtjo/59HKRnRwdZWRkuEZHfTpT0melpR0jR+aMHev1op/r168bjUa5mFatVut0uosXL/pSkcfqqM8//9yXo93PZrNNmTJFHn/48OG9nAtwrY6KjY0N5uqopqYmk8k0cOBAWXBeXl5fl2eyhVAI0dDQYDAYVCqV/B6K6OjoPo2OAqSHRXZOp9NqtY4ZM0Y+3OPGjfMYHQVI0+3bP/nJT+SL1COPPHK01/M97qMjlUql1Wr7NNjuWXero3yxb98+12yZnAvo0yJHj9VRvX+gvGO3281m89ChQ2XBs2bN2rNnjxfH4QyhtGbNGiLKyMioVcySEfdFdhkZGdu2bRNC2Gy2yZMny4f74Ycf9vpEpdf27t0r8y8X/TQ1NfVwY/mRLvfR0fHjx/1eUnNzc3ero/rq0KFD7nMBJpPJbrd7d6ggrI6ScwGpqamud1W+rMTkD+HGjRuJaNmyZdyFeNq9ezd9RT6b5dxgcXFxe3s7S0nui35GjRr18ccf33+b+0dH7ovpA6G71VG9JOcCZLX+mgsI3OoouWpy1KhRsuBp06Z1t2i59/hD+N577xHRSy+9xF2Ip/r6ejmFKF9T5Zj55Zdf5q5LHD9+/NFHH5VPAq1W6zpb3dzcbDab5Wc4ZfzKy8uDU1IPq6N6cPr0aY8Tlf6dC/Dv6iiPuYCsrCx/zQXwh/Dtt98mop///OfchXiqqqoiohEjRhw8ePDPf/7zL3/5SyIqKCjgrksIITo6Okwmk5xrGTp06HvvvafX612jo1mzZv3nP/8JflXdrY66X2VlpetMiUajMRgMdXV1gSjJY3WUd6f1Zfw85gL8eC6EP4SFhYVEVCg/ZKAkFRUVRDR+/Hj54xtvvEFEa9as4a3K3blz52bPni1f6eXzY/r06TabjbGkHlZHSVVVVa4zJfJEZRCW4PiyOspms02aNCmgcwH8IVy5ciURvf3229yFeDp06JAc9Msfly9fTkRms5m3Kg9Op/Ott95KSEiIj49ft24ddzn/1eXqqOrqaoPBIJtSZGSkTqerrKwMWkleLPqx2WyPPfaY/CtGjBjh+6Ll7vCHUJ5xel9+pk5JbDYbEc2bN0/++MILLxDRBx98wFtVqHA6nR988IH8zhG1Wp2SkiK7X79+/X784x9funSJpapero7at2/f3Llz5c2GDBnS1zMlfcUfwmXLlhHRxo0buQvxtHXrViJauHCh/HHp0qVEtHnzZtaiQkxdXZ1reScRLV68OJhfvdedHlZHHTx4cN68ebLapKSkAC1a9qAmbordvAVfre+7oUOHlpWVrV27trKycv78+a7FZby0Wm1eXl5BQUFRUVFBQcGmTZtWrVoVGxu7YcOGLVu2ENHgwYOXL1++cuVK16mpgOIPoWK3MfMoDF+t7zU5p6UoctJo4cKFL7/88okTJ5577jl5eXx8/IoVK1asWJGQkBC0YvhDqNgnt0dh6IThZ/78+WfPns3NzT169CgR5eXlbdy40XWiNWj4Q6jYJ7fdbqf7QqjAFwvwhUajKS8v//LLL/v16xf8+En8IVR4J8TGo98ErnUOLLzZEMa/FNsJu9x4VIEvFhDq+Duhx6hPOV4fMGDF7NmxyclERE5n0WOPNTgcGo2Guy4IN8whbG1t7ezsjImJkWdyFWXUF1/Qvn302mtERE1N/7d3L8XH01cLxAD8hXk4qug3Wk1NRESyRTc3f/1vAL9iDqGi32jJ4MkXCPdAAviVIjqhQkN4fydUZseGEKeITqjQ4ah78DAchYBBJ+yee/BkV1TmiwWEOHTCbghBdjsRUVwcETohBJAiQqjETtjSQg4HaTQkz51gYgYCRhHDUSV2Qo/Wh4kZCBh0wm54vAnEcBQCBiHsRpedUIF1QuhDCLuBTgjBgveE3YiNpWnT6KtNuXCKAgKHedm0cjvhY4/R4cNERI2NFBNDf/0r/eUvJAR3WRCGmDvh3bt3SZmd0Omk3/2OUlIoJYXi4mjePDp/nr7aKh3Aj9hC2Nzc/NZbb+3fvz8pKekPf/iD3PhBQX7zGyoqoo8+ouZmunWLJkyg3Fy6cYO7LAhHgf5OxfvZ7fZ169bJ3V6JKDIykohSUlK2bNkS/GK61t4uBgwQ7vU4HCIrS6xdy1cThK2gdsL29vaioqLMzMxf/OIX9fX1M2bM2LVr19mzZ+fNm1dXV6fVahcsWFBdXR3MkrpWVUVNTeT2rbWkUtGTT9KpU3w1QfgKTtblrm7p6enyTrOzs61Wq+tap9NZUlIyePBgIkpISDCbzX7c8sYb+/cLlUp41PDmm+LJJ5kKgnAW8BD2fof32traJUuWyJs9/vjjZ8+eDXRt3bp6VRAJj92CXnpJvPACU0EQzgIYQu92eC8tLR02bBgRxcTEFBYW3rt3L3AVdsvhEGlp4o9//PqS1laRliaUt2sNhIGAhNDpdO7YseP555+X8Rs9evSGDRt6v6vbnTt39Hq93HMvOzv7yJEjgSjyATZsEPHxoqhIVFaK8nLx1FNi4kQR+L1B4BvI/yEsKyt76qmnUlNTU1NTFyxY4PUO73v27PnWt75FRGq12mAwNDc3+73UBygtFbm5IjVVjB0rXn1V+LbZMkB3/BnC8vLyJUuWyPhlZWWtX7++ra3NlwO2tLQYjUa5qXJ6evquXbv8VSqAcvgnhJ9++ulzzz0n4zd+/Pj169f7cVPFY8eO5eTkEFFERIROp7uFjgThpW8h3LRp0507d9wvOXPmjF6vl/HLzMxcs2bN3bt3/VmgEEKIjo4Ok8kkd1pW1ml9AJ/1NoTXrl3buXPnypUrL126VFZWJoQ4d+6cXq9PS0tLTU3NyMgIUPzcXbhwITc3V0725OfnX7t2LaB3BxAcvV0xo1arq6qq9u/fX1xcHBMTs3Hjxnnz5m3bti0mJuaVV145cuTIqlWrAr2taUZGRllZmcViiY+P3759e1ZWVlFRkcAnGyDU9T6vJpPJarUuXbq0oaGhuro6MzPztddeq6urC9gLRLdqamoWLVok658zZ8758+eDXwOAv/QhhCdOnHA6nRUVFfKMX1NTU8Cq6hWr1ZqcnExEsbGxJpOp9+chARQlQoTycO7OnTsFBQVFRUVENGnSpHfffXfGjBncRQH0TWiHUNqxY8fPfvazq1evRkREfO9739u2bRt3RQB9EA4hJKKWlpYf/vCHpaWlRLR79+65c+dyVwTQW/zbZfuFRqP5xz/+MXr0aCKKwpdQQEgJkxC6k7M1AKEirEKo6D2eALoRViFU7h5PAN0Lk4kZInI6nWq1OiIiorOzU34WESAkhE8nlB84jIuLQwIhtIRPCJX7jfoAPQqfECr3G/UBehQ+IcTUKISo8AkhpkYhRIVPCNEJIUSFTwjRCSFEhU8IVSrVjBkzXN81DBAqwieEDQ0NVVVV3FUA9Fn4hNButxNRXFwcdyEAfRM+IWxpaSGEEEJQ+IRQdkKNRsNdCEDfhE8IsWIGQlT4hBDvCSFEhU8I0QkhRIVPCOXEDN4TQsgJnxDKTojhKISc8AmhfE+I4SiEnHALITohhBw1dwF+Exsb29HRgRBCyAmfL3pqbW2NioqSe2sDhJBwGI46nU4hxIoVK+Q+bdzlAPRNOHTCM2fOrF69WqVSZWZmRkZG/vrXv+auCKAPwiGERFRdXV1YWDhp0iSDwcBdC0DfhMNwlIiKi4t/+9vf1tTU3Lx5k7sWgL4Jk04IELrCpBMChC6EEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzP4f+bJfHGOisBEAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = Molecule(subset_df['SMILES'][0], input_type='smiles')\n",
    "mol.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f557b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7973 molecules.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(subset_path)\n",
    "print(f\"Loaded {len(df)} molecules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04007d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*C=Cc1ccc2c3ccc(*)cc3n(-c3ccc(OCCCCCCCCCC)c(OC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.386695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*CC(=O)NCCCCCCNC(=O)Cc1ccc(O*)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*CC(*)c1ccccc1C(=O)NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355580</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*c1ccc2c(c1)C(=O)N(c1ccc(Oc3ccc(N4C(=O)c5ccc(-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*CC(*)OC(=O)c1ccc(-c2ccccc2)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  Tg       FFV        Tc  \\\n",
       "0  *C=Cc1ccc2c3ccc(*)cc3n(-c3ccc(OCCCCCCCCCC)c(OC... NaN  0.386695       NaN   \n",
       "1                  *CC(=O)NCCCCCCNC(=O)Cc1ccc(O*)cc1 NaN  0.335504       NaN   \n",
       "2                              *CC(*)c1ccccc1C(=O)NC NaN  0.355580  0.183667   \n",
       "3  *c1ccc2c(c1)C(=O)N(c1ccc(Oc3ccc(N4C(=O)c5ccc(-... NaN  0.401573       NaN   \n",
       "4                    *CC(*)OC(=O)c1ccc(-c2ccccc2)cc1 NaN  0.353609       NaN   \n",
       "\n",
       "   Density  Rg  \n",
       "0      NaN NaN  \n",
       "1      NaN NaN  \n",
       "2      NaN NaN  \n",
       "3      NaN NaN  \n",
       "4      NaN NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1779d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values by Column:\n",
      "         Total Missing  Percent Missing\n",
      "SMILES               0         0.000000\n",
      "Tg                7462        93.590869\n",
      "FFV                943        11.827418\n",
      "Tc                7236        90.756303\n",
      "Density           7360        92.311551\n",
      "Rg                7359        92.299009\n",
      "\n",
      "Feature Statistics (Min, Max, Mean, etc.):\n",
      "               Tg          FFV          Tc     Density          Rg\n",
      "count  511.000000  7030.000000  737.000000  613.000000  614.000000\n",
      "mean    96.452314     0.367212    0.256334    0.985484   16.419787\n",
      "std    111.228279     0.029609    0.089538    0.146189    4.608640\n",
      "min   -148.029738     0.226992    0.046500    0.748691    9.728355\n",
      "25%     13.674509     0.349549    0.186000    0.890243   12.540328\n",
      "50%     74.040183     0.364264    0.236000    0.948193   15.052194\n",
      "75%    161.147595     0.380790    0.330500    1.062096   20.411067\n",
      "max    472.250000     0.777097    0.524000    1.840999   34.672906\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "total_rows = len(df)\n",
    "percent_missing = (missing_values / total_rows) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Total Missing': missing_values,\n",
    "    'Percent Missing': percent_missing\n",
    "})\n",
    "\n",
    "print(\"Missing Values by Column:\")\n",
    "print(missing_df)\n",
    "print(\"\\nFeature Statistics (Min, Max, Mean, etc.):\")\n",
    "print(df[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125f621",
   "metadata": {},
   "source": [
    "The only property that appears will succeed with a simple imputation strategy is FFV. All other properties contain very high percent missing. Therefore, I will impute median for FFV, train a model for FFV, and train separate models for other properties. I will attempt to filter out missing values for each property. If this yields uncessful, I may explore sampling techniques or use the trained model to impute values to train a secondaery model. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe69f3",
   "metadata": {},
   "source": [
    "# Tg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc711963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Tg DataFrame shape: (7973, 2)\n",
      "Initial Tg Missing Values:\n",
      "SMILES       0\n",
      "Tg        7462\n",
      "dtype: int64\n",
      "\n",
      "Cleaned Tg DataFrame shape: (511, 2)\n",
      "Cleaned Tg Missing Values:\n",
      "SMILES    0\n",
      "Tg        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a new DataFrame with only the SMILES and Tg columns\n",
    "df_tg = df[['SMILES', 'Tg']].copy()\n",
    "\n",
    "print(\"Initial Tg DataFrame shape:\", df_tg.shape)\n",
    "print(\"Initial Tg Missing Values:\")\n",
    "print(df_tg.isnull().sum())\n",
    "\n",
    "# 2. Drop all rows where the 'Tg' value is missing\n",
    "df_tg.dropna(subset=['Tg'], inplace=True)\n",
    "\n",
    "print(\"\\nCleaned Tg DataFrame shape:\", df_tg.shape)\n",
    "print(\"Cleaned Tg Missing Values:\")\n",
    "print(df_tg.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d169da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem, Descriptors, HybridizationType, SanitizeFlags\n",
    "def rdkit_ogb_agree(smi: str) -> bool:\n",
    "    m = Chem.MolFromSmiles(smi)\n",
    "    if m is None:\n",
    "        return False\n",
    "    return m.GetNumAtoms() == smiles2graph(smi)[\"num_nodes\"]\n",
    "\n",
    "def canonicalize_polymer_smiles(smiles: str, cap_atomic_num: int = 6) -> str:\n",
    "    \"\"\"\n",
    "    Turn every '*' (dummy atom) into a real atom (default C) in the RDKit graph,\n",
    "    preserving existing bond orders/stereo; sanitize, remove explicit Hs, and\n",
    "    return canonical isomeric SMILES.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"RDKit could not parse SMILES: {smiles}\")\n",
    "\n",
    "    rw = Chem.RWMol(mol)\n",
    "    for a in rw.GetAtoms():\n",
    "        if a.GetAtomicNum() == 0:   # '*'\n",
    "            a.SetAtomicNum(cap_atomic_num)  # 6 = carbon\n",
    "            a.SetFormalCharge(0)\n",
    "            a.SetIsAromatic(False)\n",
    "            a.SetNoImplicit(False)\n",
    "            a.SetNumExplicitHs(0)\n",
    "\n",
    "    mol2 = rw.GetMol()\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol2)\n",
    "    except Exception:\n",
    "        Chem.SanitizeMol(mol2, sanitizeOps=SanitizeFlags.SANITIZE_ALL ^ SanitizeFlags.SANITIZE_KEKULIZE)\n",
    "        Chem.Kekulize(mol2, clearAromaticFlags=True)\n",
    "\n",
    "    mol2 = Chem.RemoveHs(mol2)\n",
    "    return Chem.MolToSmiles(mol2, isomericSmiles=True, canonical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff48e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on *CC(*)(C)C(=O)OCCOC(=O)c1cc(OC(=O)c2ccc(N=Nc3ccc(OCCCCCCC)cc3)cc2)cc(OC(=O)c2ccc(N=Nc3ccc(OCCCCCCC)cc3)cc2)c1 | Reason: Bad Conformer Id\n",
      "Failed on *c1ccc(-c2cc(Oc3ccc(S(=O)(=O)O[Na])cc3)c(*)cc2Oc2ccc(S(=O)(=O)O[Na])cc2)cc1 | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *C#CC(Cn1c2ccc(CCCCCCCCCCCCCCCC)cc2c2cc(CCCCCCCCCCCCCCCC)ccc21)=C(*)Cn1c2ccc(CCCCCCCCCCCCCCCC)cc2c2cc(CCCCCCCCCCCCCCCC)ccc21 | Reason: Bad Conformer Id\n",
      "Failed on *C#Cc1cc(OC(COCCOCCOCCOC)COCCOCCOCCOC)c(C#Cc2cc(OCCOCCOCCOCCC(=O)O[Na])c(*)cc2OCCOCCOCCOCCC(=O)O[Na])cc1OC(COCCOCCOCCOC)COCCOCCOCCOC | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *Oc1ccc(C(c2ccc(Oc3ccc(C(=O)c4ccc(*)cc4)cc3)cc2)c2ccccc2C(=O)O[Na])cc1 | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *Nc1ccc(NC(=O)c2cc(C(*)=O)c(C(=O)O)cc2C(=O)O)cc1S(=O)(=O)O[Na] | Reason: The MMFF parameters are not available for all of the molecule's atoms.\n",
      "Failed on *c1ccc2c(c1)C(CCCCCCCC)(CCCCCCCC)c1cc(-c3ccc4c(c3)C(CCCCCCCCCCCC)(CCCCCCCCCCCC)c3cc(*)ccc3-4)ccc1-2 | Reason: Bad Conformer Id\n",
      "Kept 504 molecules after filtering.\n",
      "Kept 504 molecules after filtering.\n",
      "Saved cleaned Tg dataset to 'cleaned_tg_dataset.csv'.\n",
      "Target shape: (504,)\n",
      "RDKit FP shape: (504, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Build the molecule list\n",
    "valid_mol_objs = []\n",
    "valid_targets = []  # Now stores an array with one value per molecule\n",
    "\n",
    "for i, row in df_tg.iterrows():\n",
    "    smi = row['SMILES']\n",
    "    \n",
    "    # 2.a Clean the SMILES first\n",
    "    cleaned_smiles = canonicalize_polymer_smiles(smi)\n",
    "\n",
    "    try:\n",
    "        # 2.b Create your custom Molecule from the cleaned string\n",
    "        mol = Molecule(cleaned_smiles, input_type='smiles')\n",
    "        mol.hydrogens('add')\n",
    "        mol.to_xyz(optimizer='MMFF', maxIters=200)\n",
    "\n",
    "        # 2.c Only keep molecules that got a 3-D geometry\n",
    "        if mol.xyz is not None:\n",
    "            valid_mol_objs.append(mol)\n",
    "            \n",
    "            # Keep only the 'Tg' target column as a NumPy array\n",
    "            valid_targets.append(\n",
    "                row[['Tg']].values\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipped bc missing xyz: {smi}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on {smi} | Reason: {e}\")\n",
    "\n",
    "print(f\"Kept {len(valid_mol_objs)} molecules after filtering.\")\n",
    "\n",
    "df_clean = pd.DataFrame({\n",
    "    'SMILES': [m.smiles for m in valid_mol_objs],\n",
    "    'Tg':     [t[0] for t in valid_targets],\n",
    "})\n",
    "print(f\"Kept {len(df_clean)} molecules after filtering.\")\n",
    "df_clean.to_csv('cleaned_tg_dataset.csv', index=False)\n",
    "print(\"Saved cleaned Tg dataset to 'cleaned_tg_dataset.csv'.\")\n",
    "\n",
    "y = np.array([t[0] for t in valid_targets])\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# Your feature computation will now work correctly\n",
    "fp_featurizer = RDKitFingerprint(\n",
    "    fingerprint_type='morgan', vector='bit', n_bits=1024, radius=3\n",
    ")\n",
    "X_fp = fp_featurizer.represent(valid_mol_objs)\n",
    "\n",
    "print(\"RDKit FP shape:\", X_fp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff620911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Feature Splits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_48a9e6c1_1f67_4483_ae19_82c16e1e1250\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>Split</th>\n",
       "      <th>Shape</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.3.0 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_48a9e6c1_1f67_4483_ae19_82c16e1e1250:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"X_train_fp_scaled\", \"(403, 1024)\"], [\"X_test_fp_scaled\", \"(101, 1024)\"], [\"y_train_scaled\", \"(403, 1)\"], [\"y_test_scaled\", \"(101, 1)\"], [\"X_train_fp_unscaled\", \"(403, 1024)\"], [\"X_test_fp_unscaled\", \"(101, 1024)\"], [\"y_train_unscaled\", \"(403,)\"], [\"y_test_unscaled\", \"(101,)\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # 1. make separate train/test splits for both scaled and unscaled targets\n",
    "# # scaled targets (MLP, KRR, GNN)\n",
    "# X_train_fp_scaled, X_test_fp_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "#     X_fp, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "# # X_train_cm_scaled, X_test_cm_scaled, _, _ = train_test_split(\n",
    "# #     X_cm, y, test_size=0.2, random_state=42\n",
    "# # )\n",
    "\n",
    "# xscaler_fp = StandardScaler()\n",
    "# # xscaler_cm = StandardScaler()\n",
    "# yscaler = StandardScaler()\n",
    "\n",
    "# X_train_fp_scaled = xscaler_fp.fit_transform(X_train_fp_scaled)\n",
    "# X_test_fp_scaled  = xscaler_fp.transform(X_test_fp_scaled)\n",
    "\n",
    "# # X_train_cm_scaled = xscaler_cm.fit_transform(X_train_cm_scaled)\n",
    "# # X_test_cm_scaled  = xscaler_cm.transform(X_test_cm_scaled)\n",
    "\n",
    "# y_train_scaled = yscaler.fit_transform(y_train_scaled)\n",
    "# y_test_scaled  = yscaler.transform(y_test_scaled)\n",
    "\n",
    "# # b) unscaled targets (Random Forest)\n",
    "# y_unscaled = y              \n",
    "# X_train_fp_unscaled, X_test_fp_unscaled, y_train_unscaled, y_test_unscaled = train_test_split(\n",
    "#     X_fp, y_unscaled, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # 2. show shapes\n",
    "# tools.display_dataframe_to_user(\n",
    "#     name=\"Cleaned Feature Splits\",\n",
    "#     dataframe=pd.DataFrame({\n",
    "#         \"Split\": [\n",
    "#             \"X_train_fp_scaled\", \"X_test_fp_scaled\",\n",
    "#             # \"X_train_cm_scaled\", \"X_test_cm_scaled\",\n",
    "#             \"y_train_scaled\",   \"y_test_scaled\",\n",
    "#             \"X_train_fp_unscaled\", \"X_test_fp_unscaled\",\n",
    "#             \"y_train_unscaled\",   \"y_test_unscaled\"\n",
    "#         ],\n",
    "#         \"Shape\": [\n",
    "#             X_train_fp_scaled.shape, X_test_fp_scaled.shape,\n",
    "#             # X_train_cm_scaled.shape, X_test_cm_scaled.shape,\n",
    "#             y_train_scaled.shape,   y_test_scaled.shape,\n",
    "#             X_train_fp_unscaled.shape, X_test_fp_unscaled.shape,\n",
    "#             y_train_unscaled.shape,   y_test_unscaled.shape\n",
    "#         ]\n",
    "#     })\n",
    "# )\n",
    "\n",
    "# 1. make separate train/test splits for both scaled and unscaled targets\n",
    "# a) Scaled targets (for KRR)\n",
    "# Your y is now a 1D array of FFV values.\n",
    "X_train_fp, X_test_fp, y_train, y_test = train_test_split(\n",
    "    X_fp, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "xscaler_fp = StandardScaler()\n",
    "yscaler = StandardScaler()\n",
    "\n",
    "X_train_fp_scaled = xscaler_fp.fit_transform(X_train_fp)\n",
    "X_test_fp_scaled = xscaler_fp.transform(X_test_fp)\n",
    "\n",
    "# Reshape y arrays for the StandardScaler\n",
    "y_train_scaled = yscaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = yscaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# b) Unscaled targets (for models that don't need scaling, like Random Forest)\n",
    "# These are the original, unscaled splits. You can use the variables you already created.\n",
    "X_train_fp_unscaled = X_train_fp\n",
    "X_test_fp_unscaled = X_test_fp\n",
    "y_train_unscaled = y_train\n",
    "y_test_unscaled = y_test\n",
    "\n",
    "# 2. show shapes\n",
    "# The shape display now reflects the single target variable\n",
    "tools.display_dataframe_to_user(\n",
    "    name=\"Cleaned Feature Splits\",\n",
    "    dataframe=pd.DataFrame({\n",
    "        \"Split\": [\n",
    "            \"X_train_fp_scaled\", \"X_test_fp_scaled\",\n",
    "            \"y_train_scaled\", \"y_test_scaled\",\n",
    "            \"X_train_fp_unscaled\", \"X_test_fp_unscaled\",\n",
    "            \"y_train_unscaled\", \"y_test_unscaled\"\n",
    "        ],\n",
    "        \"Shape\": [\n",
    "            X_train_fp_scaled.shape, X_test_fp_scaled.shape,\n",
    "            y_train_scaled.shape, y_test_scaled.shape,\n",
    "            X_train_fp_unscaled.shape, X_test_fp_unscaled.shape,\n",
    "            y_train_unscaled.shape, y_test_unscaled.shape\n",
    "        ]\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dc183",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression baseline first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9778d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  63.695431  85.338681   0.415116\n"
     ]
    }
   ],
   "source": [
    "# Kernel Ridge on RDKit fingerprints\n",
    "krr = KernelRidge(kernel='rbf', alpha=1.0)\n",
    "krr.fit(X_train_fp_scaled, y_train_scaled)\n",
    "\n",
    "# predict on scaled test set\n",
    "y_pred_krr_scaled = krr.predict(X_test_fp_scaled)\n",
    "\n",
    "# Inverse transform predictions and test targets to compare with unscaled values\n",
    "# You must reshape y_pred_krr_scaled and y_test_scaled to 2D before inverse transforming\n",
    "y_pred_krr = yscaler.inverse_transform(y_pred_krr_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_krr = yscaler.inverse_transform(y_test_scaled).flatten()\n",
    "\n",
    "# Eval against true unscaled test target\n",
    "print(\"Kernel Ridge (RDKit FP)\")\n",
    "metrics_krr = regression_metrics(y_test_krr, y_pred_krr)\n",
    "print(metrics_krr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fedd",
   "metadata": {},
   "source": [
    "## Random Forest Regression baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ea7be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.404863  73.313325   0.568338\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RDKit FP) \n",
    "rfr = RandomForestRegressor(n_estimators=100, max_depth=30, random_state=42)\n",
    "rfr.fit(X_train_fp_unscaled, y_train_unscaled)\n",
    "# predict\n",
    "y_pred_rfr = rfr.predict(X_test_fp_unscaled)\n",
    "# eval\n",
    "print(\"Random Forest (RDKit FP)\")\n",
    "metrics_rfr = regression_metrics(y_test_unscaled, y_pred_rfr)\n",
    "print(metrics_rfr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74973657",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron with Morgan Fingerprints baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70bbb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6521\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8103\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5092\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3847\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3149\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2796\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2548\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2333\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2206\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2144\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2100\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2060\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2040\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2025\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2010\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2000\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1990\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1982\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1968\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1962\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1956\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1949\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1944\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1938\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1932\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1927\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1921\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1910\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1905\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1894\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1889\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1879\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1873\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1868\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1857\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1852\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1847\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1842\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1837\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1832\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1827\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1821\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1816\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1811\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1806\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1801\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1796\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1792\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1787\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1782\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1777\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1772\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1767\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1762\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1757\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1752\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1747\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1742\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1738\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1733\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1728\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1723\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1718\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1714\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1709\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1704\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1699\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1695\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1690\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1685\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1681\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1676\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1671\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1667\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1662\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1658\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1653\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1649\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1644\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1639\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1635\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1630\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1626\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1621\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1617\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1613\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1608\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1604\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1599\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1595\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1590\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1586\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1581\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1577\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1573\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1568\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1564\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1560\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1555\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1551\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1547\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1542\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1538\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1534\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1530\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1525\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1521\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1517\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1513\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1509\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1505\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1501\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1497\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1492\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1488\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1484\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1480\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1476\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1472\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1468\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1463\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1459\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1455\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1452\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1448\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1443\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1440\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1436\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1432\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1428\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1424\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1420\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1416\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1412\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1408\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1404\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1400\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1393\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1389\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1385\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1381\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1377\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1373\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1370\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1366\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1362\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1358\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1355\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1351\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1347\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1343\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1340\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1336\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1332\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1329\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1325\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1321\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1318\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1307\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1304\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1300\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1296\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1293\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1289\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1285\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1282\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1278\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1275\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1271\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1268\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1264\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1261\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1257\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1254\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1250\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1247\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1244\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1240\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1237\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1234\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1230\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1227\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1223\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1220\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1217\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1213\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1210\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1206\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1203\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1200\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1197\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1193\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "MLP (RDKit FP)\n",
      "         MAE      RMSE  r_squared\n",
      "0  54.047308  71.89681   0.584857\n"
     ]
    }
   ],
   "source": [
    "# MLP (Fingerprint)\n",
    "mlp_fp = MLP(\n",
    "    engine='tensorflow',\n",
    "    nfeatures=X_train_fp_scaled.shape[1],\n",
    "    nneurons=[64, 128], # These are the hidden layers\n",
    "    activations=['ReLU', 'ReLU'],\n",
    "    learning_rate=0.01,\n",
    "    alpha=0.001,\n",
    "    nepochs=200,\n",
    "    batch_size=64,\n",
    "    loss='mean_squared_error',\n",
    "    is_regression=True\n",
    ")\n",
    "\n",
    "mlp_fp.fit(X=X_train_fp_scaled, y=y_train_scaled.ravel()) # Use .ravel() to convert to 1D\n",
    "y_pred_fp_scaled = mlp_fp.predict(X_test_fp_scaled)\n",
    "# Reshape the output from predict() to 2D before inverse transforming\n",
    "y_pred_fp = yscaler.inverse_transform(y_pred_fp_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_fp = yscaler.inverse_transform(y_test_scaled).flatten()\n",
    "\n",
    "# Eval against true unscaled test target\n",
    "print(\"MLP (RDKit FP)\")\n",
    "metrics_mlp = regression_metrics(y_test, y_pred_fp)\n",
    "print(metrics_mlp[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abe3c7",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron with Coulomb Matrix representation baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64495ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP (Coulomb matrix)\n",
    "# mlp_cm = MLP(\n",
    "#     engine='tensorflow', \n",
    "#     nfeatures=X_train_cm_scaled.shape[1], \n",
    "#     nneurons=[64, 128], \n",
    "#     activations=['ReLU', 'ReLU'],\n",
    "#     learning_rate=0.0001, \n",
    "#     alpha=0.001, \n",
    "#     nepochs=100, \n",
    "#     batch_size=64, \n",
    "#     loss='mean_squared_error', \n",
    "#     is_regression=True\n",
    "#     )\n",
    "\n",
    "# mlp_cm.fit(X=X_train_cm_scaled, y=y_train_scaled)\n",
    "# y_pred_cm_scaled = mlp_cm.predict(X_test_cm_scaled)\n",
    "# y_pred_cm = yscaler.inverse_transform(y_pred_cm_scaled)\n",
    "# y_test_cm = yscaler.inverse_transform(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7101926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Comparison\n",
      "\n",
      "Kernel Ridge (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  63.695431  85.338681   0.415116\n",
      "\n",
      "Random Forest (RDKit FP)\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.404863  73.313325   0.568338\n",
      "\n",
      "MLP (RDKit FP)\n",
      "         MAE      RMSE  r_squared\n",
      "0  54.047308  71.89681   0.584857\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "results = {\"Kernel Ridge (RDKit FP)\": regression_metrics(y_test_krr, y_pred_krr),\n",
    "           \"Random Forest (RDKit FP)\": regression_metrics(y_test_unscaled, y_pred_rfr),\n",
    "           \"MLP (RDKit FP)\": regression_metrics(y_test_fp, y_pred_fp),\n",
    "        #    \"MLP (Coulomb Matrix)\": regression_metrics(y_test_cm, y_pred_cm)\n",
    "        }\n",
    "\n",
    "# display\n",
    "print(\"Final Model Comparison\")\n",
    "for name, metrics_df in results.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(metrics_df[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e7366",
   "metadata": {},
   "source": [
    "## Parity Plots and Residuals Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86ff8791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_regression_results(y_true, y_pred, title=\"Model Evaluation\", save_dir=\"plots\"):\n",
    "    residuals = y_true.flatten() - y_pred.flatten()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # parity plot\n",
    "    sns.scatterplot(ax=axes[0], x=y_true.flatten(), y=y_pred.flatten(), alpha=0.5)\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    axes[0].plot([min_val, max_val], [min_val, max_val], '--r')\n",
    "    axes[0].set_xlabel(\"Actual HOMO-LUMO Gap\")\n",
    "    axes[0].set_ylabel(\"Predicted HOMO-LUMO Gap\")\n",
    "    axes[0].set_title(\"Parity Plot\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].axis('equal')\n",
    "\n",
    "    # residuals histogram\n",
    "    sns.histplot(ax=axes[1], data=residuals, bins=30, kde=True)\n",
    "    axes[1].set_title(\"Residuals Histogram\")\n",
    "    axes[1].set_xlabel(\"Residual (Actual - Predicted)\")\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # overall title\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "\n",
    "    # save fig as pdf for best overleaf upload format \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = os.path.join(save_dir, f\"{title.lower().replace(' ', '_')}_plots.pdf\")\n",
    "    fig.savefig(filename, bbox_inches='tight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_regression_results(y_test_fp, y_pred_fp, title=\"MLP Untuned(RDKit FP)\")\n",
    "# plot_regression_results(y_test_cm, y_pred_cm, title=\"MLP Untuned (Coulomb Matrix)\")\n",
    "plot_regression_results(y_test_krr, y_pred_krr, title=\"Kernel Ridge Untuned (RDKit FP)\")\n",
    "plot_regression_results(y_test_unscaled, y_pred_rfr, title=\"Random Forest Untuned (RDKit FP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dce050",
   "metadata": {},
   "source": [
    "## Tune hyperparameters for baseline models with Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66717bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 18:07:31,274] A new study created in memory with name: no-name-2c5544dd-a13f-4e25-84e0-408d9fef1e39\n",
      "[I 2025-09-04 18:07:31,289] Trial 0 finished with value: 52.47805602991537 and parameters: {'alpha': 0.06586033910839106, 'kernel': 'poly'}. Best is trial 0 with value: 52.47805602991537.\n",
      "[I 2025-09-04 18:07:31,303] Trial 1 finished with value: 55.412910810865775 and parameters: {'alpha': 0.01189927541556288, 'kernel': 'rbf', 'gamma': 0.0001648963316314988}. Best is trial 0 with value: 52.47805602991537.\n",
      "[I 2025-09-04 18:07:31,316] Trial 2 finished with value: 52.14000842310857 and parameters: {'alpha': 0.26346624549357756, 'kernel': 'poly'}. Best is trial 2 with value: 52.14000842310857.\n",
      "[I 2025-09-04 18:07:31,328] Trial 3 finished with value: 52.09947380024483 and parameters: {'alpha': 0.7923779405719946, 'kernel': 'poly'}. Best is trial 3 with value: 52.09947380024483.\n",
      "[I 2025-09-04 18:07:31,340] Trial 4 finished with value: 52.32335741706265 and parameters: {'alpha': 0.14119986874068377, 'kernel': 'poly'}. Best is trial 3 with value: 52.09947380024483.\n",
      "[I 2025-09-04 18:07:31,354] Trial 5 finished with value: 55.31698809949579 and parameters: {'alpha': 0.2378916861968663, 'kernel': 'rbf', 'gamma': 6.471926225070463e-05}. Best is trial 3 with value: 52.09947380024483.\n",
      "[I 2025-09-04 18:07:31,367] Trial 6 finished with value: 51.968859362500964 and parameters: {'alpha': 0.42275121284674017, 'kernel': 'poly'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,379] Trial 7 finished with value: 58.82575559400796 and parameters: {'alpha': 0.18067640510655608, 'kernel': 'rbf', 'gamma': 2.201184790778948e-05}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,392] Trial 8 finished with value: 51.981828569578845 and parameters: {'alpha': 0.5468036981666496, 'kernel': 'poly'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,402] Trial 9 finished with value: 68.43826969386384 and parameters: {'alpha': 0.015893479145357808, 'kernel': 'linear'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,415] Trial 10 finished with value: 68.42449870540118 and parameters: {'alpha': 0.0526283971868109, 'kernel': 'linear'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,441] Trial 11 finished with value: 52.193471126620416 and parameters: {'alpha': 0.9733751803495119, 'kernel': 'poly'}. Best is trial 6 with value: 51.968859362500964.\n",
      "[I 2025-09-04 18:07:31,458] Trial 12 finished with value: 51.96500117248103 and parameters: {'alpha': 0.4920579525092092, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,476] Trial 13 finished with value: 51.97419864966313 and parameters: {'alpha': 0.4159966331024372, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,491] Trial 14 finished with value: 51.968444818788015 and parameters: {'alpha': 0.4232777190128455, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,504] Trial 15 finished with value: 68.41400583322502 and parameters: {'alpha': 0.080656110114022, 'kernel': 'linear'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,518] Trial 16 finished with value: 52.58128817556072 and parameters: {'alpha': 0.023234350205253104, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,532] Trial 17 finished with value: 52.05712524469121 and parameters: {'alpha': 0.32980900939145164, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,546] Trial 18 finished with value: 68.39458522328754 and parameters: {'alpha': 0.13261628224132208, 'kernel': 'linear'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,566] Trial 19 finished with value: 89.0327252770603 and parameters: {'alpha': 0.6298351352618616, 'kernel': 'rbf', 'gamma': 0.7952453489587329}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,580] Trial 20 finished with value: 52.54936018804663 and parameters: {'alpha': 0.03579894262103647, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,594] Trial 21 finished with value: 51.96687854001945 and parameters: {'alpha': 0.42526973300745385, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,609] Trial 22 finished with value: 51.97791306468501 and parameters: {'alpha': 0.5378915817154151, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,626] Trial 23 finished with value: 52.18061933920176 and parameters: {'alpha': 0.23348583667929712, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,641] Trial 24 finished with value: 52.054619899356105 and parameters: {'alpha': 0.3319257953086633, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,662] Trial 25 finished with value: 52.08681005398675 and parameters: {'alpha': 0.7702583560629688, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,682] Trial 26 finished with value: 52.361925368359316 and parameters: {'alpha': 0.12106605590677347, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,699] Trial 27 finished with value: 51.97560333104032 and parameters: {'alpha': 0.4142278627567089, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,715] Trial 28 finished with value: 68.37586103542857 and parameters: {'alpha': 0.1828183805648035, 'kernel': 'linear'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,730] Trial 29 finished with value: 89.032716443888 and parameters: {'alpha': 0.9587745065596295, 'kernel': 'rbf', 'gamma': 0.060706583409964786}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,745] Trial 30 finished with value: 52.42390156162841 and parameters: {'alpha': 0.090613119757921, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,762] Trial 31 finished with value: 51.96668406725522 and parameters: {'alpha': 0.42551736465255957, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,776] Trial 32 finished with value: 52.05722998098624 and parameters: {'alpha': 0.32972066238840725, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,793] Trial 33 finished with value: 52.01120905878846 and parameters: {'alpha': 0.6192240947377317, 'kernel': 'poly'}. Best is trial 12 with value: 51.96500117248103.\n",
      "[I 2025-09-04 18:07:31,811] Trial 34 finished with value: 51.96342341968574 and parameters: {'alpha': 0.48527751803893, 'kernel': 'poly'}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,825] Trial 35 finished with value: 52.24775210076025 and parameters: {'alpha': 0.18738602991439993, 'kernel': 'poly'}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,845] Trial 36 finished with value: 52.13629371446523 and parameters: {'alpha': 0.2662897587982509, 'kernel': 'poly'}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,860] Trial 37 finished with value: 78.68633182165037 and parameters: {'alpha': 0.8110462590695258, 'kernel': 'rbf', 'gamma': 0.0031603499980466985}. Best is trial 34 with value: 51.96342341968574.\n",
      "[I 2025-09-04 18:07:31,878] Trial 38 finished with value: 51.961542842093415 and parameters: {'alpha': 0.4774062604325275, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,893] Trial 39 finished with value: 51.971211985294644 and parameters: {'alpha': 0.5204914097923213, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,917] Trial 40 finished with value: 76.4026123709475 and parameters: {'alpha': 0.28634003080762305, 'kernel': 'rbf', 'gamma': 0.002922293105660872}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,936] Trial 41 finished with value: 52.04149605922797 and parameters: {'alpha': 0.6951343718689064, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,953] Trial 42 finished with value: 51.96157915011297 and parameters: {'alpha': 0.4588484548527643, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,968] Trial 43 finished with value: 51.974321170033235 and parameters: {'alpha': 0.5298554496223997, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,983] Trial 44 finished with value: 52.02247491555436 and parameters: {'alpha': 0.35968374719260787, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:31,998] Trial 45 finished with value: 52.17108459565094 and parameters: {'alpha': 0.2403799931808444, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,012] Trial 46 finished with value: 51.96810025203249 and parameters: {'alpha': 0.5058798993837317, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,025] Trial 47 finished with value: 68.13405255180737 and parameters: {'alpha': 0.8405293836136751, 'kernel': 'linear'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,042] Trial 48 finished with value: 52.02543304515025 and parameters: {'alpha': 0.6582593301255977, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,057] Trial 49 finished with value: 52.22933552237023 and parameters: {'alpha': 0.1996139831330201, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,073] Trial 50 finished with value: 52.29797265304777 and parameters: {'alpha': 0.1555967046976449, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,088] Trial 51 finished with value: 51.977345853661795 and parameters: {'alpha': 0.41203845820076174, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,104] Trial 52 finished with value: 52.61356305492147 and parameters: {'alpha': 0.011076118083251133, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,120] Trial 53 finished with value: 51.961558896907526 and parameters: {'alpha': 0.46538414726946603, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,137] Trial 54 finished with value: 51.962247498264475 and parameters: {'alpha': 0.4803295713899409, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,158] Trial 55 finished with value: 68.33332499049632 and parameters: {'alpha': 0.29724846377190656, 'kernel': 'linear'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,176] Trial 56 finished with value: 52.48466409351611 and parameters: {'alpha': 0.06295527488132921, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,196] Trial 57 finished with value: 89.03272380864796 and parameters: {'alpha': 0.4658868559955186, 'kernel': 'rbf', 'gamma': 0.07317555814354744}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,211] Trial 58 finished with value: 52.015786202609455 and parameters: {'alpha': 0.6314766599597024, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,227] Trial 59 finished with value: 52.039107593207625 and parameters: {'alpha': 0.34518175702344894, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,241] Trial 60 finished with value: 52.5507841610139 and parameters: {'alpha': 0.035226985876633615, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,257] Trial 61 finished with value: 51.96157589961576 and parameters: {'alpha': 0.4547793366561898, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,271] Trial 62 finished with value: 51.99436894744592 and parameters: {'alpha': 0.576467550067699, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,287] Trial 63 finished with value: 52.005197848010134 and parameters: {'alpha': 0.37775982614307163, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,301] Trial 64 finished with value: 52.05883787572597 and parameters: {'alpha': 0.723159624682569, 'kernel': 'poly'}. Best is trial 38 with value: 51.961542842093415.\n",
      "[I 2025-09-04 18:07:32,322] Trial 65 finished with value: 51.96153145175183 and parameters: {'alpha': 0.4693673305699074, 'kernel': 'poly'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,337] Trial 66 finished with value: 52.19862488651819 and parameters: {'alpha': 0.9842115497070224, 'kernel': 'poly'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,353] Trial 67 finished with value: 68.35331501794829 and parameters: {'alpha': 0.24340474224991604, 'kernel': 'linear'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,367] Trial 68 finished with value: 52.0945185987686 and parameters: {'alpha': 0.2990014365740163, 'kernel': 'poly'}. Best is trial 65 with value: 51.96153145175183.\n",
      "[I 2025-09-04 18:07:32,382] Trial 69 finished with value: 51.961517736909315 and parameters: {'alpha': 0.4709166016409924, 'kernel': 'poly'}. Best is trial 69 with value: 51.961517736909315.\n",
      "[I 2025-09-04 18:07:32,395] Trial 70 finished with value: 52.21490670799681 and parameters: {'alpha': 0.20941321017733855, 'kernel': 'poly'}. Best is trial 69 with value: 51.961517736909315.\n",
      "[I 2025-09-04 18:07:32,409] Trial 71 finished with value: 51.961512376108054 and parameters: {'alpha': 0.4445432859238032, 'kernel': 'poly'}. Best is trial 71 with value: 51.961512376108054.\n",
      "[I 2025-09-04 18:07:32,424] Trial 72 finished with value: 52.00040401461049 and parameters: {'alpha': 0.3835639006267663, 'kernel': 'poly'}. Best is trial 71 with value: 51.961512376108054.\n",
      "[I 2025-09-04 18:07:32,446] Trial 73 finished with value: 51.961449192903274 and parameters: {'alpha': 0.476887750531236, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,464] Trial 74 finished with value: 51.98905721435983 and parameters: {'alpha': 0.5636885577207004, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,483] Trial 75 finished with value: 51.961577273556095 and parameters: {'alpha': 0.455444107021338, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,495] Trial 76 finished with value: 52.00246719864148 and parameters: {'alpha': 0.5965885006620995, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,512] Trial 77 finished with value: 54.80725498194603 and parameters: {'alpha': 0.31408515054659203, 'kernel': 'rbf', 'gamma': 0.0003052666520487559}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,527] Trial 78 finished with value: 52.136021803345564 and parameters: {'alpha': 0.8591320897872, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,540] Trial 79 finished with value: 52.052914508281354 and parameters: {'alpha': 0.7134881862837423, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,554] Trial 80 finished with value: 52.00139150853791 and parameters: {'alpha': 0.3823650481615241, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,567] Trial 81 finished with value: 51.96146634818446 and parameters: {'alpha': 0.44060780197168276, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,580] Trial 82 finished with value: 51.96980875856301 and parameters: {'alpha': 0.4215465270818391, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,594] Trial 83 finished with value: 51.96155272109186 and parameters: {'alpha': 0.44943196500625937, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,607] Trial 84 finished with value: 51.97289675915037 and parameters: {'alpha': 0.526704776800457, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,620] Trial 85 finished with value: 52.14035964147195 and parameters: {'alpha': 0.2631999996228438, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,634] Trial 86 finished with value: 68.31318799352148 and parameters: {'alpha': 0.3516080032551108, 'kernel': 'linear'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,647] Trial 87 finished with value: 51.99945516698461 and parameters: {'alpha': 0.5890123813299221, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,662] Trial 88 finished with value: 52.6061520239504 and parameters: {'alpha': 0.013820428616055626, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,679] Trial 89 finished with value: 89.0327252770603 and parameters: {'alpha': 0.7545636235829007, 'kernel': 'rbf', 'gamma': 0.9695442488758451}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,695] Trial 90 finished with value: 52.03014132278019 and parameters: {'alpha': 0.6718282587797618, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,710] Trial 91 finished with value: 51.96156467059265 and parameters: {'alpha': 0.46424226918900763, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,724] Trial 92 finished with value: 51.96157348002087 and parameters: {'alpha': 0.46192850723210205, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,741] Trial 93 finished with value: 51.99243753425823 and parameters: {'alpha': 0.39329733290288266, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,757] Trial 94 finished with value: 51.97465944157995 and parameters: {'alpha': 0.5306066705832921, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,770] Trial 95 finished with value: 52.05527511156812 and parameters: {'alpha': 0.33137155577371186, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,789] Trial 96 finished with value: 51.96572890404508 and parameters: {'alpha': 0.4952421772726629, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,803] Trial 97 finished with value: 52.122906625902914 and parameters: {'alpha': 0.27657979269019667, 'kernel': 'poly'}. Best is trial 73 with value: 51.961449192903274.\n",
      "[I 2025-09-04 18:07:32,822] Trial 98 finished with value: 51.961370500165984 and parameters: {'alpha': 0.43450048547076636, 'kernel': 'poly'}. Best is trial 98 with value: 51.961370500165984.\n",
      "[I 2025-09-04 18:07:32,844] Trial 99 finished with value: 51.974254463201994 and parameters: {'alpha': 0.41592628731448095, 'kernel': 'poly'}. Best is trial 98 with value: 51.961370500165984.\n"
     ]
    }
   ],
   "source": [
    "def objective_krr(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 1.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly'])\n",
    "    gamma = trial.suggest_float('gamma', 1e-5, 1.0, log=True) if kernel == 'rbf' else None\n",
    "    model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma) if gamma else KernelRidge(alpha=alpha, kernel=kernel)\n",
    "    model.fit(X_train_fp_scaled, y_train_scaled)\n",
    "    preds_scaled = model.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "    preds = yscaler.inverse_transform(preds_scaled)\n",
    "    y_test_inv = yscaler.inverse_transform(y_test_scaled)\n",
    "    metrics = regression_metrics(y_test_inv, preds)\n",
    "    return metrics['MAE'][0]\n",
    "\n",
    "study_krr = optuna.create_study(direction='minimize')\n",
    "study_krr.optimize(objective_krr, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83942b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 18:07:36,340] A new study created in memory with name: no-name-571e3f03-3bb2-49d7-9e5b-88944aa83273\n",
      "[I 2025-09-04 18:07:36,695] Trial 0 finished with value: 54.611500266146024 and parameters: {'n_estimators': 100, 'max_depth': 60}. Best is trial 0 with value: 54.611500266146024.\n",
      "[I 2025-09-04 18:07:37,127] Trial 1 finished with value: 53.24178721398811 and parameters: {'n_estimators': 200, 'max_depth': 10}. Best is trial 1 with value: 53.24178721398811.\n",
      "[I 2025-09-04 18:07:37,730] Trial 2 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:38,343] Trial 3 finished with value: 54.05674128710554 and parameters: {'n_estimators': 200, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:38,560] Trial 4 finished with value: 54.704354298388026 and parameters: {'n_estimators': 50, 'max_depth': 80}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:39,190] Trial 5 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:39,914] Trial 6 finished with value: 53.47018274669734 and parameters: {'n_estimators': 250, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:40,493] Trial 7 finished with value: 53.79704749291141 and parameters: {'n_estimators': 200, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:40,937] Trial 8 finished with value: 53.54010401337062 and parameters: {'n_estimators': 150, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:41,261] Trial 9 finished with value: 54.21533823750181 and parameters: {'n_estimators': 100, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:42,099] Trial 10 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 90}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:42,933] Trial 11 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 50}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:43,552] Trial 12 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:44,280] Trial 13 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 70}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:45,066] Trial 14 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:45,682] Trial 15 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:46,397] Trial 16 finished with value: 53.57817243697484 and parameters: {'n_estimators': 250, 'max_depth': 100}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:46,878] Trial 17 finished with value: 53.94771543377596 and parameters: {'n_estimators': 150, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:47,709] Trial 18 finished with value: 53.42147900496652 and parameters: {'n_estimators': 300, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:48,440] Trial 19 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 60}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:49,306] Trial 20 finished with value: 53.42147900496652 and parameters: {'n_estimators': 300, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:49,948] Trial 21 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:50,509] Trial 22 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:51,345] Trial 23 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:51,972] Trial 24 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:52,670] Trial 25 finished with value: 53.47018274669734 and parameters: {'n_estimators': 250, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:53,244] Trial 26 finished with value: 53.79704749291141 and parameters: {'n_estimators': 200, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:53,865] Trial 27 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:54,601] Trial 28 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 50}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:54,833] Trial 29 finished with value: 54.36384490703731 and parameters: {'n_estimators': 50, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:55,173] Trial 30 finished with value: 54.611500266146024 and parameters: {'n_estimators': 100, 'max_depth': 60}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:55,793] Trial 31 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:56,440] Trial 32 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:57,046] Trial 33 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:57,740] Trial 34 finished with value: 53.531034696813975 and parameters: {'n_estimators': 250, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:58,325] Trial 35 finished with value: 53.92580128403864 and parameters: {'n_estimators': 200, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:58,959] Trial 36 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:07:59,859] Trial 37 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:00,448] Trial 38 finished with value: 54.05674128710554 and parameters: {'n_estimators': 200, 'max_depth': 70}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:00,917] Trial 39 finished with value: 53.54010401337062 and parameters: {'n_estimators': 150, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:01,630] Trial 40 finished with value: 53.47018274669734 and parameters: {'n_estimators': 250, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:02,249] Trial 41 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:02,868] Trial 42 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:03,691] Trial 43 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:04,343] Trial 44 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:05,054] Trial 45 finished with value: 53.531034696813975 and parameters: {'n_estimators': 250, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:05,672] Trial 46 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:06,397] Trial 47 finished with value: 53.531034696813975 and parameters: {'n_estimators': 250, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:07,122] Trial 48 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:07,338] Trial 49 finished with value: 54.57468448667023 and parameters: {'n_estimators': 50, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:08,077] Trial 50 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 40}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:08,706] Trial 51 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:09,340] Trial 52 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:10,162] Trial 53 finished with value: 53.38214016287373 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:10,782] Trial 54 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:11,123] Trial 55 finished with value: 54.21533823750181 and parameters: {'n_estimators': 100, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:11,959] Trial 56 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 90}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:12,501] Trial 57 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:13,323] Trial 58 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:13,864] Trial 59 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:14,327] Trial 60 finished with value: 53.805224367094354 and parameters: {'n_estimators': 150, 'max_depth': 30}. Best is trial 2 with value: 52.84979616026849.\n",
      "[I 2025-09-04 18:08:14,950] Trial 61 finished with value: 52.84979616026848 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:15,783] Trial 62 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:16,403] Trial 63 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:17,021] Trial 64 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:17,895] Trial 65 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:18,532] Trial 66 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:19,274] Trial 67 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 70}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:20,105] Trial 68 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:20,740] Trial 69 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:21,549] Trial 70 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:22,183] Trial 71 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:22,807] Trial 72 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:23,422] Trial 73 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:24,255] Trial 74 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:24,891] Trial 75 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:25,604] Trial 76 finished with value: 53.57817243697483 and parameters: {'n_estimators': 250, 'max_depth': 50}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:26,224] Trial 77 finished with value: 52.84979616026848 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:26,845] Trial 78 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:27,568] Trial 79 finished with value: 53.57817243697484 and parameters: {'n_estimators': 250, 'max_depth': 100}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:28,432] Trial 80 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:29,047] Trial 81 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:29,673] Trial 82 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:30,318] Trial 83 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:30,919] Trial 84 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:31,754] Trial 85 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:32,372] Trial 86 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:33,197] Trial 87 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:33,751] Trial 88 finished with value: 52.91805619992673 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:34,214] Trial 89 finished with value: 53.2417872139881 and parameters: {'n_estimators': 200, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:35,077] Trial 90 finished with value: 53.42147900496652 and parameters: {'n_estimators': 300, 'max_depth': 30}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:35,684] Trial 91 finished with value: 52.849796160268504 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:36,304] Trial 92 finished with value: 52.84979616026848 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:36,939] Trial 93 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:37,758] Trial 94 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:38,624] Trial 95 finished with value: 53.51406801313421 and parameters: {'n_estimators': 300, 'max_depth': 80}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:39,244] Trial 96 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:39,791] Trial 97 finished with value: 52.91805619992672 and parameters: {'n_estimators': 250, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:40,580] Trial 98 finished with value: 53.382140162873725 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 61 with value: 52.84979616026848.\n",
      "[I 2025-09-04 18:08:41,217] Trial 99 finished with value: 52.84979616026849 and parameters: {'n_estimators': 300, 'max_depth': 10}. Best is trial 61 with value: 52.84979616026848.\n"
     ]
    }
   ],
   "source": [
    "def objective_rfr(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 100, step=10)\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_fp_unscaled, y_train_unscaled)\n",
    "    preds = model.predict(X_test_fp_unscaled)\n",
    "    metrics = regression_metrics(y_test_unscaled, preds)\n",
    "    return metrics['MAE'][0]\n",
    "\n",
    "study_rfr = optuna.create_study(direction='minimize')\n",
    "study_rfr.optimize(objective_rfr, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b6bd272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:24,914] A new study created in memory with name: no-name-4ab51d06-e6c2-4787-94b5-1e523db9ae9a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 13.0463\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.5493\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0623\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7880\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.6493\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5376\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.4500\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.3826\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3276\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.2778\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2318\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1888\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.1488\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1109\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0754\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0411\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.0079\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9758\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.9449\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.9140\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8838\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8540\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8246\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7956\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7669\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7385\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7102\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6821\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6543\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6265\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5990\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5716\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5443\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5171\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4901\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4632\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4364\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4096\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3830\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3565\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3300\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3037\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2774\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2513\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2252\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1992\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1732\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1474\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1216\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0959\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0702\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0447\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0192\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9938\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9684\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9431\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9179\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8928\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8677\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8427\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8177\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.7929\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7681\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7433\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7186\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6940\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6695\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6450\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6206\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5962\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5719\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5477\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5235\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4994\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4753\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4513\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4274\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4036\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3798\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3560\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 9.3323\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3087\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2852\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2617\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2382\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2149\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1915\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.1683\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1451\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1219\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0989\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0758\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0529\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0300\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0071\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9844\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9616\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9390\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9163\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8938\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:32,502] Trial 0 finished with value: 65.97623144240474 and parameters: {'lr': 0.0006131707246017513, 'alpha': 0.014757403572832895, 'activation': 'relu', 'n1': 320, 'n2': 256}. Best is trial 0 with value: 65.97623144240474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0463\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2119\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9368\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7513\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6307\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5531\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5196\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4819\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4692\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4585\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4498\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4446\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4411\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4371\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4349\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4334\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4319\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4306\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4295\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4285\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4275\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4266\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4249\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4240\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4232\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4223\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4215\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4207\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4199\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4191\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4183\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4175\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4167\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4159\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4152\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4144\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4136\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4129\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4121\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4113\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4106\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4098\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4091\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4083\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4076\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4068\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4061\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4053\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4046\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4038\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4031\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4024\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4016\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4009\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4002\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3995\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3987\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3980\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3973\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3966\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3958\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3944\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3937\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3930\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3923\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3915\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3908\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3901\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3894\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3887\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3880\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3873\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3866\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3859\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3852\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3845\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3838\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3831\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3824\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3817\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3810\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3803\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3796\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3790\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3783\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3776\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3769\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3762\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3755\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3749\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3742\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3735\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3728\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3722\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3715\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3708\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3701\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3695\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:34,264] Trial 1 finished with value: 61.46685337652091 and parameters: {'lr': 0.007037316607790657, 'alpha': 0.0009259457413312761, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 1 with value: 61.46685337652091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4335\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8620\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5381\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3505\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2835\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2151\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1895\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1468\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1299\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1167\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1062\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0995\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0884\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0839\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0795\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0750\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0709\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0668\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0629\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0589\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0550\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0512\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0472\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0434\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0396\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0358\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0321\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0246\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0209\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0172\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0136\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0099\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0063\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0027\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9991\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9955\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9919\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9883\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9848\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9813\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9708\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9673\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9638\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9604\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9569\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9535\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9501\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9467\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9433\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9400\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9366\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9333\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9299\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9266\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9233\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9200\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9167\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9102\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9069\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9037\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9005\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8972\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8940\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8908\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8877\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8845\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8813\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8782\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8751\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8719\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8688\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8657\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8627\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8596\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8565\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8535\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8504\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8474\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8444\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8414\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8384\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8354\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8324\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8294\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8265\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8235\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8206\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8177\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8118\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8090\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8061\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8032\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8003\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7975\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:36,083] Trial 2 finished with value: 59.99714808365374 and parameters: {'lr': 0.007103555042896184, 'alpha': 0.001803930832367276, 'activation': 'gelu', 'n1': 256, 'n2': 192}. Best is trial 2 with value: 59.99714808365374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1853\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1944\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0524\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9098\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8578\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8153\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7964\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7762\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7648\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7566\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7523\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7489\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7449\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7418\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7366\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7342\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7320\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7298\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7276\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7255\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7234\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7214\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7193\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7173\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7152\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7132\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7112\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7092\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7072\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7052\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7033\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7013\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6973\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6954\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6935\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6915\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6896\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6876\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6857\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6838\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6819\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6781\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6762\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6743\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6724\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6705\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6686\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6667\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6649\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6630\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6612\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6593\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6575\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6557\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6538\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6520\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6502\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6484\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6465\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6429\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6411\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6393\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6376\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6358\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6340\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6322\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6305\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6287\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6269\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6252\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6234\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6217\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6200\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6182\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6165\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6148\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6131\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6097\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6079\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6062\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6046\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6028\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6012\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5995\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5978\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5962\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5945\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5928\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5912\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5895\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5879\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5862\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5846\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5830\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5813\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:37,651] Trial 3 finished with value: 59.55488712192801 and parameters: {'lr': 0.004657392505497789, 'alpha': 0.0021561184888452835, 'activation': 'relu', 'n1': 128, 'n2': 128}. Best is trial 3 with value: 59.55488712192801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8280\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1476\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9408\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8615\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8108\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7829\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7879\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7556\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7404\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7325\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7278\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7225\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7193\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7158\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7138\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7116\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7098\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7083\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7064\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7047\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7032\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7017\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7003\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6988\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6974\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6961\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6947\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6933\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6920\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6906\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6893\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6879\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6866\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6840\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6827\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6813\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6787\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6775\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6762\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6749\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6736\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6723\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6710\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6697\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6685\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6672\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6659\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6647\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6634\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6621\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6609\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6596\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6584\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6571\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6559\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6547\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6534\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6522\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6510\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6497\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6485\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6473\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6460\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6448\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6436\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6424\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6412\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6400\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6388\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6375\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6363\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6352\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6339\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6328\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6316\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6304\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6292\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6280\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6268\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6256\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6244\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6233\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6221\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6209\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6197\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6186\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6174\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6162\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6151\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6139\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6128\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6116\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6104\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6093\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6081\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6070\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6059\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6047\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:39,472] Trial 4 finished with value: 59.83959769023511 and parameters: {'lr': 0.005391205538210505, 'alpha': 0.001257192903748666, 'activation': 'gelu', 'n1': 192, 'n2': 384}. Best is trial 3 with value: 59.55488712192801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3738\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3670\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3664\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3614\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3317\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3240\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3112\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3013\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2926\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2734\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2624\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2540\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2342\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2285\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2071\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2319\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1770\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1549\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1386\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1257\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1111\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1032\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0695\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0531\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0428\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0290\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0381\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0089\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9717\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9640\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9746\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9392\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8966\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8834\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8678\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8693\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8350\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8205\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8112\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7929\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7808\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7697\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7573\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7480\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7488\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7247\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7222\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7181\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7142\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7077\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6871\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6776\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6711\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6717\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6545\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6542\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6482\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6391\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6288\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6233\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6175\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6132\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6073\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6032\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5993\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5948\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5909\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5835\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5802\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5773\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5717\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5656\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5653\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5600\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5551\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5509\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5473\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5440\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5410\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5393\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5367\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5297\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5264\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5236\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5208\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5175\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5179\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5192\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5116\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5078\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5062\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5026\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4983\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4985\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4928\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4912\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4914\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4867\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:41,049] Trial 5 finished with value: 57.95134360880324 and parameters: {'lr': 0.0010252295697744435, 'alpha': 0.000894687368799269, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 5 with value: 57.95134360880324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7150\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6512\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 17.5593\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4668\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3681\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2775\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1930\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1197\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.0473\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9818\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9202\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8640\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8077\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7571\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7075\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6619\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6141\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5708\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5285\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4878\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4477\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4096\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3727\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3366\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3015\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2675\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2326\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.2017\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1683\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1362\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1050\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0745\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0436\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0141\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9845\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9557\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9269\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8982\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.8700\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8418\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8142\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7869\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7602\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7335\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7071\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6806\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6550\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6289\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6031\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5775\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5523\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5272\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5021\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.4775\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4528\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4285\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4040\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3796\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.3557\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3318\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3080\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2844\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2609\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2374\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2141\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1910\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1679\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1449\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1218\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0991\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0763\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.0538\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0311\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0086\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9864\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9641\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9419\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9199\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8978\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8759\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8539\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.8321\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8103\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7887\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7670\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7455\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7240\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7026\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6813\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6598\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6387\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.6174\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5963\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5752\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5541\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5331\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5122\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4914\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4705\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4497\n",
      "4/4 [==============================] - 0s 834us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:42,714] Trial 6 finished with value: 72.7612765917017 and parameters: {'lr': 0.00011936108934714092, 'alpha': 0.04139892684630957, 'activation': 'relu', 'n1': 128, 'n2': 256}. Best is trial 5 with value: 57.95134360880324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2594\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9850\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7148\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5996\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4031\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.2582\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0912\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9319\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 19.7817\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6202\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4729\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3153\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1653\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0145\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8641\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7211\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5789\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4230\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2838\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1318\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9865\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8478\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7072\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5644\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4282\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2908\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1588\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.0245\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8845\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7466\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6156\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4930\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3518\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2315\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0988\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9690\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8407\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.7161\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.5911\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4646\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3415\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2190\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.0988\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9787\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8601\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7459\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6275\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5176\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3995\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2862\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1708\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0629\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9554\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 13.8442\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7333\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6263\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5216\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4112\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3109\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2050\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1008\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0030\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8985\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7992\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7011\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6024\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.5101\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4073\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3155\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2177\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1217\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0299\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9375\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8439\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.7615\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6654\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5777\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4856\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3980\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3108\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.2251\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1408\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0529\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9707\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.8838\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8016\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7191\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6373\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5582\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4788\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3950\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3184\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2366\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1614\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0808\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0082\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9292\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8545\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7796\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7059\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:44,394] Trial 7 finished with value: 57.49475406130353 and parameters: {'lr': 0.0007068994556534392, 'alpha': 0.03869731508263629, 'activation': 'sigmoid', 'n1': 192, 'n2': 192}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2655\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1104\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9899\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8382\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7176\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6132\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5277\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4574\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4002\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3516\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3067\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2706\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2370\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2086\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1838\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1605\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1396\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1214\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0890\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0745\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0613\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0488\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0378\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0277\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0181\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0093\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0008\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9932\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9848\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9782\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9715\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9648\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9589\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9530\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9477\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9427\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9376\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9333\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9287\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9246\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9206\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9168\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9130\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9098\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9062\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9037\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9004\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8972\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8945\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8916\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8891\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8866\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8842\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8820\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8797\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8777\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8757\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8737\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8720\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8700\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8683\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8666\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8649\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8633\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8618\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8604\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8589\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8574\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8561\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8548\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8534\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8522\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8510\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8499\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8488\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8477\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8466\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8455\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8445\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8436\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8426\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8417\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8408\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8399\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8391\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8382\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8375\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8368\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8358\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8351\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8343\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8335\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8328\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8321\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8314\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8307\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8300\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8294\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8288\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:45,990] Trial 8 finished with value: 78.30218485723917 and parameters: {'lr': 0.00012402581332656212, 'alpha': 0.003015430821816265, 'activation': 'relu', 'n1': 384, 'n2': 384}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2297\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0752\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8669\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.6755\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5013\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3621\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2509\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1622\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0873\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0249\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9719\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9249\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8852\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8500\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8186\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7919\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7638\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7411\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7200\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7006\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6822\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6659\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6502\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6355\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6211\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6084\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.5954\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5842\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5731\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5623\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5523\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5422\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5326\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5239\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5149\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5066\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4984\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4903\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4829\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4750\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4680\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4609\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4541\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4473\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4409\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4344\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4284\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4221\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4159\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4100\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4041\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3984\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3927\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3871\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3817\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3764\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3712\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3659\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3607\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3557\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3507\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3458\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3409\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3361\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3314\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3266\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3220\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3173\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3127\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3082\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3036\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2990\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2945\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2900\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2857\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2813\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2769\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2726\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2682\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2640\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.2598\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2555\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2513\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2470\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2428\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2386\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2345\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2304\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2263\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2221\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2180\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2139\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2099\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2058\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2018\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1978\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1937\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1897\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1857\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1818\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:47,652] Trial 9 finished with value: 83.68321030912738 and parameters: {'lr': 0.00014305628101450837, 'alpha': 0.013006000625615206, 'activation': 'relu', 'n1': 256, 'n2': 128}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1573\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1453\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1421\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1357\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1233\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1150\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1061\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1006\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0935\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0831\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0795\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0682\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0640\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0542\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0476\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0473\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0442\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0249\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0126\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0021\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9968\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9902\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9808\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9772\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9703\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9676\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9588\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9475\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9383\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9325\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9352\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9170\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9208\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9121\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9011\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8899\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8865\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8773\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8682\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8591\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8535\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8451\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8370\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8306\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8239\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8197\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8122\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8028\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7942\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7868\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7807\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7766\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7687\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7592\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7533\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7469\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7339\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7313\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7230\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7139\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7103\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6947\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6889\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6816\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6817\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6697\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6642\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6555\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6460\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6409\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6356\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6279\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6141\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6113\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6012\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5968\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5915\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5876\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5830\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5728\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5713\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5620\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5586\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5524\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5481\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5435\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5384\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5355\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5282\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5249\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5226\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5122\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5147\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5065\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5033\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5003\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4965\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:49,264] Trial 10 finished with value: 57.97517346034134 and parameters: {'lr': 0.00036853845956751074, 'alpha': 0.00015476639458539238, 'activation': 'sigmoid', 'n1': 320, 'n2': 320}. Best is trial 7 with value: 57.49475406130353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3986\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2354\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1900\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1557\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0989\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0824\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0562\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0351\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0155\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9839\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9570\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9367\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9058\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8849\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8589\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8359\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8376\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7906\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7499\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7232\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6992\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6792\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6645\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6417\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6115\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5944\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5807\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5751\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5744\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5484\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5416\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5630\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5429\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4934\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4834\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4706\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4716\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4578\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4480\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4403\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4356\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4258\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4207\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4142\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4107\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4111\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3930\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3847\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3799\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3792\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3806\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3673\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3583\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3524\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3535\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3418\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3382\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3369\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3290\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3255\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3213\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3137\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3102\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3064\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3034\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3003\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2993\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2962\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2922\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2888\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2887\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2781\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2755\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2734\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2708\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2691\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2671\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2650\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2630\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2594\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2558\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2546\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2525\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2514\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2497\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2482\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2462\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2446\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2439\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2415\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2405\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2376\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:50,859] Trial 11 finished with value: 57.14954265060914 and parameters: {'lr': 0.001519422226672702, 'alpha': 0.00034349596510678093, 'activation': 'sigmoid', 'n1': 192, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3800\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6918\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5007\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3052\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2524\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1969\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1562\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1365\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1178\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1070\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0975\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0906\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0788\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0766\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0746\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0731\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0695\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0686\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0682\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0673\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0671\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0670\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0668\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0667\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0664\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0664\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0663\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0658\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0657\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0657\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0656\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:52,487] Trial 12 finished with value: 70.68801466047385 and parameters: {'lr': 0.0016197931101672725, 'alpha': 0.00012750602782036794, 'activation': 'tanh', 'n1': 192, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1879\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1610\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1446\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1327\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0977\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0490\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0140\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9793\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9600\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9283\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8867\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8583\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8122\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7710\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7476\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7104\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6917\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6466\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6146\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5696\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5431\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5189\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5043\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4969\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4684\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4577\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4415\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4402\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4348\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4015\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4075\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4148\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3971\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3678\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3565\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3555\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3383\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3340\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3231\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3099\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3049\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3010\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2910\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2936\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2884\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2777\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2713\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2714\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2648\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2567\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2548\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2522\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2512\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2483\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2441\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2415\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2319\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2301\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2295\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2246\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2222\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2216\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2159\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2175\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2122\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2121\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2114\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2092\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2068\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2060\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2046\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2024\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2009\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2009\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2002\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1976\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1964\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1952\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1927\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1916\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1910\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1903\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1892\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1884\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1859\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1846\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1836\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1832\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1820\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1812\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1808\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:54,123] Trial 13 finished with value: 61.0425012665679 and parameters: {'lr': 0.002137765007936263, 'alpha': 0.00028448720470978487, 'activation': 'sigmoid', 'n1': 192, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1571\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7166\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2476\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9758\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7779\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5826\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4175\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2727\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1898\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0606\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9383\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8365\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7436\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6269\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5440\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4494\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3671\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2875\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2070\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1594\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0768\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0095\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9342\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.8735\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8064\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7489\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6906\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6363\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5847\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5334\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4885\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4376\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4045\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3504\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3057\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2691\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2254\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1839\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1448\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1109\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0772\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0438\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0147\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9453\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9156\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8906\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8660\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8321\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8059\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7841\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7661\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7384\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7414\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7253\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7015\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6656\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6417\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6161\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6149\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5905\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5666\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5526\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5303\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5131\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4980\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4917\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4755\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4648\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4475\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4266\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4111\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4026\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3875\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3760\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3647\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3624\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3614\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3481\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3396\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3577\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3617\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3679\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3795\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3597\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3155\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3456\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2919\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3051\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2775\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2709\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2473\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2381\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2509\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2651\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2317\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2473\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2396\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2309\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:55,778] Trial 14 finished with value: 63.52409774657985 and parameters: {'lr': 0.019547295308692616, 'alpha': 0.00597785411675189, 'activation': 'sigmoid', 'n1': 256, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8739\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4172\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3025\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2784\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2100\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1982\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1830\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1791\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1679\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1612\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1567\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1495\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1454\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1380\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1336\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1357\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1342\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1196\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1165\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1072\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0979\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0931\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0892\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0799\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0778\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0717\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0715\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0642\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0540\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0462\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0408\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0441\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0269\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0352\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0254\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0152\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0061\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0039\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9948\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9885\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9799\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9755\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9684\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9615\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9557\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9503\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9476\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9431\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9333\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9251\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9184\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9135\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9111\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9047\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8957\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8879\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8832\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8714\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8699\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8625\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8539\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8508\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8399\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8381\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8311\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8249\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8271\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8121\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8093\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8002\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7911\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7874\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7805\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7720\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7723\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7601\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7581\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7491\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7443\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7391\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7356\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7333\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7201\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7203\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7089\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7084\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7004\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6964\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6904\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6821\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6752\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6719\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6701\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6594\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6534\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6476\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6456\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6410\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:57,330] Trial 15 finished with value: 58.562715955041384 and parameters: {'lr': 0.00035676340184542766, 'alpha': 0.0003903578866662198, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 37.3357\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 35.7575\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 34.4924\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.3279\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.0825\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.9001\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.7407\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.6266\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5528\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5195\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.5254\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.5685\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6479\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7621\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9095\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0890\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2994\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5395\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8083\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1044\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4271\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7750\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1476\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5436\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9622\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4029\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8644\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3463\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8475\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3675\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9054\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4604\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0324\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6203\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2238\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8422\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4747\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1211\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.7812\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4535\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1381\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8346\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5425\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2609\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9904\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7298\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4793\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.2384\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.0060\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7823\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5671\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3599\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1607\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9688\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7843\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6068\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4355\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2707\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1122\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9600\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8132\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6717\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5357\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4045\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2786\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1571\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0404\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9283\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8202\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7162\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6157\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5197\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4267\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3368\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2508\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1679\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0114\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9377\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8664\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7981\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7328\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6694\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6081\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5490\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4925\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4382\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3868\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3361\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2874\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2405\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1953\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1521\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1101\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0701\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0314\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9941\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9587\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9239\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8912\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:07:58,960] Trial 16 finished with value: 65.87201327033065 and parameters: {'lr': 0.002699479695264986, 'alpha': 0.04927873066015183, 'activation': 'tanh', 'n1': 320, 'n2': 192}. Best is trial 11 with value: 57.14954265060914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2194\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2184\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2144\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2083\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1662\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1577\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1518\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1463\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1381\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1191\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1112\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1075\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0898\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0872\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0709\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0760\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1047\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0539\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0308\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0196\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0115\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0020\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0031\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9702\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9581\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9534\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9445\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9592\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9327\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8997\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8948\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9072\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8746\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8420\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8278\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8184\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8230\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7875\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7753\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7681\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7502\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7372\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7258\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7130\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7030\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7001\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6776\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6764\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6746\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6651\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6553\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6330\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6238\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6204\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6238\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5945\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5929\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5896\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5771\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5689\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5643\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5616\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5517\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5463\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5407\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5357\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5366\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5313\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5237\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5131\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5100\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5051\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4992\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4951\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4964\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4906\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4799\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4737\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4703\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4671\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4640\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4534\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4497\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4467\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4390\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4377\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4391\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4310\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4264\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4240\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4205\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4139\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4161\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4084\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4055\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4089\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4027\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:00,497] Trial 17 finished with value: 54.887397256505984 and parameters: {'lr': 0.0008268674952260534, 'alpha': 0.0004886784355305433, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3388\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2017\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2134\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1775\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1779\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1659\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1627\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1599\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1569\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1519\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1499\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1447\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1429\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1370\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1345\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1375\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1356\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1289\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1206\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1211\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1128\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1088\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1067\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0998\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0992\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0943\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0945\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0902\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0828\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0781\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0732\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0784\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0638\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0725\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0666\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0563\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0516\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0491\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0431\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0391\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0319\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0303\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0250\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0201\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0161\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0113\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0114\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0037\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0001\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9928\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9897\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9853\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9831\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9789\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9718\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9669\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9636\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9544\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9515\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9469\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9401\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9370\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9292\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9270\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9221\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9167\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9198\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9068\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9036\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8968\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8886\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8847\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8788\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8718\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8719\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8601\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8574\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8505\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8443\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8392\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8372\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8312\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8210\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8194\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8110\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8085\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8002\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7954\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7890\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7829\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7833\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7698\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7726\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7642\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7587\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7511\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7476\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7380\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7386\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7312\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:02,146] Trial 18 finished with value: 67.32759250313498 and parameters: {'lr': 0.0003127506277317366, 'alpha': 0.0004365005994739172, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2263\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2193\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2167\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2134\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1880\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1817\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1694\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1597\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1534\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1338\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1243\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1167\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0964\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0720\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0799\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0907\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0399\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0265\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0088\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9992\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9866\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9828\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9473\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9379\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9280\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9156\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9232\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8946\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8644\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8591\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8579\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8270\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8076\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7964\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7849\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7822\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7512\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7449\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7334\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7171\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7053\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6956\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6849\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6769\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6725\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6541\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6546\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6505\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6441\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6327\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6174\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6137\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6075\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6054\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5871\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5906\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5863\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5717\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5649\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5629\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5586\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5505\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5462\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5417\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5365\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5347\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5275\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5243\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5167\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5132\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5092\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5049\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5012\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4971\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4910\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4808\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4774\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4739\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4720\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4708\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4625\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4590\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4560\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4527\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4498\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4479\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4507\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4386\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4318\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4268\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4276\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4218\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4201\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4203\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4157\n",
      "4/4 [==============================] - 0s 838us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:03,805] Trial 19 finished with value: 57.10359805375634 and parameters: {'lr': 0.0008688529977470843, 'alpha': 0.000620431612666866, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 1.7689\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1850\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8495\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6139\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5447\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4978\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4623\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4338\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4118\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3914\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3746\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3589\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3454\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3336\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3236\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3140\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3055\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2986\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2926\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2818\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2779\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2740\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2709\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2678\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2627\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2605\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2585\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2550\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2535\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2521\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2509\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2499\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2488\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2478\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2470\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2462\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2455\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2448\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2441\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2436\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2431\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2426\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2422\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2418\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2407\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2401\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2399\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2396\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2395\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2392\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2390\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2387\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2385\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2384\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2382\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2381\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2380\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2378\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2377\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2376\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2375\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2374\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2373\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2373\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2372\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2371\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2370\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2369\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2369\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2368\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2366\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2366\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2365\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2365\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2364\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2362\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2362\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2360\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2360\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2359\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2359\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2358\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2358\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2357\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2357\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:06,036] Trial 20 finished with value: 73.66704382072314 and parameters: {'lr': 0.0008042694329300243, 'alpha': 0.0005797064995685693, 'activation': 'tanh', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1884\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1026\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0988\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0897\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0430\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0291\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0180\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0056\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9991\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9463\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9314\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9088\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8942\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8747\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8559\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8706\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8255\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7844\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7626\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7369\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7187\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7100\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6836\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6440\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6260\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6096\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6103\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5994\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5636\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5541\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5788\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5651\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4980\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4815\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4650\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4492\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4383\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4274\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4175\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4120\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3987\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3940\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3868\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3805\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3838\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3641\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3534\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3527\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3433\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3462\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3372\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3286\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3186\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3050\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3004\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2974\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2900\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2861\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2812\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2785\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2733\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2736\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2643\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2594\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2571\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2501\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2457\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2422\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2397\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2376\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2294\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2273\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2238\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2204\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2178\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2151\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2125\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2109\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2110\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2059\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2030\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2019\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2021\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1977\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1972\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1923\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1899\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1876\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1848\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1834\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1809\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1786\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1773\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:07,773] Trial 21 finished with value: 58.82215589005639 and parameters: {'lr': 0.001293822559519647, 'alpha': 0.00024436757942165546, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3108\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3166\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2347\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2158\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2174\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1865\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1839\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0888\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0550\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0148\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9777\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8926\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8762\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8743\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8609\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8196\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7355\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6553\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6004\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5779\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5654\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5495\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5451\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5209\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5082\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4949\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4786\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4739\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4602\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4548\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4433\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4461\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4230\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4161\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4148\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3874\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3808\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3820\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3696\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3669\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3604\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3543\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3527\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3504\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3544\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3408\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3345\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3299\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3291\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3227\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3238\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3236\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3154\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3253\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3080\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3043\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2992\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2985\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2990\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2969\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2956\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2936\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2892\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2856\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2838\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2798\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2766\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2728\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2721\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2712\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2707\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2727\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2700\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2700\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2644\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2648\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2621\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2618\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2606\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2589\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2585\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2567\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2586\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2561\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2546\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2532\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:09,500] Trial 22 finished with value: 64.36580875396851 and parameters: {'lr': 0.0027744557006031084, 'alpha': 0.0005827368166316126, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1227\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1163\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1142\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1092\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0922\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0885\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0737\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0690\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0630\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0481\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0467\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0334\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0255\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0200\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0065\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0090\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0083\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9812\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9840\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9621\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9515\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9474\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9385\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9246\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9193\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9104\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9076\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8994\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8822\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8688\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8607\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8625\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8403\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8406\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8291\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8034\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7958\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7854\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7714\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7604\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7493\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7284\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7181\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7105\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7010\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6940\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6815\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6710\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6593\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6524\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6471\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6354\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6262\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6155\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6107\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5944\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5899\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5807\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5710\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5660\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5553\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5484\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5435\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5358\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5317\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5224\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5171\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5074\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4996\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4952\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4905\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4824\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4824\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4718\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4694\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4613\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4568\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4525\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4504\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4486\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4390\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4378\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4298\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4268\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4226\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4183\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4184\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4141\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4069\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4058\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3991\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3986\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3917\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3933\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3874\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3853\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3810\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3798\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:11,192] Trial 23 finished with value: 57.49350968555152 and parameters: {'lr': 0.0005666118553888679, 'alpha': 0.0001988065057044844, 'activation': 'sigmoid', 'n1': 192, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3773\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3157\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3248\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3085\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3075\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3054\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3003\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2988\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2953\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2923\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2891\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2846\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2821\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2786\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2748\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2807\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2747\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2711\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2632\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2627\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2602\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2554\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2512\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2474\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2458\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2419\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2405\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2380\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2326\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2283\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2248\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2282\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2173\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2210\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2186\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2082\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2088\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2047\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2008\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1979\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1916\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1906\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1864\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1825\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1791\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1754\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1755\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1691\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1664\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1628\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1584\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1570\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1554\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1507\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1458\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1421\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1389\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1335\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1299\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1265\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1230\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1190\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1142\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1133\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1093\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1048\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1070\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0978\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0908\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0845\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0810\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0772\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0720\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0721\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0640\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0600\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0578\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0522\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0484\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0465\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0417\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0350\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0319\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0280\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0240\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0187\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0141\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0117\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0054\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0069\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9956\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9975\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9914\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9877\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9793\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9770\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9729\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9697\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9668\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:12,843] Trial 24 finished with value: 74.36739544316448 and parameters: {'lr': 0.00025402258047026735, 'alpha': 0.0007753327889135206, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2495\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2632\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1705\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1598\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1449\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1124\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0825\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0557\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0465\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0257\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9973\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9867\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9582\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9183\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8854\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8721\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8934\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8534\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8262\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7709\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7309\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6940\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6781\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6839\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6470\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6263\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6122\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5866\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5837\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5904\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5407\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5370\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5491\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5419\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5090\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4940\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4904\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4868\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4742\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4777\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4776\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4592\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4427\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4345\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4270\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4243\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4216\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4168\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4085\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3927\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3964\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3957\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3930\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3720\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3732\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3833\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3650\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3636\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3528\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3588\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3578\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3507\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3383\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3348\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3312\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3287\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3282\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3183\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3154\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3118\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3114\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3063\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3059\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3038\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3017\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2965\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2939\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2925\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2902\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2877\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2874\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2840\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2804\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2781\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2738\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2726\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2679\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2651\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2647\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2624\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2600\n",
      "4/4 [==============================] - 0s 668us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:14,554] Trial 25 finished with value: 56.17399134753914 and parameters: {'lr': 0.0014832161187332013, 'alpha': 0.0003380614603970123, 'activation': 'sigmoid', 'n1': 192, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0639\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0594\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0600\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0590\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0424\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0436\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0326\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0291\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0154\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0145\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0106\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9989\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0020\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9874\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0062\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0166\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9728\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9822\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9608\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9574\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9557\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9549\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9327\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9369\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9322\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9302\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9375\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9117\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8981\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8922\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8976\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8747\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8739\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8630\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8572\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8428\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8462\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8294\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8175\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8087\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8009\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7911\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7822\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7785\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7668\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7667\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7460\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7337\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7241\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7216\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7160\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7094\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6883\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6926\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6706\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6499\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6444\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6322\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6250\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6147\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6094\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6012\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5930\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5894\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5748\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5635\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5560\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5465\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5418\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5353\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5258\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5176\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5101\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5019\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4940\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4875\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4879\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4846\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4697\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4646\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4553\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4487\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4429\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4372\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4343\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4291\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4208\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4183\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4125\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4097\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4005\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4024\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3925\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3920\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3901\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3830\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:16,155] Trial 26 finished with value: 59.40491410688315 and parameters: {'lr': 0.0005225852011665604, 'alpha': 0.00010234367597197874, 'activation': 'sigmoid', 'n1': 128, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1172\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8391\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8782\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8105\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8106\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7910\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7895\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7833\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7771\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7728\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7697\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7649\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7623\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7584\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7547\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7610\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7555\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7518\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7425\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7430\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7371\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7323\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7298\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7245\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7232\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7192\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7182\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7153\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7088\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7048\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7006\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7052\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6926\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6986\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6951\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6843\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6829\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6793\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6753\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6718\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6656\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6642\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6599\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6560\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6528\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6488\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6497\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6428\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6402\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6349\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6320\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6298\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6283\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6242\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6184\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6148\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6127\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6058\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6028\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5998\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5954\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5923\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5867\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5862\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5826\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5779\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5809\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5712\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5684\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5648\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5580\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5551\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5515\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5458\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5469\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5378\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5352\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5323\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5264\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5229\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5229\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5182\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5100\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5081\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5033\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5009\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4947\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4910\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4875\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4819\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4858\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4721\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4772\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4693\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4677\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4577\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4579\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4504\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4514\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4472\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:17,827] Trial 27 finished with value: 71.64389253822792 and parameters: {'lr': 0.00021514221254018622, 'alpha': 0.0031128939043399, 'activation': 'sigmoid', 'n1': 192, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4629\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9092\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6181\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4800\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3813\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3246\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2872\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2563\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2338\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2171\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2028\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1915\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1828\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1749\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1685\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1591\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1554\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1521\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1496\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1473\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1452\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1436\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1422\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1411\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1399\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1389\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1381\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1374\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1367\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1355\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1351\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1346\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1343\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1339\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1336\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1333\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1331\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1328\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1326\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1324\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1323\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1321\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1320\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1318\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1317\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1316\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1315\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1313\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1313\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1312\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1311\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1311\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1309\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1308\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1308\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1308\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1307\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1307\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1307\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1305\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1305\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1304\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1304\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1304\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1303\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1303\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1303\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1301\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1301\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:19,511] Trial 28 finished with value: 75.46315048873812 and parameters: {'lr': 0.0009504018362641837, 'alpha': 0.00018772816978607088, 'activation': 'tanh', 'n1': 256, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7843\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4013\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0503\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8431\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7014\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6210\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5649\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5178\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4877\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4598\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4382\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4192\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4051\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3923\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3825\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3731\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3655\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3588\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3534\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3482\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3440\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3401\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3365\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3334\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3308\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3281\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3258\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3238\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3217\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3198\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3183\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3168\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3153\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3140\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3128\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3117\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3107\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3096\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3087\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3078\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3069\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3061\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3054\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3046\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3039\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3032\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3026\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3020\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3014\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3008\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3003\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2997\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2992\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2987\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2982\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2978\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2973\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2968\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2964\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2960\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2955\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2951\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2947\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2943\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2939\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2935\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2932\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2928\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2924\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2921\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2917\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2913\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2910\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2906\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2903\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2900\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2896\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2893\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2890\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2886\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2883\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2880\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2877\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2874\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2870\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2867\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2864\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2861\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2858\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2855\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2852\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2849\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2846\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2843\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2840\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2837\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2834\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2831\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2828\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2825\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:21,285] Trial 29 finished with value: 75.71937928748969 and parameters: {'lr': 0.0005303842432961027, 'alpha': 0.0013844633386373548, 'activation': 'gelu', 'n1': 384, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3925\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3866\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3192\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2998\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3019\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2609\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2246\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1668\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1574\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1118\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1015\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0686\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0354\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0336\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0133\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9780\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0091\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9101\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8866\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8309\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7606\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7264\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7012\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7041\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6739\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6155\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6111\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5921\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5801\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5643\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5389\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5355\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5375\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5388\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4968\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4788\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4718\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4591\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4495\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4414\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4490\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4497\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4210\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4110\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3982\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4047\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3999\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3933\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3773\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3731\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3725\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3729\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3753\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3628\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3561\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3477\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3500\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3480\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3474\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3375\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3331\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3365\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3330\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3291\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3210\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3174\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3148\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3143\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3091\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3118\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3095\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3066\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3060\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2998\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3022\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2961\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2956\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2940\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2922\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2931\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2908\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2888\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2850\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2837\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2828\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2830\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2814\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2825\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2789\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2773\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2764\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2754\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2739\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2788\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2745\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2729\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2706\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2690\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:22,790] Trial 30 finished with value: 58.70081934525798 and parameters: {'lr': 0.0023123022936027016, 'alpha': 0.000586292422524495, 'activation': 'sigmoid', 'n1': 128, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4406\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2482\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2420\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2164\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1433\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1048\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0885\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0609\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0454\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0189\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9526\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9201\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8960\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8786\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8478\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8479\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7715\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7389\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7164\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6988\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6844\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6677\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6336\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6206\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6086\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6033\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5991\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5859\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5688\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5729\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5733\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5411\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5253\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5123\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5114\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4929\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4848\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4781\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4736\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4640\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4594\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4591\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4476\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4563\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4421\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4226\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4181\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4214\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4150\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4090\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3988\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4051\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3928\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3824\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3830\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3730\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3689\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3659\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3623\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3580\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3543\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3499\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3471\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3435\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3420\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3380\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3374\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3281\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3276\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3245\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3222\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3209\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3155\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3142\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3096\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3068\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3046\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3037\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3013\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2993\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2971\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2964\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2937\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2922\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2918\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2895\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2876\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2842\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2843\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2812\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2806\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2790\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2770\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2768\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:24,422] Trial 31 finished with value: 56.794680817555815 and parameters: {'lr': 0.0014571610387418346, 'alpha': 0.0003171968403787017, 'activation': 'sigmoid', 'n1': 256, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2442\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1869\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1735\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1582\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1157\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1004\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0806\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0644\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0472\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0173\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9942\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9784\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9521\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9368\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9127\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9165\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8639\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8244\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8041\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7835\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7650\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7289\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6992\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6703\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6714\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6610\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6288\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6211\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6338\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6186\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5650\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5519\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5403\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5403\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5251\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5144\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5077\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5010\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4898\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4780\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4733\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4574\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4522\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4502\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4509\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4470\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4332\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4192\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4212\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4080\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4051\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4026\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3957\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3924\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3876\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3858\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3787\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3746\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3710\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3670\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3648\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3643\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3593\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3552\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3513\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3538\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3486\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3429\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3361\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3335\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3304\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3275\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3256\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3220\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3194\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3175\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3178\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3144\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3099\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3074\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3048\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3026\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3025\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3026\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2991\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2962\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2940\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2921\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2913\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2884\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2878\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2832\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2818\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2798\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:25,988] Trial 32 finished with value: 58.5561709359424 and parameters: {'lr': 0.001095587620589835, 'alpha': 0.00026712732781587935, 'activation': 'sigmoid', 'n1': 256, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5063\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3945\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3300\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2198\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1490\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0795\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0829\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9526\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8738\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8330\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7997\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7218\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6829\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6603\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6876\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7259\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6227\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6182\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5617\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5432\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5209\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5158\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5035\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4862\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4843\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4717\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4563\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4351\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4312\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4234\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4162\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4090\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3991\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3946\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3912\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4019\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3794\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3764\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3719\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3719\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3639\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3637\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3577\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3541\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3534\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3537\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3503\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3463\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3430\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3415\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3385\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3389\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3389\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3346\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3412\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3336\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3284\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3272\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3274\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3276\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3260\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3272\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3254\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3218\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3204\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3195\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3188\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3185\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3158\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3141\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3122\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3115\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3117\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3107\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3097\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3109\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3095\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3085\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3057\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3047\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3047\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3034\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3035\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3032\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3023\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3012\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3012\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3005\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3002\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3008\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3004\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3005\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2994\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2987\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2984\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:27,679] Trial 33 finished with value: 62.33236491380777 and parameters: {'lr': 0.0034300013336170374, 'alpha': 0.0004402987574185776, 'activation': 'sigmoid', 'n1': 256, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4266\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6878\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4347\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3238\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2447\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1838\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1467\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1168\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1036\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0935\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0868\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0811\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0763\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0729\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0701\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0678\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0657\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0639\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0623\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0609\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0597\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0584\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0573\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0563\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0553\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0543\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0534\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0525\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0517\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0509\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0500\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0492\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0484\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0477\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0469\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0462\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0454\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0447\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0440\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0433\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0425\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0418\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0411\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0404\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0397\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0390\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0383\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0376\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0369\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0362\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0356\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0349\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0342\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0335\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0328\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0322\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0315\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0308\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0302\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0295\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0288\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0282\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0275\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0269\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0262\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0255\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0249\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0242\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0235\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0229\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0222\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0216\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0209\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0203\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0196\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0190\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0183\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0177\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0170\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0164\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0157\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0151\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0144\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0138\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0131\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0125\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0118\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0112\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0106\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0099\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0093\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0086\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0080\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0074\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0067\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0061\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0054\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0048\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0042\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0035\n",
      "4/4 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:29,496] Trial 34 finished with value: 65.05443481641218 and parameters: {'lr': 0.001715196401300293, 'alpha': 0.0013219123216076413, 'activation': 'gelu', 'n1': 320, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5447\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6048\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5959\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3133\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2508\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2523\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1808\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1575\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0340\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9694\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8834\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8457\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8065\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8054\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8488\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7668\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7109\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6909\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6838\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6505\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6405\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6261\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6058\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6036\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6003\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6047\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5739\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5552\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5502\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5530\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5479\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5391\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5445\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5401\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5243\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5268\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5345\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5209\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4990\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4945\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4900\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4879\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4845\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4851\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4764\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4733\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4743\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4685\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4667\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4649\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4620\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4639\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4616\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4569\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4583\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4588\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4545\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4519\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4523\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4522\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4464\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4475\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4452\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4430\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4415\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4410\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4452\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4432\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4433\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4371\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4353\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4339\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4327\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4320\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4316\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4302\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4301\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4285\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4278\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4274\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4268\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4256\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4250\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4253\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4236\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4230\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4232\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4229\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4216\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4210\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4193\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4198\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4209\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4193\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4177\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4175\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4160\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4153\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:31,102] Trial 35 finished with value: 64.18843170252426 and parameters: {'lr': 0.003637777667057363, 'alpha': 0.0007445754898470012, 'activation': 'sigmoid', 'n1': 192, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6763\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8767\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3659\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2203\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1269\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0628\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0219\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9953\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9736\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9600\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9483\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9394\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9316\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9259\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9211\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9170\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9106\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9083\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9061\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9043\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9026\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9012\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8999\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8989\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8978\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8970\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8961\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8953\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8945\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8939\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8933\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8927\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8921\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8916\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8911\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8907\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8902\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8899\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8894\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8890\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8887\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8883\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8880\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8876\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8873\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8867\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8864\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8861\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8858\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8855\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8852\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8849\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8847\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8844\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8841\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8839\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8836\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8833\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8831\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8826\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8823\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8820\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8818\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8815\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8813\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8810\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8808\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8805\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8803\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8801\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8798\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8796\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8793\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8791\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8789\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8786\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8784\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8782\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8779\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8777\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8775\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8772\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8770\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8767\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8765\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8763\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8760\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8758\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8756\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8754\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8751\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8749\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8747\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8744\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8742\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8740\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8738\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:32,954] Trial 36 finished with value: 76.06853375116097 and parameters: {'lr': 0.000781099390239808, 'alpha': 0.0011604181674921877, 'activation': 'gelu', 'n1': 320, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7803\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4847\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2502\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1572\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1039\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0207\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0013\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9800\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9742\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9433\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9062\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8878\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8645\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8265\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8147\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8269\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7753\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7360\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7150\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6898\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6699\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6607\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6317\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6004\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5833\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5677\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5697\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5736\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5277\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5168\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5398\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5261\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4639\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4466\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4326\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4295\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4166\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4066\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3904\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3812\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3764\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3700\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3653\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3702\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3495\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3412\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3371\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3294\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3292\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3248\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3076\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3066\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2950\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2943\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2946\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2830\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2760\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2666\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2611\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2533\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2433\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2353\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2354\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2322\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2267\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2237\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2206\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2167\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2143\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2108\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2081\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2032\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2033\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1989\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1956\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1912\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1871\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1867\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1834\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1821\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1789\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1779\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1778\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1744\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1727\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1707\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1694\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1675\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:34,555] Trial 37 finished with value: 58.24711478208619 and parameters: {'lr': 0.0012659580917846744, 'alpha': 0.00019105348920217408, 'activation': 'sigmoid', 'n1': 128, 'n2': 256}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5300\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5876\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3921\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3307\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3053\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2785\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2508\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2260\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2198\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2071\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2065\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2046\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2033\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2029\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2013\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2011\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2007\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2007\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2007\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1999\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2001\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1997\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1992\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1990\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1989\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1987\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1984\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1982\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1980\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1978\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1977\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1973\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1972\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1970\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1968\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1966\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1965\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1962\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1960\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1959\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1957\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1955\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1954\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1952\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1950\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1949\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1947\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1946\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1944\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1943\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1941\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1938\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1936\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1935\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1932\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1930\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1929\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1927\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1925\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1924\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1922\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1921\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1919\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1918\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1914\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1913\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1911\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1910\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1908\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1907\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1905\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1903\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1902\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1901\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1898\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1896\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1894\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1893\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1891\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1888\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1887\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1885\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1882\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1880\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1879\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1877\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1876\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1874\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1873\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1871\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1870\n",
      "4/4 [==============================] - 0s 869us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:36,234] Trial 38 finished with value: 59.783804825071115 and parameters: {'lr': 0.008061907712918122, 'alpha': 0.0003608613311849593, 'activation': 'relu', 'n1': 192, 'n2': 320}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9989\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9940\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9925\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9871\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9691\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9663\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9510\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9440\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9417\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9242\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9209\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9131\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8987\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8976\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8811\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8918\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8941\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8577\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8629\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8390\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8297\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8275\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8194\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8016\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7978\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7914\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7865\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7859\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7653\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7501\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7429\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7463\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7257\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7228\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7149\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7021\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6919\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6843\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6800\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6619\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6516\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6408\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6320\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6219\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6128\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6049\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5972\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5951\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5826\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5744\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5600\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5536\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5517\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5429\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5344\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5180\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5175\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4988\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4921\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4828\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4745\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4660\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4592\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4492\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4452\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4375\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4331\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4282\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4176\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4058\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3895\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3874\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3804\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3753\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3686\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3629\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3534\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3485\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3427\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3426\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3419\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3257\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3244\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3148\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3101\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3055\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3007\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2960\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2935\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2860\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2834\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2774\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2762\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2662\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2704\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2607\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2600\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2583\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2526\n",
      "4/4 [==============================] - 0s 835us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:37,843] Trial 39 finished with value: 55.55557160710136 and parameters: {'lr': 0.0004500254115521539, 'alpha': 0.0027582362290749732, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1542\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6544\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1112\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8658\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7405\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6371\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5616\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5115\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4783\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4426\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4151\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3944\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3749\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3586\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3452\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3338\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3224\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3133\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3051\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2977\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2908\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2846\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2786\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2731\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2685\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2637\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2596\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2554\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2516\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2477\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2442\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2410\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2377\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2346\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2316\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2287\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2260\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2233\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2207\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2181\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2156\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2132\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2108\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2085\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2063\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2040\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2017\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1996\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1974\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1953\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1931\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1911\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1890\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1870\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1850\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1830\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1810\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1790\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1770\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1751\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1731\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1712\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1693\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1674\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1655\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1636\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1617\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1598\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1579\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1560\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1542\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1523\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1505\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1486\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1468\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1450\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1431\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1413\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1395\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1376\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1358\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1340\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1322\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1304\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1286\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1268\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1250\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1232\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1214\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1196\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1178\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1160\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1142\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1125\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1107\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1089\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1071\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1053\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1036\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1018\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:39,458] Trial 40 finished with value: 78.5477734197659 and parameters: {'lr': 0.000442128886129882, 'alpha': 0.004572804169783657, 'activation': 'relu', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5943\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5951\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5846\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5808\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5555\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5252\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5149\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4990\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4951\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4708\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4431\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4281\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4067\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3951\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3775\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3676\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3887\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3488\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3049\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2860\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2648\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2526\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2496\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2272\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1899\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1747\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1642\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1835\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1623\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1290\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1030\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1244\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1278\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0532\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0295\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0095\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0037\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9826\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9712\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9649\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9455\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9327\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9251\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9141\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9046\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9055\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8900\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8803\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8806\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8710\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8699\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8607\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8527\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8404\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8422\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8238\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8185\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8153\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8065\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8008\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7939\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7923\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7845\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7824\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7728\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7681\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7665\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7641\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7545\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7523\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7430\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7395\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7386\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7345\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7303\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7277\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7200\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7175\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7123\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7056\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7025\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7024\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6912\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6860\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6835\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6794\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6764\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6738\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6749\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6709\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6660\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6613\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6582\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6588\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6515\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6498\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6447\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6428\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6388\n",
      "4/4 [==============================] - 0s 878us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:41,003] Trial 41 finished with value: 57.85965679787283 and parameters: {'lr': 0.000924801486507968, 'alpha': 0.0022087628583511336, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9288\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9218\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8928\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8753\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8195\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7913\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7761\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7600\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7419\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7101\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6857\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6706\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6427\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6278\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6020\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5930\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6106\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5547\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5173\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4979\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4760\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4525\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4418\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4097\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3836\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3677\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3500\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3554\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3214\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2831\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2716\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2834\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2447\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1880\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1657\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1470\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1423\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1055\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0849\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0655\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0415\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0215\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0027\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9817\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9635\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9496\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9245\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9107\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9022\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8850\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8751\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8413\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8254\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8127\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8128\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7726\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7608\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7481\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7317\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7155\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7017\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6894\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6746\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6617\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6472\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6348\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6260\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6140\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6005\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5821\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5703\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5585\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5463\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5331\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5272\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5157\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4993\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4871\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4734\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.4618\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4509\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4397\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4341\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4160\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4033\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3936\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3832\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3705\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3646\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3562\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3412\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3295\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3206\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3091\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2968\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2886\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2736\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2621\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2588\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2430\n",
      "4/4 [==============================] - 0s 666us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:42,655] Trial 42 finished with value: 56.009657313499055 and parameters: {'lr': 0.000698821200582735, 'alpha': 0.008196610165303004, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6672\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6602\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6441\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6243\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5610\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5345\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5095\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4853\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4594\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4258\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4014\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3815\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3464\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3274\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2929\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2852\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2921\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2266\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.1929\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1659\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1402\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1129\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0965\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0567\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0307\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0085\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9880\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9866\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9478\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9029\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8869\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8792\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8352\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7948\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7699\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7483\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7392\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6896\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6695\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6476\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6160\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5921\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5681\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5435\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5208\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5014\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4720\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4552\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4395\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4202\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3976\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3646\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3506\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3319\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3222\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2773\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2627\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2474\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2211\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2009\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1843\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1655\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1458\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1280\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1105\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0930\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0767\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0577\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0416\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0212\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0048\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9896\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9725\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9544\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9400\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9229\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9051\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8892\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8722\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8560\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8420\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8292\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8168\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7920\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7768\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7608\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7458\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7306\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7161\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7054\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6874\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6715\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6579\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6421\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6240\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6131\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5937\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5801\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5693\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5516\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:44,296] Trial 43 finished with value: 55.42133869615102 and parameters: {'lr': 0.0006530219627934531, 'alpha': 0.010667358653405856, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8646\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8464\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8431\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8321\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8243\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8161\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8065\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7989\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7902\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7808\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7726\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7624\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7544\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7451\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7360\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7363\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7258\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7161\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7022\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6969\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6882\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6781\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6689\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6590\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6518\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6427\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6359\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6289\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6175\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6082\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5995\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5986\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5813\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5811\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5738\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5568\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5525\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5435\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.5336\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5264\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5147\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5088\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4993\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4904\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4822\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4737\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4684\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4575\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4503\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4411\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4327\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4260\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4194\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4101\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4003\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3919\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3844\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3739\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3661\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3581\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3500\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3416\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3317\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3273\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3186\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3093\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3076\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2935\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2852\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2779\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2670\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2589\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2514\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2416\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2381\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2256\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2167\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2112\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2007\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1932\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1873\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1787\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1670\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1602\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1519\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1438\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1344\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1259\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1187\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1089\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1079\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0908\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0905\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0793\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0726\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0593\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0534\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.0450\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0385\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0320\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:45,876] Trial 44 finished with value: 74.18297710794084 and parameters: {'lr': 0.0001801887393834703, 'alpha': 0.012333680001063628, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 17 with value: 54.887397256505984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.9119\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8497\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7820\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7075\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6122\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5295\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4401\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3555\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2736\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1790\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0918\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0112\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.9181\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8388\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7477\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.6791\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6269\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5049\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4126\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.3285\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2484\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1653\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.0941\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.9943\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.9120\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8369\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7589\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7078\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6132\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5114\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.4419\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3855\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2850\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1877\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.1087\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0347\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9741\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8722\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.7970\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7245\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6431\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5679\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4924\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4173\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3435\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2764\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1955\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.1298\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.0592\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9897\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9200\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8399\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7721\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7047\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6458\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5576\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4973\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4298\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3584\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2907\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2267\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1638\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0953\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0298\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9657\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9025\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8412\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.7778\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.7129\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6467\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5848\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.5228\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.4609\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3997\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3429\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.2799\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2188\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1598\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0972\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0377\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9795\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9237\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8685\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8015\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7435\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.6857\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6286\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5713\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.5167\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4642\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4032\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3473\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.2929\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.2358\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1771\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.1254\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.0660\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.0138\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.9657\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.9074\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:47,462] Trial 45 finished with value: 54.434319211628384 and parameters: {'lr': 0.000648662551024776, 'alpha': 0.02260346133324402, 'activation': 'sigmoid', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3387\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.8465\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4531\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2060\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0383\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8949\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7618\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6426\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5361\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4308\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.3320\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2363\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1434\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0527\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9635\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8758\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7890\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7030\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6184\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5340\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4506\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3678\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2854\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1227\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0418\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9617\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8818\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.8024\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7234\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6449\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5666\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4887\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4113\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3342\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2574\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1811\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1050\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.0293\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9539\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8789\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8042\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7299\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6558\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5821\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5087\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4356\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3629\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2904\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2183\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1465\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0749\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0037\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.9328\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8622\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7919\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7219\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6521\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5827\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5136\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4448\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3762\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3080\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2400\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1723\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.1049\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0378\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9710\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9044\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8382\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7722\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7065\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6410\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5759\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5110\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4464\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3820\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3180\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2542\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1906\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1274\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0644\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0016\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9391\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8769\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8150\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7533\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6919\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6307\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5698\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5091\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4487\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3885\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3286\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2690\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2096\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1504\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0915\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0329\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9744\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:49,265] Trial 46 finished with value: 69.39861457218095 and parameters: {'lr': 0.0006674482071770976, 'alpha': 0.022344366281202434, 'activation': 'gelu', 'n1': 384, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7258\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4953\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1855\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1632\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1495\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1068\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0929\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0763\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0583\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0388\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0265\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0091\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9906\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9800\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9577\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9609\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9529\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9112\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9099\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8782\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8611\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8512\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8353\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8119\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8007\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7857\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7764\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7662\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7390\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7184\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7036\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7003\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6729\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6635\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6505\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6290\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6125\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6002\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5843\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5634\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5471\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5306\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5150\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4992\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4835\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4726\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4539\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4479\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4293\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4133\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3946\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3826\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3728\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3568\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3425\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3227\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3146\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2933\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2811\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2656\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2527\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2377\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2255\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2106\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2001\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1882\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1757\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1635\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1492\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1343\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1208\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1082\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0990\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0863\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0768\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0649\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0521\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0384\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0281\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0167\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0074\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9995\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9828\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9751\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9602\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9512\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9405\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9299\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9227\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9132\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8984\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8918\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8791\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8715\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8575\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8546\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8393\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8339\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8254\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8140\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:50,839] Trial 47 finished with value: 57.86262325052492 and parameters: {'lr': 0.00042339336152147746, 'alpha': 0.008543526188068818, 'activation': 'sigmoid', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6998\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4304\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1473\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.9178\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7111\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 22.5653\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.4352\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3336\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.2422\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.1612\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0852\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0151\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9486\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.8854\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.8268\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7690\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7127\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6589\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6066\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5553\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5042\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4548\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4059\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.3582\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.3110\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2644\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2175\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.1720\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.1262\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0809\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0364\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9922\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9474\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9036\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8598\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8165\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7731\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7300\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.6874\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.6446\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6022\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5599\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.5178\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4758\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4340\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.3923\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.3507\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.3094\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.2680\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.2269\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1858\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1449\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.1041\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.0634\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.0228\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9824\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.9420\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.9017\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8615\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8215\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7815\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7416\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7018\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.6621\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 19.6226\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5831\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5437\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5044\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.4652\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.4260\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3870\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3480\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3091\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.2703\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2316\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1930\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.1545\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.1160\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.0776\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.0393\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0012\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9630\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9250\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.8870\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.8491\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8113\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7736\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.7359\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6984\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6608\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.6234\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5861\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5488\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5116\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4745\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4375\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4005\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3636\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3268\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2901\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:52,462] Trial 48 finished with value: 76.45138356723437 and parameters: {'lr': 0.0002693783264055018, 'alpha': 0.02658771263919912, 'activation': 'relu', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7953\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3826\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0338\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8243\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6738\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5535\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4559\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3734\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3054\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2410\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.1819\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1270\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0745\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.0246\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 14.9770\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9313\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8860\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8425\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.8005\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7592\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7189\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.6789\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.6397\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6008\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5629\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.5250\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4879\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.4509\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.4143\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3779\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3420\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3063\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.2708\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2355\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2004\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1656\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.1309\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0964\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0622\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.0278\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.9939\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.9601\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.9263\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8927\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8593\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8260\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.7928\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7598\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7268\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6940\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.6612\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6286\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5960\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.5636\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.5313\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4990\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4669\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4348\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4029\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3710\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3392\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3075\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2759\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2444\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2129\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1816\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1503\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1191\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0880\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0570\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 13.0260\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9951\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9643\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9336\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9030\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8724\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8419\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8115\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7812\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.7509\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.7207\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6906\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6606\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6306\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6007\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5709\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5412\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5115\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4819\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4524\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4229\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.3935\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3642\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3350\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3058\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.2767\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.2477\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2187\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1898\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.1610\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:54,029] Trial 49 finished with value: 79.13577456217612 and parameters: {'lr': 0.0004616504188371658, 'alpha': 0.018294769482185606, 'activation': 'tanh', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9157\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8939\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8720\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8502\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.8136\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7884\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7569\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7299\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7066\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6699\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6453\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6214\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5841\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.5661\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5285\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5265\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5220\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4527\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4275\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3934\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3704\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3434\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3230\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2778\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2563\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2355\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2113\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2041\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1610\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1192\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0996\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0858\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0414\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0156\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9898\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9625\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9441\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9053\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8856\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8604\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8290\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8046\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.7803\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7550\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7318\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.7106\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6833\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.6697\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6500\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.6305\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6022\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5721\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5565\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5371\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5264\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4821\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 8.4711\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4505\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4239\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.4033\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3864\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3671\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3463\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3273\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3090\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2906\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2743\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2547\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2360\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2143\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1973\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1809\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1629\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1434\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1288\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.1132\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0933\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0756\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0567\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0397\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.0244\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0097\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9930\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9718\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.9550\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9385\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9218\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9058\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8920\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8805\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8577\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8416\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8262\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8096\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7913\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7798\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7598\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7462\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7330\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7145\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:55,671] Trial 50 finished with value: 56.475750969483066 and parameters: {'lr': 0.0006453727281820407, 'alpha': 0.009790137385693147, 'activation': 'sigmoid', 'n1': 384, 'n2': 320}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4690\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3381\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0930\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0201\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0244\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9868\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9400\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9155\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8965\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8730\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8403\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8211\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7874\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7612\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7461\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7208\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7347\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6937\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6426\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6003\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5731\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5508\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5352\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5135\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4684\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4469\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4215\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4347\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4142\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3832\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3230\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3190\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3359\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2824\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2482\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2268\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2274\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1943\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1737\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1595\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1437\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1243\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1142\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0999\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0806\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0859\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0703\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0462\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0407\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0270\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0216\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0135\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9989\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9788\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9747\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9553\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9394\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9349\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9163\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9067\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8934\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8831\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8716\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8625\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8502\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8406\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8308\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8255\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8103\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8053\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7876\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7786\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7711\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7636\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7552\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7459\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7337\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7249\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7184\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7077\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7006\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6921\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6909\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.6763\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6639\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6559\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6466\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6388\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6335\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6249\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6171\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6078\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5983\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5908\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5851\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5747\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5675\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5592\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5539\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5439\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:57,236] Trial 51 finished with value: 55.88046729443471 and parameters: {'lr': 0.0010990602884344404, 'alpha': 0.005651126370097854, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5178\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4785\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4338\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3938\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3172\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2957\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2816\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2678\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2496\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2254\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2100\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2015\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1755\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1663\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1418\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1466\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1719\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1112\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0833\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0655\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0531\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0371\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0318\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9979\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9805\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9726\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9595\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9715\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9370\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9013\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8952\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8964\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8614\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8318\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8180\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8036\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8026\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7621\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7511\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7380\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7141\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6999\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6830\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6661\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6503\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6421\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6206\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6110\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6001\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5875\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5751\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5504\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5399\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5308\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5265\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4934\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4888\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4778\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4607\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4481\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4397\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4297\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4169\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4066\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3966\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3880\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3779\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3699\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3585\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3458\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3370\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3304\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3216\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3109\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3051\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2973\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2864\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2781\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2667\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2589\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2529\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2484\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2422\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2260\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2191\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2109\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2028\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1957\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1923\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1899\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1743\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1676\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1622\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1538\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.1426\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1415\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1280\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1234\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1197\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1090\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:08:58,918] Trial 52 finished with value: 57.723269285538926 and parameters: {'lr': 0.0006604875383176219, 'alpha': 0.006040681144711947, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5580\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5606\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5344\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5249\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5081\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4702\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4437\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4204\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4113\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3955\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3615\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3462\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3170\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2823\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2746\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2546\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2671\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2240\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1847\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1393\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1159\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0971\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0827\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0786\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0286\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0110\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9895\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0037\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9890\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9730\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9077\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8976\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9247\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8836\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8512\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8345\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8411\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8167\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8003\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7879\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7768\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7600\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7505\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7436\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7290\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7385\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7266\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7103\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7128\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6963\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7028\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6968\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6885\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6699\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6781\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6671\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6410\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6376\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6219\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6151\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6073\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5980\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5920\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5837\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5765\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5709\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5667\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5659\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5521\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5526\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5385\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5333\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5296\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5250\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5245\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5198\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5115\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5026\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4996\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4960\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4902\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4851\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4882\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4776\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4689\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4626\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4567\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4526\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4502\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4460\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4431\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4373\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4299\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4265\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4221\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4174\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4140\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4094\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4046\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4012\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:00,509] Trial 53 finished with value: 60.72872794413582 and parameters: {'lr': 0.001117578516471097, 'alpha': 0.003561639301935277, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1988\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7092\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3117\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3195\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2243\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1622\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1497\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1359\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1169\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0996\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0932\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0749\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0652\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0536\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0388\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0376\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0331\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0050\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9810\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9678\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9610\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9493\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9338\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9251\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9145\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9094\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8998\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8813\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8659\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8565\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8569\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8322\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8311\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8178\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.8027\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7884\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7821\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7697\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7537\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7415\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7297\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7182\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7065\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6945\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6872\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6737\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6680\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6529\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6411\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.6281\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6191\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6133\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6012\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5886\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5756\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5704\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5501\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5446\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5313\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5190\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5119\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4995\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4880\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4811\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4707\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4642\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4530\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4422\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4299\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4189\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4066\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4022\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3893\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3840\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3725\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3638\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3515\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3447\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3359\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3293\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3244\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3095\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3044\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2913\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2849\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2764\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2683\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2621\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2537\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2444\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2389\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2288\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2250\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2116\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2123\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2002\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1946\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1879\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1812\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:02,338] Trial 54 finished with value: 59.69757891514321 and parameters: {'lr': 0.0003889726320747716, 'alpha': 0.0072501034517637765, 'activation': 'sigmoid', 'n1': 256, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1943\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8422\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6778\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6902\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6086\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6265\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5958\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5915\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5875\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5745\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5717\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5596\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5556\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5453\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5392\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5379\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5353\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5197\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5159\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5047\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4935\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4875\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4820\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4719\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4694\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4617\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4589\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4507\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4387\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4302\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4241\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4277\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4083\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4148\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4053\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3934\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3824\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3818\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3700\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3616\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3519\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3469\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3383\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3309\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3241\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3179\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3135\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3057\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2973\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2886\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2817\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2756\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2718\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2650\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2548\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2487\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2424\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2290\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2254\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2172\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2082\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2042\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1930\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1887\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1823\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1747\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1761\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1616\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1567\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1467\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1372\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1307\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1253\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1150\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1173\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1010\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0989\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0867\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0814\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0748\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0708\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0648\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0522\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0508\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0393\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0366\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0272\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0223\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0143\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0090\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0036\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9953\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9919\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9873\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9766\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9768\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9672\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9601\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9570\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9507\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:03,959] Trial 55 finished with value: 60.41195850551317 and parameters: {'lr': 0.0003051940280185812, 'alpha': 0.004336887877957567, 'activation': 'sigmoid', 'n1': 320, 'n2': 384}. Best is trial 45 with value: 54.434319211628384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.7395\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.5572\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1991\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.8287\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.4537\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0319\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 21.6169\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2083\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8271\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4383\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0526\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.6961\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3263\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9555\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5816\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2407\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.9356\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.5784\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2560\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9338\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.5940\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2873\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9876\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7137\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.4136\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.1271\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8564\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5823\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.3319\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0810\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.8056\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5661\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.3408\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1071\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8487\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6125\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3863\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1765\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9480\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.7373\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5463\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3338\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1157\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9167\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7210\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5434\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3585\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1792\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9816\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8005\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6290\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4623\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2992\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1330\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9633\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8071\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6680\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5007\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3582\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2023\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0601\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9251\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7860\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6375\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5019\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.3706\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2423\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1230\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9882\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8669\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7509\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.6295\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5190\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3985\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2903\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.1786\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0712\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9653\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8605\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7587\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6589\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5581\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4624\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3705\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2755\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1856\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0931\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0050\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.9235\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8354\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7515\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6678\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5877\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5078\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4357\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3553\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2784\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2045\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1337\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0613\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:05,534] Trial 56 finished with value: 52.81048543606694 and parameters: {'lr': 0.00194612835157685, 'alpha': 0.03280636474326703, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.5355\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2679\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.7919\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.4116\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.9927\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.5828\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1784\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7700\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3899\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0046\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6104\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2492\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.8723\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 20.4881\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 20.1243\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7824\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4680\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.1124\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7834\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4338\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.0980\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7609\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4529\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1668\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8571\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5643\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.2803\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9983\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7322\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4783\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1817\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9294\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6959\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4465\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1799\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9351\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7025\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4781\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2375\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0159\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8100\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5855\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3595\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1493\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9420\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7520\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5593\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3653\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1650\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9667\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7850\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6108\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4383\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2575\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0761\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9118\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7595\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5822\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4262\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2602\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1126\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9662\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8163\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6532\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5091\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3677\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2312\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1017\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9526\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.8251\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6950\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5662\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4440\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3158\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1975\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0795\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9581\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8411\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7262\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6161\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5064\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3977\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2946\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1927\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.0892\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.9881\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8898\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7914\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6980\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6026\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5116\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4190\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3299\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2411\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1628\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0717\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9874\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9054\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.8275\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.7469\n",
      "4/4 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:07,270] Trial 57 finished with value: 55.33884713276276 and parameters: {'lr': 0.0017224473897670786, 'alpha': 0.035158247086843245, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.0702\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.7136\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 25.4195\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0374\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.6779\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.2724\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.8658\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4719\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1093\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7363\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3624\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 22.0171\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6582\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 21.2881\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9296\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.5998\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2978\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9511\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6474\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.3291\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 18.9924\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6787\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3871\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.1155\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.8199\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5372\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.2664\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.9861\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7340\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4928\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.2019\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.9521\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7194\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.4789\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.2220\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9836\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7536\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5349\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3018\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0854\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8831\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6638\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.4358\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2277\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0239\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.8321\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.6393\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4513\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2454\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.0504\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8691\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6935\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5221\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3397\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.1561\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9876\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8339\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6554\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.4965\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3299\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1777\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0263\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.8734\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7130\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5656\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4203\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2782\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1438\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9945\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8620\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7298\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5944\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4690\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3347\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2135\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0872\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.9630\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8421\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7208\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6047\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4899\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3758\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2656\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1594\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0498\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9444\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8366\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7332\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6354\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5334\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4359\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3375\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2428\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1477\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0626\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9667\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8748\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7860\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7011\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6136\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:08,900] Trial 58 finished with value: 56.920772943434145 and parameters: {'lr': 0.001785481306795398, 'alpha': 0.03079649038272542, 'activation': 'sigmoid', 'n1': 320, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.5054\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.8108\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.3308\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.7305\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1206\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5899\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1644\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8073\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.5496\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3704\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2707\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2460\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2891\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3975\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.5666\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7904\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0675\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3925\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.7634\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1766\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6296\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1186\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.6427\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1983\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7846\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3983\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.0381\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7021\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3886\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0971\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8247\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5700\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3319\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1112\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9056\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7131\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5330\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3663\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2111\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0662\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9306\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8034\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6859\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5770\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4733\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3770\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2887\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2057\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1285\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0551\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9885\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9268\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8670\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8101\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7577\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6676\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6284\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5873\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5526\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5196\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4905\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4600\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4346\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4029\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3936\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4110\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3906\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3578\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3266\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2958\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3127\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2678\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2328\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2158\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2070\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1902\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1792\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1698\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1601\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1522\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1436\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1353\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1238\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1316\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1179\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1279\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1178\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1146\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1082\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1074\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0999\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1006\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0918\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0960\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0822\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:10,469] Trial 59 finished with value: 62.95734778948861 and parameters: {'lr': 0.00578184151227972, 'alpha': 0.04098935941014275, 'activation': 'tanh', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6384\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5813\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3928\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2103\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0376\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8439\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6762\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4114\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2090\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0161\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8349\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6436\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4526\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2981\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1637\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0337\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8401\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6654\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4491\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3034\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1548\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0113\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8699\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7306\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6092\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4636\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3248\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1921\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0655\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9476\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8189\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6949\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5664\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4542\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3267\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.2057\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0972\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.9980\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8627\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7509\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6402\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5318\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4235\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.3171\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2120\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1128\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.0105\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.9084\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8103\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7080\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6079\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.5156\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4181\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3296\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2407\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1439\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0694\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9659\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8676\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7796\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6956\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6162\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.5298\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4490\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3619\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2798\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1982\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1172\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0427\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9631\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8867\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.8088\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7346\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.6581\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5827\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5103\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4403\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3706\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3002\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2345\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1624\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0961\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.0267\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.9614\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8930\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8279\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7627\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6993\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6386\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5764\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5132\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4538\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3932\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3347\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2797\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2208\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1631\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1054\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0504\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.9975\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:12,140] Trial 60 finished with value: 56.696271028300565 and parameters: {'lr': 0.002461490694915656, 'alpha': 0.016151784191946968, 'activation': 'sigmoid', 'n1': 384, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2478\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0172\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.6292\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.2039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.7728\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.3084\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.8436\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3769\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9510\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5081\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 21.0783\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6730\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.2592\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.8499\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4320\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0481\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6989\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.3091\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9580\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6014\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.2231\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.8920\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5531\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2490\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9205\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6053\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.3089\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0067\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7212\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4522\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.1495\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8841\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6490\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 13.3864\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1056\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8469\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5968\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.3651\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1179\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8887\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.6739\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.4503\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2182\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.0039\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.7934\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.5994\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.4027\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.2104\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9972\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8044\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6219\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4424\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2737\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0920\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9109\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7417\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5883\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4166\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2637\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1012\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9518\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8136\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6649\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5098\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3653\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2266\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0918\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9671\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8269\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6995\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5804\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4534\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3391\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2123\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9820\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8728\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7635\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6549\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5502\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4465\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3437\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2454\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1503\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0538\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9608\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8668\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7769\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6940\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6044\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5187\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4336\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3521\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2715\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1994\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1182\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0408\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9671\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8970\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8212\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:13,780] Trial 61 finished with value: 55.08044581208695 and parameters: {'lr': 0.001958106556908009, 'alpha': 0.034984303463819054, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.1616\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.8200\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 23.3166\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.5923\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9211\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2497\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6290\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.9602\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3305\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.7055\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1374\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.5334\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9948\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4749\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0187\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.6430\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0196\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5227\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1054\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6449\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2282\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8081\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4130\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.0409\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6900\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3353\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9895\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.6440\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.3227\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0134\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7192\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4242\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1348\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.8700\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5989\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.3371\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0833\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8722\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6281\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3893\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1829\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9542\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7497\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5408\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.3532\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1742\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9881\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.8000\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6372\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4599\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3010\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1454\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.9931\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8493\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7130\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.5751\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4320\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3073\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1854\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0577\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.9407\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8351\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7157\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6192\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5076\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4024\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3008\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2059\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1179\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0288\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9471\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8564\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7717\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6930\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6192\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5423\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4703\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4005\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3333\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2672\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2050\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1429\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0834\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0296\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9697\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9163\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8602\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8107\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7635\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7197\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6685\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6220\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5758\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5334\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5064\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4586\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4205\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3779\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3390\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3063\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:15,332] Trial 62 finished with value: 56.70197451274833 and parameters: {'lr': 0.0032422305194448643, 'alpha': 0.033385227441928095, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 35.5160\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 34.3798\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.6214\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.6235\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 31.7705\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.9054\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.0474\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.1749\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.3661\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5506\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.7811\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.0299\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2903\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.5957\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.8805\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.1947\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.5677\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.9090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.3039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6944\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0781\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5192\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9696\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4595\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9319\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4112\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9346\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.4585\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0081\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5727\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1206\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7054\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3259\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9270\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5151\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1325\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7661\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4188\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0672\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7358\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4311\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1060\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7900\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4932\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1997\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9326\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6632\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4134\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1290\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8790\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6411\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4108\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1858\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9562\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7343\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5226\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.3316\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1192\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.9337\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7368\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5554\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3880\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2159\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0419\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8745\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7164\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5636\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4230\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2688\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1260\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9938\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.8572\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7343\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6011\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4822\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.3608\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2470\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1350\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0261\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9217\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8167\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7158\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6204\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5284\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4354\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3468\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2549\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1717\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0973\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0157\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9349\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8583\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7845\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7133\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6468\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5783\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5118\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4479\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3937\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3272\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:17,022] Trial 63 finished with value: 54.66146450273181 and parameters: {'lr': 0.0020581756490388532, 'alpha': 0.048516082802718796, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 34.6021\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 34.1687\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.4120\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.6096\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 31.7844\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.9139\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 30.0611\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 29.2258\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.4434\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.6504\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.8943\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.1686\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 25.4433\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 24.7524\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.0413\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 23.3722\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7612\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 22.1110\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.5098\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9059\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.3075\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 19.7573\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2190\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7160\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1892\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.6712\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 17.1981\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7271\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2841\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 15.8458\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3960\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9847\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6097\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 14.2137\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7998\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4169\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0548\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.7119\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3567\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0249\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7224\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3986\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0784\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7808\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4864\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.2155\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9448\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6860\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4078\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1555\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9162\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6821\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4546\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2253\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0016\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7891\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5986\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3800\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.1930\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.9933\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8093\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6413\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4648\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2850\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1154\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9547\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7994\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6567\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.4985\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3526\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2182\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0788\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9538\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8164\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6947\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5714\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4541\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3396\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2275\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1181\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0113\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9062\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8084\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7137\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6171\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5262\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4321\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3456\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2682\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1824\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0999\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0209\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9448\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8710\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8013\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7304\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6607\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5940\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5358\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4681\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:18,657] Trial 64 finished with value: 54.59184485389007 and parameters: {'lr': 0.0020123123607267567, 'alpha': 0.048452573091974704, 'activation': 'sigmoid', 'n1': 256, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5493\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5576\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.0548\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.3595\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.7560\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.1291\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4954\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.8784\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3208\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7350\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.1715\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 20.6448\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1106\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5858\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.0550\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5618\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1229\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6370\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 17.1931\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 16.7342\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2791\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8568\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4476\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.0693\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6671\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2961\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9328\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5763\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2396\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9134\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5688\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2570\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9681\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6738\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3576\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0689\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7909\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5300\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.2573\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0032\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7707\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5217\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2678\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0362\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8104\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6043\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3949\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1938\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9723\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7673\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5779\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3963\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2203\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0371\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8551\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6880\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5372\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3651\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2149\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0558\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9112\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7734\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6345\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4828\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3489\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2181\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0930\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9783\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8463\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7303\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6224\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5061\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4050\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.2906\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1928\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0914\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9918\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8953\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7996\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7092\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6211\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5331\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4517\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3739\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2924\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2148\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1377\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0622\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9961\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9228\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8548\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7856\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7216\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6570\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6046\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5380\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4768\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4195\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3676\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3096\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:20,374] Trial 65 finished with value: 54.29691622536134 and parameters: {'lr': 0.001974353041603855, 'alpha': 0.045875023609623755, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.6103\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.7891\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2425\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.5463\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.9425\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.3232\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.7147\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.0731\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4991\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9076\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.3549\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8116\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2689\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7630\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2523\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7569\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.3161\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8142\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3748\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9231\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4516\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0392\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.6302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2672\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8680\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4797\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1282\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.7742\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.4415\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1264\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7837\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4790\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2093\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9169\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5941\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3072\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0337\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7713\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5052\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2577\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0347\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7950\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5468\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3234\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1009\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9034\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7005\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5082\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2907\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1002\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9200\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7445\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5756\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4010\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2297\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0681\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9251\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7592\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6166\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4649\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3267\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1989\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0673\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9294\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8004\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6783\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5602\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4533\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3308\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2192\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1177\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0109\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9167\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8098\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7172\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6224\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5330\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4447\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3590\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2761\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1933\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1123\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0370\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9642\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8903\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8210\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7476\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6808\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6218\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5558\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4919\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4306\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3711\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3136\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2613\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2053\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1505\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0992\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0543\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0004\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:22,067] Trial 66 finished with value: 54.65766232421647 and parameters: {'lr': 0.00214220020753589, 'alpha': 0.04442101481643664, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.5023\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.9981\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.3848\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.7039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0389\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.3509\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6681\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.9667\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3211\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6706\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0593\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4583\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8630\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.3119\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.7624\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2142\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.7322\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1760\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6914\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.1976\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7013\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.2532\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8156\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4082\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9979\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5761\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1997\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8255\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 12.4710\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1248\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7704\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4484\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1480\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8343\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5018\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1997\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.9175\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6427\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3640\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.1013\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8697\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6106\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3618\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1292\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.8940\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6858\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4764\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2816\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0579\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8637\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6812\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4997\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3278\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1476\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9738\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8074\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6653\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4921\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3490\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1956\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.0550\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9277\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7939\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6585\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5269\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4042\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2862\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1791\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0586\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9471\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8459\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7414\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6485\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5429\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4517\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3571\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2706\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1838\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1010\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0212\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9389\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8619\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7892\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7196\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6463\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5796\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5074\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4438\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3874\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3247\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2622\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2041\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1480\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0931\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0418\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9895\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9386\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8895\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8488\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7983\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:23,734] Trial 67 finished with value: 54.38580421337003 and parameters: {'lr': 0.0021726256722235855, 'alpha': 0.04672479114420974, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 28.3087\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.8229\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 27.2061\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5029\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.8105\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0884\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.3734\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.6497\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.9900\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3084\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.6713\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0465\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.4307\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8535\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.2676\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 18.7047\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2144\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6409\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.1382\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6230\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 16.1007\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6329\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1822\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7630\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3300\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8970\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5017\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1079\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7377\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3847\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0078\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6742\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3759\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0563\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7115\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3952\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1006\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8232\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5324\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2617\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0251\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7621\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4987\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2582\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.0203\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8072\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5930\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3935\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1601\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9589\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7691\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5844\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.4074\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2236\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0440\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8751\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7283\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5527\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4057\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2479\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1055\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9748\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8379\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6971\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5648\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4400\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3200\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2119\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0863\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9745\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8722\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7642\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6710\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5628\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4705\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3745\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2855\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1978\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1128\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0307\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9483\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8690\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7955\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7249\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6516\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5840\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5116\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4472\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3911\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3269\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2647\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2047\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1480\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0933\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0424\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9891\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9368\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8877\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8468\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7942\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:25,411] Trial 68 finished with value: 53.91736794297466 and parameters: {'lr': 0.0021248397770244963, 'alpha': 0.048452239153924805, 'activation': 'sigmoid', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9031\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8734\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0875\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6943\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3314\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0074\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7043\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4272\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1568\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8977\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6449\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4002\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1608\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9279\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7001\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.4772\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2592\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0459\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8370\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6325\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4323\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.2365\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0446\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8568\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6729\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4929\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3166\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1440\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9751\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8096\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6477\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4891\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3338\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1816\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0327\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8869\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7442\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6044\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4676\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3336\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2024\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0739\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9481\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.8249\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7044\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5863\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4706\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3574\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2466\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1380\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0317\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9276\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8258\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7260\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.6282\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5326\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4389\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3472\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2574\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1694\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0833\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9990\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9164\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8356\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7564\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6789\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6030\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5287\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4559\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3847\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3149\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2465\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1796\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1141\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0499\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9871\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9256\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8653\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8063\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7485\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6920\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6366\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5824\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5292\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4772\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4263\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3764\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3276\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2798\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2330\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1871\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1422\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0982\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0552\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0130\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9718\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9313\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8917\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8530\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8150\n",
      "4/4 [==============================] - 0s 666us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:27,057] Trial 69 finished with value: 57.01057855341436 and parameters: {'lr': 0.002957590254938874, 'alpha': 0.02509315814409954, 'activation': 'relu', 'n1': 192, 'n2': 320}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.3545\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.7899\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.7643\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7079\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.6886\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.6936\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7475\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8459\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9941\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1884\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4264\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7061\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0252\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3812\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7723\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1963\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6515\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1362\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6489\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1879\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7518\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3392\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9490\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5798\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2305\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9002\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5875\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2918\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0120\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7472\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4970\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2599\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0355\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8235\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6227\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4328\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2532\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0830\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9224\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7700\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6260\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4898\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3608\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2387\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1234\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0140\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9108\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8133\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7207\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6331\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5502\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4717\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3975\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3272\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2608\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1982\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1385\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0822\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0289\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9785\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9309\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8855\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8428\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8022\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7640\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7276\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6933\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6609\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6301\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6015\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5739\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5474\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5228\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4991\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4769\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4558\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4170\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3992\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3823\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3663\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3512\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3371\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3230\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3103\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2978\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2755\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2552\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2281\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2200\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2126\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1985\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1920\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1859\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1802\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:28,835] Trial 70 finished with value: 54.224988136544084 and parameters: {'lr': 0.0041223405551542875, 'alpha': 0.046427939714433056, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.0043\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.4276\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.1737\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.9376\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.7125\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5382\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4376\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3893\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4064\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4842\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6185\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8052\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0412\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3239\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6498\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0162\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4209\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8616\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3359\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8417\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3775\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9408\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5307\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1449\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7823\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4416\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1212\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8201\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5370\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2709\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0209\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7857\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5646\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3568\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1614\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9779\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8052\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6429\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4906\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3470\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2122\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0855\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9663\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8542\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7491\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6499\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5569\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4697\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3875\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3101\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2374\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1689\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1046\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0441\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9872\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9341\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8837\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8365\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7919\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7501\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7109\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6737\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6390\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6061\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5755\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5464\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5192\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4937\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4696\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4475\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4260\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4058\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3869\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3686\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3520\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3360\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3212\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2938\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2696\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2587\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2487\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2384\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2293\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2203\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2122\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2047\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1906\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1838\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1776\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1716\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1660\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1611\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1562\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1514\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1470\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1429\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1394\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:30,657] Trial 71 finished with value: 54.6606564701801 and parameters: {'lr': 0.004286202090680954, 'alpha': 0.04966097050391106, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.2335\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.8185\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.8566\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9104\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9524\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0168\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.1403\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3042\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5138\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7733\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0739\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4131\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7896\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2005\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.6443\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1187\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6222\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1531\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.7100\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2911\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8955\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5216\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1682\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8343\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5187\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2205\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9387\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6724\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4207\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1829\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9582\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7456\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5447\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3550\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1756\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0061\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8459\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6944\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5515\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4160\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2882\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1674\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0531\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9451\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8432\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7466\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6555\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5697\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4882\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4112\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3384\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2696\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2046\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1431\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0850\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0304\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9783\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9293\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8390\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7977\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7583\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7213\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6861\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6531\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6217\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5920\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5642\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5377\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5131\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4893\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4456\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4252\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4063\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3882\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3713\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3550\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3398\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3254\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3118\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2991\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2752\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2643\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2537\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2440\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2350\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2263\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2178\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1881\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1820\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1759\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1701\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1646\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1595\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1549\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:32,452] Trial 72 finished with value: 54.31076159649843 and parameters: {'lr': 0.00463546788420104, 'alpha': 0.042097378084847925, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3571\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3923\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7418\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1521\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6424\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1813\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7388\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3208\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9304\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5679\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2221\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8977\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.5911\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2996\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0245\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7639\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5175\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2835\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0621\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8523\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6536\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4653\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2868\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1177\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9573\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8055\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6615\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5251\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3957\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2732\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1570\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0468\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9424\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8435\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7497\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6609\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5766\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4967\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4212\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3493\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2813\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2168\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1557\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0977\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0429\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9907\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9415\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8948\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8509\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8085\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7693\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7308\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6953\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6613\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6295\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5991\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5706\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5427\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5165\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4923\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4687\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4465\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4056\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3869\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3688\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3520\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3357\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3209\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3061\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2927\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2668\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2553\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2443\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2336\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2236\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2138\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2050\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1884\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1809\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1734\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1666\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1598\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1536\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1491\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1429\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1384\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1327\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1231\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1183\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1142\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1100\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1065\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1030\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0998\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0975\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0959\n",
      "4/4 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:34,296] Trial 73 finished with value: 54.453783915730945 and parameters: {'lr': 0.008804173964550322, 'alpha': 0.0210942773834046, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1602\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3501\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8385\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0344\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5121\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0055\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5523\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1098\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7050\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3242\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.9643\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6289\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3124\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0145\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7338\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4690\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2197\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9840\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7619\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5526\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3552\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1691\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9928\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8268\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6701\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5225\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3845\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2517\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1285\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0106\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9021\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7957\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6980\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6043\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5163\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4337\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3553\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2820\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2129\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1474\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0856\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0278\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9717\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9192\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8703\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8234\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7795\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7386\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6999\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6626\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6286\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5951\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5642\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5351\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5077\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4820\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4586\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4345\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4123\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3925\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3730\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3538\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3367\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3197\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3055\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2911\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2634\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2588\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2465\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2241\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2130\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2013\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1897\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1839\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1715\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1557\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1479\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1421\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1306\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1252\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1204\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1160\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1119\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1076\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1036\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0997\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0962\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0929\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0900\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0869\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0793\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0849\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:36,065] Trial 74 finished with value: 54.531885326614606 and parameters: {'lr': 0.009520095859857844, 'alpha': 0.021031807479581142, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3046\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9278\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1760\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.5194\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8814\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3370\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8032\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2895\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8090\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3519\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9165\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5046\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1112\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7373\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3808\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0412\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7177\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1150\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8345\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5672\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3122\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0692\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8374\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6163\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4056\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2045\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0129\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8300\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6556\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4894\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3307\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1793\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0351\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8973\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7661\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6408\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5214\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4076\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2988\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1952\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0964\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0021\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9121\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8264\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7445\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6665\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5923\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5214\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4536\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3891\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3274\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2688\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1594\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1085\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0599\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0135\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9693\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9271\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8485\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8120\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7770\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7438\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7120\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6816\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6529\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6255\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5993\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5740\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5502\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5274\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5053\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4847\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4648\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4458\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4277\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4104\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3940\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3783\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3635\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3493\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3355\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3224\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3100\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2982\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2763\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2659\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2559\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2466\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2375\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2289\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2209\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2055\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1984\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1853\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:37,882] Trial 75 finished with value: 53.330981826575204 and parameters: {'lr': 0.005745559099222646, 'alpha': 0.028691482524501436, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.0167\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7525\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0323\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4488\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7890\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1962\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6028\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0486\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5240\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0268\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5543\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1043\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6763\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2695\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8819\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5130\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1616\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8268\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5080\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2042\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9147\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6391\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3764\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1261\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8877\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6605\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4440\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2378\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0412\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8540\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6755\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5054\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3433\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1889\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0417\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9016\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7679\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6405\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5194\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4036\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2934\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1884\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0883\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9929\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9021\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8154\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7330\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6546\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5797\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5082\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4403\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3753\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3135\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2546\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1986\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1453\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0943\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0457\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9994\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9554\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8732\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8351\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7987\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7641\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7310\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6995\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6696\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6412\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6141\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5880\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5632\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5397\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5168\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4956\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4555\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4368\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4190\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4021\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3860\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3708\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3563\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3421\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3287\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3159\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3040\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2925\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2816\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2710\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2608\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2512\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2419\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2332\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2251\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2171\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2094\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1954\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:39,708] Trial 76 finished with value: 54.142874385042184 and parameters: {'lr': 0.00542159070491758, 'alpha': 0.030944388344594388, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7769\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.5807\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8940\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2812\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6773\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0996\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5574\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0287\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5273\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.0544\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6076\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1826\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7799\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3974\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0344\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6891\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3617\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0500\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7539\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4729\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2054\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9519\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7100\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4802\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2619\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0546\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8573\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6699\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4918\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3224\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1615\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0083\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8627\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7244\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5929\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4679\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3489\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2359\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1287\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0264\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9292\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8370\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7492\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6657\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5865\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5109\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4393\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3713\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3067\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2449\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1865\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1306\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0776\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0273\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9795\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9342\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8909\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8106\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7735\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7382\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7044\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6726\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6421\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6133\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5857\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5597\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5351\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5117\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4893\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4676\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4476\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4288\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4095\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3929\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3766\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3600\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3449\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3305\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3037\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2912\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2685\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2578\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2477\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2382\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2291\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2205\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2120\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2038\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1891\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1823\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1760\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1697\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1581\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1528\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1479\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:41,473] Trial 77 finished with value: 54.22571804367231 and parameters: {'lr': 0.006210474656590668, 'alpha': 0.028307470595575146, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.1699\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7354\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8764\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4395\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4069\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4765\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5810\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7839\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0600\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4057\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8138\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2756\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7905\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3496\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9503\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5883\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2600\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9622\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6926\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4478\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2264\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0250\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8422\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6767\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5264\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3905\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2698\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1556\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0579\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9625\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8875\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8038\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7382\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6728\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6152\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5642\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5176\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4759\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4406\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4072\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3768\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3542\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3271\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3266\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3006\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2457\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2316\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2136\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1950\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1848\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1710\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1607\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1500\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1413\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1326\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1253\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1174\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1111\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1061\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0961\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0925\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0890\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0783\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0765\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0790\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0979\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0915\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0805\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0788\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0669\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0605\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0582\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0552\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0548\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0525\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0495\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0557\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0495\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0540\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:43,311] Trial 78 finished with value: 56.19758879906386 and parameters: {'lr': 0.011394619525542356, 'alpha': 0.02876680619016224, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5619\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.1673\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0264\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9782\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.9261\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9291\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9906\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1082\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2878\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5235\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8132\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1507\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5332\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9585\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4233\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9247\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4600\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0269\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6231\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2469\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8964\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5694\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2648\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9808\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7160\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4693\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2392\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0249\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8251\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6389\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4653\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3033\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1523\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0117\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8806\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7584\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6445\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5381\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4396\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3469\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2608\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1806\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1058\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0358\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9708\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9099\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8535\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8011\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7524\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7060\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6637\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6232\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5860\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5513\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5190\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4890\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4606\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4343\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4096\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3868\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3655\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3452\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3268\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3093\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2932\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2507\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2272\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2163\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2065\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1973\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1877\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1801\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1725\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1650\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1580\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1515\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1454\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1398\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1347\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1254\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1209\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1170\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1136\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1101\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1070\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1039\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1003\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0976\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0950\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0924\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0861\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0844\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0829\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0813\n",
      "4/4 [==============================] - 0s 864us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:45,139] Trial 79 finished with value: 54.92387933984133 and parameters: {'lr': 0.006219573309194602, 'alpha': 0.03869730855519753, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5796\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6544\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2432\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0026\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7814\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5707\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3843\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1970\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0254\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8595\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6986\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5422\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3903\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2422\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0976\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9566\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8190\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6846\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5535\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4254\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3003\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.1781\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0589\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9424\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8286\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7176\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6090\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5031\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3995\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2985\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1998\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1034\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0092\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9172\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8273\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7396\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6539\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5702\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4884\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4085\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3305\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2542\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1798\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1070\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0360\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9666\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8988\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8327\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7680\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7048\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6431\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5828\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5239\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4664\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4102\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3554\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3017\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2493\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1982\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1482\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0994\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0516\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0051\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9595\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9151\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8716\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8292\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7878\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7473\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7078\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6692\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6314\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5945\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5584\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5233\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4889\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4553\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4225\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3904\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3591\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3286\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2987\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2696\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2410\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2132\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1859\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1594\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1335\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1082\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0834\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0591\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0355\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0123\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9898\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9677\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9252\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9046\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8845\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8650\n",
      "4/4 [==============================] - 0s 873us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:46,953] Trial 80 finished with value: 55.47997905097739 and parameters: {'lr': 0.004761660891407249, 'alpha': 0.017383691919961128, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4726\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1791\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6582\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2170\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7532\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3150\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.9053\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5091\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1267\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7606\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4082\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0673\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7379\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4202\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1130\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8161\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5289\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2513\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9828\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7232\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4722\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2295\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9948\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7678\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5483\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3360\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1307\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9321\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7401\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5543\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3748\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2010\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0329\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8704\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7131\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5610\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4139\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2716\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1340\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0008\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8720\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7474\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6269\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5102\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3975\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2884\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1829\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0809\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9822\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8867\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7942\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7049\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6184\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5348\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4539\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3757\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2268\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1559\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0875\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0212\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9570\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8951\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8350\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7770\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7209\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6666\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6141\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5633\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5143\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4668\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4206\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3762\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3331\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2914\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2511\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2122\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1745\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1380\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1028\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0686\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0356\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0039\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9728\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9430\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9140\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8861\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8591\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8330\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8076\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7830\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7593\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7363\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7141\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6927\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6720\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6518\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6136\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5955\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:48,734] Trial 81 finished with value: 55.27014748184249 and parameters: {'lr': 0.003966510983459755, 'alpha': 0.029436816394541963, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0846\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4511\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4634\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.5710\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6677\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.8086\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.9886\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2101\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4768\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7873\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1367\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5225\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9428\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3959\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8794\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3919\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9314\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4966\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0861\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6983\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3322\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9861\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6595\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3509\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0593\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7839\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5236\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2779\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0457\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8264\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6193\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4235\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2384\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0638\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8987\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7428\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5955\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4562\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3250\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2006\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0832\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9724\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8676\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7685\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6751\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5867\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5033\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4247\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3504\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2798\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2134\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1504\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0910\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0349\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9820\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9321\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8847\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8400\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7977\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7578\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7201\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6843\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6507\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6187\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5888\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5602\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5333\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5080\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4842\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4617\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4400\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4197\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4007\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3820\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3651\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3488\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3334\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3186\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3049\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2919\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2680\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2572\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2466\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2366\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2272\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2185\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2103\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2025\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1876\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1808\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1743\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1683\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1627\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1573\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1520\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1472\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1427\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1386\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:50,522] Trial 82 finished with value: 54.747110517986215 and parameters: {'lr': 0.005044296075894868, 'alpha': 0.03898893704105874, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1712\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.1082\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.4294\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.8799\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3212\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7576\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2468\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7421\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2772\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8353\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4160\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0178\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6383\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2779\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9349\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6084\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2976\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0013\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7195\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4511\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1955\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9518\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7199\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4988\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2883\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0878\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8968\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7149\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5416\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3765\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2193\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0694\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9266\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7907\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6611\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5378\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4201\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3081\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2016\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0998\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0029\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9107\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8228\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7390\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6592\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5831\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5108\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4420\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3765\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3137\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2542\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1972\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1430\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0915\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0424\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9957\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9511\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9086\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8680\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8295\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7929\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7577\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7245\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6926\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6624\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6335\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6060\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5799\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5552\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5314\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5086\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4873\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4468\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4105\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3933\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3770\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3616\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3468\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3328\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3195\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2947\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2830\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2719\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2615\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2421\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2240\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2158\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2078\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2002\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1797\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1736\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1677\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1621\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:52,644] Trial 83 finished with value: 54.60401935582229 and parameters: {'lr': 0.006680939529286577, 'alpha': 0.025221417860610478, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.2609\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.9057\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6846\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5373\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4546\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4352\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5014\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6267\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.8254\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.0821\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3972\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7652\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1815\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6420\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1440\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6839\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2589\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8658\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5027\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1671\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8570\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5704\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3053\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0603\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8338\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6249\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4321\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2528\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0881\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9352\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7950\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6636\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5434\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4316\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3287\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2337\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1457\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0643\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9897\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9199\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8557\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7963\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7415\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6905\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6438\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5601\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5233\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4900\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4572\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4294\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4004\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3757\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3523\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3312\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3115\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2935\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2757\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2594\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2317\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2189\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2074\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1964\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1866\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1771\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1685\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1603\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1535\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1462\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1403\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1341\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1230\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1183\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1139\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1098\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1056\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1023\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0988\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0957\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0934\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0816\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0804\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0792\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0735\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0692\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0684\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0674\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0672\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "4/4 [==============================] - 0s 880us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:54,447] Trial 84 finished with value: 55.2301306889337 and parameters: {'lr': 0.007559863856886031, 'alpha': 0.035507594224455964, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.1100\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.1282\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9910\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.5752\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4630\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6171\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0027\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5823\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3675\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3295\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4319\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6669\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0115\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4496\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9694\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5566\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2040\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9016\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6435\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4219\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2336\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0700\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9296\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8102\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7074\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6206\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5467\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4799\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4301\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3792\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3486\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3031\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2762\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2487\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2239\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2043\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1880\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1727\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1646\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1545\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1412\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1347\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1250\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1228\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1173\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1091\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1098\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1159\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1102\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1043\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1030\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1029\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0896\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0867\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0843\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0810\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0778\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0814\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0814\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0762\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0767\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0760\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0874\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0870\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0971\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1064\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0853\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0758\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0745\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0772\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0722\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0704\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0749\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0787\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0839\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0849\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1027\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0900\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0831\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0969\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0823\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:56,307] Trial 85 finished with value: 54.38135509720895 and parameters: {'lr': 0.011372490571262574, 'alpha': 0.043753669347685945, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3589\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0197\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6719\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0422\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6142\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3706\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2413\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2324\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3587\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5845\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9082\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3142\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7937\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3381\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9447\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6032\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3103\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0204\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7861\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5805\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3984\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2483\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1024\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8574\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7596\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6055\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5384\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4819\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4316\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3872\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3475\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3132\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2835\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2172\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2091\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2003\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1912\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1772\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1918\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1687\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1528\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1397\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1463\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1509\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1276\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1186\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1130\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1029\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0979\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0884\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0799\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0772\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0745\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0737\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0726\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0699\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0687\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0717\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0786\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0762\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0748\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0651\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0631\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0617\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0589\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0592\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0586\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0593\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0712\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0704\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0811\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0744\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0681\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0692\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "4/4 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:58,113] Trial 86 finished with value: 55.949863005042836 and parameters: {'lr': 0.013245679779290231, 'alpha': 0.032390335022136216, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.5125\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.4318\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.3427\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2672\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.4022\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7736\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3242\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0855\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0264\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1226\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3576\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7072\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1564\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6891\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2947\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9671\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6818\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4363\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2311\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0589\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9188\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7897\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6806\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5941\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5149\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4484\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3465\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3091\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2763\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2506\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2287\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2051\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1889\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1734\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1640\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1635\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1512\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1648\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1896\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1761\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1670\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1491\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1304\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1216\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1078\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1128\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1242\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1140\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1057\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0964\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0892\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0844\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0861\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0941\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0869\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0844\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0860\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0908\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0771\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0850\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0799\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0831\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0753\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0733\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0669\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0665\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0736\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0683\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1117\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1214\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1252\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1069\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1125\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1125\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1083\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0958\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0869\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0824\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0761\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0697\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0820\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0758\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:09:59,979] Trial 87 finished with value: 57.13412939449313 and parameters: {'lr': 0.013753092965148251, 'alpha': 0.038327108731713286, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.5395\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3995\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7529\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2619\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7653\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.2932\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8385\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4261\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 10.0254\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6424\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2763\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9265\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5900\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2672\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9569\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6584\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3714\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0953\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8297\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5741\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3283\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0918\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8643\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6454\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4346\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2320\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0369\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8493\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6686\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4949\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3277\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1667\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0118\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8628\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7193\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5813\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4485\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.3206\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1977\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0792\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9653\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8557\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7502\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6486\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5509\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4568\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3663\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2794\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1956\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1149\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0372\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9625\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8907\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8215\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7549\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6909\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6292\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5699\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5128\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4579\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4050\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3540\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3051\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2579\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2126\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1689\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1269\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0865\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0476\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0104\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9395\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9062\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8739\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8430\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8132\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7846\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7304\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7049\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6803\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6567\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6341\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6120\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5909\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5705\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5511\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5324\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5143\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4968\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4799\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4638\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4481\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4331\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4188\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4049\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3915\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3786\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3663\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3545\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:01,777] Trial 88 finished with value: 54.13674064855176 and parameters: {'lr': 0.005266479996662898, 'alpha': 0.02548226942571884, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 56 with value: 52.81048543606694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1876\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3958\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1493\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0015\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8501\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7229\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6050\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4999\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3984\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3023\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2086\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1187\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0304\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9447\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8610\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7794\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6998\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6216\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5453\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4707\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3977\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3264\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2563\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1879\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1209\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0556\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9914\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9286\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8672\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8071\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7483\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6907\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6344\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5793\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5253\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4725\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4208\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3701\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3206\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2721\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2247\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1782\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1328\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0882\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0447\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0020\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9602\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9195\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8795\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8403\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8020\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7644\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7278\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6918\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6566\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6222\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5885\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5555\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5232\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4916\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4606\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4303\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4007\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3716\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3432\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3154\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2881\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2615\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2354\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2099\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1849\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1604\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1365\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1130\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0901\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0676\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0456\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0241\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0030\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9824\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9622\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9424\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9232\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9042\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8856\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8674\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8323\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8153\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7987\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7823\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7664\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7507\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7354\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7205\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7058\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6914\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6774\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6637\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6503\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:03,621] Trial 89 finished with value: 51.87719012805435 and parameters: {'lr': 0.005659908689217048, 'alpha': 0.013367428810420565, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0343\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0685\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7975\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5824\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4653\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3267\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2184\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1173\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0260\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9389\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8531\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7715\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6921\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6150\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5390\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4649\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3920\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3205\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2503\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1814\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1137\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0470\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9816\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9172\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8540\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7917\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7305\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6703\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6111\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5529\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4956\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4393\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3838\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3293\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2757\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2230\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1711\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1201\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0699\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0205\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9719\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9241\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8771\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8309\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7854\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7406\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6966\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6534\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6108\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5688\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5276\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4870\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4472\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4079\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3693\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3313\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2940\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2572\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2210\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1855\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1505\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1161\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0822\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0489\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0161\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9839\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9521\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9209\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8902\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8601\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8304\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8011\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7724\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7441\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7163\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6889\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6620\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6354\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6094\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5838\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5585\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5337\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5093\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4853\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4617\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4384\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4156\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3931\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3710\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3492\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3278\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3067\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2860\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2656\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2455\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2258\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2064\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1873\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1685\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1500\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:05,502] Trial 90 finished with value: 58.129531107344214 and parameters: {'lr': 0.003931747065517547, 'alpha': 0.014788267825545398, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6282\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7252\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3552\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1177\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8124\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5910\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3921\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1991\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0099\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8331\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6654\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5047\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3497\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1995\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0537\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9123\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7751\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6417\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5123\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3865\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2643\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1456\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9181\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8091\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7033\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6004\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5005\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4033\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3089\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2172\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1280\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0413\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9571\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8752\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7956\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7182\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6431\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5701\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4990\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4300\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3629\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2977\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2343\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1727\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1128\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0546\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9981\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9432\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8897\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8378\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7873\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7382\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6905\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6442\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5992\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5554\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5129\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4715\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4313\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3923\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3542\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3174\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2814\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2466\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1798\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1478\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1167\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0865\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0571\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0285\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0008\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9737\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9475\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9220\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8972\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8731\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8270\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8049\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7834\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7626\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7422\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7225\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7032\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6846\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6666\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6490\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6318\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6152\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5990\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5832\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5679\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5531\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5387\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5246\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5110\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4977\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4849\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:07,384] Trial 91 finished with value: 56.448921305401946 and parameters: {'lr': 0.005212677116400229, 'alpha': 0.019241661342297642, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.6721\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1908\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4788\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.8803\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.2981\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7365\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1883\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6943\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2248\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7745\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3465\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9400\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5508\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1794\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8246\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4854\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1613\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8513\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5549\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2716\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0007\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7416\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4939\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2569\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0303\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8137\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6064\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4083\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2186\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0374\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8641\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6982\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5395\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3879\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2427\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1040\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9713\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8442\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7230\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6067\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4957\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3895\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2878\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1906\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0977\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0087\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9237\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8426\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7648\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6903\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6192\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5511\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4860\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4237\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3642\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3074\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2529\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2008\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1509\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1033\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0578\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0141\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9725\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9325\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8944\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8578\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8230\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7897\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7578\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7274\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6981\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6701\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6434\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6176\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5933\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5698\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5473\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5258\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5053\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4669\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4491\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4320\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4154\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3996\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3845\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3702\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3565\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3434\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3307\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3185\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3069\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2957\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2851\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2751\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2654\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2560\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2471\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2386\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2306\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:09,177] Trial 92 finished with value: 53.66051793603558 and parameters: {'lr': 0.005706785231232192, 'alpha': 0.02717730570168838, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4230\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2813\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6719\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1149\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5863\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0802\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5963\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1262\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6824\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2603\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8572\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4732\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1066\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7566\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4221\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1021\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7961\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5035\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2236\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9560\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7002\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4552\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2211\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9970\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7827\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5778\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3817\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1942\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0147\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8431\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6790\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5218\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3715\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2278\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0903\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9587\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8328\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7123\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5973\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4869\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3815\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2807\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1842\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0918\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0035\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9189\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8381\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7610\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6871\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6162\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5486\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4836\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4217\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3624\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3058\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2516\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1996\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1500\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1024\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0570\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0136\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9718\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9321\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8940\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8576\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8227\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7893\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7575\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7272\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6980\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6699\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6433\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6177\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5930\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5697\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5472\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5257\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5051\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4854\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4666\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4486\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4315\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4151\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3993\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3841\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3695\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3559\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3427\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3179\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3061\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2950\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2843\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2741\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2645\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2551\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2461\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2376\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2294\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2217\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:11,006] Trial 93 finished with value: 55.13825186992917 and parameters: {'lr': 0.006023648939669022, 'alpha': 0.025608930381952826, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.2661\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4897\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1263\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9051\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7195\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5040\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3225\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1144\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9333\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7622\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5967\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4283\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2716\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1175\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9713\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8287\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6909\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5566\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4268\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3011\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1788\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0608\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9451\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8328\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7239\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6183\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5160\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4164\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3197\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2257\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1345\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0459\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9598\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8761\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7949\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7160\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6393\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5649\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4926\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4223\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3540\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2878\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2233\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1607\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0999\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0408\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9834\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9277\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8736\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8209\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7699\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7202\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6720\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6251\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5796\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5354\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4925\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4507\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4102\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3708\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3326\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2954\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2593\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2242\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1901\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1570\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1249\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0937\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0634\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0339\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0052\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9774\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9504\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9240\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8986\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8738\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8497\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8262\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8035\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7814\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7600\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7392\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7190\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6801\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6436\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6261\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6091\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5926\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5765\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5609\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5457\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5310\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5167\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5028\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4892\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4761\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4634\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4511\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:12,831] Trial 94 finished with value: 55.18334923023347 and parameters: {'lr': 0.007249996136264344, 'alpha': 0.014062824067704701, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.0250\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 11.3852\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.9268\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5371\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.2529\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9803\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7584\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5522\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3441\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1443\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9548\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7715\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5909\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4159\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2455\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0787\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9156\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7560\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5998\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4470\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2973\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1506\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0071\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8665\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7288\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5939\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4618\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3323\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2055\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0813\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9597\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8404\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7236\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6092\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4971\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3873\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2797\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1742\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0710\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9697\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8705\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7734\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6782\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5849\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4936\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4041\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3163\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2305\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1462\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0637\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9829\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9036\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8260\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7500\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6755\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6025\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5310\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4609\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3922\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3249\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2590\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1944\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1311\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0690\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0083\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9488\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8904\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8333\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7772\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7224\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6687\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6159\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5643\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5137\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4641\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4156\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3680\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3213\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2757\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2309\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1871\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1441\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1020\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0607\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0203\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9806\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9418\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9038\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8301\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7943\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7592\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7249\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6912\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6582\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6259\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5943\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5632\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5328\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5031\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:14,712] Trial 95 finished with value: 54.400481701617174 and parameters: {'lr': 0.0025573425263952228, 'alpha': 0.028210335093461072, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.7481\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.6631\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.2909\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.9439\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6741\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3850\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1206\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8751\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6384\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.4115\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1906\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9758\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7659\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5610\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3607\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1650\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9736\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7862\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6029\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4235\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2480\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0761\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.9079\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7432\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5821\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4244\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2699\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.1188\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9707\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8259\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6841\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5453\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4093\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2762\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1459\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0184\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8935\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7712\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6516\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5344\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4197\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3073\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1974\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0897\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9843\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8811\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7801\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6812\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5843\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4895\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3967\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3057\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2168\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1296\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0443\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9608\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8790\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7990\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7206\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6438\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5687\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4951\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4231\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3525\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2835\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2159\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1497\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0849\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0214\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9594\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8986\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8389\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7806\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7235\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6676\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6128\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5592\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5067\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4554\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4051\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3558\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3076\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2605\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2142\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1689\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1246\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0812\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0388\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9972\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9565\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9166\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8775\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8393\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8018\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7652\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7294\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6942\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6598\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6261\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5932\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:16,571] Trial 96 finished with value: 55.179252811348114 and parameters: {'lr': 0.003132280531967108, 'alpha': 0.023861343794290158, 'activation': 'gelu', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9706\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1561\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9325\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7667\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6790\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5910\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5139\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4429\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.3787\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3190\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2604\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2037\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1484\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0944\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0413\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9889\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9375\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8869\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8370\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7879\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7394\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6917\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6445\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5978\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5519\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5065\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4618\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4176\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3740\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3310\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2886\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2467\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2053\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1644\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1242\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0844\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0451\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0064\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9681\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9303\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8931\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8563\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8200\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7841\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7487\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7138\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6793\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6453\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6117\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5785\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5457\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5134\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4815\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4500\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4189\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3883\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3580\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3281\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2985\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2694\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2406\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2122\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1842\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1565\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1292\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1023\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0756\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0494\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0234\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9978\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9725\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9476\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9229\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8986\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8746\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8509\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8275\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8044\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7816\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7591\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7369\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7149\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6933\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6719\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6508\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6300\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6094\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5891\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5691\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5493\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5298\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5105\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4915\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4727\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4541\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4358\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4177\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3999\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3823\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3649\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:18,389] Trial 97 finished with value: 67.3344204733916 and parameters: {'lr': 0.003667060694435729, 'alpha': 0.01251252893772502, 'activation': 'gelu', 'n1': 128, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.3530\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0170\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.2973\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6584\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9925\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3343\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7154\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.1308\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.5841\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.0634\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.5696\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1012\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.6568\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2342\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8328\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4514\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0889\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7441\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4165\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1051\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8090\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5274\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2597\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0052\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7630\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5329\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3140\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1059\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9080\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7198\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5408\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3705\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2086\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0547\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9082\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7690\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6365\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5105\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3909\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2768\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1685\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0655\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9675\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8741\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7855\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7011\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6210\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5450\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4726\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4034\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3380\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2754\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2161\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1597\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1060\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0552\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0065\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9603\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9164\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8746\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8350\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7971\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7612\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7269\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6945\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6635\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6341\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6062\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5798\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5545\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5303\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5075\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4646\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4450\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4262\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4082\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3910\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3748\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3594\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3447\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3309\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3178\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3050\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2928\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2705\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2603\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2504\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2318\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2233\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2150\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2072\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1930\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1861\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1798\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1738\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1682\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:20,253] Trial 98 finished with value: 55.53417099862192 and parameters: {'lr': 0.005553259285402389, 'alpha': 0.031422762431068584, 'activation': 'gelu', 'n1': 192, 'n2': 128}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.7737\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.7919\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3475\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.8931\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 9.4857\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1215\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7553\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.4123\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 8.0940\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7823\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.4852\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.2009\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9271\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6646\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.4121\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.1692\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9357\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.7114\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4954\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2877\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0879\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8956\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7108\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.5328\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3617\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1971\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.0386\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8863\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7397\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5988\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4631\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.3326\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2069\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0863\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9700\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8582\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7505\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6473\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5480\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4520\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3601\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2711\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1858\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1037\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0246\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9486\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8757\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8057\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7385\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6733\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6107\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5509\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4931\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4370\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3829\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3320\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2823\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2343\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1877\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1439\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1013\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0606\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0212\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9842\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9473\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9130\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8818\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8492\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8184\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7879\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7601\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7354\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7055\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6826\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6594\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6333\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6129\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5919\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5715\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5550\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5426\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5352\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5103\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4902\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4728\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4642\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4858\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4497\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4199\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3984\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3802\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3645\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3506\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3333\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3223\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3097\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2980\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2772\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2670\n",
      "4/4 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:10:21,794] Trial 99 finished with value: 62.044510384425536 and parameters: {'lr': 0.006585817412694317, 'alpha': 0.020427505645992144, 'activation': 'tanh', 'n1': 192, 'n2': 192}. Best is trial 89 with value: 51.87719012805435.\n"
     ]
    }
   ],
   "source": [
    "def objective_mlp_fp(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-4, 2e-2, log=True)\n",
    "    alpha = trial.suggest_float('alpha', 1e-4, 5e-2, log=True)\n",
    "    act = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid', 'gelu'])\n",
    "    n1 = trial.suggest_int('n1', 128, 384, step=64)\n",
    "    n2 = trial.suggest_int('n2', 128, 384, step=64)\n",
    "\n",
    "    model = MLP(engine='tensorflow', nfeatures=X_train_fp_scaled.shape[1], nneurons=[n1, n2],\n",
    "                activations=[act, act], learning_rate=lr, alpha=alpha,\n",
    "                nepochs=100, batch_size=64, loss='mean_squared_error', is_regression=True)\n",
    "    \n",
    "    model.fit(X_train_fp_scaled, y_train_scaled)\n",
    "    preds_scaled = model.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "    preds = yscaler.inverse_transform(preds_scaled)\n",
    "    y_test_inv = yscaler.inverse_transform(y_test_scaled)\n",
    "    metrics = regression_metrics(y_test_inv, preds)\n",
    "    return metrics['MAE'][0]\n",
    "\n",
    "study_mlp_fp = optuna.create_study(direction='minimize')\n",
    "study_mlp_fp.optimize(objective_mlp_fp, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cac4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_mlp_cm(trial):\n",
    "#     lr = trial.suggest_float('lr', 1e-6, 1e-2, log=True)\n",
    "#     alpha = trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "#     act = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid', 'gelu'])\n",
    "#     n1 = trial.suggest_int('n1', 64, 256, step=64)\n",
    "#     n2 = trial.suggest_int('n2', 64, 256, step=64)\n",
    "\n",
    "#     model = MLP(engine='tensorflow', nfeatures=X_train_cm_scaled.shape[1], nneurons=[n1, n2],\n",
    "#                 activations=[act, act], learning_rate=lr, alpha=alpha,\n",
    "#                 nepochs=100, batch_size=64, loss='mean_squared_error', is_regression=True)\n",
    "\n",
    "#     model.fit(X_train_cm_scaled, y_train_scaled)\n",
    "#     preds_scaled = model.predict(X_test_cm_scaled).reshape(-1, 1)\n",
    "#     preds = yscaler.inverse_transform(preds_scaled)\n",
    "#     y_test_inv = yscaler.inverse_transform(y_test_scaled)\n",
    "#     metrics = regression_metrics(y_test_inv, preds)\n",
    "#     return metrics['MAE'][0]\n",
    "\n",
    "# study_mlp_cm = optuna.create_study(direction='minimize')\n",
    "# study_mlp_cm.optimize(objective_mlp_cm, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47ff58",
   "metadata": {},
   "source": [
    "## Retrain Models with Best Parameters Found in Respective Optuna Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2132a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned Kernel Ridge (RDKit FP):\n",
      "         MAE       RMSE  r_squared\n",
      "0  51.961371  69.519814   0.611854\n"
     ]
    }
   ],
   "source": [
    "best_krr = study_krr.best_params\n",
    "\n",
    "# build final model using best params\n",
    "if best_krr['kernel'] == 'rbf':\n",
    "    final_krr = KernelRidge(alpha=best_krr['alpha'], kernel='rbf', gamma=best_krr['gamma'])\n",
    "else:\n",
    "    final_krr = KernelRidge(alpha=best_krr['alpha'], kernel=best_krr['kernel'])\n",
    "\n",
    "# train on scaled data\n",
    "final_krr.fit(X_train_fp_scaled, y_train_scaled)\n",
    "# predict on test set (scaled)\n",
    "final_preds_krr_scaled = final_krr.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "# inverse transform both predictions and gt\n",
    "final_preds_krr = yscaler.inverse_transform(final_preds_krr_scaled)\n",
    "y_test_krr = yscaler.inverse_transform(y_test_scaled)\n",
    "# eval\n",
    "final_metrics_krr = regression_metrics(y_test_krr, final_preds_krr)\n",
    "print(\"Final Tuned Kernel Ridge (RDKit FP):\")\n",
    "print(final_metrics_krr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d89540fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tuned Random Forest (RDKit FP):\n",
      "         MAE       RMSE  r_squared\n",
      "0  52.849796  72.147222   0.581961\n"
     ]
    }
   ],
   "source": [
    "# rebuild and retrain the RFR model\n",
    "best_rfr = study_rfr.best_params\n",
    "final_rfr = RandomForestRegressor(n_estimators=best_rfr['n_estimators'], max_depth=best_rfr['max_depth'], random_state=42)\n",
    "final_rfr.fit(X_train_fp_unscaled, y_train_unscaled)\n",
    "\n",
    "# predict on test set\n",
    "final_preds_rfr = final_rfr.predict(X_test_fp_unscaled)\n",
    "\n",
    "# eval using unscaled targets\n",
    "final_metrics_rfr = regression_metrics(y_test_unscaled, final_preds_rfr)\n",
    "print(\"Final Tuned Random Forest (RDKit FP):\")\n",
    "print(final_metrics_rfr[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68ac4ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 6.1200\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 5.3776\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 5.1536\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.9777\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.8416\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.7229\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.6043\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4930\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3931\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2974\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2036\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1140\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0264\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9411\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8577\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7762\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6967\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6188\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5427\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4684\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3953\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3243\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2544\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1859\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1191\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0537\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9897\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9271\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8657\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8057\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7470\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6895\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6332\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5781\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5242\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4714\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4198\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3692\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3197\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2712\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2238\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1774\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1320\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0875\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0439\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0013\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9595\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9188\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8788\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8396\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8013\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7638\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7271\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6911\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6560\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6216\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5879\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5549\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5226\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4910\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4600\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4297\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4001\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3710\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3426\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3148\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2876\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2609\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2349\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2094\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1843\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1599\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1359\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1124\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0895\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0670\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0450\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0234\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0024\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9817\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9615\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9418\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9225\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9035\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8850\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8668\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8490\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8317\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8147\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7980\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7816\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7657\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7500\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7347\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7197\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7051\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6907\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6766\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6629\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6495\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Final Tuned MLP (RDKit FP):\n",
      "         MAE       RMSE  r_squared\n",
      "0  55.969241  71.134271   0.593617\n"
     ]
    }
   ],
   "source": [
    "best_fp = study_mlp_fp.best_params\n",
    "final_mlp_fp = MLP(\n",
    "    engine='tensorflow', \n",
    "    nfeatures=X_train_fp_scaled.shape[1], \n",
    "    nneurons=[best_fp['n1'], best_fp['n2']], \n",
    "    activations=[best_fp['activation'], best_fp['activation']], \n",
    "    learning_rate=best_fp['lr'], \n",
    "    alpha=best_fp['alpha'], \n",
    "    nepochs=100, \n",
    "    batch_size=64, \n",
    "    loss='mean_squared_error', \n",
    "    is_regression=True\n",
    "    )\n",
    "\n",
    "# train on scaled data\n",
    "final_mlp_fp.fit(X_train_fp_scaled, y_train_scaled)\n",
    "\n",
    "# predict and inverse transform\n",
    "final_preds_fp_scaled = final_mlp_fp.predict(X_test_fp_scaled).reshape(-1, 1)\n",
    "final_preds_inv_fp = yscaler.inverse_transform(final_preds_fp_scaled)\n",
    "y_test_inv_fp = yscaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "# eval in eV\n",
    "final_metrics_fp = regression_metrics(y_test_inv_fp, final_preds_inv_fp)\n",
    "print(\"Final Tuned MLP (RDKit FP):\")\n",
    "print(final_metrics_fp[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406d6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_cm = study_mlp_cm.best_params\n",
    "# final_mlp_cm = MLP(engine='tensorflow', nfeatures=X_train_cm_scaled.shape[1], nneurons=[best_cm['n1'], best_cm['n2']], activations=[best_cm['activation'], best_cm['activation']], learning_rate=best_cm['lr'], alpha=best_cm['alpha'], nepochs=100, batch_size=64, loss='mean_squared_error', is_regression=True)\n",
    "\n",
    "# # train on scaled data\n",
    "# final_mlp_cm.fit(X_train_cm_scaled, y_train_scaled)\n",
    "\n",
    "# # predict and inverse transform\n",
    "# final_preds_cm_scaled = final_mlp_cm.predict(X_test_cm_scaled).reshape(-1, 1)\n",
    "# final_preds_inv_cm = yscaler.inverse_transform(final_preds_cm_scaled)\n",
    "# y_test_inv_cm = yscaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "# # eval in eV\n",
    "# final_metrics_cm = regression_metrics(y_test_inv_cm, final_preds_inv_cm)\n",
    "# print(\"Final Tuned MLP (Coulomb Matrix):\")\n",
    "# print(final_metrics_cm[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3c54319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_regression_results(y_test_krr, final_preds_krr, title=\"Final Kernel Ridge (RDKit FP)\", save_dir=\"plots\")\n",
    "plot_regression_results(y_test_unscaled, final_preds_rfr, title=\"Final Random Forest (RDKit FP)\", save_dir=\"plots\")\n",
    "plot_regression_results(y_test_inv_fp, final_preds_inv_fp, title=\"Final MLP (RDKit FP)\", save_dir=\"plots\")\n",
    "# plot_regression_results(y_test_inv_cm, final_preds_inv_cm, title=\"Final MLP (Coulomb Matrix)\", save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4771aa",
   "metadata": {},
   "source": [
    "\n",
    "| Model Type             | Featurization        |   MAE |  RMSE |   R² | Notes             |\n",
    "|------------------------|----------------------|-------|-------|------|-------------------|\n",
    "| MLP (Tuned)          | RDKit Fingerprints   | 0.426 | 0.574 | 0.798 | Strong performance across all metrics   |\n",
    "| KRR (Tuned)          | RDKit Fingerprints   | 0.454 | 0.593 | 0.784 | Good overall, slightly lower R² than MLP|\n",
    "| RF (Tuned)           | RDKit Fingerprints   | 0.423| 0.583 | 0.791  | Top MAE, but slightly higher R²/RMSE    |\n",
    "| MLP (Tuned)          | Coulomb Matrix       | 0.636 | 0.819 | 0.588 | Significantly worse than FP models      |\n",
    "| MLP (Untuned Baseline) | RDKit Fingerprints | 0.467 | 0.609 | 0.772 | Reasonable baseline performance         |\n",
    "| KRR (Untuned Baseline) | RDKit Fingerprints | 0.519 | 0.668 | 0.726 | Noticeable drop from tuned KRR          |\n",
    "| RF (Untuned Baseline) | RDKit Fingerprints  | 0.426| 0.587 | 0.788  | Surprisingly strong untuned performance |\n",
    "| MLP (Untuned Baseline) | Coulomb Matrix     | 0.663 | 0.847 | 0.559 | Confirms Coulomb Matrix as weak         |\n",
    "\n",
    "Save best model and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbd2c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_Tg/best_mlp_fp_model_keras\\assets\n"
     ]
    }
   ],
   "source": [
    "# create a save directory\n",
    "os.makedirs(\"saved_models_Tg\", exist_ok=True)\n",
    "\n",
    "# save the final trained MLP model (Keras backend)\n",
    "final_mlp_fp.model.save(\"saved_models_Tg/best_mlp_fp_model_keras\")\n",
    "\n",
    "# save the X and Y scalers\n",
    "joblib.dump(xscaler_fp, \"saved_models_Tg/xscaler_fp.pkl\")\n",
    "joblib.dump(yscaler, \"saved_models_Tg/yscaler.pkl\")\n",
    "\n",
    "# save evaluation metrics\n",
    "final_metrics_fp.to_csv(\"saved_models_Tg/best_mlp_fp_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c226234",
   "metadata": {},
   "source": [
    "If you wanted to reload these later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "136af5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # load model and scalersand metrics\n",
    "# mlp_model = load_model(\"saved_models/best_mlp_fp_model_keras\")\n",
    "# xscaler_fp = joblib.load(\"saved_models/xscaler_fp.pkl\")\n",
    "# yscaler = joblib.load(\"saved_models/yscaler.pkl\")\n",
    "# metrics_df = pd.read_csv(\"saved_models/best_mlp_fp_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39535b4",
   "metadata": {},
   "source": [
    "# Training a Baseline GNN with ChemML\n",
    "ChemML's `tensorise_molecules` generates its own graph. Its important to note this graph is not the official graph from PCQM4Mv2. It may miss out on features OGB uses like formal charge, aromatacity flags, atomic chirality, and explicit hydrogens. However, tensorise_molecules is a good choice for quick prototyping and it handles graph generation and tensor formatting in a numpy-friendly way which was easier for me to understand. Final training will use smiles2graph for compatability with OGB splits and better feature representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccf8404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorising molecules in batches of 3000 ...\n",
      "504/504 [==================================================] - 10s 21ms/step\n",
      "Merging batch tensors ...    [DONE]\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 211.7961 - val_loss: 4.2279\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 46.4533 - val_loss: 14.0274\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28.2108 - val_loss: 3.2301\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.4109 - val_loss: 1.5478\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.2681 - val_loss: 1.6073\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2334 - val_loss: 0.9518\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8695 - val_loss: 1.7679\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8212 - val_loss: 0.9395\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2838 - val_loss: 1.1337\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9148 - val_loss: 0.7203\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6777 - val_loss: 0.8583\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6795 - val_loss: 0.7020\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6499 - val_loss: 0.7226\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6196 - val_loss: 0.7228\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5953 - val_loss: 0.6909\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5893 - val_loss: 0.7078\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5822 - val_loss: 0.6924\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5646 - val_loss: 0.6915\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5587 - val_loss: 0.6715\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5430 - val_loss: 0.6900\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5471 - val_loss: 0.7025\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5288 - val_loss: 0.6764\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5226 - val_loss: 0.7052\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5216 - val_loss: 0.6499\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5155 - val_loss: 0.6368\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5142 - val_loss: 0.6304\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5326 - val_loss: 1.0120\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6685 - val_loss: 0.6601\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5541 - val_loss: 0.6479\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4863 - val_loss: 0.6632\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4917 - val_loss: 0.6229\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4726 - val_loss: 0.7242\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5008 - val_loss: 0.6272\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5132 - val_loss: 0.6747\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4792 - val_loss: 0.6368\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4688 - val_loss: 0.6301\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4696 - val_loss: 0.6288\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4554 - val_loss: 0.6082\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4514 - val_loss: 0.6020\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4562 - val_loss: 0.7418\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5110 - val_loss: 0.5845\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4618 - val_loss: 0.6125\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4417 - val_loss: 0.5801\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4365 - val_loss: 0.6427\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4417 - val_loss: 0.6012\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4398 - val_loss: 0.5700\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4700 - val_loss: 0.5857\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4523 - val_loss: 0.7112\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5394 - val_loss: 0.6151\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5749 - val_loss: 0.6894\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8199 - val_loss: 0.5804\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5987 - val_loss: 0.7847\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6360 - val_loss: 0.5950\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5132 - val_loss: 0.7455\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5105 - val_loss: 0.6626\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4553 - val_loss: 0.6309\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4611 - val_loss: 0.6041\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4396 - val_loss: 0.5399\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4441 - val_loss: 0.5729\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4739 - val_loss: 0.5355\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4396 - val_loss: 0.5156\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4136 - val_loss: 0.5944\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4283 - val_loss: 0.6399\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4233 - val_loss: 0.5263\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4101 - val_loss: 0.5203\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4088 - val_loss: 0.5100\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4426 - val_loss: 0.5161\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4946 - val_loss: 0.5158\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5028 - val_loss: 0.5596\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3919 - val_loss: 0.4978\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4081 - val_loss: 0.5164\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3929 - val_loss: 0.6080\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4218 - val_loss: 0.5481\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3995 - val_loss: 0.5227\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4007 - val_loss: 0.7335\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4996 - val_loss: 0.5636\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4202 - val_loss: 0.4919\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4053 - val_loss: 0.5299\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3869 - val_loss: 0.4896\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3812 - val_loss: 0.4675\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3813 - val_loss: 0.5008\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3748 - val_loss: 0.5493\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3724 - val_loss: 0.4691\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4298 - val_loss: 0.4635\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4619 - val_loss: 0.4724\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3935 - val_loss: 0.4819\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3688 - val_loss: 0.5240\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3841 - val_loss: 0.4516\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3668 - val_loss: 0.4893\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3832 - val_loss: 0.4782\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3919 - val_loss: 0.4692\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5588 - val_loss: 0.4972\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6389 - val_loss: 0.6583\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5432 - val_loss: 0.5554\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4932 - val_loss: 0.4556\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4090 - val_loss: 0.5302\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4351 - val_loss: 0.5617\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4033 - val_loss: 0.4695\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3590 - val_loss: 0.4851\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3740 - val_loss: 0.4935\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "\n",
      "GNN Model Results:\n",
      "         MAE       RMSE  r_squared\n",
      "0  64.024827  82.887383    0.50126\n"
     ]
    }
   ],
   "source": [
    "# tensorize molecules\n",
    "X_atoms, X_bonds, X_edges = tensorise_molecules(valid_mol_objs)\n",
    "y = df_clean['Tg'].values.reshape(-1, 1)\n",
    "\n",
    "# train test split (80/20)\n",
    "split = int(0.8 * len(y))\n",
    "X_atoms_train, X_atoms_test = X_atoms[:split], X_atoms[split:]\n",
    "X_bonds_train, X_bonds_test = X_bonds[:split], X_bonds[split:]\n",
    "X_edges_train, X_edges_test = X_edges[:split], X_edges[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# scale target\n",
    "yscaler = StandardScaler()\n",
    "y_train_scaled = yscaler.fit_transform(y_train)\n",
    "\n",
    "# model input shapes\n",
    "max_atoms = X_atoms.shape[1]\n",
    "max_degree = X_bonds.shape[2]\n",
    "num_atom_features = X_atoms.shape[-1]\n",
    "num_bond_features = X_bonds.shape[-1]\n",
    "\n",
    "# input layers\n",
    "atoms_input = Input(shape=(max_atoms, num_atom_features), name=\"atom_inputs\")\n",
    "bonds_input = Input(shape=(max_atoms, max_degree, num_bond_features), name=\"bond_inputs\")\n",
    "edges_input = Input(shape=(max_atoms, max_degree), name=\"edge_inputs\", dtype=\"int32\")\n",
    "\n",
    "# GNN layers\n",
    "conv1 = NeuralGraphHidden(8, activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "conv2 = NeuralGraphHidden(8, activation='relu')([conv1, bonds_input, edges_input])\n",
    "\n",
    "fp1 = NeuralGraphOutput(128, activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "fp2 = NeuralGraphOutput(128, activation='relu')([conv1, bonds_input, edges_input])\n",
    "fp3 = NeuralGraphOutput(128, activation='relu')([conv2, bonds_input, edges_input])\n",
    "\n",
    "# fingerprint aggregation\n",
    "fingerprint = Add()([fp1, fp2, fp3])\n",
    "\n",
    "# dense layers\n",
    "dense1 = Dense(128, activation='relu')(fingerprint)\n",
    "dense2 = Dense(64, activation='relu')(dense1)\n",
    "output = Dense(1, activation='linear')(dense2)\n",
    "\n",
    "# model compilation\n",
    "model = Model(inputs=[atoms_input, bonds_input, edges_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# model training\n",
    "model.fit([X_atoms_train, X_bonds_train, X_edges_train], y_train_scaled, epochs=100, batch_size=64, verbose=1, validation_split=0.1)\n",
    "\n",
    "# preds and eval\n",
    "y_pred = model.predict([X_atoms_test, X_bonds_test, X_edges_test])\n",
    "y_pred = yscaler.inverse_transform(y_pred)\n",
    "metrics = regression_metrics(y_test, y_pred)\n",
    "print(\"\\nGNN Model Results:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a97ae357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plot_regression_results(y_test, y_pred, title=\"GNN Model Untuned(ChemML)\", save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2fb6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 20:17:31,688] A new study created in memory with name: no-name-db90c8e1-5bb4-4a60-b540-debf549064f0\n",
      "[I 2025-09-04 20:17:38,194] Trial 0 finished with value: 0.5784119963645935 and parameters: {'conv_width': 16, 'fp_length': 160, 'n1': 160, 'n2': 64, 'lr': 0.0074779903531160775, 'alpha': 1.1713607039847262e-05}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:17:44,489] Trial 1 finished with value: 0.6189797520637512 and parameters: {'conv_width': 8, 'fp_length': 160, 'n1': 192, 'n2': 96, 'lr': 2.0096572916443418e-05, 'alpha': 6.93435054090891e-07}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:17:50,936] Trial 2 finished with value: 1.3424192667007446 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 1.0740694360574098e-05, 'alpha': 4.07655092722975e-07}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:17:57,470] Trial 3 finished with value: 0.6044057607650757 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 64, 'lr': 6.596998891781441e-05, 'alpha': 1.941359685789118e-05}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:18:03,767] Trial 4 finished with value: 0.6049039959907532 and parameters: {'conv_width': 16, 'fp_length': 128, 'n1': 192, 'n2': 96, 'lr': 0.00027988431131782123, 'alpha': 1.159506120928712e-05}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:18:10,498] Trial 5 finished with value: 0.5962063074111938 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0018054056294628683, 'alpha': 1.7557314840648281e-06}. Best is trial 0 with value: 0.5784119963645935.\n",
      "[I 2025-09-04 20:18:16,875] Trial 6 finished with value: 0.5641050934791565 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 64, 'lr': 0.0060757578056530245, 'alpha': 1.721509024173768e-07}. Best is trial 6 with value: 0.5641050934791565.\n",
      "[I 2025-09-04 20:18:23,410] Trial 7 finished with value: 0.5705327987670898 and parameters: {'conv_width': 16, 'fp_length': 160, 'n1': 128, 'n2': 64, 'lr': 0.006647279938663217, 'alpha': 1.7247199953302038e-08}. Best is trial 6 with value: 0.5641050934791565.\n",
      "[I 2025-09-04 20:18:29,854] Trial 8 finished with value: 0.5577208399772644 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0029586076211748423, 'alpha': 6.276447369983516e-07}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:35,969] Trial 9 finished with value: 0.5714065432548523 and parameters: {'conv_width': 16, 'fp_length': 160, 'n1': 160, 'n2': 64, 'lr': 0.0009738613712093438, 'alpha': 4.715300931273199e-08}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:42,603] Trial 10 finished with value: 0.6675637364387512 and parameters: {'conv_width': 32, 'fp_length': 128, 'n1': 128, 'n2': 96, 'lr': 0.0003263552163811872, 'alpha': 7.709695168770715e-05}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:49,582] Trial 11 finished with value: 0.5724877119064331 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.002252920145793403, 'alpha': 9.883023293820313e-08}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:18:56,067] Trial 12 finished with value: 0.5720522999763489 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.009925460457487913, 'alpha': 1.5944183054400058e-07}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:19:02,579] Trial 13 finished with value: 0.559759795665741 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.001986914000079734, 'alpha': 2.2965734881221143e-06}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:19:09,042] Trial 14 finished with value: 0.6146386861801147 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.0006072112617258865, 'alpha': 2.937041447079816e-06}. Best is trial 8 with value: 0.5577208399772644.\n",
      "[I 2025-09-04 20:19:15,651] Trial 15 finished with value: 0.537324070930481 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0020164019475540753, 'alpha': 3.465355151599912e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:22,090] Trial 16 finished with value: 0.7567039132118225 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.00014040897926649256, 'alpha': 5.823941393086069e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:28,545] Trial 17 finished with value: 0.561646044254303 and parameters: {'conv_width': 32, 'fp_length': 128, 'n1': 128, 'n2': 96, 'lr': 0.0027867540318616607, 'alpha': 6.140867853012933e-07}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:34,939] Trial 18 finished with value: 0.564617931842804 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0006355932927206463, 'alpha': 4.090645773300607e-05}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:41,591] Trial 19 finished with value: 0.5807154178619385 and parameters: {'conv_width': 32, 'fp_length': 128, 'n1': 128, 'n2': 96, 'lr': 0.003244941112614663, 'alpha': 5.55485584606677e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:48,045] Trial 20 finished with value: 0.5718845129013062 and parameters: {'conv_width': 32, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.0011164544070239126, 'alpha': 1.3647780168139255e-06}. Best is trial 15 with value: 0.537324070930481.\n",
      "[I 2025-09-04 20:19:54,486] Trial 21 finished with value: 0.5342585444450378 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.004041990960813106, 'alpha': 3.2842280041595312e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:01,059] Trial 22 finished with value: 0.5475216507911682 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0039136896910184705, 'alpha': 3.0960292215100224e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:07,548] Trial 23 finished with value: 0.5465244054794312 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.005029828858431721, 'alpha': 2.645806301792376e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:13,999] Trial 24 finished with value: 0.5760974884033203 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.00141425990182562, 'alpha': 4.560527980867315e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:20,765] Trial 25 finished with value: 0.5863977074623108 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.004342575290405733, 'alpha': 4.603889221331369e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:27,583] Trial 26 finished with value: 0.5919985771179199 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.0006690605825164465, 'alpha': 1.1532872007705319e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:34,118] Trial 27 finished with value: 0.5598962306976318 and parameters: {'conv_width': 8, 'fp_length': 128, 'n1': 160, 'n2': 96, 'lr': 0.0054903208790964934, 'alpha': 2.078603916227733e-05}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:40,499] Trial 28 finished with value: 0.5905507206916809 and parameters: {'conv_width': 32, 'fp_length': 160, 'n1': 192, 'n2': 64, 'lr': 0.0002597243753261715, 'alpha': 1.132694885097053e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:47,123] Trial 29 finished with value: 0.581702470779419 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.008655632825834132, 'alpha': 9.596447288930111e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:20:53,913] Trial 30 finished with value: 0.5551465153694153 and parameters: {'conv_width': 32, 'fp_length': 160, 'n1': 160, 'n2': 64, 'lr': 0.00496881669997927, 'alpha': 3.268332862528285e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:00,639] Trial 31 finished with value: 0.554656445980072 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.003906554291532843, 'alpha': 3.1506959143936316e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:07,344] Trial 32 finished with value: 0.5641250610351562 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0014519175592323209, 'alpha': 2.883619043205416e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:14,442] Trial 33 finished with value: 0.6160750389099121 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0035726584929979483, 'alpha': 8.341838407088706e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:20,927] Trial 34 finished with value: 0.6618874073028564 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 4.256581098756559e-05, 'alpha': 6.865754482198901e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:27,466] Trial 35 finished with value: 0.5780915021896362 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.007105025368208672, 'alpha': 5.042153213061166e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:34,161] Trial 36 finished with value: 0.538110077381134 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0021748847115820665, 'alpha': 2.0007329921186313e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:40,626] Trial 37 finished with value: 0.603560745716095 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.0008420589418001226, 'alpha': 1.5820737554131193e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:47,274] Trial 38 finished with value: 0.5781627893447876 and parameters: {'conv_width': 8, 'fp_length': 160, 'n1': 160, 'n2': 96, 'lr': 0.002210393525207414, 'alpha': 8.59709298242375e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:21:53,988] Trial 39 finished with value: 0.5526089072227478 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.001505996205233068, 'alpha': 1.9979152635099817e-05}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:00,622] Trial 40 finished with value: 0.5688043236732483 and parameters: {'conv_width': 8, 'fp_length': 128, 'n1': 160, 'n2': 64, 'lr': 0.002518946674988459, 'alpha': 1.5628752663946832e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:07,047] Trial 41 finished with value: 0.6949878931045532 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 1.0326341508593729e-05, 'alpha': 2.666760116293639e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:13,670] Trial 42 finished with value: 0.5842966437339783 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.005108891492545455, 'alpha': 1.2545596698485203e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:20,108] Trial 43 finished with value: 0.5730230212211609 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.007320894795257771, 'alpha': 3.9001066492494993e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:26,617] Trial 44 finished with value: 0.6084129214286804 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.003448015490816507, 'alpha': 8.797166508380697e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:33,181] Trial 45 finished with value: 0.5656376481056213 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 160, 'n2': 96, 'lr': 0.0004410837401054787, 'alpha': 2.1642658132693283e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:39,985] Trial 46 finished with value: 0.5588310360908508 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 128, 'n2': 96, 'lr': 0.001896598865677006, 'alpha': 8.686045414635347e-07}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:46,468] Trial 47 finished with value: 0.5685777068138123 and parameters: {'conv_width': 32, 'fp_length': 160, 'n1': 128, 'n2': 96, 'lr': 0.0011520140448633685, 'alpha': 2.9433059437832768e-08}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:52,864] Trial 48 finished with value: 0.5571005344390869 and parameters: {'conv_width': 16, 'fp_length': 96, 'n1': 160, 'n2': 64, 'lr': 0.00970425029035456, 'alpha': 1.8215717787647826e-06}. Best is trial 21 with value: 0.5342585444450378.\n",
      "[I 2025-09-04 20:22:59,293] Trial 49 finished with value: 0.5857318639755249 and parameters: {'conv_width': 8, 'fp_length': 96, 'n1': 192, 'n2': 96, 'lr': 0.00553543963449258, 'alpha': 4.931892543453002e-07}. Best is trial 21 with value: 0.5342585444450378.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "def objective_gnn(trial):\n",
    "    conv_width = trial.suggest_categorical('conv_width', [8, 16, 32])\n",
    "    fp_length = trial.suggest_categorical('fp_length', [96, 128, 160])\n",
    "    n1 = trial.suggest_int('n1', 128, 192, step=32)\n",
    "    n2 = trial.suggest_int('n2', 64, 96, step=32)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    alpha = trial.suggest_float('alpha', 1e-8, 1e-4, log=True)\n",
    "    activation = 'relu'\n",
    "\n",
    "    # model definition\n",
    "    atoms_input = Input(shape=(max_atoms, num_atom_features), name=\"atom_inputs\")\n",
    "    bonds_input = Input(shape=(max_atoms, max_degree, num_bond_features), name=\"bond_inputs\")\n",
    "    edges_input = Input(shape=(max_atoms, max_degree), name=\"edge_inputs\", dtype=\"int32\")\n",
    "\n",
    "    conv1 = NeuralGraphHidden(conv_width, activation=activation)([atoms_input, bonds_input, edges_input])\n",
    "    conv2 = NeuralGraphHidden(conv_width, activation=activation)([conv1, bonds_input, edges_input])\n",
    "\n",
    "    fp1 = NeuralGraphOutput(fp_length, activation=activation)([atoms_input, bonds_input, edges_input])\n",
    "    fp2 = NeuralGraphOutput(fp_length, activation=activation)([conv1, bonds_input, edges_input])\n",
    "    fp3 = NeuralGraphOutput(fp_length, activation=activation)([conv2, bonds_input, edges_input])\n",
    "    fingerprint = Add()([fp1, fp2, fp3])\n",
    "\n",
    "    dense1 = Dense(n1, activation=activation, kernel_regularizer=regularizers.l2(alpha))(fingerprint)\n",
    "    dense2 = Dense(n2, activation=activation, kernel_regularizer=regularizers.l2(alpha))(dense1)\n",
    "    output = Dense(1, activation='linear')(dense2)\n",
    "\n",
    "    model = Model(inputs=[atoms_input, bonds_input, edges_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mean_squared_error', metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit([X_atoms_train, X_bonds_train, X_edges_train], y_train_scaled, epochs=100, batch_size=64, verbose=0, validation_split=0.2)\n",
    "\n",
    "    # return best validation MAE\n",
    "    val_mae = min(history.history[\"val_mean_absolute_error\"])  \n",
    "    return val_mae\n",
    "\n",
    "study_gnn = optuna.create_study(direction='minimize')  \n",
    "study_gnn.optimize(objective_gnn, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf7a39",
   "metadata": {},
   "source": [
    "## Retraining ChemML GNN with Best Parameter Found in Optuna Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b42b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 29ms/step - loss: 1828.2208\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 83.8997\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 36.6573\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 12.0149\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 2.5238\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.7810\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9541\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6475\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6104\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5773\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6357\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5952\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5855\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6282\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5679\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5756\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7490\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6103\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8978\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5940\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.5970\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1729\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6433\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6396\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6033\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5880\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5465\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5005\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4977\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4888\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5279\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5266\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5108\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4905\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6250\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6263\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6872\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5321\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5040\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4851\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4948\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4488\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4801\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4589\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5944\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5019\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5447\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6054\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4802\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5260\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4407\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4370\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4353\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5234\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5044\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5047\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6158\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5042\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4602\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4912\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4307\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4939\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4422\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4177\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4197\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4769\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4585\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4371\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4901\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4971\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4136\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4761\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4384\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4103\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4164\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4595\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4228\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4113\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3974\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4181\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4769\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4770\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4617\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3903\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4006\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4033\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4014\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4113\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4275\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3906\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3882\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4155\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3907\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3932\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3954\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3798\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3986\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4250\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4703\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6096\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4939\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4746\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4528\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5432\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4354\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3802\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3677\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4294\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4542\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4317\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5032\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3869\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3672\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4195\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5143\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5925\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5765\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5279\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5752\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6548\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4994\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4859\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5152\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3848\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4057\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4008\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4022\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3477\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4596\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3874\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4219\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6346\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4464\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4780\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5022\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6741\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6913\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6828\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5262\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3459\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4105\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4824\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4417\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3424\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3827\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3952\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4203\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3621\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3811\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3764\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3494\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3422\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3342\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3948\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5323\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5102\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4940\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4958\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3296\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3462\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3762\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3377\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4346\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4526\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4875\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3503\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3610\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3752\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3289\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3597\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3698\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3610\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4692\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3836\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3808\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4367\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5109\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5578\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4529\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4756\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6174\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6124\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4004\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3989\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3363\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3772\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3728\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5978\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4394\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4070\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3210\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4358\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4208\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4671\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3532\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3693\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3585\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "\n",
      "Final Tuned GNN Results:\n",
      "         MAE       RMSE  r_squared\n",
      "0  54.193508  72.170596    0.62189\n"
     ]
    }
   ],
   "source": [
    "params = study_gnn.best_params\n",
    "\n",
    "# redefine and compile using best params\n",
    "atoms_input = Input(shape=(max_atoms, num_atom_features), name=\"atom_inputs\")\n",
    "bonds_input = Input(shape=(max_atoms, max_degree, num_bond_features), name=\"bond_inputs\")\n",
    "edges_input = Input(shape=(max_atoms, max_degree), name=\"edge_inputs\", dtype=\"int32\")\n",
    "\n",
    "conv1 = NeuralGraphHidden(params['conv_width'], activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "conv2 = NeuralGraphHidden(params['conv_width'], activation='relu')([conv1, bonds_input, edges_input])\n",
    "\n",
    "fp1 = NeuralGraphOutput(params['fp_length'], activation='relu')([atoms_input, bonds_input, edges_input])\n",
    "fp2 = NeuralGraphOutput(params['fp_length'],activation='relu')([conv1, bonds_input, edges_input])\n",
    "fp3 = NeuralGraphOutput(params['fp_length'], activation='relu')([conv2, bonds_input, edges_input])\n",
    "fingerprint = Add()([fp1, fp2, fp3])\n",
    "\n",
    "dense1 = Dense(params['n1'], activation='relu', kernel_regularizer=regularizers.l2(params['alpha']))(fingerprint)\n",
    "dense2 = Dense(params['n2'], activation='relu', kernel_regularizer=regularizers.l2(params['alpha']))(dense1)\n",
    "output = Dense(1, activation='linear')(dense2)\n",
    "\n",
    "final_gnn = Model(inputs=[atoms_input, bonds_input, edges_input], outputs=output)\n",
    "final_gnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']), loss='mean_squared_error')\n",
    "\n",
    "final_gnn.fit([X_atoms_train, X_bonds_train, X_edges_train], y_train_scaled, epochs=200, batch_size=64, verbose=1)\n",
    "\n",
    "# final eval\n",
    "y_pred_final = final_gnn.predict([X_atoms_test, X_bonds_test, X_edges_test])\n",
    "y_pred_final = yscaler.inverse_transform(y_pred_final)\n",
    "final_metrics = regression_metrics(y_test, y_pred_final)\n",
    "print(\"\\nFinal Tuned GNN Results:\")\n",
    "print(final_metrics[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3bf3a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_regression_results(y_test, y_pred_final, title=\"Tuned ChemML GNN\", save_dir=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64159a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_Tg/gnn_tensorise_molecules_model\\gnn_tensorise_molecules_model_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# make a directory for this specific model\n",
    "save_dir = \"saved_models_Tg/gnn_tensorise_molecules_model\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. save the trained GNN model\n",
    "final_gnn.save(os.path.join(save_dir, \"gnn_tensorise_molecules_model_tf\"), save_format=\"tf\")\n",
    "\n",
    "# 2. save the y target scaler\n",
    "with open(os.path.join(save_dir, \"gnn_tensorise_molecules_target_scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(yscaler, f)\n",
    "\n",
    "# 3. save the final metrics\n",
    "final_metrics.to_csv(os.path.join(save_dir, \"gnn_tensorise_molecules_metrics.csv\"), index=False)\n",
    "\n",
    "# 4. save predictions\n",
    "pred_df = pd.DataFrame({\"true_gap\": y_test.flatten(), \"predicted_gap\": y_pred_final.flatten()})\n",
    "pred_df.to_csv(os.path.join(save_dir, \"gnn_tensorise_molecules_predictions.csv\"), index=False)\n",
    "\n",
    "# 5. save the best hyperparameters\n",
    "with open(os.path.join(save_dir, \"gnn_tensorise_molecules_best_params.json\"), \"w\") as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77f7ec",
   "metadata": {},
   "source": [
    "## ChemML GNN Model Results\n",
    "| Model Type             | Featurization        |   MAE |  RMSE |   R² | Notes             |\n",
    "|------------------------|----------------------|-------|-------|------|-------------------|\n",
    "| GNN (Tuned)            | tensorise_molecules Graph   | 0.302 | 0.411 | 0.900 | Best performance across all metrics   |\n",
    "| GNN (Untuned)          | tensorise_molecules Graph   | 0.400 | 0.519 | 0.841 | Good overall|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42db218",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Model Training\n",
    "\n",
    "Having explored different molecular graph representations and model architectures, I am now moving to training what is expected to be the best-performing model using the full dataset. The earlier GNN model was based on `tensorise_molecules` (ChemML) graphs and had strong performance with a **mean absolute error (MAE) around 0.30**. These graphs are based on RDKit's internal descriptors and do not reflect the original PCQM4Mv2 graph structure used in the Open Graph Benchmark (OGB). Therefore, I will shift focus to the `smiles2graph` representation provided by OGB, which aligns more directly with the benchmark's evaluation setup and top-performing models on the leaderboard.\n",
    "\n",
    "\n",
    "| Source                         | Atom/Bond Features                                                 | Format                                          | Customizable?     | Alignment with PCQM4Mv2?  |\n",
    "| ------------------------------ | ------------------------------------------------------------------ | ----------------------------------------------- | ----------------- | ---------------------- |\n",
    "| `tensorise_molecules` (ChemML) | RDKit-based descriptors (ex: atom number, degree, hybridization) | NumPy tensors (`X_atoms`, `X_bonds`, `X_edges`) | Limited           |  Not aligned          |\n",
    "| `smiles2graph` (OGB / PyG)     | Predefined categorical features from PCQM4Mv2                      | PyTorch Geometric `Data` objects                |  Highly flexible |  Matches OGB standard |\n",
    "\n",
    "By using `smiles2graph`, we:\n",
    "\n",
    "* Use OGB-standard graph construction and feature encoding for fair comparisons with leaderboard models\n",
    "* Include learnable AtomEncoder and BondEncoder embeddings from `ogb.graphproppred.mol_encoder`, which improve model expressiveness\n",
    "* Maintain compatibility with PyTorch Geometric, DGL, and OGB tools\n",
    "\n",
    "I will also concatenate GNN-derived embeddings with SMILES-based RDKit descriptors, feeding this hybrid representation into MLP head. This allows you to combine structural and cheminformatics perspectives for improved prediction accuracy. With this setup, I aim to improve upon the MAE of \\~0.30 achieved earlier and push closer toward state-of-the-art performance.\n",
    "\n",
    "\n",
    "## Step 1: Load PyG-Compatible Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf8037c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu118\n",
      "CUDA available?  True\n",
      "Device count: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3070 Ti\n",
      "Current device: 0\n"
     ]
    }
   ],
   "source": [
    "def check_cuda():\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA available? \", torch.cuda.is_available())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Device count:\", torch.cuda.device_count())\n",
    "        print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "        print(\"Current device:\", torch.cuda.current_device())\n",
    "    else:\n",
    "        print(\"Running on CPU\")\n",
    "\n",
    "check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52c907b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load OGB dataset \n",
    "df_tg = pd.read_csv('cleaned_tg_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a988df2",
   "metadata": {},
   "source": [
    "#  Step 2: Extract SMILES from Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a684ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 504 molecules.\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract SMILES and Tg targets\n",
    "# `df_tg` already contains the SMILES and Tg columns.\n",
    "smiles_list = df_tg['SMILES'].tolist()\n",
    "Tg_list = df_tg['Tg'].tolist()\n",
    "\n",
    "num_mols = len(smiles_list)\n",
    "print(f\"Loaded {num_mols} molecules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa26be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of RDKit features: (504, 9)\n"
     ]
    }
   ],
   "source": [
    "def compute_rdkit_features(smiles):\n",
    "    cleaned_smiles = canonicalize_polymer_smiles(smiles)\n",
    "    mol = Chem.MolFromSmiles(cleaned_smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * 9  # Update the number of NaNs to match new features\n",
    "\n",
    "    # Check for empty molecule\n",
    "    if mol.GetNumAtoms() == 0:\n",
    "        return [np.nan] * 9\n",
    "\n",
    "    # Add features that capture size, shape, and interactions\n",
    "    return [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.RingCount(mol),\n",
    "        Descriptors.FractionCSP3(mol),  # New: Fraction of sp3 hybridized carbons\n",
    "        Descriptors.MolLogP(mol),      # New: Octanol-water partition coefficient\n",
    "        Descriptors.NumSaturatedRings(mol) # New: Number of saturated rings\n",
    "    ]\n",
    "\n",
    "rdkit_features = np.array([compute_rdkit_features(smi) for smi in smiles_list])\n",
    "print(f\"Shape of RDKit features: {rdkit_features.shape}\") # Should be (N, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f6d257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 504 molecules with valid RDKit features.\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN values (failed RDKit featurization)\n",
    "valid_indices = ~np.isnan(rdkit_features).any(axis=1)\n",
    "rdkit_features = rdkit_features[valid_indices]\n",
    "smiles_list = np.array(smiles_list)[valid_indices].tolist()\n",
    "Tg_list = np.array(Tg_list)[valid_indices].tolist()\n",
    "\n",
    "print(f\"Kept {len(smiles_list)} molecules with valid RDKit features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c75372",
   "metadata": {},
   "source": [
    "# Step 4: attach RDKit features to PyG data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "755a330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1032, 9], edge_index=[2, 2182], edge_attr=[2182, 3], y=[32], rdkit_feats=[288], batch=[1032], ptr=[33])\n",
      "Batch's node features shape: torch.Size([1032, 9])\n",
      "Batch's RDKit features shape: torch.Size([288])\n",
      "Batch's targets shape: torch.Size([32])\n",
      "Batch's 'batch' attribute shape: torch.Size([1032])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Assuming your previous cells have loaded and processed the data into these lists:\n",
    "# smiles_list: list of SMILES strings\n",
    "# rdkit_features: numpy array of RDKit features (N, 6)\n",
    "# Tg_list: list of Tg values (N,)\n",
    "\n",
    "# 1. Create a list of PyG Data objects\n",
    "rdkit_features_tensor = torch.tensor(rdkit_features, dtype=torch.float32)\n",
    "ffv_targets_tensor = torch.tensor(Tg_list, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "data_list = []\n",
    "for i in range(len(smiles_list)):\n",
    "    # smiles2graph returns a dictionary\n",
    "    graph_dict = smiles2graph(smiles_list[i])\n",
    "    \n",
    "    # Create the Data object from the dictionary keys, converting to tensors\n",
    "    # Convert node and edge features to LongTensor \n",
    "    data = Data(\n",
    "        x=torch.tensor(graph_dict['node_feat'], dtype=torch.long),\n",
    "        edge_index=torch.tensor(graph_dict['edge_index'], dtype=torch.long),\n",
    "        edge_attr=torch.tensor(graph_dict['edge_feat'], dtype=torch.long),\n",
    "        rdkit_feats=rdkit_features_tensor[i],\n",
    "        y=ffv_targets_tensor[i]\n",
    "    )\n",
    "    data_list.append(data)\n",
    "\n",
    "# 2. Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create PyG DataLoaders\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Verification\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    print(\"Batch's node features shape:\", batch.x.shape)\n",
    "    print(\"Batch's RDKit features shape:\", batch.rdkit_feats.shape)\n",
    "    print(\"Batch's targets shape:\", batch.y.shape)\n",
    "    print(\"Batch's 'batch' attribute shape:\", batch.batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2984411",
   "metadata": {},
   "source": [
    "## Step 5: Define the Hybrid GNN Model\n",
    "\n",
    "The final architecture uses both structural and cheminformatics data by combining GNN-learned graph embeddings with SMILES-derived RDKit descriptors. This Hybrid GNN model uses `smiles2graph` for graph construction and augments it with RDKit-based molecular features for improved prediction accuracy.\n",
    "\n",
    "### Model Components:\n",
    "\n",
    "* **AtomEncoder / BondEncoder**\n",
    "  Transforms categorical atom and bond features (provided by OGB) into learnable embeddings using the encoders from `ogb.graphproppred.mol_encoder`. These provide a strong foundation for expressive graph learning.\n",
    "\n",
    "* **GINEConv Layers (x2)**\n",
    "  I use two stacked GINEConv layers (Graph Isomorphism Network with Edge features). These layers perform neighborhood aggregation based on edge attributes, allowing the model to capture localized chemical environments.\n",
    "\n",
    "* **Global Mean Pooling**\n",
    "  After message passing, node level embeddings are aggregated into a fixed size graph level representation using `global_mean_pool`.\n",
    "\n",
    "* **Concatenation with RDKit Descriptors**\n",
    "  The pooled GNN embedding is concatenated with external RDKit descriptors, which capture global molecular properties not easily inferred from graph data alone.\n",
    "\n",
    "* **MLP Prediction Head**\n",
    "  A multilayer perceptron processes the combined feature vector with ReLU activations, dropout regularization, and linear layers to predict the HOMO–LUMO gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ccbf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGNN(Module):\n",
    "    def __init__(self, gnn_dim, rdkit_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.gnn_dim = gnn_dim\n",
    "        self.rdkit_dim = rdkit_dim\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim=gnn_dim)\n",
    "        self.bond_encoder = BondEncoder(emb_dim=gnn_dim)\n",
    "\n",
    "        self.conv1 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), ReLU(), Linear(gnn_dim, gnn_dim)))\n",
    "        self.conv2 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), ReLU(), Linear(gnn_dim, gnn_dim)))\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        self.mlp = Sequential(Linear(gnn_dim + rdkit_dim, hidden_dim), ReLU(), \n",
    "                              Dropout(dropout_rate),\n",
    "                              Linear(hidden_dim, hidden_dim // 2), ReLU(), \n",
    "                              Dropout(dropout_rate),\n",
    "                              Linear(hidden_dim // 2, 1))\n",
    "\n",
    "    def forward(self, data):\n",
    "        # encode atoms and bonds\n",
    "        x = self.atom_encoder(data.x)\n",
    "        edge_attr = self.bond_encoder(data.edge_attr)\n",
    "\n",
    "        # GNN convolutions\n",
    "        x = self.conv1(x, data.edge_index, edge_attr)\n",
    "        x = self.conv2(x, data.edge_index, edge_attr)\n",
    "        x = self.pool(x, data.batch)\n",
    "\n",
    "        # handle RDKit features\n",
    "        rdkit_feats = getattr(data, 'rdkit_feats', None)\n",
    "        if rdkit_feats is not None:\n",
    "            # Reshape the RDKit features tensor to be (batch_size, rdkit_dim)\n",
    "            # The number of samples in the batch is given by x.shape[0] after pooling\n",
    "            reshaped_rdkit_feats = rdkit_feats.view(x.shape[0], self.rdkit_dim)\n",
    "            \n",
    "            # The check for shape mismatch is now more accurate\n",
    "            if x.shape[0] != reshaped_rdkit_feats.shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: GNN output ({x.shape[0]}) vs rdkit_feats ({reshaped_rdkit_feats.shape[0]})\")\n",
    "            \n",
    "            x = torch.cat([x, reshaped_rdkit_feats], dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"RDKit features not found in the data object\")\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252f39e",
   "metadata": {},
   "source": [
    "# Step 7: training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b42e8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 13/13 [00:00<00:00, 60.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 14966.3594 | Val Loss: 11512.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 13/13 [00:00<00:00, 108.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 11906.9952 | Val Loss: 10899.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 13/13 [00:00<00:00, 137.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 10743.5882 | Val Loss: 9611.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 13/13 [00:00<00:00, 142.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 8785.2726 | Val Loss: 7241.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 13/13 [00:00<00:00, 159.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 7528.4167 | Val Loss: 5260.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 13/13 [00:00<00:00, 137.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 6511.8596 | Val Loss: 4957.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 13/13 [00:00<00:00, 176.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 6373.2479 | Val Loss: 4830.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 13/13 [00:00<00:00, 176.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 6298.0629 | Val Loss: 5033.8071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 13/13 [00:00<00:00, 186.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 6202.5310 | Val Loss: 5345.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 13/13 [00:00<00:00, 134.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 6072.5672 | Val Loss: 4692.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 13/13 [00:00<00:00, 163.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 5881.2335 | Val Loss: 4204.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 13/13 [00:00<00:00, 179.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 6033.7601 | Val Loss: 4466.8452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 13/13 [00:00<00:00, 185.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 5463.4788 | Val Loss: 4294.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 13/13 [00:00<00:00, 184.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 5408.3220 | Val Loss: 4383.6265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 13/13 [00:00<00:00, 136.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 5344.6624 | Val Loss: 4296.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 13/13 [00:00<00:00, 176.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 5411.0324 | Val Loss: 3983.4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 13/13 [00:00<00:00, 181.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 5319.1669 | Val Loss: 4663.2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 13/13 [00:00<00:00, 186.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 5129.0777 | Val Loss: 4066.8186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 13/13 [00:00<00:00, 129.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 5256.7687 | Val Loss: 3979.9556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 13/13 [00:00<00:00, 176.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 5255.6154 | Val Loss: 3947.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 13/13 [00:00<00:00, 198.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 5253.9093 | Val Loss: 4706.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 13/13 [00:00<00:00, 191.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 5246.5694 | Val Loss: 3758.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 13/13 [00:00<00:00, 187.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 5158.5458 | Val Loss: 4060.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 13/13 [00:00<00:00, 148.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 5331.8830 | Val Loss: 3814.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 13/13 [00:00<00:00, 178.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 5026.8323 | Val Loss: 3753.6299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 13/13 [00:00<00:00, 200.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 5182.3270 | Val Loss: 3895.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 13/13 [00:00<00:00, 189.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 5047.7889 | Val Loss: 4028.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 13/13 [00:00<00:00, 199.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 4810.3956 | Val Loss: 3649.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 13/13 [00:00<00:00, 153.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 5639.8314 | Val Loss: 4151.3579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: 100%|██████████| 13/13 [00:00<00:00, 193.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 4844.5139 | Val Loss: 3883.1401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 13/13 [00:00<00:00, 186.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 6156.9958 | Val Loss: 4602.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 13/13 [00:00<00:00, 188.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 5210.3431 | Val Loss: 3886.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 13/13 [00:00<00:00, 133.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 4991.4911 | Val Loss: 3676.1914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 13/13 [00:00<00:00, 169.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 4763.9710 | Val Loss: 4195.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 13/13 [00:00<00:00, 197.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 4901.2642 | Val Loss: 4628.0796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 13/13 [00:00<00:00, 197.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 5414.0003 | Val Loss: 3806.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 13/13 [00:00<00:00, 186.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 5099.8593 | Val Loss: 3547.3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 13/13 [00:00<00:00, 141.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 4911.2688 | Val Loss: 3910.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 13/13 [00:00<00:00, 180.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 5103.1292 | Val Loss: 3805.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 13/13 [00:00<00:00, 200.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 5131.8367 | Val Loss: 3614.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 13/13 [00:00<00:00, 173.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 4767.0297 | Val Loss: 3555.4512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 13/13 [00:00<00:00, 185.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 4818.1657 | Val Loss: 3624.4854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 13/13 [00:00<00:00, 145.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 4576.8361 | Val Loss: 4143.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 13/13 [00:00<00:00, 180.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 4342.7143 | Val Loss: 3691.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 13/13 [00:00<00:00, 188.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 4263.7348 | Val Loss: 3396.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 13/13 [00:00<00:00, 198.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 4343.3689 | Val Loss: 3821.3723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 13/13 [00:00<00:00, 194.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 4252.4639 | Val Loss: 3425.8694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 13/13 [00:00<00:00, 141.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 4496.8659 | Val Loss: 3433.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 13/13 [00:00<00:00, 176.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 4650.5424 | Val Loss: 3835.2700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 13/13 [00:00<00:00, 120.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 4575.2184 | Val Loss: 3520.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 13/13 [00:00<00:00, 183.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 4339.4751 | Val Loss: 3492.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 13/13 [00:00<00:00, 144.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 4168.6959 | Val Loss: 3818.1165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 13/13 [00:00<00:00, 164.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 4114.1805 | Val Loss: 3461.8186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 13/13 [00:00<00:00, 185.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 4162.3618 | Val Loss: 4534.2358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55: 100%|██████████| 13/13 [00:00<00:00, 190.80it/s]\n",
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_16100\\2343932047.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(save_dir, \"hybridgnn_untuned.pt\")))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 4186.9516 | Val Loss: 3480.4678\n",
      "Early stopping triggered at epoch 55\n",
      "\n",
      "GNN Evaluation:\n",
      "         MAE       RMSE  r_squared\n",
      "0  41.419392  58.276566   0.727249\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = HybridGNN(gnn_dim=128, rdkit_dim=rdkit_features.shape[1], hidden_dim=256)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            preds.append(pred.cpu())\n",
    "            targets.append(batch.y.view(-1, 1).cpu())\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    loss = F.mse_loss(preds, targets)\n",
    "    return loss.item(), preds, targets\n",
    "\n",
    "# training loop\n",
    "for epoch in range(1, 101): # long since early stopping\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch:02d}\"):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_loss, val_preds, val_targets = evaluate(model, valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        save_dir = \"saved_models/gnn_smiles2graph_model\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"hybridgnn_untuned.pt\"))\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# final eval on val set\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, \"hybridgnn_untuned.pt\")))\n",
    "model.eval()\n",
    "_, final_preds, final_targets = evaluate(model, valid_loader)\n",
    "metrics = regression_metrics(final_targets.numpy(), final_preds.numpy())\n",
    "print(\"\\nGNN Evaluation:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34585261",
   "metadata": {},
   "source": [
    "# Step 8: Optuna tuning of Hybrid GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85485072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGNN(Module):\n",
    "    def __init__(self, gnn_dim, rdkit_dim, hidden_dim, dropout_rate=0.2, activation='ReLU'):\n",
    "        super().__init__()\n",
    "        act_map = {'ReLU': torch.nn.ReLU(), 'ELU': torch.nn.ELU(), 'GELU': torch.nn.GELU(), 'LeakyReLU': torch.nn.LeakyReLU(), 'PReLU': torch.nn.PReLU(), 'Swish': torch.nn.SiLU()}\n",
    "        act_fn = act_map[activation]\n",
    "        self.gnn_dim = gnn_dim\n",
    "        self.rdkit_dim = rdkit_dim\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim=gnn_dim)\n",
    "        self.bond_encoder = BondEncoder(emb_dim=gnn_dim)\n",
    "\n",
    "        self.conv1 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), act_fn, Linear(gnn_dim, gnn_dim)))\n",
    "        self.conv2 = GINEConv(Sequential(Linear(gnn_dim, gnn_dim), act_fn, Linear(gnn_dim, gnn_dim)))\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        self.mlp = Sequential(Linear(gnn_dim + rdkit_dim, hidden_dim), act_fn, \n",
    "                              Dropout(dropout_rate), \n",
    "                              Linear(hidden_dim, hidden_dim // 2), act_fn, \n",
    "                              Dropout(dropout_rate), \n",
    "                              Linear(hidden_dim // 2, 1))\n",
    "\n",
    "    def forward(self, data):\n",
    "        # encode atoms and bonds\n",
    "        x = self.atom_encoder(data.x)\n",
    "        edge_attr = self.bond_encoder(data.edge_attr)\n",
    "\n",
    "        # GNN convolutions\n",
    "        x = self.conv1(x, data.edge_index, edge_attr)\n",
    "        x = self.conv2(x, data.edge_index, edge_attr)\n",
    "        x = self.pool(x, data.batch)\n",
    "\n",
    "        # handle RDKit features\n",
    "        rdkit_feats = getattr(data, 'rdkit_feats', None)\n",
    "        if rdkit_feats is not None:\n",
    "            # Reshape the RDKit features tensor to be (batch_size, rdkit_dim)\n",
    "            # The number of samples in the batch is given by x.shape[0] after pooling\n",
    "            reshaped_rdkit_feats = rdkit_feats.view(x.shape[0], self.rdkit_dim)\n",
    "            \n",
    "            # The check for shape mismatch is now more accurate\n",
    "            if x.shape[0] != reshaped_rdkit_feats.shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: GNN output ({x.shape[0]}) vs rdkit_feats ({reshaped_rdkit_feats.shape[0]})\")\n",
    "            \n",
    "            x = torch.cat([x, reshaped_rdkit_feats], dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"RDKit features not found in the data object\")\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f1fc3",
   "metadata": {},
   "source": [
    "Multiple rounds of tuning have suggested to refine my search space to ReLU, GELU, and Swish activation functions and Adam and AdamW optimizers. Therefore, I have commented out unused parameters like momentum for SGD and the unused optimizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f95a50c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:29,258] A new study created in RDB with name: final_2d_gnn_study_Tg_6\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning:\n",
      "\n",
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch 01 | Train Loss: 21353.0280 | Val Loss: 21130.4590 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 02 | Train Loss: 19865.8993 | Val Loss: 18284.1584 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 03 | Train Loss: 15630.9519 | Val Loss: 10764.1219 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 04 | Train Loss: 11053.8478 | Val Loss: 10290.9002 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 05 | Train Loss: 11017.4944 | Val Loss: 9036.3738 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 06 | Train Loss: 9980.0131 | Val Loss: 10554.1747 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 07 | Train Loss: 10365.6873 | Val Loss: 8638.2348 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 08 | Train Loss: 9144.0439 | Val Loss: 8065.1139 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 09 | Train Loss: 8325.6938 | Val Loss: 7044.7456 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 10 | Train Loss: 7781.7158 | Val Loss: 7842.9243 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 11 | Train Loss: 8178.6324 | Val Loss: 6498.4299 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 12 | Train Loss: 8316.6447 | Val Loss: 6362.2449 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 13 | Train Loss: 8261.4705 | Val Loss: 10151.1127 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 14 | Train Loss: 10300.5500 | Val Loss: 9062.9704 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 15 | Train Loss: 8387.8969 | Val Loss: 6256.0062 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 16 | Train Loss: 8027.7714 | Val Loss: 6804.7266 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 17 | Train Loss: 8136.6083 | Val Loss: 6389.5003 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 18 | Train Loss: 7273.9918 | Val Loss: 6850.1320 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 19 | Train Loss: 7018.8632 | Val Loss: 6044.4165 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 20 | Train Loss: 6844.8144 | Val Loss: 5958.0921 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 21 | Train Loss: 6573.4831 | Val Loss: 6063.0277 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 22 | Train Loss: 7023.3348 | Val Loss: 6266.6360 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 23 | Train Loss: 6681.7824 | Val Loss: 5747.2831 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 24 | Train Loss: 6345.9251 | Val Loss: 5734.2718 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 25 | Train Loss: 6495.6864 | Val Loss: 5617.0221 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 26 | Train Loss: 6971.9966 | Val Loss: 5615.4820 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 27 | Train Loss: 6852.6686 | Val Loss: 5841.1797 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 28 | Train Loss: 6591.9268 | Val Loss: 5553.1186 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 29 | Train Loss: 6208.5577 | Val Loss: 5512.8743 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 30 | Train Loss: 6145.1449 | Val Loss: 5615.7737 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 31 | Train Loss: 6245.7563 | Val Loss: 5369.6848 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 32 | Train Loss: 6694.1776 | Val Loss: 5412.0314 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 33 | Train Loss: 6580.7355 | Val Loss: 5936.2916 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 34 | Train Loss: 6605.8082 | Val Loss: 6305.3558 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 35 | Train Loss: 6154.6697 | Val Loss: 5289.3824 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 36 | Train Loss: 6489.4237 | Val Loss: 5768.6029 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 37 | Train Loss: 7436.7431 | Val Loss: 7926.3175 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 38 | Train Loss: 7656.9246 | Val Loss: 6106.2988 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 39 | Train Loss: 6048.5042 | Val Loss: 5514.3473 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 40 | Train Loss: 6168.6932 | Val Loss: 5599.1377 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 41 | Train Loss: 5989.7053 | Val Loss: 5756.3513 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 42 | Train Loss: 6116.5735 | Val Loss: 5330.0261 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 43 | Train Loss: 6460.3011 | Val Loss: 5282.2629 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 44 | Train Loss: 5686.7737 | Val Loss: 5362.6274 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 45 | Train Loss: 5933.9280 | Val Loss: 5464.0448 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 46 | Train Loss: 6418.8665 | Val Loss: 5502.8188 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 47 | Train Loss: 6028.8700 | Val Loss: 5288.4523 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 48 | Train Loss: 6094.0825 | Val Loss: 5730.8054 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 49 | Train Loss: 5943.8747 | Val Loss: 5506.4825 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 50 | Train Loss: 6526.2807 | Val Loss: 5304.5914 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 51 | Train Loss: 6291.7994 | Val Loss: 5634.2154 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 52 | Train Loss: 5935.9406 | Val Loss: 5250.3599 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 53 | Train Loss: 6281.5498 | Val Loss: 5324.1084 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 54 | Train Loss: 5594.3858 | Val Loss: 5741.4183 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 55 | Train Loss: 5823.7329 | Val Loss: 5415.2401 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 56 | Train Loss: 5403.6510 | Val Loss: 5258.5157 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 57 | Train Loss: 5895.2210 | Val Loss: 5202.2073 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 58 | Train Loss: 5652.8852 | Val Loss: 5373.3937 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 59 | Train Loss: 5587.9845 | Val Loss: 5503.2850 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 60 | Train Loss: 5775.4484 | Val Loss: 5197.7836 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 61 | Train Loss: 6294.1817 | Val Loss: 5730.7982 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 62 | Train Loss: 7190.1893 | Val Loss: 5304.7791 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 63 | Train Loss: 5703.0713 | Val Loss: 5441.7806 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 64 | Train Loss: 5529.9358 | Val Loss: 5572.6472 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 65 | Train Loss: 6152.8143 | Val Loss: 5984.6942 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 66 | Train Loss: 7853.1062 | Val Loss: 8724.4539 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 67 | Train Loss: 6892.7465 | Val Loss: 5468.7446 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 68 | Train Loss: 6937.5074 | Val Loss: 5447.8419 | Optimizer: AdamW\n",
      "Trial 0 | Epoch 69 | Train Loss: 6438.8175 | Val Loss: 8130.5448 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:35,160] Trial 0 finished with value: 5197.783649209105 and parameters: {'gnn_dim': 1024, 'hidden_dim': 256, 'dropout_rate': 0.34789969778599206, 'lr': 0.00019706110180855172, 'activation': 'GELU', 'optimizer': 'AdamW', 'weight_decay': 6.918777663255381e-06}. Best is trial 0 with value: 5197.783649209105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch 70 | Train Loss: 7642.9100 | Val Loss: 5354.3312 | Optimizer: AdamW\n",
      "Trial 0 - Early stopping triggered at epoch 70\n",
      "Trial 1 | Epoch 01 | Train Loss: 18620.6935 | Val Loss: 13732.5400 | Optimizer: Adam\n",
      "Trial 1 | Epoch 02 | Train Loss: 12839.7794 | Val Loss: 10173.1253 | Optimizer: Adam\n",
      "Trial 1 | Epoch 03 | Train Loss: 10908.4518 | Val Loss: 9593.9016 | Optimizer: Adam\n",
      "Trial 1 | Epoch 04 | Train Loss: 10015.3029 | Val Loss: 8103.3509 | Optimizer: Adam\n",
      "Trial 1 | Epoch 05 | Train Loss: 8782.8457 | Val Loss: 7833.3933 | Optimizer: Adam\n",
      "Trial 1 | Epoch 06 | Train Loss: 8556.1367 | Val Loss: 7152.4838 | Optimizer: Adam\n",
      "Trial 1 | Epoch 07 | Train Loss: 8040.3176 | Val Loss: 6746.5570 | Optimizer: Adam\n",
      "Trial 1 | Epoch 08 | Train Loss: 7345.4207 | Val Loss: 6321.3125 | Optimizer: Adam\n",
      "Trial 1 | Epoch 09 | Train Loss: 7099.1777 | Val Loss: 6901.4940 | Optimizer: Adam\n",
      "Trial 1 | Epoch 10 | Train Loss: 7535.1776 | Val Loss: 8169.6968 | Optimizer: Adam\n",
      "Trial 1 | Epoch 11 | Train Loss: 8920.2610 | Val Loss: 5942.3490 | Optimizer: Adam\n",
      "Trial 1 | Epoch 12 | Train Loss: 6880.5802 | Val Loss: 6177.0060 | Optimizer: Adam\n",
      "Trial 1 | Epoch 13 | Train Loss: 8161.5025 | Val Loss: 7537.0814 | Optimizer: Adam\n",
      "Trial 1 | Epoch 14 | Train Loss: 10331.2932 | Val Loss: 9223.1536 | Optimizer: Adam\n",
      "Trial 1 | Epoch 15 | Train Loss: 7944.3160 | Val Loss: 7358.6396 | Optimizer: Adam\n",
      "Trial 1 | Epoch 16 | Train Loss: 7356.6317 | Val Loss: 6228.5521 | Optimizer: Adam\n",
      "Trial 1 | Epoch 17 | Train Loss: 6940.2238 | Val Loss: 5562.0852 | Optimizer: Adam\n",
      "Trial 1 | Epoch 18 | Train Loss: 6270.3703 | Val Loss: 5451.0160 | Optimizer: Adam\n",
      "Trial 1 | Epoch 19 | Train Loss: 6435.7679 | Val Loss: 5281.0046 | Optimizer: Adam\n",
      "Trial 1 | Epoch 20 | Train Loss: 6265.9927 | Val Loss: 5288.6326 | Optimizer: Adam\n",
      "Trial 1 | Epoch 21 | Train Loss: 6216.1580 | Val Loss: 5155.1259 | Optimizer: Adam\n",
      "Trial 1 | Epoch 22 | Train Loss: 6269.8754 | Val Loss: 5220.5687 | Optimizer: Adam\n",
      "Trial 1 | Epoch 23 | Train Loss: 6212.6202 | Val Loss: 5337.3658 | Optimizer: Adam\n",
      "Trial 1 | Epoch 24 | Train Loss: 6298.1471 | Val Loss: 5451.9714 | Optimizer: Adam\n",
      "Trial 1 | Epoch 25 | Train Loss: 5719.5692 | Val Loss: 5220.1320 | Optimizer: Adam\n",
      "Trial 1 | Epoch 26 | Train Loss: 6156.2430 | Val Loss: 5113.9316 | Optimizer: Adam\n",
      "Trial 1 | Epoch 27 | Train Loss: 6148.1090 | Val Loss: 5246.8241 | Optimizer: Adam\n",
      "Trial 1 | Epoch 28 | Train Loss: 6123.1403 | Val Loss: 5806.9252 | Optimizer: Adam\n",
      "Trial 1 | Epoch 29 | Train Loss: 6221.3139 | Val Loss: 5296.6871 | Optimizer: Adam\n",
      "Trial 1 | Epoch 30 | Train Loss: 5948.3139 | Val Loss: 5146.2958 | Optimizer: Adam\n",
      "Trial 1 | Epoch 31 | Train Loss: 5487.4228 | Val Loss: 5262.7856 | Optimizer: Adam\n",
      "Trial 1 | Epoch 32 | Train Loss: 7044.6826 | Val Loss: 5550.7390 | Optimizer: Adam\n",
      "Trial 1 | Epoch 33 | Train Loss: 6624.4719 | Val Loss: 5312.1883 | Optimizer: Adam\n",
      "Trial 1 | Epoch 34 | Train Loss: 5805.7351 | Val Loss: 5055.3495 | Optimizer: Adam\n",
      "Trial 1 | Epoch 35 | Train Loss: 5421.4037 | Val Loss: 5719.2731 | Optimizer: Adam\n",
      "Trial 1 | Epoch 36 | Train Loss: 5532.9885 | Val Loss: 5171.5548 | Optimizer: Adam\n",
      "Trial 1 | Epoch 37 | Train Loss: 5574.7511 | Val Loss: 5213.8522 | Optimizer: Adam\n",
      "Trial 1 | Epoch 38 | Train Loss: 5589.0490 | Val Loss: 5052.4301 | Optimizer: Adam\n",
      "Trial 1 | Epoch 39 | Train Loss: 6630.1405 | Val Loss: 5214.9673 | Optimizer: Adam\n",
      "Trial 1 | Epoch 40 | Train Loss: 6109.5562 | Val Loss: 5395.1719 | Optimizer: Adam\n",
      "Trial 1 | Epoch 41 | Train Loss: 5703.1291 | Val Loss: 5125.5164 | Optimizer: Adam\n",
      "Trial 1 | Epoch 42 | Train Loss: 5409.4031 | Val Loss: 5133.6055 | Optimizer: Adam\n",
      "Trial 1 | Epoch 43 | Train Loss: 5548.8415 | Val Loss: 5337.5085 | Optimizer: Adam\n",
      "Trial 1 | Epoch 44 | Train Loss: 5584.0838 | Val Loss: 5105.6995 | Optimizer: Adam\n",
      "Trial 1 | Epoch 45 | Train Loss: 5294.3338 | Val Loss: 5115.0533 | Optimizer: Adam\n",
      "Trial 1 | Epoch 46 | Train Loss: 5436.9091 | Val Loss: 5320.2660 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:37,619] Trial 1 finished with value: 5052.430064260224 and parameters: {'gnn_dim': 256, 'hidden_dim': 384, 'dropout_rate': 0.3386970659282392, 'lr': 0.0008805083733534888, 'activation': 'ReLU', 'optimizer': 'Adam', 'weight_decay': 1.4250321078722525e-06}. Best is trial 1 with value: 5052.430064260224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 | Epoch 47 | Train Loss: 5252.2945 | Val Loss: 5193.4824 | Optimizer: Adam\n",
      "Trial 1 | Epoch 48 | Train Loss: 5083.4840 | Val Loss: 5198.2090 | Optimizer: Adam\n",
      "Trial 1 - Early stopping triggered at epoch 48\n",
      "Trial 2 | Epoch 01 | Train Loss: 26717.4958 | Val Loss: 22543.5034 | Optimizer: SGD\n",
      "Trial 2 | Epoch 02 | Train Loss: 22012.2307 | Val Loss: 22414.0762 | Optimizer: SGD\n",
      "Trial 2 | Epoch 03 | Train Loss: 21927.4850 | Val Loss: 22379.3090 | Optimizer: SGD\n",
      "Trial 2 | Epoch 04 | Train Loss: 21896.4000 | Val Loss: 22353.1413 | Optimizer: SGD\n",
      "Trial 2 | Epoch 05 | Train Loss: 21870.1305 | Val Loss: 22327.3915 | Optimizer: SGD\n",
      "Trial 2 | Epoch 06 | Train Loss: 21844.0990 | Val Loss: 22298.9447 | Optimizer: SGD\n",
      "Trial 2 | Epoch 07 | Train Loss: 21813.0929 | Val Loss: 22263.8213 | Optimizer: SGD\n",
      "Trial 2 | Epoch 08 | Train Loss: 21774.2502 | Val Loss: 22223.2584 | Optimizer: SGD\n",
      "Trial 2 | Epoch 09 | Train Loss: 21735.6673 | Val Loss: 22187.5272 | Optimizer: SGD\n",
      "Trial 2 | Epoch 10 | Train Loss: 21702.3429 | Val Loss: 22152.4934 | Optimizer: SGD\n",
      "Trial 2 | Epoch 11 | Train Loss: 21664.5881 | Val Loss: 22112.9139 | Optimizer: SGD\n",
      "Trial 2 | Epoch 12 | Train Loss: 21622.3813 | Val Loss: 22069.5543 | Optimizer: SGD\n",
      "Trial 2 | Epoch 13 | Train Loss: 21576.9883 | Val Loss: 22018.5930 | Optimizer: SGD\n",
      "Trial 2 | Epoch 14 | Train Loss: 21526.4797 | Val Loss: 21965.2229 | Optimizer: SGD\n",
      "Trial 2 | Epoch 15 | Train Loss: 21474.4161 | Val Loss: 21909.7994 | Optimizer: SGD\n",
      "Trial 2 | Epoch 16 | Train Loss: 21413.8103 | Val Loss: 21835.6127 | Optimizer: SGD\n",
      "Trial 2 | Epoch 17 | Train Loss: 21327.8272 | Val Loss: 21742.7774 | Optimizer: SGD\n",
      "Trial 2 | Epoch 18 | Train Loss: 21233.9397 | Val Loss: 21644.2758 | Optimizer: SGD\n",
      "Trial 2 | Epoch 19 | Train Loss: 21131.4556 | Val Loss: 21529.7241 | Optimizer: SGD\n",
      "Trial 2 | Epoch 20 | Train Loss: 21003.0830 | Val Loss: 21389.7889 | Optimizer: SGD\n",
      "Trial 2 | Epoch 21 | Train Loss: 20866.4377 | Val Loss: 21229.3604 | Optimizer: SGD\n",
      "Trial 2 | Epoch 22 | Train Loss: 20692.0881 | Val Loss: 21031.7585 | Optimizer: SGD\n",
      "Trial 2 | Epoch 23 | Train Loss: 20467.7947 | Val Loss: 20772.9058 | Optimizer: SGD\n",
      "Trial 2 | Epoch 24 | Train Loss: 20215.4425 | Val Loss: 20496.5618 | Optimizer: SGD\n",
      "Trial 2 | Epoch 25 | Train Loss: 19928.2580 | Val Loss: 20190.3124 | Optimizer: SGD\n",
      "Trial 2 | Epoch 26 | Train Loss: 19604.0351 | Val Loss: 19859.3126 | Optimizer: SGD\n",
      "Trial 2 | Epoch 27 | Train Loss: 19261.3635 | Val Loss: 19474.6782 | Optimizer: SGD\n",
      "Trial 2 | Epoch 28 | Train Loss: 18831.5860 | Val Loss: 18963.6246 | Optimizer: SGD\n",
      "Trial 2 | Epoch 29 | Train Loss: 18278.5757 | Val Loss: 18430.2806 | Optimizer: SGD\n",
      "Trial 2 | Epoch 30 | Train Loss: 17802.2765 | Val Loss: 17931.5306 | Optimizer: SGD\n",
      "Trial 2 | Epoch 31 | Train Loss: 17241.3197 | Val Loss: 17358.2519 | Optimizer: SGD\n",
      "Trial 2 | Epoch 32 | Train Loss: 16693.8562 | Val Loss: 16762.0039 | Optimizer: SGD\n",
      "Trial 2 | Epoch 33 | Train Loss: 16052.5171 | Val Loss: 16165.6006 | Optimizer: SGD\n",
      "Trial 2 | Epoch 34 | Train Loss: 15455.9119 | Val Loss: 15539.9672 | Optimizer: SGD\n",
      "Trial 2 | Epoch 35 | Train Loss: 14767.0090 | Val Loss: 14966.2135 | Optimizer: SGD\n",
      "Trial 2 | Epoch 36 | Train Loss: 14373.5859 | Val Loss: 14437.1467 | Optimizer: SGD\n",
      "Trial 2 | Epoch 37 | Train Loss: 13702.4983 | Val Loss: 13893.2282 | Optimizer: SGD\n",
      "Trial 2 | Epoch 38 | Train Loss: 13327.8073 | Val Loss: 13540.6595 | Optimizer: SGD\n",
      "Trial 2 | Epoch 39 | Train Loss: 12973.7586 | Val Loss: 13320.8727 | Optimizer: SGD\n",
      "Trial 2 | Epoch 40 | Train Loss: 12841.9493 | Val Loss: 13134.5730 | Optimizer: SGD\n",
      "Trial 2 | Epoch 41 | Train Loss: 12516.8880 | Val Loss: 13010.2134 | Optimizer: SGD\n",
      "Trial 2 | Epoch 42 | Train Loss: 12540.7847 | Val Loss: 12946.0082 | Optimizer: SGD\n",
      "Trial 2 | Epoch 43 | Train Loss: 12562.3564 | Val Loss: 12890.2100 | Optimizer: SGD\n",
      "Trial 2 | Epoch 44 | Train Loss: 12435.6267 | Val Loss: 12846.4665 | Optimizer: SGD\n",
      "Trial 2 | Epoch 45 | Train Loss: 12288.8074 | Val Loss: 12828.6403 | Optimizer: SGD\n",
      "Trial 2 | Epoch 46 | Train Loss: 12574.4778 | Val Loss: 12829.8249 | Optimizer: SGD\n",
      "Trial 2 | Epoch 47 | Train Loss: 12287.5043 | Val Loss: 12844.0854 | Optimizer: SGD\n",
      "Trial 2 | Epoch 48 | Train Loss: 12310.9270 | Val Loss: 12862.4476 | Optimizer: SGD\n",
      "Trial 2 | Epoch 49 | Train Loss: 12323.8613 | Val Loss: 12875.3338 | Optimizer: SGD\n",
      "Trial 2 | Epoch 50 | Train Loss: 12262.6861 | Val Loss: 12876.2175 | Optimizer: SGD\n",
      "Trial 2 | Epoch 51 | Train Loss: 12399.3553 | Val Loss: 12852.3454 | Optimizer: SGD\n",
      "Trial 2 | Epoch 52 | Train Loss: 12345.2854 | Val Loss: 12844.1248 | Optimizer: SGD\n",
      "Trial 2 | Epoch 53 | Train Loss: 12398.5714 | Val Loss: 12854.0364 | Optimizer: SGD\n",
      "Trial 2 | Epoch 54 | Train Loss: 12403.9709 | Val Loss: 12841.0108 | Optimizer: SGD\n",
      "Trial 2 | Epoch 55 | Train Loss: 12332.7889 | Val Loss: 12828.5054 | Optimizer: SGD\n",
      "Trial 2 | Epoch 56 | Train Loss: 12313.4847 | Val Loss: 12843.5159 | Optimizer: SGD\n",
      "Trial 2 | Epoch 57 | Train Loss: 12414.5948 | Val Loss: 12841.4325 | Optimizer: SGD\n",
      "Trial 2 | Epoch 58 | Train Loss: 12426.9735 | Val Loss: 12829.0850 | Optimizer: SGD\n",
      "Trial 2 | Epoch 59 | Train Loss: 12067.2371 | Val Loss: 12831.5474 | Optimizer: SGD\n",
      "Trial 2 | Epoch 60 | Train Loss: 12359.3402 | Val Loss: 12856.4145 | Optimizer: SGD\n",
      "Trial 2 | Epoch 61 | Train Loss: 12546.2793 | Val Loss: 12872.5543 | Optimizer: SGD\n",
      "Trial 2 | Epoch 62 | Train Loss: 12622.9149 | Val Loss: 12867.0435 | Optimizer: SGD\n",
      "Trial 2 | Epoch 63 | Train Loss: 12361.7393 | Val Loss: 12868.3581 | Optimizer: SGD\n",
      "Trial 2 | Epoch 64 | Train Loss: 12546.1070 | Val Loss: 12941.9218 | Optimizer: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:42,843] Trial 2 finished with value: 12828.505365065586 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.1865352470138201, 'lr': 1.9496309765903227e-05, 'activation': 'ReLU', 'optimizer': 'SGD', 'momentum': 0.8249147681381581, 'weight_decay': 2.4239649920149693e-06}. Best is trial 1 with value: 5052.430064260224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 | Epoch 65 | Train Loss: 12746.9392 | Val Loss: 12978.9382 | Optimizer: SGD\n",
      "Trial 2 - Early stopping triggered at epoch 65\n",
      "Trial 3 | Epoch 01 | Train Loss: 21209.7255 | Val Loss: 20547.8431 | Optimizer: Adam\n",
      "Trial 3 | Epoch 02 | Train Loss: 19734.1264 | Val Loss: 19040.5971 | Optimizer: Adam\n",
      "Trial 3 | Epoch 03 | Train Loss: 18498.1451 | Val Loss: 17618.5432 | Optimizer: Adam\n",
      "Trial 3 | Epoch 04 | Train Loss: 16811.9537 | Val Loss: 15874.3342 | Optimizer: Adam\n",
      "Trial 3 | Epoch 05 | Train Loss: 15148.1524 | Val Loss: 13387.7922 | Optimizer: Adam\n",
      "Trial 3 | Epoch 06 | Train Loss: 12602.1459 | Val Loss: 10640.4751 | Optimizer: Adam\n",
      "Trial 3 | Epoch 07 | Train Loss: 10679.9815 | Val Loss: 10541.7943 | Optimizer: Adam\n",
      "Trial 3 | Epoch 08 | Train Loss: 10638.4144 | Val Loss: 9569.0723 | Optimizer: Adam\n",
      "Trial 3 | Epoch 09 | Train Loss: 9983.7287 | Val Loss: 9736.4614 | Optimizer: Adam\n",
      "Trial 3 | Epoch 10 | Train Loss: 9894.3647 | Val Loss: 8944.3889 | Optimizer: Adam\n",
      "Trial 3 | Epoch 11 | Train Loss: 9411.9073 | Val Loss: 8303.2753 | Optimizer: Adam\n",
      "Trial 3 | Epoch 12 | Train Loss: 8636.9261 | Val Loss: 7918.3532 | Optimizer: Adam\n",
      "Trial 3 | Epoch 13 | Train Loss: 8438.1565 | Val Loss: 7483.8633 | Optimizer: Adam\n",
      "Trial 3 | Epoch 14 | Train Loss: 8257.4964 | Val Loss: 7300.0013 | Optimizer: Adam\n",
      "Trial 3 | Epoch 15 | Train Loss: 8064.6736 | Val Loss: 7087.7779 | Optimizer: Adam\n",
      "Trial 3 | Epoch 16 | Train Loss: 7737.5333 | Val Loss: 6963.3062 | Optimizer: Adam\n",
      "Trial 3 | Epoch 17 | Train Loss: 8266.6494 | Val Loss: 7417.4608 | Optimizer: Adam\n",
      "Trial 3 | Epoch 18 | Train Loss: 8047.1536 | Val Loss: 6724.7986 | Optimizer: Adam\n",
      "Trial 3 | Epoch 19 | Train Loss: 8183.6213 | Val Loss: 7745.8227 | Optimizer: Adam\n",
      "Trial 3 | Epoch 20 | Train Loss: 8423.7842 | Val Loss: 7226.7028 | Optimizer: Adam\n",
      "Trial 3 | Epoch 21 | Train Loss: 7871.9055 | Val Loss: 6457.8069 | Optimizer: Adam\n",
      "Trial 3 | Epoch 22 | Train Loss: 7322.2896 | Val Loss: 6301.0741 | Optimizer: Adam\n",
      "Trial 3 | Epoch 23 | Train Loss: 7287.4119 | Val Loss: 6128.3434 | Optimizer: Adam\n",
      "Trial 3 | Epoch 24 | Train Loss: 7043.0629 | Val Loss: 6050.2366 | Optimizer: Adam\n",
      "Trial 3 | Epoch 25 | Train Loss: 6702.0292 | Val Loss: 5742.8836 | Optimizer: Adam\n",
      "Trial 3 | Epoch 26 | Train Loss: 6950.6050 | Val Loss: 5493.6707 | Optimizer: Adam\n",
      "Trial 3 | Epoch 27 | Train Loss: 6623.2600 | Val Loss: 5336.7608 | Optimizer: Adam\n",
      "Trial 3 | Epoch 28 | Train Loss: 6564.7624 | Val Loss: 5507.7914 | Optimizer: Adam\n",
      "Trial 3 | Epoch 29 | Train Loss: 7025.7850 | Val Loss: 5327.9660 | Optimizer: Adam\n",
      "Trial 3 | Epoch 30 | Train Loss: 6525.9474 | Val Loss: 5850.5497 | Optimizer: Adam\n",
      "Trial 3 | Epoch 31 | Train Loss: 7016.5447 | Val Loss: 5654.3927 | Optimizer: Adam\n",
      "Trial 3 | Epoch 32 | Train Loss: 6659.9610 | Val Loss: 5313.6286 | Optimizer: Adam\n",
      "Trial 3 | Epoch 33 | Train Loss: 6499.3808 | Val Loss: 5729.4991 | Optimizer: Adam\n",
      "Trial 3 | Epoch 34 | Train Loss: 6684.7051 | Val Loss: 5367.4969 | Optimizer: Adam\n",
      "Trial 3 | Epoch 35 | Train Loss: 6510.4375 | Val Loss: 5572.2395 | Optimizer: Adam\n",
      "Trial 3 | Epoch 36 | Train Loss: 6343.5393 | Val Loss: 5405.5583 | Optimizer: Adam\n",
      "Trial 3 | Epoch 37 | Train Loss: 6215.4449 | Val Loss: 5580.5039 | Optimizer: Adam\n",
      "Trial 3 | Epoch 38 | Train Loss: 7203.8247 | Val Loss: 5433.4264 | Optimizer: Adam\n",
      "Trial 3 | Epoch 39 | Train Loss: 6366.8044 | Val Loss: 6264.4601 | Optimizer: Adam\n",
      "Trial 3 | Epoch 40 | Train Loss: 7246.8101 | Val Loss: 5599.2164 | Optimizer: Adam\n",
      "Trial 3 | Epoch 41 | Train Loss: 6514.7199 | Val Loss: 5624.1732 | Optimizer: Adam\n",
      "Trial 3 | Epoch 42 | Train Loss: 6358.7078 | Val Loss: 5157.1024 | Optimizer: Adam\n",
      "Trial 3 | Epoch 43 | Train Loss: 6319.4083 | Val Loss: 5489.1824 | Optimizer: Adam\n",
      "Trial 3 | Epoch 44 | Train Loss: 6815.5513 | Val Loss: 5565.7592 | Optimizer: Adam\n",
      "Trial 3 | Epoch 45 | Train Loss: 6427.0744 | Val Loss: 5214.0761 | Optimizer: Adam\n",
      "Trial 3 | Epoch 46 | Train Loss: 6257.8920 | Val Loss: 5137.0084 | Optimizer: Adam\n",
      "Trial 3 | Epoch 47 | Train Loss: 6007.4264 | Val Loss: 5255.0897 | Optimizer: Adam\n",
      "Trial 3 | Epoch 48 | Train Loss: 6117.7973 | Val Loss: 5243.3359 | Optimizer: Adam\n",
      "Trial 3 | Epoch 49 | Train Loss: 6126.5046 | Val Loss: 5227.5188 | Optimizer: Adam\n",
      "Trial 3 | Epoch 50 | Train Loss: 6269.5703 | Val Loss: 6529.2741 | Optimizer: Adam\n",
      "Trial 3 | Epoch 51 | Train Loss: 6712.0058 | Val Loss: 5793.2319 | Optimizer: Adam\n",
      "Trial 3 | Epoch 52 | Train Loss: 6406.5871 | Val Loss: 5265.0193 | Optimizer: Adam\n",
      "Trial 3 | Epoch 53 | Train Loss: 6339.0591 | Val Loss: 5362.8041 | Optimizer: Adam\n",
      "Trial 3 | Epoch 54 | Train Loss: 6255.5754 | Val Loss: 5236.6155 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:46,043] Trial 3 finished with value: 5137.008415316358 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.33601299717314004, 'lr': 0.00011346972633906472, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 6.85481436715093e-05}. Best is trial 1 with value: 5052.430064260224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 | Epoch 55 | Train Loss: 6105.0193 | Val Loss: 5484.9383 | Optimizer: Adam\n",
      "Trial 3 | Epoch 56 | Train Loss: 6104.0638 | Val Loss: 5247.7969 | Optimizer: Adam\n",
      "Trial 3 - Early stopping triggered at epoch 56\n",
      "Trial 4 | Epoch 01 | Train Loss: 20638.3185 | Val Loss: 19509.7425 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 02 | Train Loss: 18708.2655 | Val Loss: 17643.9660 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 03 | Train Loss: 17017.6209 | Val Loss: 15954.9260 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 04 | Train Loss: 15461.9907 | Val Loss: 14300.6933 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 05 | Train Loss: 14054.1709 | Val Loss: 12741.5159 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 06 | Train Loss: 12686.1595 | Val Loss: 11324.3750 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 07 | Train Loss: 11287.9765 | Val Loss: 10338.0924 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 08 | Train Loss: 10953.1182 | Val Loss: 10124.3860 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 09 | Train Loss: 10783.7309 | Val Loss: 9763.8713 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 10 | Train Loss: 10354.8297 | Val Loss: 9580.6763 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 11 | Train Loss: 10273.7061 | Val Loss: 9291.1042 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 12 | Train Loss: 9837.1400 | Val Loss: 8748.9585 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 13 | Train Loss: 9610.1393 | Val Loss: 8641.5621 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 14 | Train Loss: 9341.4313 | Val Loss: 8130.4333 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 15 | Train Loss: 8764.8322 | Val Loss: 8014.1687 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 16 | Train Loss: 8717.1506 | Val Loss: 7983.8013 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 17 | Train Loss: 8754.0967 | Val Loss: 7819.4107 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 18 | Train Loss: 8186.0321 | Val Loss: 7459.6903 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 19 | Train Loss: 8380.1513 | Val Loss: 7274.9217 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 20 | Train Loss: 8145.4188 | Val Loss: 7213.6697 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 21 | Train Loss: 7918.0017 | Val Loss: 7214.1586 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 22 | Train Loss: 7952.4552 | Val Loss: 7121.6022 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 23 | Train Loss: 7817.0269 | Val Loss: 6835.5813 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 24 | Train Loss: 7474.4189 | Val Loss: 6661.2917 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 25 | Train Loss: 7547.5264 | Val Loss: 6472.2332 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 26 | Train Loss: 7381.4151 | Val Loss: 6328.0112 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 27 | Train Loss: 7261.0399 | Val Loss: 6190.2353 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 28 | Train Loss: 7133.4966 | Val Loss: 6025.2212 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 29 | Train Loss: 6987.3095 | Val Loss: 5938.5434 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 30 | Train Loss: 7041.3355 | Val Loss: 6097.1953 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 31 | Train Loss: 7037.7303 | Val Loss: 5622.2674 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 32 | Train Loss: 6797.3308 | Val Loss: 5610.6254 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 33 | Train Loss: 6765.3145 | Val Loss: 5717.6509 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 34 | Train Loss: 6775.9152 | Val Loss: 5603.8585 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 35 | Train Loss: 6670.8957 | Val Loss: 5583.9804 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 36 | Train Loss: 6416.9217 | Val Loss: 5533.3032 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 37 | Train Loss: 6503.5438 | Val Loss: 5531.9597 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 38 | Train Loss: 6560.2671 | Val Loss: 5777.3718 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 39 | Train Loss: 6641.0292 | Val Loss: 5570.2802 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 40 | Train Loss: 6584.8482 | Val Loss: 5534.6078 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 41 | Train Loss: 6166.8707 | Val Loss: 5525.6969 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 42 | Train Loss: 6407.6278 | Val Loss: 5635.6309 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 43 | Train Loss: 6398.0223 | Val Loss: 5617.2413 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 44 | Train Loss: 6667.4563 | Val Loss: 5655.3543 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 45 | Train Loss: 6448.9603 | Val Loss: 5492.2768 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 46 | Train Loss: 6350.9211 | Val Loss: 5587.4452 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 47 | Train Loss: 6430.7907 | Val Loss: 5593.2529 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 48 | Train Loss: 6549.0219 | Val Loss: 5513.6833 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 49 | Train Loss: 6138.0558 | Val Loss: 5423.7747 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 50 | Train Loss: 6296.3615 | Val Loss: 5651.5363 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 51 | Train Loss: 6199.3876 | Val Loss: 5367.3518 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 52 | Train Loss: 6190.5239 | Val Loss: 5368.4195 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 53 | Train Loss: 6020.6609 | Val Loss: 5409.4963 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 54 | Train Loss: 6256.4633 | Val Loss: 5252.3469 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 55 | Train Loss: 6127.2480 | Val Loss: 5866.7235 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 56 | Train Loss: 6985.2508 | Val Loss: 6720.0188 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 57 | Train Loss: 7287.6706 | Val Loss: 5646.9892 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 58 | Train Loss: 6241.5288 | Val Loss: 5728.5442 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 59 | Train Loss: 6523.4738 | Val Loss: 5298.8404 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 60 | Train Loss: 5815.8133 | Val Loss: 5234.1190 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 61 | Train Loss: 5747.4884 | Val Loss: 5314.9004 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 62 | Train Loss: 5895.5372 | Val Loss: 5175.7814 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 63 | Train Loss: 5946.7793 | Val Loss: 5131.5836 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 64 | Train Loss: 5780.0056 | Val Loss: 5168.2378 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 65 | Train Loss: 6041.8720 | Val Loss: 5263.2372 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 66 | Train Loss: 5782.1896 | Val Loss: 5140.6673 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 67 | Train Loss: 5834.9206 | Val Loss: 5079.9073 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 68 | Train Loss: 5793.2699 | Val Loss: 5039.8003 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 69 | Train Loss: 5831.9314 | Val Loss: 5210.0930 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 70 | Train Loss: 5693.1917 | Val Loss: 5067.8719 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 71 | Train Loss: 5946.4335 | Val Loss: 5073.9891 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 72 | Train Loss: 5772.2292 | Val Loss: 5020.4025 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 73 | Train Loss: 5554.8352 | Val Loss: 5013.7911 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 74 | Train Loss: 5813.0707 | Val Loss: 5256.8965 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 75 | Train Loss: 6019.2178 | Val Loss: 4916.2666 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 76 | Train Loss: 5852.4677 | Val Loss: 5961.5160 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 77 | Train Loss: 6622.8583 | Val Loss: 5623.0823 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 78 | Train Loss: 5926.0316 | Val Loss: 5214.7512 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 79 | Train Loss: 5496.5477 | Val Loss: 5033.3379 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 80 | Train Loss: 5530.8700 | Val Loss: 4903.1293 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 81 | Train Loss: 5575.3819 | Val Loss: 4895.3239 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 82 | Train Loss: 5428.3461 | Val Loss: 5040.6800 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 83 | Train Loss: 5598.5076 | Val Loss: 5118.3207 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 84 | Train Loss: 5736.0560 | Val Loss: 5118.4187 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 85 | Train Loss: 5540.3124 | Val Loss: 4940.7024 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 86 | Train Loss: 5574.6523 | Val Loss: 5616.1505 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 87 | Train Loss: 6241.7410 | Val Loss: 4935.1441 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 88 | Train Loss: 5380.1236 | Val Loss: 5254.7739 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 89 | Train Loss: 5924.6147 | Val Loss: 5885.7597 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:50,867] Trial 4 finished with value: 4895.3238691165125 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.18059684143646632, 'lr': 0.00012869301102808614, 'activation': 'Swish', 'optimizer': 'AdamW', 'weight_decay': 2.3165953485163707e-05}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 | Epoch 90 | Train Loss: 6104.8352 | Val Loss: 5104.1217 | Optimizer: AdamW\n",
      "Trial 4 | Epoch 91 | Train Loss: 5371.6885 | Val Loss: 4906.7218 | Optimizer: AdamW\n",
      "Trial 4 - Early stopping triggered at epoch 91\n",
      "Trial 5 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:51,008] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 | Epoch 01 | Train Loss: 20367.9253 | Val Loss: 17058.3622 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 02 | Train Loss: 15071.1234 | Val Loss: 10888.6746 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 03 | Train Loss: 10936.3272 | Val Loss: 9876.5172 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 04 | Train Loss: 10884.0288 | Val Loss: 10083.3526 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 05 | Train Loss: 9891.0620 | Val Loss: 8681.1629 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 06 | Train Loss: 9216.8615 | Val Loss: 9445.0307 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 07 | Train Loss: 9937.2442 | Val Loss: 8663.2830 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 08 | Train Loss: 8687.7468 | Val Loss: 8164.9112 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 09 | Train Loss: 8728.9136 | Val Loss: 7794.4601 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 10 | Train Loss: 8585.3888 | Val Loss: 7732.6860 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 11 | Train Loss: 8324.5966 | Val Loss: 7813.1113 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 12 | Train Loss: 9083.6291 | Val Loss: 7226.4139 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 13 | Train Loss: 8760.1761 | Val Loss: 7310.6071 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 14 | Train Loss: 7822.8155 | Val Loss: 7415.3730 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 15 | Train Loss: 7710.6476 | Val Loss: 7372.2721 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 16 | Train Loss: 7946.8376 | Val Loss: 5955.0740 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 17 | Train Loss: 7172.6098 | Val Loss: 5688.3901 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 18 | Train Loss: 7353.2675 | Val Loss: 7210.5318 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 19 | Train Loss: 7411.6486 | Val Loss: 5952.2629 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 20 | Train Loss: 6795.5326 | Val Loss: 5819.2288 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 21 | Train Loss: 7427.8467 | Val Loss: 6825.9611 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 22 | Train Loss: 6866.4796 | Val Loss: 5880.8264 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 23 | Train Loss: 6952.9137 | Val Loss: 5512.5257 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 24 | Train Loss: 6658.7500 | Val Loss: 5251.7366 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 25 | Train Loss: 6791.8552 | Val Loss: 5173.1718 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 26 | Train Loss: 6230.1501 | Val Loss: 5613.3285 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 27 | Train Loss: 6559.4755 | Val Loss: 5477.3840 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 28 | Train Loss: 6321.2784 | Val Loss: 5476.7827 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 29 | Train Loss: 6243.3381 | Val Loss: 5451.0382 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 30 | Train Loss: 5954.3138 | Val Loss: 5214.4130 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 31 | Train Loss: 5932.4844 | Val Loss: 5183.3219 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 32 | Train Loss: 5888.5607 | Val Loss: 5261.5494 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:53,089] Trial 6 finished with value: 5173.171805676119 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.25985474455857405, 'lr': 0.000396935242987587, 'activation': 'ReLU', 'optimizer': 'AdamW', 'weight_decay': 1.3210659763817696e-05}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 | Epoch 33 | Train Loss: 5926.2010 | Val Loss: 5353.0906 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 34 | Train Loss: 7574.3283 | Val Loss: 7917.6559 | Optimizer: AdamW\n",
      "Trial 6 | Epoch 35 | Train Loss: 6812.7642 | Val Loss: 5990.6624 | Optimizer: AdamW\n",
      "Trial 6 - Early stopping triggered at epoch 35\n",
      "Trial 7 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:53,173] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 | Epoch 01 | Train Loss: 18414.7025 | Val Loss: 12275.0585 | Optimizer: Adam\n",
      "Trial 8 | Epoch 02 | Train Loss: 11678.4854 | Val Loss: 10389.4472 | Optimizer: Adam\n",
      "Trial 8 | Epoch 03 | Train Loss: 11652.7947 | Val Loss: 9423.6070 | Optimizer: Adam\n",
      "Trial 8 | Epoch 04 | Train Loss: 10222.4200 | Val Loss: 9244.9703 | Optimizer: Adam\n",
      "Trial 8 | Epoch 05 | Train Loss: 10004.7690 | Val Loss: 8118.7797 | Optimizer: Adam\n",
      "Trial 8 | Epoch 06 | Train Loss: 8487.1510 | Val Loss: 6046.5025 | Optimizer: Adam\n",
      "Trial 8 | Epoch 07 | Train Loss: 8397.4805 | Val Loss: 6178.3683 | Optimizer: Adam\n",
      "Trial 8 | Epoch 08 | Train Loss: 7405.6785 | Val Loss: 5613.0283 | Optimizer: Adam\n",
      "Trial 8 | Epoch 09 | Train Loss: 7573.1514 | Val Loss: 5843.8423 | Optimizer: Adam\n",
      "Trial 8 | Epoch 10 | Train Loss: 7159.1995 | Val Loss: 5699.8547 | Optimizer: Adam\n",
      "Trial 8 | Epoch 11 | Train Loss: 6823.8289 | Val Loss: 6468.5953 | Optimizer: Adam\n",
      "Trial 8 | Epoch 12 | Train Loss: 6764.0656 | Val Loss: 6101.6251 | Optimizer: Adam\n",
      "Trial 8 | Epoch 13 | Train Loss: 7339.6434 | Val Loss: 6349.6920 | Optimizer: Adam\n",
      "Trial 8 | Epoch 14 | Train Loss: 7329.9364 | Val Loss: 5297.9581 | Optimizer: Adam\n",
      "Trial 8 | Epoch 15 | Train Loss: 5929.9707 | Val Loss: 5373.1807 | Optimizer: Adam\n",
      "Trial 8 | Epoch 16 | Train Loss: 6305.6066 | Val Loss: 6272.0902 | Optimizer: Adam\n",
      "Trial 8 | Epoch 17 | Train Loss: 6699.7994 | Val Loss: 5288.0695 | Optimizer: Adam\n",
      "Trial 8 | Epoch 18 | Train Loss: 5825.9862 | Val Loss: 5243.6613 | Optimizer: Adam\n",
      "Trial 8 | Epoch 19 | Train Loss: 5554.1420 | Val Loss: 5678.4631 | Optimizer: Adam\n",
      "Trial 8 | Epoch 20 | Train Loss: 6053.2234 | Val Loss: 5209.7486 | Optimizer: Adam\n",
      "Trial 8 | Epoch 21 | Train Loss: 5941.6798 | Val Loss: 5215.5829 | Optimizer: Adam\n",
      "Trial 8 | Epoch 22 | Train Loss: 5983.0838 | Val Loss: 5122.9473 | Optimizer: Adam\n",
      "Trial 8 | Epoch 23 | Train Loss: 5849.9575 | Val Loss: 5592.7406 | Optimizer: Adam\n",
      "Trial 8 | Epoch 24 | Train Loss: 6311.1764 | Val Loss: 5327.9475 | Optimizer: Adam\n",
      "Trial 8 | Epoch 25 | Train Loss: 5631.0378 | Val Loss: 5158.0909 | Optimizer: Adam\n",
      "Trial 8 | Epoch 26 | Train Loss: 6142.2334 | Val Loss: 5041.5451 | Optimizer: Adam\n",
      "Trial 8 | Epoch 27 | Train Loss: 5533.2396 | Val Loss: 6251.0352 | Optimizer: Adam\n",
      "Trial 8 | Epoch 28 | Train Loss: 8740.3556 | Val Loss: 8250.1659 | Optimizer: Adam\n",
      "Trial 8 | Epoch 29 | Train Loss: 6104.0685 | Val Loss: 7480.3352 | Optimizer: Adam\n",
      "Trial 8 | Epoch 30 | Train Loss: 6164.5534 | Val Loss: 6773.6767 | Optimizer: Adam\n",
      "Trial 8 | Epoch 31 | Train Loss: 7381.0439 | Val Loss: 5243.6377 | Optimizer: Adam\n",
      "Trial 8 | Epoch 32 | Train Loss: 6279.8738 | Val Loss: 5108.5738 | Optimizer: Adam\n",
      "Trial 8 | Epoch 33 | Train Loss: 6960.5387 | Val Loss: 7580.8426 | Optimizer: Adam\n",
      "Trial 8 | Epoch 34 | Train Loss: 6774.0010 | Val Loss: 5393.0101 | Optimizer: Adam\n",
      "Trial 8 | Epoch 35 | Train Loss: 5885.5559 | Val Loss: 5242.0726 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:55,009] Trial 8 finished with value: 5041.545129846643 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.35612764458112756, 'lr': 0.0009189169772612875, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 2.349467656920903e-06}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 | Epoch 36 | Train Loss: 5784.3935 | Val Loss: 5084.1263 | Optimizer: Adam\n",
      "Trial 8 - Early stopping triggered at epoch 36\n",
      "Trial 9 | Epoch 01 | Train Loss: 18182.1289 | Val Loss: 12629.2969 | Optimizer: RMSprop\n",
      "Trial 9 | Epoch 02 | Train Loss: 10512.2684 | Val Loss: 13156.9573 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:55,257] Trial 9 pruned. \n",
      "[I 2025-09-05 18:59:55,366] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 | Epoch 03 | Train Loss: 10333.1951 | Val Loss: 12765.7452 | Optimizer: RMSprop\n",
      "Trial 10 | Epoch 01 | Train Loss: 21420.7787 | Val Loss: 21476.4468 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:55,482] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 | Epoch 01 | Train Loss: 22107.7970 | Val Loss: 22584.6427 | Optimizer: Adam\n",
      "Trial 12 | Epoch 01 | Train Loss: 19463.6455 | Val Loss: 16345.1535 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 02 | Train Loss: 13281.4543 | Val Loss: 13088.4520 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 03 | Train Loss: 12072.6706 | Val Loss: 8550.4144 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 04 | Train Loss: 9270.7147 | Val Loss: 15311.1166 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 05 | Train Loss: 10860.8160 | Val Loss: 8351.2006 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 06 | Train Loss: 10088.0657 | Val Loss: 6383.9705 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 07 | Train Loss: 7472.2313 | Val Loss: 6144.9340 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 08 | Train Loss: 7430.1338 | Val Loss: 8554.8698 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 09 | Train Loss: 7624.8978 | Val Loss: 7402.3055 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 10 | Train Loss: 7718.7273 | Val Loss: 23018.7686 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 11 | Train Loss: 14053.1739 | Val Loss: 7034.7562 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 12 | Train Loss: 6886.7059 | Val Loss: 6263.9366 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 13 | Train Loss: 7072.7367 | Val Loss: 7553.6808 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 14 | Train Loss: 7261.2203 | Val Loss: 40830.0743 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 15 | Train Loss: 17105.9764 | Val Loss: 8125.1935 | Optimizer: RMSprop\n",
      "Trial 12 | Epoch 16 | Train Loss: 7754.9121 | Val Loss: 6458.2625 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:56,424] Trial 12 finished with value: 6144.934003665124 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.28521461902471096, 'lr': 0.0009538062531716071, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 2.4084023484740054e-05}. Best is trial 4 with value: 4895.3238691165125.\n",
      "[I 2025-09-05 18:59:56,535] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 | Epoch 17 | Train Loss: 7463.5920 | Val Loss: 6187.6516 | Optimizer: RMSprop\n",
      "Trial 12 - Early stopping triggered at epoch 17\n",
      "Trial 13 | Epoch 01 | Train Loss: 22115.8189 | Val Loss: 22018.9758 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:56,661] Trial 14 pruned. \n",
      "[I 2025-09-05 18:59:56,806] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 | Epoch 01 | Train Loss: 22235.4201 | Val Loss: 22098.0740 | Optimizer: AdamW\n",
      "Trial 15 | Epoch 01 | Train Loss: 21594.4020 | Val Loss: 21905.3358 | Optimizer: Adam\n",
      "Trial 16 | Epoch 01 | Train Loss: 18497.1564 | Val Loss: 14331.0536 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 02 | Train Loss: 13502.4014 | Val Loss: 10821.9086 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 03 | Train Loss: 11523.3900 | Val Loss: 10153.5270 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 04 | Train Loss: 11070.3478 | Val Loss: 9712.3665 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 05 | Train Loss: 10177.1393 | Val Loss: 8725.5594 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 06 | Train Loss: 9448.3656 | Val Loss: 7857.8472 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 07 | Train Loss: 8755.5193 | Val Loss: 6892.0728 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 08 | Train Loss: 8078.2533 | Val Loss: 6131.8825 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 09 | Train Loss: 8102.2658 | Val Loss: 5829.6055 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 10 | Train Loss: 7047.7425 | Val Loss: 5830.5977 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 11 | Train Loss: 7778.8632 | Val Loss: 5868.3436 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 12 | Train Loss: 6743.7304 | Val Loss: 7672.4445 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 13 | Train Loss: 9151.2851 | Val Loss: 5573.8672 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 14 | Train Loss: 6468.7886 | Val Loss: 5304.8620 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 15 | Train Loss: 6525.5156 | Val Loss: 5355.6574 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 16 | Train Loss: 6266.6616 | Val Loss: 5850.9419 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 17 | Train Loss: 7499.7511 | Val Loss: 8328.5336 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 18 | Train Loss: 8270.9961 | Val Loss: 5609.1312 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 19 | Train Loss: 6294.7869 | Val Loss: 5970.7171 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 20 | Train Loss: 6589.9515 | Val Loss: 5360.6449 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 21 | Train Loss: 6616.8004 | Val Loss: 5508.3219 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 22 | Train Loss: 7911.7516 | Val Loss: 5464.3374 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:58,103] Trial 16 finished with value: 5304.862024377893 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3128222564081033, 'lr': 0.0005056700478673483, 'activation': 'Swish', 'optimizer': 'AdamW', 'weight_decay': 1.659857613372755e-05}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 | Epoch 23 | Train Loss: 6739.6887 | Val Loss: 7189.9082 | Optimizer: AdamW\n",
      "Trial 16 | Epoch 24 | Train Loss: 7781.9860 | Val Loss: 5637.1688 | Optimizer: AdamW\n",
      "Trial 16 - Early stopping triggered at epoch 24\n",
      "Trial 17 | Epoch 01 | Train Loss: 18344.0937 | Val Loss: 11520.3243 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 02 | Train Loss: 10925.0214 | Val Loss: 10112.7385 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 03 | Train Loss: 10113.0838 | Val Loss: 9112.5618 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 04 | Train Loss: 9469.5033 | Val Loss: 9564.3833 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 05 | Train Loss: 9383.2806 | Val Loss: 8047.5243 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 06 | Train Loss: 8508.7545 | Val Loss: 8117.7146 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 07 | Train Loss: 8294.6991 | Val Loss: 7198.6394 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 08 | Train Loss: 7811.7346 | Val Loss: 7143.0471 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 09 | Train Loss: 7793.6831 | Val Loss: 6904.9328 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 10 | Train Loss: 7781.1391 | Val Loss: 7627.7845 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 11 | Train Loss: 7793.6550 | Val Loss: 6686.3671 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 12 | Train Loss: 7613.4210 | Val Loss: 8407.6826 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 13 | Train Loss: 7503.6711 | Val Loss: 8328.6180 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 14 | Train Loss: 7667.4665 | Val Loss: 10707.8247 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:59,005] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 | Epoch 15 | Train Loss: 8327.0332 | Val Loss: 9094.4134 | Optimizer: RMSprop\n",
      "Trial 17 | Epoch 16 | Train Loss: 7498.8860 | Val Loss: 7213.2735 | Optimizer: RMSprop\n",
      "Trial 18 | Epoch 01 | Train Loss: 21723.3924 | Val Loss: 22195.2944 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:59,143] Trial 18 pruned. \n",
      "[I 2025-09-05 18:59:59,249] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 | Epoch 01 | Train Loss: 21116.4216 | Val Loss: 19968.0652 | Optimizer: Adam\n",
      "Trial 20 | Epoch 01 | Train Loss: 18261.9019 | Val Loss: 13885.3567 | Optimizer: Adam\n",
      "Trial 20 | Epoch 02 | Train Loss: 12811.2327 | Val Loss: 10417.5478 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:59,556] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 | Epoch 03 | Train Loss: 11640.1472 | Val Loss: 9843.5403 | Optimizer: Adam\n",
      "Trial 20 | Epoch 04 | Train Loss: 10984.4684 | Val Loss: 10242.6752 | Optimizer: Adam\n",
      "Trial 20 | Epoch 05 | Train Loss: 11155.1581 | Val Loss: 9899.9366 | Optimizer: Adam\n",
      "Trial 21 | Epoch 01 | Train Loss: 18231.6490 | Val Loss: 11665.2880 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:59,772] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 | Epoch 02 | Train Loss: 12827.9375 | Val Loss: 10970.8426 | Optimizer: Adam\n",
      "Trial 21 | Epoch 03 | Train Loss: 11482.5378 | Val Loss: 10653.9043 | Optimizer: Adam\n",
      "Trial 22 | Epoch 01 | Train Loss: 19493.9644 | Val Loss: 14609.0361 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 18:59:59,984] Trial 22 pruned. \n",
      "[I 2025-09-05 19:00:00,095] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 | Epoch 02 | Train Loss: 12447.7837 | Val Loss: 11068.6745 | Optimizer: Adam\n",
      "Trial 22 | Epoch 03 | Train Loss: 11593.6961 | Val Loss: 10328.7026 | Optimizer: Adam\n",
      "Trial 23 | Epoch 01 | Train Loss: 20930.8919 | Val Loss: 18053.7844 | Optimizer: Adam\n",
      "Trial 24 | Epoch 01 | Train Loss: 19734.1637 | Val Loss: 15835.6678 | Optimizer: Adam\n",
      "Trial 24 | Epoch 02 | Train Loss: 14359.9311 | Val Loss: 10532.2763 | Optimizer: Adam\n",
      "Trial 24 | Epoch 03 | Train Loss: 11320.3157 | Val Loss: 10112.9367 | Optimizer: Adam\n",
      "Trial 24 | Epoch 04 | Train Loss: 10781.0044 | Val Loss: 9368.0493 | Optimizer: Adam\n",
      "Trial 24 | Epoch 05 | Train Loss: 10319.0236 | Val Loss: 8512.6437 | Optimizer: Adam\n",
      "Trial 24 | Epoch 06 | Train Loss: 9817.2587 | Val Loss: 8248.6840 | Optimizer: Adam\n",
      "Trial 24 | Epoch 07 | Train Loss: 10002.4177 | Val Loss: 7499.5688 | Optimizer: Adam\n",
      "Trial 24 | Epoch 08 | Train Loss: 8813.1667 | Val Loss: 9402.4070 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:00,621] Trial 24 pruned. \n",
      "[I 2025-09-05 19:00:00,761] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 | Epoch 09 | Train Loss: 9525.6077 | Val Loss: 7660.9636 | Optimizer: Adam\n",
      "Trial 25 | Epoch 01 | Train Loss: 21012.7895 | Val Loss: 19246.3172 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:00,871] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 27 | Epoch 01 | Train Loss: 19392.1198 | Val Loss: 14728.2466 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:01,201] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 | Epoch 02 | Train Loss: 12072.5317 | Val Loss: 10520.7062 | Optimizer: RMSprop\n",
      "Trial 27 | Epoch 03 | Train Loss: 10187.6914 | Val Loss: 14888.9181 | Optimizer: RMSprop\n",
      "Trial 28 | Epoch 01 | Train Loss: 21563.2778 | Val Loss: 20785.4409 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:01,311] Trial 28 pruned. \n",
      "[I 2025-09-05 19:00:01,468] Trial 29 pruned. \n",
      "[I 2025-09-05 19:00:01,575] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 | Epoch 01 | Train Loss: 17757.3276 | Val Loss: 91311.2861 | Optimizer: AdamW\n",
      "Trial 30 | Epoch 01 | Train Loss: 20921.9402 | Val Loss: 18904.9862 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:01,690] Trial 31 pruned. \n",
      "[I 2025-09-05 19:00:01,816] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 | Epoch 01 | Train Loss: 21569.5930 | Val Loss: 20752.9936 | Optimizer: Adam\n",
      "Trial 32 | Epoch 01 | Train Loss: 22110.7901 | Val Loss: 21699.4340 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:01,934] Trial 33 pruned. \n",
      "[I 2025-09-05 19:00:02,071] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 | Epoch 01 | Train Loss: 21364.3809 | Val Loss: 21536.4079 | Optimizer: Adam\n",
      "Trial 34 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:02,236] Trial 35 pruned. \n",
      "[I 2025-09-05 19:00:02,347] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 | Epoch 01 | Train Loss: 20513.5065 | Val Loss: 17818.4524 | Optimizer: Adam\n",
      "Trial 36 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:02,469] Trial 37 pruned. \n",
      "[I 2025-09-05 19:00:02,626] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 | Epoch 01 | Train Loss: 22105.2289 | Val Loss: 22361.0676 | Optimizer: Adam\n",
      "Trial 38 | Epoch 01 | Train Loss: 20919.9185 | Val Loss: 18043.4887 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:02,729] Trial 39 pruned. \n",
      "[I 2025-09-05 19:00:02,846] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 | Epoch 01 | Train Loss: 16034.5317 | Val Loss: 24857.8595 | Optimizer: RMSprop\n",
      "Trial 40 | Epoch 01 | Train Loss: 22011.7830 | Val Loss: 22005.1576 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:03,068] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 | Epoch 01 | Train Loss: 19231.1712 | Val Loss: 14458.2909 | Optimizer: AdamW\n",
      "Trial 41 | Epoch 02 | Train Loss: 12430.8512 | Val Loss: 10284.4174 | Optimizer: AdamW\n",
      "Trial 41 | Epoch 03 | Train Loss: 11142.1630 | Val Loss: 11899.6287 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:03,330] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 | Epoch 01 | Train Loss: 18983.2471 | Val Loss: 11584.8781 | Optimizer: AdamW\n",
      "Trial 42 | Epoch 02 | Train Loss: 12104.6931 | Val Loss: 10815.6020 | Optimizer: AdamW\n",
      "Trial 42 | Epoch 03 | Train Loss: 11901.9215 | Val Loss: 11586.1464 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:03,509] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 | Epoch 01 | Train Loss: 19784.1168 | Val Loss: 16182.0033 | Optimizer: AdamW\n",
      "Trial 43 | Epoch 02 | Train Loss: 13351.5628 | Val Loss: 13130.7326 | Optimizer: AdamW\n",
      "Trial 44 | Epoch 01 | Train Loss: 22554.9700 | Val Loss: 22058.8608 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:03,614] Trial 44 pruned. \n",
      "[I 2025-09-05 19:00:03,733] Trial 45 pruned. \n",
      "[I 2025-09-05 19:00:03,828] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 | Epoch 01 | Train Loss: 21440.7207 | Val Loss: 21620.4726 | Optimizer: AdamW\n",
      "Trial 46 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 47 | Epoch 01 | Train Loss: 17270.8290 | Val Loss: 14020.8895 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:04,033] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 | Epoch 02 | Train Loss: 12366.3123 | Val Loss: 12012.0623 | Optimizer: RMSprop\n",
      "Trial 47 | Epoch 03 | Train Loss: 10846.8721 | Val Loss: 10473.5828 | Optimizer: RMSprop\n",
      "Trial 48 | Epoch 01 | Train Loss: 19500.0107 | Val Loss: 15457.3522 | Optimizer: Adam\n",
      "Trial 48 | Epoch 02 | Train Loss: 13843.4684 | Val Loss: 10371.6013 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:04,355] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 | Epoch 03 | Train Loss: 12082.0926 | Val Loss: 10099.5462 | Optimizer: Adam\n",
      "Trial 48 | Epoch 04 | Train Loss: 10739.1710 | Val Loss: 10341.4996 | Optimizer: Adam\n",
      "Trial 48 | Epoch 05 | Train Loss: 11187.6546 | Val Loss: 10575.0338 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:04,561] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 | Epoch 01 | Train Loss: 17848.8720 | Val Loss: 12855.9665 | Optimizer: Adam\n",
      "Trial 49 | Epoch 02 | Train Loss: 12341.0486 | Val Loss: 11574.6296 | Optimizer: Adam\n",
      "Trial 49 | Epoch 03 | Train Loss: 13781.1996 | Val Loss: 10795.3403 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:04,704] Trial 50 pruned. \n",
      "[I 2025-09-05 19:00:04,859] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 | Epoch 01 | Train Loss: 21737.0683 | Val Loss: 22055.1724 | Optimizer: AdamW\n",
      "Trial 51 | Epoch 01 | Train Loss: 21559.0977 | Val Loss: 21427.5259 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:05,017] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 | Epoch 01 | Train Loss: 21378.2413 | Val Loss: 21406.2011 | Optimizer: AdamW\n",
      "Trial 53 | Epoch 01 | Train Loss: 21089.7648 | Val Loss: 20662.4095 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:05,178] Trial 53 pruned. \n",
      "[I 2025-09-05 19:00:05,287] Trial 54 pruned. \n",
      "[I 2025-09-05 19:00:05,454] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 | Epoch 01 | Train Loss: 20692.0094 | Val Loss: 18851.0399 | Optimizer: Adam\n",
      "Trial 55 | Epoch 01 | Train Loss: 21619.2368 | Val Loss: 21345.0738 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:05,563] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 | Epoch 01 | Train Loss: 21439.0662 | Val Loss: 20731.7871 | Optimizer: Adam\n",
      "Trial 57 | Epoch 01 | Train Loss: 16020.7649 | Val Loss: 10029.4849 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 02 | Train Loss: 17794.6862 | Val Loss: 10761.6078 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 03 | Train Loss: 10330.7279 | Val Loss: 7536.2369 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 04 | Train Loss: 8528.2598 | Val Loss: 34195.0634 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 05 | Train Loss: 16903.5322 | Val Loss: 7386.0053 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 06 | Train Loss: 8482.5334 | Val Loss: 6407.8713 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 07 | Train Loss: 7849.3581 | Val Loss: 6124.6067 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 08 | Train Loss: 7735.5575 | Val Loss: 7831.5256 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 09 | Train Loss: 8423.8800 | Val Loss: 13881.5605 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 10 | Train Loss: 9725.2917 | Val Loss: 5805.0017 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 11 | Train Loss: 7217.2877 | Val Loss: 5803.7720 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 12 | Train Loss: 7031.0349 | Val Loss: 5684.6504 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 13 | Train Loss: 7062.7476 | Val Loss: 17455.4483 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 14 | Train Loss: 12057.4786 | Val Loss: 5981.9352 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 15 | Train Loss: 6933.9884 | Val Loss: 5972.3664 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 16 | Train Loss: 7119.2419 | Val Loss: 5678.4241 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 17 | Train Loss: 6716.9929 | Val Loss: 6473.9585 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 18 | Train Loss: 6951.9610 | Val Loss: 5396.9226 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 19 | Train Loss: 6566.7036 | Val Loss: 5370.6178 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 20 | Train Loss: 6116.2116 | Val Loss: 10105.5031 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 21 | Train Loss: 7730.0701 | Val Loss: 49512.5170 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 22 | Train Loss: 20141.9160 | Val Loss: 7528.3332 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 23 | Train Loss: 7138.4560 | Val Loss: 5412.2564 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 24 | Train Loss: 6355.1615 | Val Loss: 10079.0075 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 25 | Train Loss: 7693.3225 | Val Loss: 11521.2478 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 26 | Train Loss: 7650.4666 | Val Loss: 9408.5815 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:07,120] Trial 57 finished with value: 5370.617841555749 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3297342560264259, 'lr': 0.0005897786395570446, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.0439629457863275e-05}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 | Epoch 27 | Train Loss: 7327.3374 | Val Loss: 6635.0418 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 28 | Train Loss: 6753.4207 | Val Loss: 12870.6701 | Optimizer: RMSprop\n",
      "Trial 57 | Epoch 29 | Train Loss: 7959.3213 | Val Loss: 6119.7745 | Optimizer: RMSprop\n",
      "Trial 57 - Early stopping triggered at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:07,340] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 | Epoch 01 | Train Loss: 19203.1161 | Val Loss: 13324.9888 | Optimizer: AdamW\n",
      "Trial 58 | Epoch 02 | Train Loss: 12625.2149 | Val Loss: 10286.0780 | Optimizer: AdamW\n",
      "Trial 58 | Epoch 03 | Train Loss: 11395.0268 | Val Loss: 11517.5284 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:07,454] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 | Epoch 01 | Train Loss: 21795.0930 | Val Loss: 20198.4576 | Optimizer: Adam\n",
      "Trial 60 | Epoch 01 | Train Loss: 23519.7650 | Val Loss: 4044656.7068 | Optimizer: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:07,624] Trial 60 pruned. \n",
      "[I 2025-09-05 19:00:07,845] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 | Epoch 01 | Train Loss: 18679.1762 | Val Loss: 13757.8904 | Optimizer: AdamW\n",
      "Trial 61 | Epoch 02 | Train Loss: 12976.0395 | Val Loss: 10500.2357 | Optimizer: AdamW\n",
      "Trial 61 | Epoch 03 | Train Loss: 11988.9649 | Val Loss: 10304.7760 | Optimizer: AdamW\n",
      "Trial 62 | Epoch 01 | Train Loss: 17582.7035 | Val Loss: 11939.1513 | Optimizer: AdamW\n",
      "Trial 62 | Epoch 02 | Train Loss: 11546.7679 | Val Loss: 12430.7539 | Optimizer: AdamW\n",
      "Trial 62 | Epoch 03 | Train Loss: 13470.5586 | Val Loss: 9976.3998 | Optimizer: AdamW\n",
      "Trial 62 | Epoch 04 | Train Loss: 10909.9300 | Val Loss: 10202.9135 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:08,175] Trial 62 pruned. \n",
      "[I 2025-09-05 19:00:08,284] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 | Epoch 05 | Train Loss: 10760.4758 | Val Loss: 9299.6267 | Optimizer: AdamW\n",
      "Trial 63 | Epoch 01 | Train Loss: 21872.6684 | Val Loss: 21124.9614 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 01 | Train Loss: 18249.7788 | Val Loss: 11762.4321 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 02 | Train Loss: 11714.4292 | Val Loss: 10569.9854 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 03 | Train Loss: 11258.0825 | Val Loss: 9488.3326 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 04 | Train Loss: 9773.4718 | Val Loss: 7711.5902 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 05 | Train Loss: 8496.2073 | Val Loss: 7533.4448 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 06 | Train Loss: 7788.8766 | Val Loss: 5625.6416 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 07 | Train Loss: 7322.0306 | Val Loss: 5503.0114 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 08 | Train Loss: 7058.7412 | Val Loss: 6224.2737 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 09 | Train Loss: 7702.9532 | Val Loss: 7746.3104 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 10 | Train Loss: 10107.6931 | Val Loss: 9147.6876 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 11 | Train Loss: 11670.2955 | Val Loss: 12409.9022 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 12 | Train Loss: 11183.7469 | Val Loss: 5925.6898 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 13 | Train Loss: 7418.8277 | Val Loss: 5973.9125 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 14 | Train Loss: 6930.4196 | Val Loss: 6371.6061 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 15 | Train Loss: 6937.6128 | Val Loss: 5381.1529 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 16 | Train Loss: 8928.4716 | Val Loss: 5154.6870 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 17 | Train Loss: 7030.6544 | Val Loss: 6303.2482 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 18 | Train Loss: 6563.1277 | Val Loss: 5261.3784 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 19 | Train Loss: 6405.5195 | Val Loss: 5409.6409 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 20 | Train Loss: 6126.6402 | Val Loss: 5331.1254 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 21 | Train Loss: 6080.5611 | Val Loss: 5667.1368 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 22 | Train Loss: 7362.2029 | Val Loss: 6301.5237 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 23 | Train Loss: 6256.7165 | Val Loss: 5708.1124 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:09,876] Trial 64 finished with value: 5154.686996648341 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3254243160531117, 'lr': 0.0008770788250256469, 'activation': 'Swish', 'optimizer': 'AdamW', 'weight_decay': 1.0873995636900527e-05}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 | Epoch 24 | Train Loss: 6149.1330 | Val Loss: 5334.2965 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 25 | Train Loss: 6143.2599 | Val Loss: 5399.9213 | Optimizer: AdamW\n",
      "Trial 64 | Epoch 26 | Train Loss: 6147.4068 | Val Loss: 5161.7721 | Optimizer: AdamW\n",
      "Trial 64 - Early stopping triggered at epoch 26\n",
      "Trial 65 | Epoch 01 | Train Loss: 18795.7763 | Val Loss: 12189.5834 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:10,085] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 | Epoch 02 | Train Loss: 11846.8365 | Val Loss: 10806.1291 | Optimizer: AdamW\n",
      "Trial 65 | Epoch 03 | Train Loss: 11433.8493 | Val Loss: 10465.5194 | Optimizer: AdamW\n",
      "Trial 66 | Epoch 01 | Train Loss: 19662.2253 | Val Loss: 15085.7398 | Optimizer: Adam\n",
      "Trial 66 | Epoch 02 | Train Loss: 12664.6359 | Val Loss: 10440.4511 | Optimizer: Adam\n",
      "Trial 66 | Epoch 03 | Train Loss: 10941.9318 | Val Loss: 9827.8916 | Optimizer: Adam\n",
      "Trial 66 | Epoch 04 | Train Loss: 10013.2809 | Val Loss: 8790.7099 | Optimizer: Adam\n",
      "Trial 66 | Epoch 05 | Train Loss: 9058.8860 | Val Loss: 7963.4157 | Optimizer: Adam\n",
      "Trial 66 | Epoch 06 | Train Loss: 9112.3674 | Val Loss: 5758.5422 | Optimizer: Adam\n",
      "Trial 66 | Epoch 07 | Train Loss: 7741.9527 | Val Loss: 6821.2376 | Optimizer: Adam\n",
      "Trial 66 | Epoch 08 | Train Loss: 8206.4420 | Val Loss: 5601.9688 | Optimizer: Adam\n",
      "Trial 66 | Epoch 09 | Train Loss: 7132.1089 | Val Loss: 6169.6239 | Optimizer: Adam\n",
      "Trial 66 | Epoch 10 | Train Loss: 7576.5103 | Val Loss: 5767.3931 | Optimizer: Adam\n",
      "Trial 66 | Epoch 11 | Train Loss: 6727.0175 | Val Loss: 6001.2665 | Optimizer: Adam\n",
      "Trial 66 | Epoch 12 | Train Loss: 7591.7928 | Val Loss: 5900.5471 | Optimizer: Adam\n",
      "Trial 66 | Epoch 13 | Train Loss: 7223.7099 | Val Loss: 5749.3887 | Optimizer: Adam\n",
      "Trial 66 | Epoch 14 | Train Loss: 6216.8413 | Val Loss: 6231.2444 | Optimizer: Adam\n",
      "Trial 66 | Epoch 15 | Train Loss: 9489.8047 | Val Loss: 6957.3896 | Optimizer: Adam\n",
      "Trial 66 | Epoch 16 | Train Loss: 9194.7476 | Val Loss: 10413.5890 | Optimizer: Adam\n",
      "Trial 66 | Epoch 17 | Train Loss: 9396.0415 | Val Loss: 6420.9073 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:11,180] Trial 66 finished with value: 5601.968828366126 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.36452763896294366, 'lr': 0.0006188124850156175, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 8.31164154954343e-06}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 | Epoch 18 | Train Loss: 7361.6715 | Val Loss: 6324.1298 | Optimizer: Adam\n",
      "Trial 66 - Early stopping triggered at epoch 18\n",
      "Trial 67 | Epoch 01 | Train Loss: 17309.6981 | Val Loss: 12035.8050 | Optimizer: AdamW\n",
      "Trial 67 | Epoch 02 | Train Loss: 11961.2144 | Val Loss: 11823.5375 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:11,354] Trial 67 pruned. \n",
      "[I 2025-09-05 19:00:11,475] Trial 68 pruned. \n",
      "[I 2025-09-05 19:00:11,583] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 | Epoch 01 | Train Loss: 20100.4519 | Val Loss: 18782.6994 | Optimizer: Adam\n",
      "Trial 69 | Epoch 01 | Train Loss: 20721.2156 | Val Loss: 19656.6884 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:11,741] Trial 70 pruned. \n",
      "[I 2025-09-05 19:00:11,849] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 | Epoch 01 | Train Loss: 20621.9527 | Val Loss: 17353.3133 | Optimizer: AdamW\n",
      "Trial 71 | Epoch 01 | Train Loss: 21474.4414 | Val Loss: 21981.1940 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:12,015] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 | Epoch 01 | Train Loss: 17706.5273 | Val Loss: 11187.6777 | Optimizer: AdamW\n",
      "Trial 72 | Epoch 02 | Train Loss: 11921.4243 | Val Loss: 11887.2393 | Optimizer: AdamW\n",
      "Trial 73 | Epoch 01 | Train Loss: 19562.6071 | Val Loss: 14355.1678 | Optimizer: AdamW\n",
      "Trial 73 | Epoch 02 | Train Loss: 13444.0112 | Val Loss: 10596.8604 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:12,219] Trial 73 pruned. \n",
      "[I 2025-09-05 19:00:12,327] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 | Epoch 03 | Train Loss: 11724.6022 | Val Loss: 10658.5914 | Optimizer: AdamW\n",
      "Trial 74 | Epoch 01 | Train Loss: 21097.2420 | Val Loss: 19830.6830 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:12,460] Trial 75 pruned. \n",
      "[I 2025-09-05 19:00:12,590] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 | Epoch 01 | Train Loss: 1446187.3305 | Val Loss: 28918.2694 | Optimizer: RMSprop\n",
      "Trial 76 | Epoch 01 | Train Loss: 19696.2003 | Val Loss: 16159.7561 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:12,680] Trial 77 pruned. \n",
      "[I 2025-09-05 19:00:12,796] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 78 | Epoch 01 | Train Loss: 21732.7578 | Val Loss: 22061.4992 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:12,955] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 | Epoch 01 | Train Loss: 19674.5411 | Val Loss: 15637.0244 | Optimizer: Adam\n",
      "Trial 79 | Epoch 02 | Train Loss: 14291.0804 | Val Loss: 11411.9707 | Optimizer: Adam\n",
      "Trial 80 | Epoch 01 | Train Loss: 20098.7185 | Val Loss: 16796.6557 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:13,072] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 | Epoch 01 | Train Loss: 19683.3535 | Val Loss: 11322.8192 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 02 | Train Loss: 11942.3133 | Val Loss: 7680.2847 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 03 | Train Loss: 8298.2695 | Val Loss: 305281.9223 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 04 | Train Loss: 71010.2956 | Val Loss: 14665.9682 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 05 | Train Loss: 13287.1794 | Val Loss: 8259.7597 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 06 | Train Loss: 9390.1258 | Val Loss: 6207.6341 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 07 | Train Loss: 7471.4061 | Val Loss: 5659.1690 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 08 | Train Loss: 7846.9781 | Val Loss: 6085.7767 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 09 | Train Loss: 7223.4790 | Val Loss: 5471.8524 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 10 | Train Loss: 7265.9161 | Val Loss: 5655.0826 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 11 | Train Loss: 7296.2084 | Val Loss: 5620.9122 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 12 | Train Loss: 7069.8272 | Val Loss: 5496.0016 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 13 | Train Loss: 7393.2891 | Val Loss: 5397.3230 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 14 | Train Loss: 6914.7183 | Val Loss: 8429.0782 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 15 | Train Loss: 7512.1235 | Val Loss: 5256.8307 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 16 | Train Loss: 7040.3377 | Val Loss: 8166.1966 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 17 | Train Loss: 7299.0717 | Val Loss: 5402.5387 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 18 | Train Loss: 6625.8403 | Val Loss: 5394.8150 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 19 | Train Loss: 6493.3517 | Val Loss: 6226.4407 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 20 | Train Loss: 7006.3833 | Val Loss: 5672.6270 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 21 | Train Loss: 6479.0999 | Val Loss: 5376.2360 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 22 | Train Loss: 6392.1348 | Val Loss: 9457.6931 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 23 | Train Loss: 8387.3565 | Val Loss: 6004.1184 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:14,922] Trial 81 finished with value: 5256.830708068094 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.32998068704503075, 'lr': 0.0006025493886575723, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.0599936251987833e-05}. Best is trial 4 with value: 4895.3238691165125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 | Epoch 24 | Train Loss: 6769.5208 | Val Loss: 6411.1678 | Optimizer: RMSprop\n",
      "Trial 81 | Epoch 25 | Train Loss: 6577.9356 | Val Loss: 5962.8397 | Optimizer: RMSprop\n",
      "Trial 81 - Early stopping triggered at epoch 25\n",
      "Trial 82 | Epoch 01 | Train Loss: 16885.7738 | Val Loss: 12809.9564 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 02 | Train Loss: 12049.5643 | Val Loss: 9024.6080 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 03 | Train Loss: 9348.3307 | Val Loss: 10740.5984 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 04 | Train Loss: 9660.4803 | Val Loss: 22035.2991 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 05 | Train Loss: 13000.9764 | Val Loss: 7830.8766 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 06 | Train Loss: 8362.0632 | Val Loss: 6076.3017 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 07 | Train Loss: 7955.1817 | Val Loss: 5909.9257 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 08 | Train Loss: 7619.0784 | Val Loss: 6337.3571 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 09 | Train Loss: 7277.4975 | Val Loss: 5856.3488 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 10 | Train Loss: 7077.7149 | Val Loss: 11116.6944 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 11 | Train Loss: 9581.2477 | Val Loss: 8718.2637 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 12 | Train Loss: 7966.5639 | Val Loss: 5893.5694 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 13 | Train Loss: 7063.6275 | Val Loss: 7010.1870 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 14 | Train Loss: 6818.5084 | Val Loss: 6624.5407 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 15 | Train Loss: 7223.9203 | Val Loss: 8280.6358 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 16 | Train Loss: 6897.6406 | Val Loss: 5545.9192 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 17 | Train Loss: 6439.9331 | Val Loss: 7931.5197 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 18 | Train Loss: 6897.9236 | Val Loss: 5430.9329 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 19 | Train Loss: 6221.4479 | Val Loss: 13063.4951 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 20 | Train Loss: 8839.6427 | Val Loss: 8464.8106 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 21 | Train Loss: 6526.6311 | Val Loss: 23817.5735 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 22 | Train Loss: 13319.6890 | Val Loss: 7696.7020 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 23 | Train Loss: 6940.3866 | Val Loss: 5373.8557 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 24 | Train Loss: 6122.6384 | Val Loss: 5245.8322 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 25 | Train Loss: 5955.0001 | Val Loss: 5805.3435 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 26 | Train Loss: 6265.8519 | Val Loss: 14160.0741 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 27 | Train Loss: 8189.1099 | Val Loss: 6400.5334 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 28 | Train Loss: 6373.4009 | Val Loss: 5170.7823 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 29 | Train Loss: 5892.1447 | Val Loss: 5570.3272 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 30 | Train Loss: 5900.1414 | Val Loss: 5095.0064 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 31 | Train Loss: 5732.5105 | Val Loss: 4992.4513 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 32 | Train Loss: 5634.1071 | Val Loss: 5711.1249 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 33 | Train Loss: 5400.8852 | Val Loss: 4888.9511 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 34 | Train Loss: 5519.6015 | Val Loss: 5101.3969 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 35 | Train Loss: 5714.7012 | Val Loss: 5275.7388 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 36 | Train Loss: 5929.9210 | Val Loss: 7772.2159 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 37 | Train Loss: 6277.4553 | Val Loss: 9270.7508 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 38 | Train Loss: 6432.3795 | Val Loss: 7926.8410 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 39 | Train Loss: 6930.3862 | Val Loss: 5656.7291 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 40 | Train Loss: 5577.9192 | Val Loss: 7047.9853 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 41 | Train Loss: 6207.4803 | Val Loss: 5170.8981 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:18,873] Trial 82 finished with value: 4888.95108748071 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.27876939870047435, 'lr': 0.0005771166905138669, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.518316725621616e-05}. Best is trial 82 with value: 4888.95108748071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 | Epoch 42 | Train Loss: 5319.1335 | Val Loss: 7644.8821 | Optimizer: RMSprop\n",
      "Trial 82 | Epoch 43 | Train Loss: 6066.0592 | Val Loss: 7252.2764 | Optimizer: RMSprop\n",
      "Trial 82 - Early stopping triggered at epoch 43\n",
      "Trial 83 | Epoch 01 | Train Loss: 15389.8896 | Val Loss: 10787.8028 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 02 | Train Loss: 13041.5515 | Val Loss: 11357.8222 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 03 | Train Loss: 10531.1278 | Val Loss: 6371.1379 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 04 | Train Loss: 8811.6643 | Val Loss: 14557.4386 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 05 | Train Loss: 11664.9838 | Val Loss: 6880.9593 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 06 | Train Loss: 9172.8626 | Val Loss: 6957.5577 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 07 | Train Loss: 7835.4339 | Val Loss: 5929.6888 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 08 | Train Loss: 7569.5991 | Val Loss: 5958.1033 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 09 | Train Loss: 9431.8974 | Val Loss: 7723.7666 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 10 | Train Loss: 7727.2002 | Val Loss: 5734.8863 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 11 | Train Loss: 6690.4449 | Val Loss: 6641.4301 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 12 | Train Loss: 7085.3479 | Val Loss: 11313.9844 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 13 | Train Loss: 9150.4109 | Val Loss: 6831.0283 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 14 | Train Loss: 7352.8859 | Val Loss: 6059.9991 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 15 | Train Loss: 6637.3008 | Val Loss: 8495.6753 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 16 | Train Loss: 7658.6155 | Val Loss: 20040.5854 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 17 | Train Loss: 12910.0652 | Val Loss: 5574.9707 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 18 | Train Loss: 7192.2342 | Val Loss: 6200.0162 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 19 | Train Loss: 6665.4328 | Val Loss: 5561.1758 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 20 | Train Loss: 6713.0678 | Val Loss: 5903.7496 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 21 | Train Loss: 6558.1187 | Val Loss: 5422.9427 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 22 | Train Loss: 6237.5784 | Val Loss: 5535.2645 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 23 | Train Loss: 6303.2068 | Val Loss: 8017.0526 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 24 | Train Loss: 6858.3679 | Val Loss: 5743.3761 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 25 | Train Loss: 5908.4395 | Val Loss: 6556.2821 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 26 | Train Loss: 5844.7651 | Val Loss: 12112.8460 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 27 | Train Loss: 8624.1184 | Val Loss: 6059.2462 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 28 | Train Loss: 5792.2771 | Val Loss: 5502.7938 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 29 | Train Loss: 6130.2886 | Val Loss: 6487.0272 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 30 | Train Loss: 6184.2522 | Val Loss: 6648.7287 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 31 | Train Loss: 6472.2406 | Val Loss: 5113.4606 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 32 | Train Loss: 5832.6980 | Val Loss: 5454.6607 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 33 | Train Loss: 6170.4172 | Val Loss: 5210.8839 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 34 | Train Loss: 5810.9038 | Val Loss: 5264.5668 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 35 | Train Loss: 5792.4650 | Val Loss: 9983.9169 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 36 | Train Loss: 7151.6866 | Val Loss: 5350.7867 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 37 | Train Loss: 5921.1154 | Val Loss: 6004.0260 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 38 | Train Loss: 5971.1779 | Val Loss: 4950.5633 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 39 | Train Loss: 5372.7549 | Val Loss: 5445.9702 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 40 | Train Loss: 5626.3549 | Val Loss: 5492.7848 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 41 | Train Loss: 5884.6699 | Val Loss: 17000.1035 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 42 | Train Loss: 9262.8409 | Val Loss: 6185.3706 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 43 | Train Loss: 6393.0833 | Val Loss: 5106.4169 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 44 | Train Loss: 5698.4280 | Val Loss: 4778.9363 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 45 | Train Loss: 5048.9806 | Val Loss: 23891.7200 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 46 | Train Loss: 11785.4485 | Val Loss: 5558.8429 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 47 | Train Loss: 5909.2965 | Val Loss: 5081.9049 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 48 | Train Loss: 5460.4367 | Val Loss: 4898.0723 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 49 | Train Loss: 5604.3515 | Val Loss: 6166.5226 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 50 | Train Loss: 5585.8159 | Val Loss: 4725.6817 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 51 | Train Loss: 5198.5469 | Val Loss: 10476.6999 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 52 | Train Loss: 6803.4620 | Val Loss: 4636.1918 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 53 | Train Loss: 5444.4964 | Val Loss: 6357.8022 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 54 | Train Loss: 5750.3071 | Val Loss: 9268.0308 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 55 | Train Loss: 5469.1474 | Val Loss: 4960.5667 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 56 | Train Loss: 4921.8245 | Val Loss: 9933.6511 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 57 | Train Loss: 6522.4218 | Val Loss: 5033.4383 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 58 | Train Loss: 5200.6159 | Val Loss: 12458.5978 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 59 | Train Loss: 8139.2792 | Val Loss: 5306.1012 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 60 | Train Loss: 5594.5249 | Val Loss: 4860.7671 | Optimizer: RMSprop\n",
      "Trial 83 | Epoch 61 | Train Loss: 5233.1905 | Val Loss: 5212.9443 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:24,658] Trial 83 finished with value: 4636.191819179206 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3584274447765387, 'lr': 0.0005990547500235965, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 9.325930827977706e-06}. Best is trial 83 with value: 4636.191819179206.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 | Epoch 62 | Train Loss: 4881.3492 | Val Loss: 5432.1179 | Optimizer: RMSprop\n",
      "Trial 83 - Early stopping triggered at epoch 62\n",
      "Trial 84 | Epoch 01 | Train Loss: 15923.3301 | Val Loss: 9257.5431 | Optimizer: RMSprop\n",
      "Trial 84 | Epoch 02 | Train Loss: 40929.1045 | Val Loss: 17223.7619 | Optimizer: RMSprop\n",
      "Trial 84 | Epoch 03 | Train Loss: 14687.0446 | Val Loss: 8308.2209 | Optimizer: RMSprop\n",
      "Trial 84 | Epoch 04 | Train Loss: 8660.0773 | Val Loss: 9842.2552 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:25,196] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 | Epoch 05 | Train Loss: 9530.2941 | Val Loss: 13174.7588 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 01 | Train Loss: 22988.8590 | Val Loss: 10238.9877 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 02 | Train Loss: 12006.7109 | Val Loss: 9592.8315 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 03 | Train Loss: 9581.9338 | Val Loss: 6227.6544 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 04 | Train Loss: 7566.7183 | Val Loss: 5918.1820 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 05 | Train Loss: 7604.8570 | Val Loss: 14784.0768 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 06 | Train Loss: 11419.9992 | Val Loss: 7329.2869 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 07 | Train Loss: 7665.3843 | Val Loss: 7449.8943 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 08 | Train Loss: 7952.2569 | Val Loss: 38495.3870 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 09 | Train Loss: 17481.0575 | Val Loss: 7584.7527 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 10 | Train Loss: 8053.0706 | Val Loss: 10507.2764 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 11 | Train Loss: 8672.0610 | Val Loss: 5842.2255 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 12 | Train Loss: 7167.9561 | Val Loss: 7804.7983 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 13 | Train Loss: 7492.6647 | Val Loss: 5951.2943 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 14 | Train Loss: 6870.8723 | Val Loss: 8310.3234 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 15 | Train Loss: 6768.2373 | Val Loss: 8055.0278 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 16 | Train Loss: 7219.1158 | Val Loss: 5805.3796 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 17 | Train Loss: 6803.0854 | Val Loss: 9698.7469 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 18 | Train Loss: 7414.2076 | Val Loss: 10191.6401 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 19 | Train Loss: 7868.1271 | Val Loss: 7385.4200 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 20 | Train Loss: 6706.7422 | Val Loss: 11973.8761 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 21 | Train Loss: 8684.0922 | Val Loss: 6835.1288 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 22 | Train Loss: 6199.9101 | Val Loss: 5308.8730 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 23 | Train Loss: 6064.0443 | Val Loss: 5328.3724 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 24 | Train Loss: 5665.2442 | Val Loss: 6225.9502 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 25 | Train Loss: 6119.9715 | Val Loss: 5411.1431 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 26 | Train Loss: 5655.4049 | Val Loss: 6914.0905 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 27 | Train Loss: 7019.7446 | Val Loss: 5334.0746 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 28 | Train Loss: 5631.9569 | Val Loss: 11895.5495 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 29 | Train Loss: 8872.3848 | Val Loss: 5771.2227 | Optimizer: RMSprop\n",
      "Trial 85 | Epoch 30 | Train Loss: 6103.4895 | Val Loss: 10106.7041 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:28,097] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 | Epoch 31 | Train Loss: 7419.9578 | Val Loss: 21528.8410 | Optimizer: RMSprop\n",
      "Trial 86 | Epoch 01 | Train Loss: 23934.8886 | Val Loss: 216959.4309 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:28,282] Trial 86 pruned. \n",
      "[I 2025-09-05 19:00:28,567] Trial 87 pruned. \n",
      "[I 2025-09-05 19:00:28,721] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 | Epoch 01 | Train Loss: 19410.3814 | Val Loss: 16615.9246 | Optimizer: RMSprop\n",
      "Trial 88 | Epoch 01 | Train Loss: 19779.8118 | Val Loss: 15159.5496 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:28,904] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 | Epoch 01 | Train Loss: 19101.3196 | Val Loss: 14659.0189 | Optimizer: RMSprop\n",
      "Trial 90 | Epoch 01 | Train Loss: 55194.6040 | Val Loss: 14547.7076 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:29,072] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 | Epoch 01 | Train Loss: 15591.3854 | Val Loss: 10535.2642 | Optimizer: RMSprop\n",
      "Trial 91 | Epoch 02 | Train Loss: 11212.7702 | Val Loss: 12343.6965 | Optimizer: RMSprop\n",
      "Trial 91 | Epoch 03 | Train Loss: 10435.4071 | Val Loss: 10191.7295 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:29,453] Trial 91 pruned. \n",
      "[I 2025-09-05 19:00:29,720] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 | Epoch 01 | Train Loss: 12817.6035 | Val Loss: 14571.5300 | Optimizer: RMSprop\n",
      "Trial 93 | Epoch 01 | Train Loss: 16704.3357 | Val Loss: 10709.2764 | Optimizer: RMSprop\n",
      "Trial 93 | Epoch 02 | Train Loss: 13329.8881 | Val Loss: 10866.5276 | Optimizer: RMSprop\n",
      "Trial 93 | Epoch 03 | Train Loss: 9934.9078 | Val Loss: 8798.2069 | Optimizer: RMSprop\n",
      "Trial 93 | Epoch 04 | Train Loss: 9254.3796 | Val Loss: 13009.7937 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:30,295] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 | Epoch 05 | Train Loss: 9323.9527 | Val Loss: 142528.8812 | Optimizer: RMSprop\n",
      "Trial 94 | Epoch 01 | Train Loss: 14693.9921 | Val Loss: 10801.9735 | Optimizer: RMSprop\n",
      "Trial 94 | Epoch 02 | Train Loss: 12435.4553 | Val Loss: 10422.7616 | Optimizer: RMSprop\n",
      "Trial 94 | Epoch 03 | Train Loss: 10891.2638 | Val Loss: 8131.8160 | Optimizer: RMSprop\n",
      "Trial 94 | Epoch 04 | Train Loss: 10878.5430 | Val Loss: 9363.4064 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:30,934] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 | Epoch 05 | Train Loss: 8800.0867 | Val Loss: 355547.7755 | Optimizer: RMSprop\n",
      "Trial 94 | Epoch 06 | Train Loss: 89766.5357 | Val Loss: 12173.7280 | Optimizer: RMSprop\n",
      "Trial 95 | Epoch 01 | Train Loss: 18743.3694 | Val Loss: 14248.3990 | Optimizer: Adam\n",
      "Trial 95 | Epoch 02 | Train Loss: 12796.6439 | Val Loss: 10552.5556 | Optimizer: Adam\n",
      "Trial 95 | Epoch 03 | Train Loss: 12267.7519 | Val Loss: 10696.4584 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:31,308] Trial 95 pruned. \n",
      "[I 2025-09-05 19:00:31,503] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 | Epoch 01 | Train Loss: 21711.4079 | Val Loss: 17007.3021 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:31,855] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 | Epoch 01 | Train Loss: 21526.5153 | Val Loss: 21053.0791 | Optimizer: Adam\n",
      "Trial 98 | Epoch 01 | Train Loss: 16378.6464 | Val Loss: 9957.3255 | Optimizer: RMSprop\n",
      "Trial 98 | Epoch 02 | Train Loss: 9984.9807 | Val Loss: 9022.2716 | Optimizer: RMSprop\n",
      "Trial 98 | Epoch 03 | Train Loss: 8978.4894 | Val Loss: 10138.2597 | Optimizer: RMSprop\n",
      "Trial 98 | Epoch 04 | Train Loss: 8802.8340 | Val Loss: 7210.0752 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:32,518] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 | Epoch 05 | Train Loss: 7777.7179 | Val Loss: 7291.1440 | Optimizer: RMSprop\n",
      "Trial 98 | Epoch 06 | Train Loss: 7871.7159 | Val Loss: 22627.9728 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:32,691] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 100 | Epoch 01 | Train Loss: 17840.5529 | Val Loss: 12411.9830 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:32,978] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 | Epoch 02 | Train Loss: 11570.4594 | Val Loss: 11306.3361 | Optimizer: Adam\n",
      "Trial 101 | Epoch 01 | Train Loss: 21139.0361 | Val Loss: 18865.9870 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:33,152] Trial 101 pruned. \n",
      "[I 2025-09-05 19:00:33,429] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 | Epoch 01 | Train Loss: 18400.6398 | Val Loss: 12419.2816 | Optimizer: AdamW\n",
      "Trial 102 | Epoch 02 | Train Loss: 11893.0664 | Val Loss: 10837.8800 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:33,587] Trial 103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 | Epoch 01 | Train Loss: 20197.2969 | Val Loss: 17259.6626 | Optimizer: AdamW\n",
      "Trial 104 | Epoch 01 | Train Loss: 19166.8727 | Val Loss: 14041.7050 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:34,026] Trial 104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 | Epoch 02 | Train Loss: 12712.6286 | Val Loss: 10657.2649 | Optimizer: AdamW\n",
      "Trial 104 | Epoch 03 | Train Loss: 12000.6928 | Val Loss: 11252.6546 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:34,221] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 | Epoch 01 | Train Loss: 20584.6626 | Val Loss: 17869.4487 | Optimizer: Adam\n",
      "Trial 106 | Epoch 01 | Train Loss: 19217.4505 | Val Loss: 10725.9548 | Optimizer: AdamW\n",
      "Trial 106 | Epoch 02 | Train Loss: 12019.5464 | Val Loss: 11302.8758 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:34,782] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 | Epoch 03 | Train Loss: 9701.1501 | Val Loss: 14461.6448 | Optimizer: AdamW\n",
      "Trial 107 | Epoch 01 | Train Loss: 20028.1910 | Val Loss: 17003.9769 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:34,944] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 | Epoch 01 | Train Loss: 19043.6992 | Val Loss: 12845.7867 | Optimizer: Adam\n",
      "Trial 108 | Epoch 02 | Train Loss: 12700.2753 | Val Loss: 10246.6323 | Optimizer: Adam\n",
      "Trial 108 | Epoch 03 | Train Loss: 11433.5428 | Val Loss: 10899.3792 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:35,289] Trial 108 pruned. \n",
      "[I 2025-09-05 19:00:35,468] Trial 109 pruned. \n",
      "[I 2025-09-05 19:00:35,624] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 | Epoch 01 | Train Loss: 15831.0936 | Val Loss: 18758.1171 | Optimizer: RMSprop\n",
      "Trial 110 | Epoch 01 | Train Loss: 20849.7920 | Val Loss: 19539.6497 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:35,872] Trial 111 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 | Epoch 01 | Train Loss: 16994.9479 | Val Loss: 16445.6883 | Optimizer: RMSprop\n",
      "Trial 112 | Epoch 01 | Train Loss: 16984.8711 | Val Loss: 13159.0093 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:36,348] Trial 112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 | Epoch 02 | Train Loss: 12427.0641 | Val Loss: 10776.1605 | Optimizer: RMSprop\n",
      "Trial 112 | Epoch 03 | Train Loss: 11299.9672 | Val Loss: 12554.8546 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:36,543] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 | Epoch 01 | Train Loss: 38386.8892 | Val Loss: 18571.8035 | Optimizer: RMSprop\n",
      "Trial 114 | Epoch 01 | Train Loss: 14051.4231 | Val Loss: 11089.3154 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:36,810] Trial 114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 | Epoch 02 | Train Loss: 11416.0157 | Val Loss: 12105.8875 | Optimizer: RMSprop\n",
      "Trial 115 | Epoch 01 | Train Loss: 18286.6120 | Val Loss: 11829.6926 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:37,169] Trial 115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 | Epoch 02 | Train Loss: 11169.1361 | Val Loss: 9947.3006 | Optimizer: Adam\n",
      "Trial 115 | Epoch 03 | Train Loss: 11169.3475 | Val Loss: 10804.5201 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:37,367] Trial 116 pruned. \n",
      "[I 2025-09-05 19:00:37,495] Trial 117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 | Epoch 01 | Train Loss: 20116.6986 | Val Loss: 17149.8623 | Optimizer: AdamW\n",
      "Trial 117 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:37,769] Trial 118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 | Epoch 01 | Train Loss: 19402.1206 | Val Loss: 16634.0829 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:38,040] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 | Epoch 01 | Train Loss: 21833.5588 | Val Loss: 21344.2042 | Optimizer: AdamW\n",
      "Trial 120 | Epoch 01 | Train Loss: 21632.4763 | Val Loss: 21885.5373 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:38,211] Trial 120 pruned. \n",
      "[I 2025-09-05 19:00:38,426] Trial 121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 | Epoch 01 | Train Loss: 19820.7079 | Val Loss: 15287.6740 | Optimizer: Adam\n",
      "Trial 122 | Epoch 01 | Train Loss: 18807.1647 | Val Loss: 13944.5703 | Optimizer: Adam\n",
      "Trial 122 | Epoch 02 | Train Loss: 12659.2481 | Val Loss: 10087.5023 | Optimizer: Adam\n",
      "Trial 122 | Epoch 03 | Train Loss: 10677.2839 | Val Loss: 9764.1572 | Optimizer: Adam\n",
      "Trial 122 | Epoch 04 | Train Loss: 10488.1688 | Val Loss: 8043.6744 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:39,154] Trial 122 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 | Epoch 05 | Train Loss: 9088.3239 | Val Loss: 6997.9759 | Optimizer: Adam\n",
      "Trial 122 | Epoch 06 | Train Loss: 9680.2561 | Val Loss: 7706.3657 | Optimizer: Adam\n",
      "Trial 123 | Epoch 01 | Train Loss: 18194.2641 | Val Loss: 10306.2154 | Optimizer: Adam\n",
      "Trial 123 | Epoch 02 | Train Loss: 11640.9112 | Val Loss: 11050.2534 | Optimizer: Adam\n",
      "Trial 123 | Epoch 03 | Train Loss: 11777.6541 | Val Loss: 9745.0422 | Optimizer: Adam\n",
      "Trial 123 | Epoch 04 | Train Loss: 9684.5646 | Val Loss: 6863.4454 | Optimizer: Adam\n",
      "Trial 123 | Epoch 05 | Train Loss: 9189.2633 | Val Loss: 7854.6305 | Optimizer: Adam\n",
      "Trial 123 | Epoch 06 | Train Loss: 8311.9033 | Val Loss: 6469.2392 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:40,006] Trial 123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 | Epoch 07 | Train Loss: 7718.1000 | Val Loss: 7016.7041 | Optimizer: Adam\n",
      "Trial 123 | Epoch 08 | Train Loss: 7719.1601 | Val Loss: 10610.6287 | Optimizer: Adam\n",
      "Trial 124 | Epoch 01 | Train Loss: 18945.0258 | Val Loss: 12801.6718 | Optimizer: Adam\n",
      "Trial 124 | Epoch 02 | Train Loss: 11821.7235 | Val Loss: 10173.9070 | Optimizer: Adam\n",
      "Trial 124 | Epoch 03 | Train Loss: 11353.2365 | Val Loss: 10607.1526 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:40,396] Trial 124 pruned. \n",
      "[I 2025-09-05 19:00:40,781] Trial 125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 | Epoch 01 | Train Loss: 19087.2351 | Val Loss: 13808.1751 | Optimizer: RMSprop\n",
      "Trial 125 | Epoch 02 | Train Loss: 12584.9395 | Val Loss: 14092.0237 | Optimizer: RMSprop\n",
      "Trial 126 | Epoch 01 | Train Loss: 18355.3150 | Val Loss: 13886.7969 | Optimizer: Adam\n",
      "Trial 126 | Epoch 02 | Train Loss: 12681.9481 | Val Loss: 10554.8201 | Optimizer: Adam\n",
      "Trial 126 | Epoch 03 | Train Loss: 11440.9417 | Val Loss: 10415.3852 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:41,136] Trial 126 pruned. \n",
      "[I 2025-09-05 19:00:41,404] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 | Epoch 01 | Train Loss: 20046.1151 | Val Loss: 13947.0625 | Optimizer: AdamW\n",
      "Trial 127 | Epoch 02 | Train Loss: 12732.5579 | Val Loss: 11016.1639 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:41,582] Trial 128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 | Epoch 01 | Train Loss: 17719.1276 | Val Loss: 16582.7541 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:41,843] Trial 129 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 | Epoch 01 | Train Loss: 19287.8464 | Val Loss: 15138.5802 | Optimizer: AdamW\n",
      "Trial 130 | Epoch 01 | Train Loss: 18988.7215 | Val Loss: 14737.6891 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:42,014] Trial 130 pruned. \n",
      "[I 2025-09-05 19:00:42,201] Trial 131 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 | Epoch 01 | Train Loss: 16788.0905 | Val Loss: 1686043.1065 | Optimizer: RMSprop\n",
      "Trial 132 | Epoch 01 | Train Loss: 17428.9897 | Val Loss: 14575.5561 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:42,373] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 | Epoch 01 | Train Loss: 17822.6463 | Val Loss: 11772.5538 | Optimizer: RMSprop\n",
      "Trial 133 | Epoch 02 | Train Loss: 11403.5116 | Val Loss: 10164.7791 | Optimizer: RMSprop\n",
      "Trial 133 | Epoch 03 | Train Loss: 10169.9103 | Val Loss: 8566.7467 | Optimizer: RMSprop\n",
      "Trial 133 | Epoch 04 | Train Loss: 9145.1807 | Val Loss: 11707.5767 | Optimizer: RMSprop\n",
      "Trial 133 | Epoch 05 | Train Loss: 9331.7007 | Val Loss: 7848.2381 | Optimizer: RMSprop\n",
      "Trial 133 | Epoch 06 | Train Loss: 8449.9790 | Val Loss: 8556.1212 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:43,067] Trial 133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 | Epoch 01 | Train Loss: 16188.0634 | Val Loss: 8704.3558 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 02 | Train Loss: 12225.7499 | Val Loss: 12590.5399 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 03 | Train Loss: 10122.4654 | Val Loss: 11617.2848 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 04 | Train Loss: 8855.4507 | Val Loss: 6198.9763 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 05 | Train Loss: 9030.1776 | Val Loss: 8532.2325 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 06 | Train Loss: 9343.6104 | Val Loss: 9890.7286 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 07 | Train Loss: 8390.9883 | Val Loss: 6453.9905 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 08 | Train Loss: 7488.9248 | Val Loss: 8148.4234 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 09 | Train Loss: 8197.9090 | Val Loss: 7975.8983 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 10 | Train Loss: 7704.5696 | Val Loss: 20123.4932 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 11 | Train Loss: 11971.7209 | Val Loss: 6664.8920 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 12 | Train Loss: 6797.2604 | Val Loss: 6064.5963 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 13 | Train Loss: 6423.0937 | Val Loss: 8020.4192 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 14 | Train Loss: 7226.1375 | Val Loss: 7425.3107 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 15 | Train Loss: 6838.0498 | Val Loss: 26942.2711 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 16 | Train Loss: 14279.9166 | Val Loss: 6880.7392 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 17 | Train Loss: 7106.2088 | Val Loss: 5795.9650 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 18 | Train Loss: 6561.0609 | Val Loss: 5295.0870 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 19 | Train Loss: 6733.5114 | Val Loss: 5770.8883 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 20 | Train Loss: 6777.9852 | Val Loss: 5647.9227 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 21 | Train Loss: 6310.3746 | Val Loss: 12512.0026 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 22 | Train Loss: 11000.6927 | Val Loss: 8475.4572 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 23 | Train Loss: 8292.0901 | Val Loss: 5169.7855 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 24 | Train Loss: 6165.1002 | Val Loss: 10367.1686 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 25 | Train Loss: 7760.6620 | Val Loss: 5716.6819 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 26 | Train Loss: 6595.5455 | Val Loss: 5373.8614 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 27 | Train Loss: 5809.9410 | Val Loss: 9245.0870 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 28 | Train Loss: 7403.7985 | Val Loss: 5485.2976 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 29 | Train Loss: 5991.8234 | Val Loss: 5112.7651 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 30 | Train Loss: 5951.2102 | Val Loss: 31924.6067 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 31 | Train Loss: 13444.4763 | Val Loss: 5930.3293 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 32 | Train Loss: 5846.2204 | Val Loss: 6603.7513 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 33 | Train Loss: 6147.3778 | Val Loss: 5071.1484 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 34 | Train Loss: 5979.9056 | Val Loss: 5004.2293 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 35 | Train Loss: 5761.3073 | Val Loss: 5869.4474 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 36 | Train Loss: 5777.1865 | Val Loss: 5795.3531 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 37 | Train Loss: 5748.7050 | Val Loss: 7377.8302 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 38 | Train Loss: 6026.7744 | Val Loss: 6371.8854 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 39 | Train Loss: 5821.7693 | Val Loss: 5808.8053 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 40 | Train Loss: 5967.8364 | Val Loss: 5126.6322 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 41 | Train Loss: 5406.2940 | Val Loss: 4921.3955 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 42 | Train Loss: 5340.2566 | Val Loss: 5181.7151 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 43 | Train Loss: 5247.5516 | Val Loss: 6164.6794 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 44 | Train Loss: 5934.6960 | Val Loss: 42472.9262 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 45 | Train Loss: 19259.7101 | Val Loss: 5760.2213 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 46 | Train Loss: 5429.8073 | Val Loss: 15423.8943 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 47 | Train Loss: 7659.8785 | Val Loss: 5298.9694 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 48 | Train Loss: 6134.8351 | Val Loss: 5215.0875 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 49 | Train Loss: 5734.4133 | Val Loss: 6643.2144 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 50 | Train Loss: 5710.0493 | Val Loss: 5123.0584 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 51 | Train Loss: 5506.4903 | Val Loss: 4753.6036 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 52 | Train Loss: 5515.2562 | Val Loss: 5014.1295 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 53 | Train Loss: 5417.6347 | Val Loss: 6721.1505 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 54 | Train Loss: 5621.1926 | Val Loss: 6867.4624 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 55 | Train Loss: 5593.8547 | Val Loss: 4676.4508 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 56 | Train Loss: 5026.2968 | Val Loss: 6004.5452 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 57 | Train Loss: 5608.8185 | Val Loss: 4874.5704 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 58 | Train Loss: 5030.2451 | Val Loss: 4777.8709 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 59 | Train Loss: 5189.8162 | Val Loss: 5186.7743 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 60 | Train Loss: 5139.3503 | Val Loss: 5981.7087 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 61 | Train Loss: 5368.4121 | Val Loss: 5104.2293 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 62 | Train Loss: 5075.5942 | Val Loss: 4700.3748 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 63 | Train Loss: 5060.9589 | Val Loss: 6062.5957 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 64 | Train Loss: 5028.2206 | Val Loss: 5867.3123 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 65 | Train Loss: 5690.1892 | Val Loss: 4657.8621 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 66 | Train Loss: 4859.4330 | Val Loss: 7100.8840 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 67 | Train Loss: 6142.8658 | Val Loss: 48894.9838 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 68 | Train Loss: 14183.5266 | Val Loss: 5105.5739 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 69 | Train Loss: 5354.2950 | Val Loss: 4917.2349 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 70 | Train Loss: 5196.9387 | Val Loss: 4873.9928 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 71 | Train Loss: 5195.0035 | Val Loss: 5001.3955 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 72 | Train Loss: 5056.3478 | Val Loss: 5648.1153 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 73 | Train Loss: 5065.6136 | Val Loss: 4643.7518 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 74 | Train Loss: 4883.0021 | Val Loss: 4712.3983 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 75 | Train Loss: 4861.5929 | Val Loss: 4951.0482 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 76 | Train Loss: 4801.2572 | Val Loss: 23225.2347 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 77 | Train Loss: 8561.6189 | Val Loss: 4806.6043 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 78 | Train Loss: 4791.8173 | Val Loss: 4638.7941 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 79 | Train Loss: 4889.1749 | Val Loss: 7833.5255 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 80 | Train Loss: 5449.4715 | Val Loss: 4556.0672 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 81 | Train Loss: 4966.7640 | Val Loss: 8296.5476 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 82 | Train Loss: 5831.2008 | Val Loss: 4645.4622 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 83 | Train Loss: 4944.6544 | Val Loss: 4751.1923 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 84 | Train Loss: 4849.2433 | Val Loss: 4680.6981 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 85 | Train Loss: 4652.9152 | Val Loss: 4729.1450 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 86 | Train Loss: 4691.3294 | Val Loss: 7634.5990 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 87 | Train Loss: 5557.4329 | Val Loss: 4705.9246 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 88 | Train Loss: 4815.8014 | Val Loss: 10358.4613 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:51,669] Trial 134 finished with value: 4556.067195939429 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.34404144200017467, 'lr': 0.0005555079210176292, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 9.056299733554687e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 | Epoch 89 | Train Loss: 6716.0107 | Val Loss: 4781.4254 | Optimizer: RMSprop\n",
      "Trial 134 | Epoch 90 | Train Loss: 4515.1379 | Val Loss: 7402.1189 | Optimizer: RMSprop\n",
      "Trial 134 - Early stopping triggered at epoch 90\n",
      "Trial 135 | Epoch 01 | Train Loss: 16555.2916 | Val Loss: 12667.3109 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 02 | Train Loss: 12546.4954 | Val Loss: 10829.1999 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 03 | Train Loss: 10536.2361 | Val Loss: 7933.1343 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 04 | Train Loss: 9735.7457 | Val Loss: 7438.9362 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 05 | Train Loss: 8609.3638 | Val Loss: 8939.9786 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 06 | Train Loss: 8232.0192 | Val Loss: 5711.6492 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 07 | Train Loss: 7784.0227 | Val Loss: 7392.7625 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 08 | Train Loss: 7330.4591 | Val Loss: 10801.4872 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 09 | Train Loss: 8358.4816 | Val Loss: 6528.5512 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 10 | Train Loss: 7572.1892 | Val Loss: 8084.3983 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 11 | Train Loss: 7225.1624 | Val Loss: 9723.9783 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 12 | Train Loss: 8133.0616 | Val Loss: 45753.4878 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 13 | Train Loss: 22089.2780 | Val Loss: 6780.9674 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 14 | Train Loss: 7558.4223 | Val Loss: 6517.1153 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 15 | Train Loss: 7250.5848 | Val Loss: 5577.4226 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 16 | Train Loss: 6684.7693 | Val Loss: 7216.9956 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 17 | Train Loss: 7200.3441 | Val Loss: 5529.4538 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 18 | Train Loss: 6455.6029 | Val Loss: 7104.5087 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 19 | Train Loss: 6981.8545 | Val Loss: 6592.5066 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 20 | Train Loss: 6761.4718 | Val Loss: 6020.8602 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 21 | Train Loss: 6058.3164 | Val Loss: 8246.3033 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 22 | Train Loss: 6843.1479 | Val Loss: 5474.3704 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 23 | Train Loss: 6094.9436 | Val Loss: 5597.4588 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 24 | Train Loss: 6155.0714 | Val Loss: 5531.3257 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 25 | Train Loss: 6023.4392 | Val Loss: 6893.0044 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 26 | Train Loss: 6525.8284 | Val Loss: 6855.5190 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 27 | Train Loss: 7046.2317 | Val Loss: 5678.4568 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 28 | Train Loss: 6348.4069 | Val Loss: 5108.8751 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 29 | Train Loss: 6181.6309 | Val Loss: 6891.6160 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 30 | Train Loss: 6257.3845 | Val Loss: 5270.2487 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 31 | Train Loss: 5809.1772 | Val Loss: 7798.3926 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 32 | Train Loss: 6804.0966 | Val Loss: 5273.0514 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 33 | Train Loss: 6041.5127 | Val Loss: 6178.5611 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 34 | Train Loss: 5992.1758 | Val Loss: 10067.8937 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 35 | Train Loss: 7665.7769 | Val Loss: 8441.9189 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 36 | Train Loss: 6794.2198 | Val Loss: 5546.2630 | Optimizer: RMSprop\n",
      "Trial 135 | Epoch 37 | Train Loss: 5882.0528 | Val Loss: 22537.5885 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:55,545] Trial 135 finished with value: 5108.875099464699 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.34484267281148634, 'lr': 0.0005499340402916562, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 9.104485043537205e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 | Epoch 38 | Train Loss: 9511.4838 | Val Loss: 6593.1591 | Optimizer: RMSprop\n",
      "Trial 135 - Early stopping triggered at epoch 38\n",
      "Trial 136 | Epoch 01 | Train Loss: 17001.4608 | Val Loss: 10476.0918 | Optimizer: RMSprop\n",
      "Trial 136 | Epoch 02 | Train Loss: 11277.8158 | Val Loss: 8031.4586 | Optimizer: RMSprop\n",
      "Trial 136 | Epoch 03 | Train Loss: 11573.8576 | Val Loss: 11620.6050 | Optimizer: RMSprop\n",
      "Trial 136 | Epoch 04 | Train Loss: 10090.4997 | Val Loss: 8908.6348 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:56,164] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 | Epoch 05 | Train Loss: 8585.4171 | Val Loss: 7814.6021 | Optimizer: RMSprop\n",
      "Trial 136 | Epoch 06 | Train Loss: 8430.2664 | Val Loss: 13383.5463 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:56,528] Trial 137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 | Epoch 01 | Train Loss: 15373.4338 | Val Loss: 10830.1975 | Optimizer: RMSprop\n",
      "Trial 137 | Epoch 02 | Train Loss: 11533.4808 | Val Loss: 14976.1428 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 01 | Train Loss: 37203.2484 | Val Loss: 12997.5553 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 02 | Train Loss: 12274.9727 | Val Loss: 9672.7814 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 03 | Train Loss: 9522.8550 | Val Loss: 7498.7376 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 04 | Train Loss: 8220.7873 | Val Loss: 7434.6523 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 05 | Train Loss: 7501.8627 | Val Loss: 15479.3865 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 06 | Train Loss: 10435.8179 | Val Loss: 6189.5674 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 07 | Train Loss: 7373.0542 | Val Loss: 5938.8398 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 08 | Train Loss: 7163.5639 | Val Loss: 6475.9953 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 09 | Train Loss: 7544.3349 | Val Loss: 5702.8684 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 10 | Train Loss: 7079.7957 | Val Loss: 10681.4385 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 11 | Train Loss: 8822.6407 | Val Loss: 5926.7816 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 12 | Train Loss: 6677.8891 | Val Loss: 8187.9845 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 13 | Train Loss: 7480.0432 | Val Loss: 6410.0002 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 14 | Train Loss: 6561.3541 | Val Loss: 8864.3171 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 15 | Train Loss: 7411.1726 | Val Loss: 5410.6367 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 16 | Train Loss: 6491.1570 | Val Loss: 5304.7206 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 17 | Train Loss: 6580.0313 | Val Loss: 5335.9868 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 18 | Train Loss: 6428.2230 | Val Loss: 11250.5580 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 19 | Train Loss: 7963.7900 | Val Loss: 5354.3283 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 20 | Train Loss: 6103.1363 | Val Loss: 5875.5315 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 21 | Train Loss: 6520.6826 | Val Loss: 5348.3096 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 22 | Train Loss: 6453.2963 | Val Loss: 6095.5240 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 23 | Train Loss: 6553.2447 | Val Loss: 9175.1004 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 24 | Train Loss: 7144.8937 | Val Loss: 6796.4978 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:58,969] Trial 138 finished with value: 5304.720594618056 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3380344802190641, 'lr': 0.0004932119011151507, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.3553334407880868e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 | Epoch 25 | Train Loss: 7132.4349 | Val Loss: 31934.0030 | Optimizer: RMSprop\n",
      "Trial 138 | Epoch 26 | Train Loss: 13656.1525 | Val Loss: 6023.5249 | Optimizer: RMSprop\n",
      "Trial 138 - Early stopping triggered at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:59,186] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 | Epoch 01 | Train Loss: 15076.3825 | Val Loss: 14851.0436 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:59,416] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 | Epoch 01 | Train Loss: 13734.4894 | Val Loss: 68072.5580 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 01 | Train Loss: 17231.5014 | Val Loss: 10844.2236 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 02 | Train Loss: 12170.4277 | Val Loss: 9299.9596 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 03 | Train Loss: 10078.1031 | Val Loss: 56033.2994 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 04 | Train Loss: 22762.5120 | Val Loss: 7919.4324 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:00:59,990] Trial 141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 | Epoch 05 | Train Loss: 8947.6313 | Val Loss: 7479.7905 | Optimizer: RMSprop\n",
      "Trial 141 | Epoch 06 | Train Loss: 8668.3878 | Val Loss: 8168.5369 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:00,262] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142 | Epoch 01 | Train Loss: 21724.3682 | Val Loss: 11803.5036 | Optimizer: RMSprop\n",
      "Trial 142 | Epoch 02 | Train Loss: 11920.1973 | Val Loss: 13032.9327 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 01 | Train Loss: 15885.5337 | Val Loss: 10449.2945 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 02 | Train Loss: 11060.6194 | Val Loss: 8761.6379 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 03 | Train Loss: 11054.2586 | Val Loss: 7349.9776 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 04 | Train Loss: 8499.9933 | Val Loss: 10041.2198 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 05 | Train Loss: 8454.0420 | Val Loss: 6557.2057 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 06 | Train Loss: 7848.3290 | Val Loss: 8759.6491 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 07 | Train Loss: 8593.3478 | Val Loss: 6981.9505 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 08 | Train Loss: 7219.1760 | Val Loss: 5845.8910 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 09 | Train Loss: 6909.7698 | Val Loss: 15096.4650 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 10 | Train Loss: 12663.7687 | Val Loss: 6115.7824 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 11 | Train Loss: 6979.3569 | Val Loss: 6970.4265 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 12 | Train Loss: 7237.6400 | Val Loss: 5463.1009 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 13 | Train Loss: 6947.2588 | Val Loss: 8490.5424 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 14 | Train Loss: 7715.5646 | Val Loss: 11072.2992 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 15 | Train Loss: 8870.0554 | Val Loss: 5976.6504 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 16 | Train Loss: 6279.7828 | Val Loss: 5507.7819 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 17 | Train Loss: 6225.0399 | Val Loss: 5502.2751 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 18 | Train Loss: 6452.3986 | Val Loss: 28903.9721 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 19 | Train Loss: 12100.6972 | Val Loss: 5333.8596 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 20 | Train Loss: 6142.3202 | Val Loss: 5354.7707 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 21 | Train Loss: 6297.0506 | Val Loss: 13250.6385 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 22 | Train Loss: 7757.2726 | Val Loss: 5624.7464 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 23 | Train Loss: 6414.4401 | Val Loss: 5217.7743 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 24 | Train Loss: 6180.6176 | Val Loss: 12729.1227 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 25 | Train Loss: 10219.4398 | Val Loss: 6714.9173 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 26 | Train Loss: 6180.3380 | Val Loss: 5445.0253 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 27 | Train Loss: 5652.7719 | Val Loss: 5948.9835 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 28 | Train Loss: 6388.8104 | Val Loss: 5611.0617 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 29 | Train Loss: 6076.5733 | Val Loss: 8147.9695 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 30 | Train Loss: 6948.0706 | Val Loss: 5528.1984 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 31 | Train Loss: 6504.4039 | Val Loss: 5421.8273 | Optimizer: RMSprop\n",
      "Trial 143 | Epoch 32 | Train Loss: 5974.1580 | Val Loss: 6072.1199 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:03,431] Trial 143 finished with value: 5217.774314597801 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3386983578683681, 'lr': 0.00039321042774086146, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.857533471319384e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 | Epoch 33 | Train Loss: 5976.8534 | Val Loss: 8989.9072 | Optimizer: RMSprop\n",
      "Trial 143 - Early stopping triggered at epoch 33\n",
      "Trial 144 | Epoch 01 | Train Loss: 16120.5623 | Val Loss: 12223.7379 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:03,682] Trial 144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 | Epoch 02 | Train Loss: 10994.2301 | Val Loss: 35156.3391 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 01 | Train Loss: 14194.2644 | Val Loss: 11393.0640 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 02 | Train Loss: 11689.5919 | Val Loss: 9393.1691 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 03 | Train Loss: 9102.9177 | Val Loss: 7012.6940 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 04 | Train Loss: 8191.0635 | Val Loss: 6811.5902 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 05 | Train Loss: 7893.1982 | Val Loss: 5707.7698 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 06 | Train Loss: 7498.2709 | Val Loss: 5606.9367 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 07 | Train Loss: 7041.4432 | Val Loss: 20942.3526 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 08 | Train Loss: 9499.0606 | Val Loss: 6835.1373 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 09 | Train Loss: 7281.4599 | Val Loss: 6062.4043 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 10 | Train Loss: 6870.5114 | Val Loss: 6439.6238 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 11 | Train Loss: 6998.2206 | Val Loss: 5484.0318 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 12 | Train Loss: 6488.1090 | Val Loss: 5409.5500 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 13 | Train Loss: 6320.8805 | Val Loss: 7309.1747 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 14 | Train Loss: 6772.4533 | Val Loss: 5404.4341 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 15 | Train Loss: 6394.8508 | Val Loss: 6006.4123 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 16 | Train Loss: 6811.3451 | Val Loss: 5973.2594 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 17 | Train Loss: 6292.5603 | Val Loss: 6619.8024 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 18 | Train Loss: 6493.6726 | Val Loss: 6205.5757 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 19 | Train Loss: 6608.0990 | Val Loss: 5998.2072 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 20 | Train Loss: 6371.6694 | Val Loss: 13133.2461 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 21 | Train Loss: 8053.9747 | Val Loss: 5481.0999 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 22 | Train Loss: 5847.2386 | Val Loss: 5266.6653 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 23 | Train Loss: 5752.4753 | Val Loss: 5821.5315 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 24 | Train Loss: 5930.8174 | Val Loss: 8044.8474 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 25 | Train Loss: 6927.5695 | Val Loss: 10311.6593 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 26 | Train Loss: 7646.0163 | Val Loss: 5882.4567 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 27 | Train Loss: 6129.4495 | Val Loss: 5215.9525 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 28 | Train Loss: 5947.5207 | Val Loss: 5232.7506 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 29 | Train Loss: 5563.5369 | Val Loss: 5158.2917 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 30 | Train Loss: 5852.9851 | Val Loss: 22140.1435 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 31 | Train Loss: 8778.0345 | Val Loss: 5443.4915 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 32 | Train Loss: 5837.1867 | Val Loss: 5310.9427 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 33 | Train Loss: 5803.3852 | Val Loss: 5177.4469 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 34 | Train Loss: 5811.9578 | Val Loss: 5079.5094 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 35 | Train Loss: 5669.3543 | Val Loss: 5070.9634 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 36 | Train Loss: 5873.1298 | Val Loss: 5996.4068 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 37 | Train Loss: 5984.6815 | Val Loss: 13310.5652 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 38 | Train Loss: 8513.7764 | Val Loss: 7309.5199 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 39 | Train Loss: 6380.6832 | Val Loss: 6360.5951 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 40 | Train Loss: 5856.0222 | Val Loss: 5216.3368 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 41 | Train Loss: 5976.7508 | Val Loss: 5356.8550 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 42 | Train Loss: 5587.3789 | Val Loss: 5240.6490 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 43 | Train Loss: 5548.1306 | Val Loss: 5487.4445 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 44 | Train Loss: 5507.0549 | Val Loss: 4909.3860 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 45 | Train Loss: 5287.9868 | Val Loss: 5661.4879 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 46 | Train Loss: 5853.2779 | Val Loss: 11234.3105 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 47 | Train Loss: 7245.9112 | Val Loss: 8029.2372 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 48 | Train Loss: 6449.0725 | Val Loss: 5265.3226 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 49 | Train Loss: 5617.7813 | Val Loss: 7468.7295 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 50 | Train Loss: 5888.0242 | Val Loss: 6581.5432 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 51 | Train Loss: 5464.0273 | Val Loss: 5515.2993 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 52 | Train Loss: 5847.5899 | Val Loss: 5080.8621 | Optimizer: RMSprop\n",
      "Trial 145 | Epoch 53 | Train Loss: 5225.1885 | Val Loss: 5442.9916 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:08,850] Trial 145 finished with value: 4909.3860104407795 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.33848914593289514, 'lr': 0.0003945850812546342, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.2399767027471175e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 | Epoch 54 | Train Loss: 5305.1667 | Val Loss: 5064.6258 | Optimizer: RMSprop\n",
      "Trial 145 - Early stopping triggered at epoch 54\n",
      "Trial 146 | Epoch 01 | Train Loss: 14895.3853 | Val Loss: 13515.0625 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:09,015] Trial 146 pruned. \n",
      "[I 2025-09-05 19:01:09,262] Trial 147 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 | Epoch 01 | Train Loss: 14528.6050 | Val Loss: 13252.4286 | Optimizer: RMSprop\n",
      "Trial 148 | Epoch 01 | Train Loss: 17877.8306 | Val Loss: 14824.2224 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:09,423] Trial 148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 | Epoch 01 | Train Loss: 16538.5239 | Val Loss: 10175.6852 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 02 | Train Loss: 10545.0829 | Val Loss: 612614.4726 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 03 | Train Loss: 126697.1945 | Val Loss: 9623.1206 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 04 | Train Loss: 9850.5891 | Val Loss: 7025.6381 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 05 | Train Loss: 7867.2475 | Val Loss: 6749.8968 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 06 | Train Loss: 7806.9573 | Val Loss: 5739.6766 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 07 | Train Loss: 7658.2116 | Val Loss: 7216.6860 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 08 | Train Loss: 7738.8686 | Val Loss: 5586.3793 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 09 | Train Loss: 7473.5859 | Val Loss: 5386.7086 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 10 | Train Loss: 6974.7868 | Val Loss: 5755.2851 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 11 | Train Loss: 6930.3744 | Val Loss: 5408.5452 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 12 | Train Loss: 7251.1512 | Val Loss: 5901.9565 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 13 | Train Loss: 6788.7439 | Val Loss: 6035.7093 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 14 | Train Loss: 7045.5448 | Val Loss: 6037.6877 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 15 | Train Loss: 6913.0716 | Val Loss: 5408.0328 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 16 | Train Loss: 6870.5951 | Val Loss: 5803.1007 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:11,317] Trial 149 finished with value: 5386.708568431713 and parameters: {'gnn_dim': 384, 'hidden_dim': 512, 'dropout_rate': 0.3409812000063129, 'lr': 0.0004236985648273598, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.2945012826282918e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 | Epoch 17 | Train Loss: 6799.1915 | Val Loss: 5950.9909 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 18 | Train Loss: 6940.1164 | Val Loss: 5544.1029 | Optimizer: RMSprop\n",
      "Trial 149 | Epoch 19 | Train Loss: 6504.0576 | Val Loss: 6108.4172 | Optimizer: RMSprop\n",
      "Trial 149 - Early stopping triggered at epoch 19\n",
      "Trial 150 | Epoch 01 | Train Loss: 13762.3273 | Val Loss: 9269.1574 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 02 | Train Loss: 9922.0819 | Val Loss: 13505.6769 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 03 | Train Loss: 10281.4983 | Val Loss: 32213.1660 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 04 | Train Loss: 15500.7797 | Val Loss: 6843.1147 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 05 | Train Loss: 7619.1200 | Val Loss: 6258.1499 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 06 | Train Loss: 7262.9514 | Val Loss: 5983.2604 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 07 | Train Loss: 7181.5845 | Val Loss: 5649.1873 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 08 | Train Loss: 7270.0792 | Val Loss: 7292.8719 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 09 | Train Loss: 7857.7181 | Val Loss: 7126.7014 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 10 | Train Loss: 6627.8280 | Val Loss: 5472.3377 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 11 | Train Loss: 7057.0330 | Val Loss: 5689.2579 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 12 | Train Loss: 7258.7505 | Val Loss: 5490.4759 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 13 | Train Loss: 6518.1387 | Val Loss: 6798.1752 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 14 | Train Loss: 7535.1714 | Val Loss: 5805.3790 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 15 | Train Loss: 6666.3966 | Val Loss: 5398.0155 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 16 | Train Loss: 6361.1277 | Val Loss: 7507.5147 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 17 | Train Loss: 6507.5651 | Val Loss: 5519.1120 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 18 | Train Loss: 6164.7600 | Val Loss: 6610.3598 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 19 | Train Loss: 6646.7570 | Val Loss: 5353.4137 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 20 | Train Loss: 6073.4273 | Val Loss: 7281.2623 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 21 | Train Loss: 6924.2964 | Val Loss: 7291.4755 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 22 | Train Loss: 6417.5995 | Val Loss: 5208.0454 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 23 | Train Loss: 5905.4038 | Val Loss: 5892.1364 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 24 | Train Loss: 6243.4095 | Val Loss: 5928.0044 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 25 | Train Loss: 6294.9098 | Val Loss: 6356.1666 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 26 | Train Loss: 6481.8840 | Val Loss: 7830.9701 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 27 | Train Loss: 6207.2160 | Val Loss: 8738.9705 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 28 | Train Loss: 6822.8729 | Val Loss: 6473.1583 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 29 | Train Loss: 6385.2887 | Val Loss: 5223.0307 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 30 | Train Loss: 5741.3815 | Val Loss: 5274.4776 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 31 | Train Loss: 5967.4691 | Val Loss: 9158.2337 | Optimizer: RMSprop\n",
      "Trial 150 | Epoch 32 | Train Loss: 6426.3778 | Val Loss: 5308.0950 | Optimizer: RMSprop\n",
      "Trial 150 - Early stopping triggered at epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:14,371] Trial 150 finished with value: 5208.045373987268 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3465303462264981, 'lr': 0.00032516388931184184, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.1123987231590512e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 151 | Epoch 01 | Train Loss: 15718.8921 | Val Loss: 10550.3076 | Optimizer: RMSprop\n",
      "Trial 151 | Epoch 02 | Train Loss: 10622.9936 | Val Loss: 7251.2448 | Optimizer: RMSprop\n",
      "Trial 151 | Epoch 03 | Train Loss: 11325.3871 | Val Loss: 7905.7098 | Optimizer: RMSprop\n",
      "Trial 151 | Epoch 04 | Train Loss: 7822.4560 | Val Loss: 8631.7984 | Optimizer: RMSprop\n",
      "Trial 151 | Epoch 05 | Train Loss: 7999.8273 | Val Loss: 19380.2520 | Optimizer: RMSprop\n",
      "Trial 151 | Epoch 06 | Train Loss: 11566.0410 | Val Loss: 7967.0813 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:15,020] Trial 151 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 152 | Epoch 01 | Train Loss: 15462.3165 | Val Loss: 11223.3264 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 02 | Train Loss: 10696.5220 | Val Loss: 8445.4159 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 03 | Train Loss: 8500.2038 | Val Loss: 6188.5991 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 04 | Train Loss: 12189.1361 | Val Loss: 5826.3719 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 05 | Train Loss: 7249.6635 | Val Loss: 5908.4823 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 06 | Train Loss: 7053.5176 | Val Loss: 5556.9167 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 07 | Train Loss: 7118.9864 | Val Loss: 6237.6024 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 08 | Train Loss: 7162.5705 | Val Loss: 5561.8122 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 09 | Train Loss: 7031.2398 | Val Loss: 39634.4908 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 10 | Train Loss: 14705.0493 | Val Loss: 7780.9850 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 11 | Train Loss: 7282.3028 | Val Loss: 6128.7662 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 12 | Train Loss: 6936.5417 | Val Loss: 5661.7271 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 13 | Train Loss: 6477.4687 | Val Loss: 5317.5467 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 14 | Train Loss: 7080.8260 | Val Loss: 5760.6810 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 15 | Train Loss: 6751.4075 | Val Loss: 16103.2558 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 16 | Train Loss: 9053.6360 | Val Loss: 5397.9805 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 17 | Train Loss: 6584.8104 | Val Loss: 5328.5755 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 18 | Train Loss: 6499.8086 | Val Loss: 7704.7239 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 19 | Train Loss: 7491.9141 | Val Loss: 5367.6526 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 20 | Train Loss: 6586.8674 | Val Loss: 5186.5377 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 21 | Train Loss: 6280.8657 | Val Loss: 5267.2689 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 22 | Train Loss: 6467.1393 | Val Loss: 8998.0321 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 23 | Train Loss: 7743.5420 | Val Loss: 5348.3142 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 24 | Train Loss: 6391.8407 | Val Loss: 5305.9793 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 25 | Train Loss: 6135.8014 | Val Loss: 6843.5739 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 26 | Train Loss: 6725.7658 | Val Loss: 5191.9936 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 27 | Train Loss: 6119.2262 | Val Loss: 5111.5211 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 28 | Train Loss: 6183.3621 | Val Loss: 6350.3319 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 29 | Train Loss: 6333.5354 | Val Loss: 5076.7908 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 30 | Train Loss: 5780.1705 | Val Loss: 5814.7791 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 31 | Train Loss: 5996.5239 | Val Loss: 5023.5668 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 32 | Train Loss: 6087.2903 | Val Loss: 7270.1098 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 33 | Train Loss: 6721.8434 | Val Loss: 6303.9059 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 34 | Train Loss: 6210.2345 | Val Loss: 9942.7204 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 35 | Train Loss: 7659.2332 | Val Loss: 8840.0203 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 36 | Train Loss: 6858.5859 | Val Loss: 9108.3794 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 37 | Train Loss: 7228.4253 | Val Loss: 5198.3626 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 38 | Train Loss: 6144.5200 | Val Loss: 5385.2293 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 39 | Train Loss: 6143.9560 | Val Loss: 5003.4137 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 40 | Train Loss: 6132.3466 | Val Loss: 5801.1359 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 41 | Train Loss: 5877.6470 | Val Loss: 5032.2367 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 42 | Train Loss: 5888.4992 | Val Loss: 5020.3395 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 43 | Train Loss: 5733.1919 | Val Loss: 7580.1866 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 44 | Train Loss: 6427.0879 | Val Loss: 18313.6205 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 45 | Train Loss: 8425.3535 | Val Loss: 5333.9782 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 46 | Train Loss: 5758.2939 | Val Loss: 5865.8321 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 47 | Train Loss: 5737.4546 | Val Loss: 11487.2307 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 48 | Train Loss: 9095.4222 | Val Loss: 5340.5029 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 49 | Train Loss: 5800.7951 | Val Loss: 4925.1792 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 50 | Train Loss: 5633.1668 | Val Loss: 4949.8084 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 51 | Train Loss: 5653.8416 | Val Loss: 5130.2909 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 52 | Train Loss: 5630.6213 | Val Loss: 4899.0386 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 53 | Train Loss: 5763.2087 | Val Loss: 5685.3497 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 54 | Train Loss: 5949.8904 | Val Loss: 4900.7593 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 55 | Train Loss: 5721.1220 | Val Loss: 5055.6617 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 56 | Train Loss: 6086.2170 | Val Loss: 5171.5873 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 57 | Train Loss: 5554.6867 | Val Loss: 6095.6412 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 58 | Train Loss: 6033.0830 | Val Loss: 5115.7065 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 59 | Train Loss: 5325.1183 | Val Loss: 4990.1181 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 60 | Train Loss: 5225.8042 | Val Loss: 8276.0066 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 61 | Train Loss: 6236.4065 | Val Loss: 5020.3312 | Optimizer: RMSprop\n",
      "Trial 152 | Epoch 62 | Train Loss: 5639.8534 | Val Loss: 5472.0253 | Optimizer: RMSprop\n",
      "Trial 152 - Early stopping triggered at epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:20,877] Trial 152 finished with value: 4899.03860737365 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3450919219654015, 'lr': 0.00031987520208023667, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.0710947423292408e-06}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:01:21,044] Trial 153 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 153 | Epoch 01 | Train Loss: 15055.9185 | Val Loss: 13033.3223 | Optimizer: RMSprop\n",
      "Trial 154 | Epoch 01 | Train Loss: 15345.2356 | Val Loss: 11801.6563 | Optimizer: RMSprop\n",
      "Trial 154 | Epoch 02 | Train Loss: 11518.7566 | Val Loss: 9896.6056 | Optimizer: RMSprop\n",
      "Trial 154 | Epoch 03 | Train Loss: 10281.3345 | Val Loss: 9472.9197 | Optimizer: RMSprop\n",
      "Trial 154 | Epoch 04 | Train Loss: 9199.7399 | Val Loss: 10000.0001 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:21,586] Trial 154 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 154 | Epoch 05 | Train Loss: 8925.0598 | Val Loss: 10928.0207 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 01 | Train Loss: 15872.6735 | Val Loss: 10072.6051 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 02 | Train Loss: 11207.9908 | Val Loss: 8547.6276 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 03 | Train Loss: 8875.7382 | Val Loss: 99696.4592 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 04 | Train Loss: 27059.2403 | Val Loss: 8334.7005 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 05 | Train Loss: 8825.7197 | Val Loss: 6689.0491 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 06 | Train Loss: 7710.1493 | Val Loss: 5858.7249 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 07 | Train Loss: 7349.6942 | Val Loss: 6215.0523 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 08 | Train Loss: 7604.6271 | Val Loss: 5512.5886 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 09 | Train Loss: 7127.6081 | Val Loss: 6303.3684 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 10 | Train Loss: 7360.2668 | Val Loss: 6650.6086 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 11 | Train Loss: 7588.8198 | Val Loss: 5437.9145 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 12 | Train Loss: 7078.3476 | Val Loss: 5582.8035 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 13 | Train Loss: 6872.8192 | Val Loss: 7305.5885 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 14 | Train Loss: 7542.6311 | Val Loss: 6524.3131 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 15 | Train Loss: 7015.7729 | Val Loss: 5389.4964 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 16 | Train Loss: 6596.5307 | Val Loss: 5364.1414 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 17 | Train Loss: 6640.2077 | Val Loss: 8714.5986 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 18 | Train Loss: 7665.8543 | Val Loss: 5268.7974 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 19 | Train Loss: 6436.2266 | Val Loss: 15192.4370 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 20 | Train Loss: 8022.3815 | Val Loss: 5396.9876 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 21 | Train Loss: 7051.5462 | Val Loss: 15538.4987 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 22 | Train Loss: 8331.5612 | Val Loss: 5340.3658 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 23 | Train Loss: 6788.0809 | Val Loss: 5181.0648 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 24 | Train Loss: 6223.2694 | Val Loss: 5493.0523 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 25 | Train Loss: 6105.8764 | Val Loss: 5570.8869 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 26 | Train Loss: 6449.2922 | Val Loss: 5692.9277 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 27 | Train Loss: 6392.0721 | Val Loss: 6132.8445 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 28 | Train Loss: 6426.9027 | Val Loss: 5137.1098 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 29 | Train Loss: 5950.5728 | Val Loss: 43155.2494 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 30 | Train Loss: 14211.0804 | Val Loss: 5415.9759 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 31 | Train Loss: 5945.7583 | Val Loss: 5724.5824 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 32 | Train Loss: 6325.2340 | Val Loss: 5036.2958 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 33 | Train Loss: 5997.3749 | Val Loss: 6329.4485 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 34 | Train Loss: 6370.7488 | Val Loss: 5140.3109 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 35 | Train Loss: 6001.7620 | Val Loss: 5107.5753 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 36 | Train Loss: 5844.0968 | Val Loss: 5336.4149 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 37 | Train Loss: 5933.4718 | Val Loss: 5072.0876 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 38 | Train Loss: 6056.2382 | Val Loss: 6064.2302 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 39 | Train Loss: 6100.2336 | Val Loss: 5641.5810 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 40 | Train Loss: 5732.8681 | Val Loss: 5155.1705 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 41 | Train Loss: 6031.8556 | Val Loss: 5731.3792 | Optimizer: RMSprop\n",
      "Trial 155 | Epoch 42 | Train Loss: 6246.3784 | Val Loss: 5928.2915 | Optimizer: RMSprop\n",
      "Trial 155 - Early stopping triggered at epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:25,541] Trial 155 finished with value: 5036.295765817901 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.35215422949179953, 'lr': 0.0003280483367968459, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.0124718992796603e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 156 | Epoch 01 | Train Loss: 14505.2424 | Val Loss: 9390.6923 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 02 | Train Loss: 9902.5377 | Val Loss: 11285.1028 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 03 | Train Loss: 9675.0880 | Val Loss: 7526.3885 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 04 | Train Loss: 7827.3427 | Val Loss: 7633.2079 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 05 | Train Loss: 7702.3036 | Val Loss: 10222.0545 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 06 | Train Loss: 7526.3882 | Val Loss: 6232.1940 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 07 | Train Loss: 7275.0030 | Val Loss: 6390.8253 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 08 | Train Loss: 7040.3007 | Val Loss: 5483.2498 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 09 | Train Loss: 6597.6676 | Val Loss: 7577.2325 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 10 | Train Loss: 7106.6817 | Val Loss: 5949.6409 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 11 | Train Loss: 6887.7111 | Val Loss: 15777.6192 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 12 | Train Loss: 9303.5205 | Val Loss: 6318.1333 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 13 | Train Loss: 6490.8731 | Val Loss: 5903.0919 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 14 | Train Loss: 6627.6080 | Val Loss: 6710.7253 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 15 | Train Loss: 6860.1851 | Val Loss: 6780.1895 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 16 | Train Loss: 6621.0124 | Val Loss: 5971.6518 | Optimizer: RMSprop\n",
      "Trial 156 | Epoch 17 | Train Loss: 6166.0068 | Val Loss: 10825.8512 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:27,344] Trial 156 finished with value: 5483.249786000193 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3524117218508306, 'lr': 0.0002846214809071986, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.0180786761587102e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 156 | Epoch 18 | Train Loss: 7601.8102 | Val Loss: 6256.2667 | Optimizer: RMSprop\n",
      "Trial 156 - Early stopping triggered at epoch 18\n",
      "Trial 157 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:27,554] Trial 157 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 158 | Epoch 01 | Train Loss: 15430.3785 | Val Loss: 10453.6864 | Optimizer: RMSprop\n",
      "Trial 158 | Epoch 02 | Train Loss: 10957.6006 | Val Loss: 11066.9810 | Optimizer: RMSprop\n",
      "Trial 158 | Epoch 03 | Train Loss: 10292.6407 | Val Loss: 10847.5760 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:27,884] Trial 158 pruned. \n",
      "[I 2025-09-05 19:01:28,066] Trial 159 pruned. \n",
      "[I 2025-09-05 19:01:28,212] Trial 160 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 159 | Epoch 01 | Train Loss: 15670.5281 | Val Loss: 24761.1031 | Optimizer: RMSprop\n",
      "Trial 160 | Epoch 01 | Train Loss: 14043.6836 | Val Loss: 14639.3742 | Optimizer: RMSprop\n",
      "Trial 161 | Epoch 01 | Train Loss: 15918.2731 | Val Loss: 11423.7932 | Optimizer: RMSprop\n",
      "Trial 161 | Epoch 02 | Train Loss: 11544.7776 | Val Loss: 10471.4934 | Optimizer: RMSprop\n",
      "Trial 161 | Epoch 03 | Train Loss: 10097.5498 | Val Loss: 40005.0023 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:28,556] Trial 161 pruned. \n",
      "[I 2025-09-05 19:01:28,757] Trial 162 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 162 | Epoch 01 | Train Loss: 15303.8986 | Val Loss: 13046.3157 | Optimizer: RMSprop\n",
      "Trial 163 | Epoch 01 | Train Loss: 14464.8559 | Val Loss: 10578.7552 | Optimizer: RMSprop\n",
      "Trial 163 | Epoch 02 | Train Loss: 11010.4595 | Val Loss: 9661.5151 | Optimizer: RMSprop\n",
      "Trial 163 | Epoch 03 | Train Loss: 10106.7427 | Val Loss: 10641.9637 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:29,224] Trial 163 pruned. \n",
      "[I 2025-09-05 19:01:29,413] Trial 164 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 164 | Epoch 01 | Train Loss: 15111.4393 | Val Loss: 12658.4320 | Optimizer: RMSprop\n",
      "Trial 165 | Epoch 01 | Train Loss: 14434.7547 | Val Loss: 11408.1341 | Optimizer: RMSprop\n",
      "Trial 165 | Epoch 02 | Train Loss: 11225.6646 | Val Loss: 10399.8728 | Optimizer: RMSprop\n",
      "Trial 165 | Epoch 03 | Train Loss: 9662.1827 | Val Loss: 8092.0433 | Optimizer: RMSprop\n",
      "Trial 165 | Epoch 04 | Train Loss: 8513.5453 | Val Loss: 11298.1402 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:30,061] Trial 165 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165 | Epoch 05 | Train Loss: 9012.8743 | Val Loss: 9378.1134 | Optimizer: RMSprop\n",
      "Trial 165 | Epoch 06 | Train Loss: 8355.5396 | Val Loss: 8009.0544 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:30,242] Trial 166 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 166 | Epoch 01 | Train Loss: 20991.8169 | Val Loss: 18968.3298 | Optimizer: AdamW\n",
      "Trial 167 | Epoch 01 | Train Loss: 15852.9470 | Val Loss: 15330.3050 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:30,412] Trial 167 pruned. \n",
      "[I 2025-09-05 19:01:30,716] Trial 168 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 168 | Epoch 01 | Train Loss: 82173.1294 | Val Loss: 13490.7272 | Optimizer: RMSprop\n",
      "Trial 169 | Epoch 01 | Train Loss: 19163.6150 | Val Loss: 14918.3559 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:30,882] Trial 169 pruned. \n",
      "[I 2025-09-05 19:01:31,149] Trial 170 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 170 | Epoch 01 | Train Loss: 14479.2279 | Val Loss: 12925.2431 | Optimizer: RMSprop\n",
      "Trial 171 | Epoch 01 | Train Loss: 14268.4436 | Val Loss: 10920.4175 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:31,421] Trial 171 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171 | Epoch 02 | Train Loss: 11950.8642 | Val Loss: 11618.0785 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 01 | Train Loss: 15098.4049 | Val Loss: 11658.8704 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 02 | Train Loss: 11881.1780 | Val Loss: 7321.4103 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 03 | Train Loss: 8700.3871 | Val Loss: 41361.9999 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 04 | Train Loss: 16491.7866 | Val Loss: 7708.4304 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 05 | Train Loss: 8241.3630 | Val Loss: 8515.1338 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 06 | Train Loss: 8878.9886 | Val Loss: 6053.4476 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 07 | Train Loss: 8040.1986 | Val Loss: 13201.1247 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 08 | Train Loss: 10494.8457 | Val Loss: 9745.9539 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 09 | Train Loss: 8421.3239 | Val Loss: 6012.2287 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 10 | Train Loss: 7299.9145 | Val Loss: 8686.2228 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 11 | Train Loss: 8128.9400 | Val Loss: 5937.2341 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 12 | Train Loss: 7124.5694 | Val Loss: 5742.4944 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 13 | Train Loss: 7286.5852 | Val Loss: 5341.5941 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 14 | Train Loss: 6700.8256 | Val Loss: 10242.5536 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 15 | Train Loss: 8124.6060 | Val Loss: 5395.4823 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 16 | Train Loss: 6495.2690 | Val Loss: 7582.5931 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 17 | Train Loss: 6986.7690 | Val Loss: 5243.6658 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 18 | Train Loss: 6545.9698 | Val Loss: 6636.4137 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 19 | Train Loss: 6787.6774 | Val Loss: 6252.4809 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 20 | Train Loss: 6391.6462 | Val Loss: 7740.3322 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 21 | Train Loss: 6718.1764 | Val Loss: 9857.7164 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 22 | Train Loss: 8199.6694 | Val Loss: 7789.4306 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 23 | Train Loss: 7089.6724 | Val Loss: 5312.8797 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 24 | Train Loss: 6153.4490 | Val Loss: 5819.5844 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 25 | Train Loss: 6113.6670 | Val Loss: 9455.9614 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:33,975] Trial 172 finished with value: 5243.665801625193 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.34102979490428426, 'lr': 0.00043644545151318463, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 8.053774267468954e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 172 | Epoch 26 | Train Loss: 7382.7039 | Val Loss: 5350.9534 | Optimizer: RMSprop\n",
      "Trial 172 | Epoch 27 | Train Loss: 5900.1954 | Val Loss: 5500.7978 | Optimizer: RMSprop\n",
      "Trial 172 - Early stopping triggered at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:34,192] Trial 173 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 173 | Epoch 01 | Train Loss: 17864.9978 | Val Loss: 12280.2633 | Optimizer: RMSprop\n",
      "Trial 174 | Epoch 01 | Train Loss: 15327.7720 | Val Loss: 10401.7434 | Optimizer: RMSprop\n",
      "Trial 174 | Epoch 02 | Train Loss: 10621.9779 | Val Loss: 10671.9657 | Optimizer: RMSprop\n",
      "Trial 174 | Epoch 03 | Train Loss: 9663.7241 | Val Loss: 9023.6398 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:34,683] Trial 174 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 174 | Epoch 04 | Train Loss: 8894.1751 | Val Loss: 12973.7817 | Optimizer: RMSprop\n",
      "Trial 175 | Epoch 01 | Train Loss: 15979.3717 | Val Loss: 10753.0909 | Optimizer: RMSprop\n",
      "Trial 175 | Epoch 02 | Train Loss: 11290.1091 | Val Loss: 17809.9657 | Optimizer: RMSprop\n",
      "Trial 175 | Epoch 03 | Train Loss: 13309.4133 | Val Loss: 6670.6599 | Optimizer: RMSprop\n",
      "Trial 175 | Epoch 04 | Train Loss: 8994.9037 | Val Loss: 6407.0795 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:35,337] Trial 175 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 175 | Epoch 05 | Train Loss: 8407.2737 | Val Loss: 6612.3758 | Optimizer: RMSprop\n",
      "Trial 175 | Epoch 06 | Train Loss: 7832.5486 | Val Loss: 13324.8756 | Optimizer: RMSprop\n",
      "Trial 176 | Epoch 01 | Train Loss: 15431.5575 | Val Loss: 10767.3731 | Optimizer: RMSprop\n",
      "Trial 176 | Epoch 02 | Train Loss: 10008.3091 | Val Loss: 13219.6763 | Optimizer: RMSprop\n",
      "Trial 176 | Epoch 03 | Train Loss: 10536.0111 | Val Loss: 54323.7525 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:35,689] Trial 176 pruned. \n",
      "[I 2025-09-05 19:01:35,869] Trial 177 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 177 | Epoch 01 | Train Loss: 20590.6602 | Val Loss: 18195.4317 | Optimizer: AdamW\n",
      "Trial 178 | Epoch 01 | Train Loss: 19400.7726 | Val Loss: 15338.7296 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:36,049] Trial 178 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 179 | Epoch 01 | Train Loss: 16682.5503 | Val Loss: 11801.1123 | Optimizer: RMSprop\n",
      "Trial 179 | Epoch 02 | Train Loss: 11290.2996 | Val Loss: 9273.6671 | Optimizer: RMSprop\n",
      "Trial 179 | Epoch 03 | Train Loss: 9463.3829 | Val Loss: 10890.9983 | Optimizer: RMSprop\n",
      "Trial 179 | Epoch 04 | Train Loss: 10120.4884 | Val Loss: 7772.3984 | Optimizer: RMSprop\n",
      "Trial 179 | Epoch 05 | Train Loss: 8756.0138 | Val Loss: 8339.0086 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:36,765] Trial 179 pruned. \n",
      "[I 2025-09-05 19:01:36,910] Trial 180 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 179 | Epoch 06 | Train Loss: 8570.4489 | Val Loss: 7598.8345 | Optimizer: RMSprop\n",
      "Trial 180 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 181 | Epoch 01 | Train Loss: 14498.3332 | Val Loss: 10601.6824 | Optimizer: RMSprop\n",
      "Trial 181 | Epoch 02 | Train Loss: 11589.8272 | Val Loss: 10484.9786 | Optimizer: RMSprop\n",
      "Trial 181 | Epoch 03 | Train Loss: 10723.5912 | Val Loss: 13585.8241 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:37,275] Trial 181 pruned. \n",
      "[I 2025-09-05 19:01:37,463] Trial 182 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 182 | Epoch 01 | Train Loss: 16600.4892 | Val Loss: 12914.4142 | Optimizer: RMSprop\n",
      "Trial 183 | Epoch 01 | Train Loss: 14348.9545 | Val Loss: 12380.6676 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:37,646] Trial 183 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 184 | Epoch 01 | Train Loss: 16371.8197 | Val Loss: 10497.0662 | Optimizer: RMSprop\n",
      "Trial 184 | Epoch 02 | Train Loss: 11200.4967 | Val Loss: 14482.9067 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:38,079] Trial 184 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 184 | Epoch 03 | Train Loss: 11820.5717 | Val Loss: 20718.7351 | Optimizer: RMSprop\n",
      "Trial 185 | Epoch 01 | Train Loss: 14664.0055 | Val Loss: 10776.4012 | Optimizer: RMSprop\n",
      "Trial 185 | Epoch 02 | Train Loss: 12148.4037 | Val Loss: 10285.9745 | Optimizer: RMSprop\n",
      "Trial 185 | Epoch 03 | Train Loss: 10486.9626 | Val Loss: 9598.9884 | Optimizer: RMSprop\n",
      "Trial 185 | Epoch 04 | Train Loss: 9794.6380 | Val Loss: 8400.5103 | Optimizer: RMSprop\n",
      "Trial 185 | Epoch 05 | Train Loss: 8616.8095 | Val Loss: 6314.4159 | Optimizer: RMSprop\n",
      "Trial 185 | Epoch 06 | Train Loss: 8068.1765 | Val Loss: 8206.1582 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:38,747] Trial 185 pruned. \n",
      "[I 2025-09-05 19:01:39,016] Trial 186 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 | Epoch 01 | Train Loss: 19966.5691 | Val Loss: 12199.7459 | Optimizer: AdamW\n",
      "Trial 187 | Epoch 01 | Train Loss: 14454.2132 | Val Loss: 14717.1227 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:39,182] Trial 187 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 188 | Epoch 01 | Train Loss: 18313.3000 | Val Loss: 11387.6900 | Optimizer: Adam\n",
      "Trial 188 | Epoch 02 | Train Loss: 11801.8608 | Val Loss: 10241.4097 | Optimizer: Adam\n",
      "Trial 188 | Epoch 03 | Train Loss: 11234.9833 | Val Loss: 9318.3698 | Optimizer: Adam\n",
      "Trial 188 | Epoch 04 | Train Loss: 10147.6215 | Val Loss: 6748.1771 | Optimizer: Adam\n",
      "Trial 188 | Epoch 05 | Train Loss: 7913.6300 | Val Loss: 6001.3267 | Optimizer: Adam\n",
      "Trial 188 | Epoch 06 | Train Loss: 8092.5537 | Val Loss: 8987.9912 | Optimizer: Adam\n",
      "Trial 188 | Epoch 07 | Train Loss: 9482.7119 | Val Loss: 8786.0774 | Optimizer: Adam\n",
      "Trial 188 | Epoch 08 | Train Loss: 9728.5059 | Val Loss: 7644.4802 | Optimizer: Adam\n",
      "Trial 188 | Epoch 09 | Train Loss: 7238.1903 | Val Loss: 8311.2346 | Optimizer: Adam\n",
      "Trial 188 | Epoch 10 | Train Loss: 8577.4755 | Val Loss: 7459.3570 | Optimizer: Adam\n",
      "Trial 188 | Epoch 11 | Train Loss: 9193.4205 | Val Loss: 6770.2478 | Optimizer: Adam\n",
      "Trial 188 | Epoch 12 | Train Loss: 6937.9496 | Val Loss: 6031.6551 | Optimizer: Adam\n",
      "Trial 188 | Epoch 13 | Train Loss: 6491.9829 | Val Loss: 5729.9081 | Optimizer: Adam\n",
      "Trial 188 | Epoch 14 | Train Loss: 6381.4305 | Val Loss: 6565.2348 | Optimizer: Adam\n",
      "Trial 188 | Epoch 15 | Train Loss: 7339.9965 | Val Loss: 6315.0511 | Optimizer: Adam\n",
      "Trial 188 | Epoch 16 | Train Loss: 8011.1585 | Val Loss: 8302.0881 | Optimizer: Adam\n",
      "Trial 188 | Epoch 17 | Train Loss: 7377.3439 | Val Loss: 5976.9627 | Optimizer: Adam\n",
      "Trial 188 | Epoch 18 | Train Loss: 7042.9956 | Val Loss: 5996.8826 | Optimizer: Adam\n",
      "Trial 188 | Epoch 19 | Train Loss: 6305.3877 | Val Loss: 5218.6133 | Optimizer: Adam\n",
      "Trial 188 | Epoch 20 | Train Loss: 6005.8792 | Val Loss: 5331.7920 | Optimizer: Adam\n",
      "Trial 188 | Epoch 21 | Train Loss: 5896.1325 | Val Loss: 5362.1600 | Optimizer: Adam\n",
      "Trial 188 | Epoch 22 | Train Loss: 5899.2371 | Val Loss: 5463.1347 | Optimizer: Adam\n",
      "Trial 188 | Epoch 23 | Train Loss: 6848.4842 | Val Loss: 5632.7074 | Optimizer: Adam\n",
      "Trial 188 | Epoch 24 | Train Loss: 5620.2589 | Val Loss: 5415.0445 | Optimizer: Adam\n",
      "Trial 188 | Epoch 25 | Train Loss: 5848.5200 | Val Loss: 6404.9262 | Optimizer: Adam\n",
      "Trial 188 | Epoch 26 | Train Loss: 6204.4575 | Val Loss: 6262.2409 | Optimizer: Adam\n",
      "Trial 188 | Epoch 27 | Train Loss: 7294.7890 | Val Loss: 6885.9210 | Optimizer: Adam\n",
      "Trial 188 | Epoch 28 | Train Loss: 7211.0415 | Val Loss: 5153.0303 | Optimizer: Adam\n",
      "Trial 188 | Epoch 29 | Train Loss: 7052.2014 | Val Loss: 7403.0397 | Optimizer: Adam\n",
      "Trial 188 | Epoch 30 | Train Loss: 10097.9684 | Val Loss: 10131.8619 | Optimizer: Adam\n",
      "Trial 188 | Epoch 31 | Train Loss: 7977.3165 | Val Loss: 7299.8701 | Optimizer: Adam\n",
      "Trial 188 | Epoch 32 | Train Loss: 7884.5970 | Val Loss: 7075.5216 | Optimizer: Adam\n",
      "Trial 188 | Epoch 33 | Train Loss: 7795.9245 | Val Loss: 7034.8173 | Optimizer: Adam\n",
      "Trial 188 | Epoch 34 | Train Loss: 6416.4463 | Val Loss: 5178.5880 | Optimizer: Adam\n",
      "Trial 188 | Epoch 35 | Train Loss: 5697.5796 | Val Loss: 5170.8965 | Optimizer: Adam\n",
      "Trial 188 | Epoch 36 | Train Loss: 5937.3157 | Val Loss: 5467.3517 | Optimizer: Adam\n",
      "Trial 188 | Epoch 37 | Train Loss: 5963.0274 | Val Loss: 5162.3282 | Optimizer: Adam\n",
      "Trial 188 | Epoch 38 | Train Loss: 5529.8746 | Val Loss: 5135.6422 | Optimizer: Adam\n",
      "Trial 188 | Epoch 39 | Train Loss: 5604.8554 | Val Loss: 5022.1926 | Optimizer: Adam\n",
      "Trial 188 | Epoch 40 | Train Loss: 6932.0593 | Val Loss: 5493.5189 | Optimizer: Adam\n",
      "Trial 188 | Epoch 41 | Train Loss: 6455.9422 | Val Loss: 5831.0944 | Optimizer: Adam\n",
      "Trial 188 | Epoch 42 | Train Loss: 5979.4068 | Val Loss: 5134.3943 | Optimizer: Adam\n",
      "Trial 188 | Epoch 43 | Train Loss: 5790.5329 | Val Loss: 5662.4246 | Optimizer: Adam\n",
      "Trial 188 | Epoch 44 | Train Loss: 5632.7173 | Val Loss: 4963.6038 | Optimizer: Adam\n",
      "Trial 188 | Epoch 45 | Train Loss: 5183.2733 | Val Loss: 5084.2405 | Optimizer: Adam\n",
      "Trial 188 | Epoch 46 | Train Loss: 5251.3102 | Val Loss: 5456.0951 | Optimizer: Adam\n",
      "Trial 188 | Epoch 47 | Train Loss: 5026.0466 | Val Loss: 5341.5740 | Optimizer: Adam\n",
      "Trial 188 | Epoch 48 | Train Loss: 5125.5798 | Val Loss: 5245.5823 | Optimizer: Adam\n",
      "Trial 188 | Epoch 49 | Train Loss: 5301.8316 | Val Loss: 5662.4103 | Optimizer: Adam\n",
      "Trial 188 | Epoch 50 | Train Loss: 5457.4167 | Val Loss: 5599.8927 | Optimizer: Adam\n",
      "Trial 188 | Epoch 51 | Train Loss: 6112.7179 | Val Loss: 6148.6981 | Optimizer: Adam\n",
      "Trial 188 | Epoch 52 | Train Loss: 5330.0557 | Val Loss: 6944.9206 | Optimizer: Adam\n",
      "Trial 188 | Epoch 53 | Train Loss: 6982.9239 | Val Loss: 6507.8756 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:44,145] Trial 188 finished with value: 4963.60376880787 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.32004497572323753, 'lr': 0.0008702912440150264, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 3.7657807683114416e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 188 | Epoch 54 | Train Loss: 6059.4924 | Val Loss: 5284.1809 | Optimizer: Adam\n",
      "Trial 188 - Early stopping triggered at epoch 54\n",
      "Trial 189 | Epoch 01 | Train Loss: 19053.3300 | Val Loss: 11240.8640 | Optimizer: Adam\n",
      "Trial 189 | Epoch 02 | Train Loss: 11351.9983 | Val Loss: 10751.1297 | Optimizer: Adam\n",
      "Trial 189 | Epoch 03 | Train Loss: 11370.0795 | Val Loss: 8688.9726 | Optimizer: Adam\n",
      "Trial 189 | Epoch 04 | Train Loss: 10291.9201 | Val Loss: 8360.0702 | Optimizer: Adam\n",
      "Trial 189 | Epoch 05 | Train Loss: 8888.9753 | Val Loss: 6107.6879 | Optimizer: Adam\n",
      "Trial 189 | Epoch 06 | Train Loss: 8165.5062 | Val Loss: 7913.6474 | Optimizer: Adam\n",
      "Trial 189 | Epoch 07 | Train Loss: 9869.7364 | Val Loss: 6630.1040 | Optimizer: Adam\n",
      "Trial 189 | Epoch 08 | Train Loss: 8478.0216 | Val Loss: 6263.9435 | Optimizer: Adam\n",
      "Trial 189 | Epoch 09 | Train Loss: 7289.8226 | Val Loss: 5930.2119 | Optimizer: Adam\n",
      "Trial 189 | Epoch 10 | Train Loss: 6947.8932 | Val Loss: 6135.6695 | Optimizer: Adam\n",
      "Trial 189 | Epoch 11 | Train Loss: 9210.8217 | Val Loss: 8679.4597 | Optimizer: Adam\n",
      "Trial 189 | Epoch 12 | Train Loss: 7730.2617 | Val Loss: 15923.6867 | Optimizer: Adam\n",
      "Trial 189 | Epoch 13 | Train Loss: 11175.1009 | Val Loss: 9704.3343 | Optimizer: Adam\n",
      "Trial 189 | Epoch 14 | Train Loss: 11032.0078 | Val Loss: 9294.4041 | Optimizer: Adam\n",
      "Trial 189 | Epoch 15 | Train Loss: 8170.4963 | Val Loss: 5814.1834 | Optimizer: Adam\n",
      "Trial 189 | Epoch 16 | Train Loss: 6753.5164 | Val Loss: 5835.9964 | Optimizer: Adam\n",
      "Trial 189 | Epoch 17 | Train Loss: 6305.1671 | Val Loss: 5374.7458 | Optimizer: Adam\n",
      "Trial 189 | Epoch 18 | Train Loss: 6256.6841 | Val Loss: 5511.8406 | Optimizer: Adam\n",
      "Trial 189 | Epoch 19 | Train Loss: 6470.5690 | Val Loss: 5248.1405 | Optimizer: Adam\n",
      "Trial 189 | Epoch 20 | Train Loss: 6638.1593 | Val Loss: 5309.1215 | Optimizer: Adam\n",
      "Trial 189 | Epoch 21 | Train Loss: 6461.2949 | Val Loss: 5600.9400 | Optimizer: Adam\n",
      "Trial 189 | Epoch 22 | Train Loss: 5946.1454 | Val Loss: 5379.6858 | Optimizer: Adam\n",
      "Trial 189 | Epoch 23 | Train Loss: 5870.8839 | Val Loss: 5500.8853 | Optimizer: Adam\n",
      "Trial 189 | Epoch 24 | Train Loss: 6178.7081 | Val Loss: 5205.3502 | Optimizer: Adam\n",
      "Trial 189 | Epoch 25 | Train Loss: 5480.4280 | Val Loss: 5158.2394 | Optimizer: Adam\n",
      "Trial 189 | Epoch 26 | Train Loss: 5688.3836 | Val Loss: 5356.0424 | Optimizer: Adam\n",
      "Trial 189 | Epoch 27 | Train Loss: 5882.1940 | Val Loss: 5154.4701 | Optimizer: Adam\n",
      "Trial 189 | Epoch 28 | Train Loss: 5706.6009 | Val Loss: 5188.3131 | Optimizer: Adam\n",
      "Trial 189 | Epoch 29 | Train Loss: 5460.6329 | Val Loss: 5527.0891 | Optimizer: Adam\n",
      "Trial 189 | Epoch 30 | Train Loss: 6887.3140 | Val Loss: 5723.3372 | Optimizer: Adam\n",
      "Trial 189 | Epoch 31 | Train Loss: 5621.5418 | Val Loss: 6255.4931 | Optimizer: Adam\n",
      "Trial 189 | Epoch 32 | Train Loss: 8162.7388 | Val Loss: 7852.5335 | Optimizer: Adam\n",
      "Trial 189 | Epoch 33 | Train Loss: 9207.2377 | Val Loss: 8595.1044 | Optimizer: Adam\n",
      "Trial 189 | Epoch 34 | Train Loss: 7098.4370 | Val Loss: 5196.8770 | Optimizer: Adam\n",
      "Trial 189 | Epoch 35 | Train Loss: 6462.6765 | Val Loss: 7081.3833 | Optimizer: Adam\n",
      "Trial 189 | Epoch 36 | Train Loss: 6582.8836 | Val Loss: 5083.1228 | Optimizer: Adam\n",
      "Trial 189 | Epoch 37 | Train Loss: 6976.1782 | Val Loss: 4965.0047 | Optimizer: Adam\n",
      "Trial 189 | Epoch 38 | Train Loss: 6278.2840 | Val Loss: 6615.2650 | Optimizer: Adam\n",
      "Trial 189 | Epoch 39 | Train Loss: 6228.9016 | Val Loss: 5186.8567 | Optimizer: Adam\n",
      "Trial 189 | Epoch 40 | Train Loss: 5407.8690 | Val Loss: 6312.5133 | Optimizer: Adam\n",
      "Trial 189 | Epoch 41 | Train Loss: 6128.8951 | Val Loss: 5440.3884 | Optimizer: Adam\n",
      "Trial 189 | Epoch 42 | Train Loss: 5695.6329 | Val Loss: 5275.1416 | Optimizer: Adam\n",
      "Trial 189 | Epoch 43 | Train Loss: 5315.9149 | Val Loss: 5116.7012 | Optimizer: Adam\n",
      "Trial 189 | Epoch 44 | Train Loss: 5302.0730 | Val Loss: 5256.8947 | Optimizer: Adam\n",
      "Trial 189 | Epoch 45 | Train Loss: 5899.6693 | Val Loss: 5757.1048 | Optimizer: Adam\n",
      "Trial 189 | Epoch 46 | Train Loss: 5098.0641 | Val Loss: 5343.6046 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:48,751] Trial 189 finished with value: 4965.00473210841 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.3196900599921548, 'lr': 0.0008366507177717356, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 3.647131477457351e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 189 | Epoch 47 | Train Loss: 5155.7123 | Val Loss: 5507.5203 | Optimizer: Adam\n",
      "Trial 189 - Early stopping triggered at epoch 47\n",
      "Trial 190 | Epoch 01 | Train Loss: 18405.0275 | Val Loss: 10866.3908 | Optimizer: Adam\n",
      "Trial 190 | Epoch 02 | Train Loss: 10904.2679 | Val Loss: 9194.7639 | Optimizer: Adam\n",
      "Trial 190 | Epoch 03 | Train Loss: 9672.9125 | Val Loss: 7379.8504 | Optimizer: Adam\n",
      "Trial 190 | Epoch 04 | Train Loss: 9024.2220 | Val Loss: 5848.6662 | Optimizer: Adam\n",
      "Trial 190 | Epoch 05 | Train Loss: 7148.5678 | Val Loss: 5949.1402 | Optimizer: Adam\n",
      "Trial 190 | Epoch 06 | Train Loss: 7461.4690 | Val Loss: 5844.6774 | Optimizer: Adam\n",
      "Trial 190 | Epoch 07 | Train Loss: 7532.2791 | Val Loss: 5353.2428 | Optimizer: Adam\n",
      "Trial 190 | Epoch 08 | Train Loss: 6665.7462 | Val Loss: 6375.8598 | Optimizer: Adam\n",
      "Trial 190 | Epoch 09 | Train Loss: 7784.5466 | Val Loss: 5621.0743 | Optimizer: Adam\n",
      "Trial 190 | Epoch 10 | Train Loss: 6670.7586 | Val Loss: 5754.7819 | Optimizer: Adam\n",
      "Trial 190 | Epoch 11 | Train Loss: 8271.5609 | Val Loss: 6867.7530 | Optimizer: Adam\n",
      "Trial 190 | Epoch 12 | Train Loss: 6796.3369 | Val Loss: 5349.3977 | Optimizer: Adam\n",
      "Trial 190 | Epoch 13 | Train Loss: 6341.8806 | Val Loss: 5730.0848 | Optimizer: Adam\n",
      "Trial 190 | Epoch 14 | Train Loss: 5910.3638 | Val Loss: 5528.0243 | Optimizer: Adam\n",
      "Trial 190 | Epoch 15 | Train Loss: 6030.9118 | Val Loss: 5465.9042 | Optimizer: Adam\n",
      "Trial 190 | Epoch 16 | Train Loss: 6063.3873 | Val Loss: 5242.1750 | Optimizer: Adam\n",
      "Trial 190 | Epoch 17 | Train Loss: 6313.6797 | Val Loss: 5191.1478 | Optimizer: Adam\n",
      "Trial 190 | Epoch 18 | Train Loss: 6524.8629 | Val Loss: 5708.7663 | Optimizer: Adam\n",
      "Trial 190 | Epoch 19 | Train Loss: 5825.8356 | Val Loss: 5464.4308 | Optimizer: Adam\n",
      "Trial 190 | Epoch 20 | Train Loss: 5903.1136 | Val Loss: 5790.2093 | Optimizer: Adam\n",
      "Trial 190 | Epoch 21 | Train Loss: 5897.9745 | Val Loss: 6048.9236 | Optimizer: Adam\n",
      "Trial 190 | Epoch 22 | Train Loss: 7033.3400 | Val Loss: 6557.6177 | Optimizer: Adam\n",
      "Trial 190 | Epoch 23 | Train Loss: 6619.2164 | Val Loss: 5479.2192 | Optimizer: Adam\n",
      "Trial 190 | Epoch 24 | Train Loss: 5952.0810 | Val Loss: 5839.8635 | Optimizer: Adam\n",
      "Trial 190 | Epoch 25 | Train Loss: 6120.5043 | Val Loss: 5154.7070 | Optimizer: Adam\n",
      "Trial 190 | Epoch 26 | Train Loss: 5832.7611 | Val Loss: 5809.1113 | Optimizer: Adam\n",
      "Trial 190 | Epoch 27 | Train Loss: 6588.3005 | Val Loss: 5412.9298 | Optimizer: Adam\n",
      "Trial 190 | Epoch 28 | Train Loss: 5914.7816 | Val Loss: 5167.1275 | Optimizer: Adam\n",
      "Trial 190 | Epoch 29 | Train Loss: 6276.3914 | Val Loss: 5550.1112 | Optimizer: Adam\n",
      "Trial 190 | Epoch 30 | Train Loss: 5856.6822 | Val Loss: 5364.5965 | Optimizer: Adam\n",
      "Trial 190 | Epoch 31 | Train Loss: 5768.7160 | Val Loss: 5319.4688 | Optimizer: Adam\n",
      "Trial 190 | Epoch 32 | Train Loss: 5860.5679 | Val Loss: 5571.1547 | Optimizer: Adam\n",
      "Trial 190 | Epoch 33 | Train Loss: 5198.2780 | Val Loss: 5062.0517 | Optimizer: Adam\n",
      "Trial 190 | Epoch 34 | Train Loss: 4983.9138 | Val Loss: 5224.2142 | Optimizer: Adam\n",
      "Trial 190 | Epoch 35 | Train Loss: 5043.0862 | Val Loss: 5235.2631 | Optimizer: Adam\n",
      "Trial 190 | Epoch 36 | Train Loss: 5888.1053 | Val Loss: 4987.2736 | Optimizer: Adam\n",
      "Trial 190 | Epoch 37 | Train Loss: 5637.5326 | Val Loss: 6038.1563 | Optimizer: Adam\n",
      "Trial 190 | Epoch 38 | Train Loss: 5623.6308 | Val Loss: 5009.4499 | Optimizer: Adam\n",
      "Trial 190 | Epoch 39 | Train Loss: 5118.4893 | Val Loss: 5272.0838 | Optimizer: Adam\n",
      "Trial 190 | Epoch 40 | Train Loss: 5168.3599 | Val Loss: 5397.2935 | Optimizer: Adam\n",
      "Trial 190 | Epoch 41 | Train Loss: 5472.4400 | Val Loss: 5989.8208 | Optimizer: Adam\n",
      "Trial 190 | Epoch 42 | Train Loss: 5994.5791 | Val Loss: 5180.0621 | Optimizer: Adam\n",
      "Trial 190 | Epoch 43 | Train Loss: 5439.5506 | Val Loss: 5246.5724 | Optimizer: Adam\n",
      "Trial 190 | Epoch 44 | Train Loss: 5223.3792 | Val Loss: 4838.9671 | Optimizer: Adam\n",
      "Trial 190 | Epoch 45 | Train Loss: 5221.1093 | Val Loss: 5191.8068 | Optimizer: Adam\n",
      "Trial 190 | Epoch 46 | Train Loss: 5859.1579 | Val Loss: 5653.1492 | Optimizer: Adam\n",
      "Trial 190 | Epoch 47 | Train Loss: 5457.4091 | Val Loss: 5185.8421 | Optimizer: Adam\n",
      "Trial 190 | Epoch 48 | Train Loss: 5212.2082 | Val Loss: 5323.5700 | Optimizer: Adam\n",
      "Trial 190 | Epoch 49 | Train Loss: 5072.7980 | Val Loss: 4869.1526 | Optimizer: Adam\n",
      "Trial 190 | Epoch 50 | Train Loss: 4822.1531 | Val Loss: 6481.3862 | Optimizer: Adam\n",
      "Trial 190 | Epoch 51 | Train Loss: 7917.3901 | Val Loss: 5088.7147 | Optimizer: Adam\n",
      "Trial 190 | Epoch 52 | Train Loss: 6361.9181 | Val Loss: 6742.5711 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:53,923] Trial 190 finished with value: 4838.967086226852 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.3202434181813916, 'lr': 0.0008808587742518549, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 4.327603663684977e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 190 | Epoch 53 | Train Loss: 6913.1703 | Val Loss: 8103.4842 | Optimizer: Adam\n",
      "Trial 190 | Epoch 54 | Train Loss: 8655.6076 | Val Loss: 6008.5010 | Optimizer: Adam\n",
      "Trial 190 - Early stopping triggered at epoch 54\n",
      "Trial 191 | Epoch 01 | Train Loss: 17736.6825 | Val Loss: 10620.2605 | Optimizer: Adam\n",
      "Trial 191 | Epoch 02 | Train Loss: 13295.4514 | Val Loss: 11271.1889 | Optimizer: Adam\n",
      "Trial 191 | Epoch 03 | Train Loss: 12489.1875 | Val Loss: 12176.6011 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:54,347] Trial 191 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 192 | Epoch 01 | Train Loss: 18908.6789 | Val Loss: 10802.8148 | Optimizer: Adam\n",
      "Trial 192 | Epoch 02 | Train Loss: 11400.8648 | Val Loss: 9925.1165 | Optimizer: Adam\n",
      "Trial 192 | Epoch 03 | Train Loss: 9835.1547 | Val Loss: 6874.3565 | Optimizer: Adam\n",
      "Trial 192 | Epoch 04 | Train Loss: 7741.8408 | Val Loss: 6312.5023 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:55,147] Trial 192 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 192 | Epoch 05 | Train Loss: 8305.6849 | Val Loss: 7421.6848 | Optimizer: Adam\n",
      "Trial 192 | Epoch 06 | Train Loss: 7376.1094 | Val Loss: 6889.5632 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:55,294] Trial 193 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 193 | Epoch 01 | Train Loss: 19174.7163 | Val Loss: 12635.7443 | Optimizer: Adam\n",
      "Trial 194 | Epoch 01 | Train Loss: 18620.9419 | Val Loss: 10896.6702 | Optimizer: Adam\n",
      "Trial 194 | Epoch 02 | Train Loss: 11216.2229 | Val Loss: 10326.4013 | Optimizer: Adam\n",
      "Trial 194 | Epoch 03 | Train Loss: 10860.5097 | Val Loss: 8443.8941 | Optimizer: Adam\n",
      "Trial 194 | Epoch 04 | Train Loss: 8887.3753 | Val Loss: 6471.0314 | Optimizer: Adam\n",
      "Trial 194 | Epoch 05 | Train Loss: 7393.6331 | Val Loss: 6098.1981 | Optimizer: Adam\n",
      "Trial 194 | Epoch 06 | Train Loss: 9845.6600 | Val Loss: 7731.4337 | Optimizer: Adam\n",
      "Trial 194 | Epoch 07 | Train Loss: 7905.1120 | Val Loss: 10604.3101 | Optimizer: Adam\n",
      "Trial 194 | Epoch 08 | Train Loss: 9531.2142 | Val Loss: 8203.9835 | Optimizer: Adam\n",
      "Trial 194 | Epoch 09 | Train Loss: 9737.5427 | Val Loss: 7766.4905 | Optimizer: Adam\n",
      "Trial 194 | Epoch 10 | Train Loss: 7500.7086 | Val Loss: 5747.0021 | Optimizer: Adam\n",
      "Trial 194 | Epoch 11 | Train Loss: 7042.3710 | Val Loss: 5378.6177 | Optimizer: Adam\n",
      "Trial 194 | Epoch 12 | Train Loss: 6683.8455 | Val Loss: 5344.8234 | Optimizer: Adam\n",
      "Trial 194 | Epoch 13 | Train Loss: 6529.8958 | Val Loss: 5496.5393 | Optimizer: Adam\n",
      "Trial 194 | Epoch 14 | Train Loss: 6624.9093 | Val Loss: 6988.5880 | Optimizer: Adam\n",
      "Trial 194 | Epoch 15 | Train Loss: 8167.7380 | Val Loss: 7422.6077 | Optimizer: Adam\n",
      "Trial 194 | Epoch 16 | Train Loss: 9316.2610 | Val Loss: 8432.3682 | Optimizer: Adam\n",
      "Trial 194 | Epoch 17 | Train Loss: 8007.7624 | Val Loss: 5724.0710 | Optimizer: Adam\n",
      "Trial 194 | Epoch 18 | Train Loss: 6308.7927 | Val Loss: 5366.8275 | Optimizer: Adam\n",
      "Trial 194 | Epoch 19 | Train Loss: 6184.5722 | Val Loss: 5375.3224 | Optimizer: Adam\n",
      "Trial 194 | Epoch 20 | Train Loss: 6151.5104 | Val Loss: 5457.3026 | Optimizer: Adam\n",
      "Trial 194 | Epoch 21 | Train Loss: 6921.8605 | Val Loss: 5183.2464 | Optimizer: Adam\n",
      "Trial 194 | Epoch 22 | Train Loss: 6095.8109 | Val Loss: 5222.5841 | Optimizer: Adam\n",
      "Trial 194 | Epoch 23 | Train Loss: 6285.2756 | Val Loss: 5165.1129 | Optimizer: Adam\n",
      "Trial 194 | Epoch 24 | Train Loss: 6237.2564 | Val Loss: 5705.9659 | Optimizer: Adam\n",
      "Trial 194 | Epoch 25 | Train Loss: 7044.9249 | Val Loss: 6276.9245 | Optimizer: Adam\n",
      "Trial 194 | Epoch 26 | Train Loss: 6481.2813 | Val Loss: 5351.8370 | Optimizer: Adam\n",
      "Trial 194 | Epoch 27 | Train Loss: 5792.9567 | Val Loss: 5499.5969 | Optimizer: Adam\n",
      "Trial 194 | Epoch 28 | Train Loss: 5644.9439 | Val Loss: 5619.5353 | Optimizer: Adam\n",
      "Trial 194 | Epoch 29 | Train Loss: 5694.3754 | Val Loss: 6173.2400 | Optimizer: Adam\n",
      "Trial 194 | Epoch 30 | Train Loss: 6379.3337 | Val Loss: 5783.9058 | Optimizer: Adam\n",
      "Trial 194 | Epoch 31 | Train Loss: 7129.8124 | Val Loss: 5764.3204 | Optimizer: Adam\n",
      "Trial 194 | Epoch 32 | Train Loss: 6375.2542 | Val Loss: 5215.5620 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:57,353] Trial 194 finished with value: 5165.112871334876 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.31700788963620274, 'lr': 0.000822167962658358, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 6.406461562687465e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 194 | Epoch 33 | Train Loss: 5949.8189 | Val Loss: 5255.8869 | Optimizer: Adam\n",
      "Trial 194 - Early stopping triggered at epoch 33\n",
      "Trial 195 | Epoch 01 | Train Loss: 18042.0902 | Val Loss: 10210.3801 | Optimizer: Adam\n",
      "Trial 195 | Epoch 02 | Train Loss: 11492.0163 | Val Loss: 10602.1478 | Optimizer: Adam\n",
      "Trial 195 | Epoch 03 | Train Loss: 10781.2503 | Val Loss: 8051.2110 | Optimizer: Adam\n",
      "Trial 195 | Epoch 04 | Train Loss: 8553.9882 | Val Loss: 5679.0303 | Optimizer: Adam\n",
      "Trial 195 | Epoch 05 | Train Loss: 7762.4104 | Val Loss: 6459.4874 | Optimizer: Adam\n",
      "Trial 195 | Epoch 06 | Train Loss: 7942.8019 | Val Loss: 5835.3210 | Optimizer: Adam\n",
      "Trial 195 | Epoch 07 | Train Loss: 6982.4987 | Val Loss: 6275.1687 | Optimizer: Adam\n",
      "Trial 195 | Epoch 08 | Train Loss: 7413.6488 | Val Loss: 5936.0828 | Optimizer: Adam\n",
      "Trial 195 | Epoch 09 | Train Loss: 6785.2532 | Val Loss: 6489.9695 | Optimizer: Adam\n",
      "Trial 195 | Epoch 10 | Train Loss: 6911.7225 | Val Loss: 7097.7119 | Optimizer: Adam\n",
      "Trial 195 | Epoch 11 | Train Loss: 7743.8736 | Val Loss: 6853.6029 | Optimizer: Adam\n",
      "Trial 195 | Epoch 12 | Train Loss: 6809.0845 | Val Loss: 6238.4335 | Optimizer: Adam\n",
      "Trial 195 | Epoch 13 | Train Loss: 6549.5904 | Val Loss: 5953.3815 | Optimizer: Adam\n",
      "Trial 195 | Epoch 14 | Train Loss: 6256.2069 | Val Loss: 5383.6809 | Optimizer: Adam\n",
      "Trial 195 | Epoch 15 | Train Loss: 5854.6292 | Val Loss: 7148.0424 | Optimizer: Adam\n",
      "Trial 195 | Epoch 16 | Train Loss: 7037.2686 | Val Loss: 5968.7790 | Optimizer: Adam\n",
      "Trial 195 | Epoch 17 | Train Loss: 6117.3119 | Val Loss: 6581.4103 | Optimizer: Adam\n",
      "Trial 195 | Epoch 18 | Train Loss: 6267.8433 | Val Loss: 5470.7282 | Optimizer: Adam\n",
      "Trial 195 | Epoch 19 | Train Loss: 5907.6992 | Val Loss: 5326.9129 | Optimizer: Adam\n",
      "Trial 195 | Epoch 20 | Train Loss: 5702.9388 | Val Loss: 7586.0143 | Optimizer: Adam\n",
      "Trial 195 | Epoch 21 | Train Loss: 8236.2685 | Val Loss: 5267.6445 | Optimizer: Adam\n",
      "Trial 195 | Epoch 22 | Train Loss: 6756.5280 | Val Loss: 7053.5242 | Optimizer: Adam\n",
      "Trial 195 | Epoch 23 | Train Loss: 6538.0649 | Val Loss: 7446.7037 | Optimizer: Adam\n",
      "Trial 195 | Epoch 24 | Train Loss: 7663.7262 | Val Loss: 8659.9439 | Optimizer: Adam\n",
      "Trial 195 | Epoch 25 | Train Loss: 9504.4527 | Val Loss: 6452.8273 | Optimizer: Adam\n",
      "Trial 195 | Epoch 26 | Train Loss: 6396.6172 | Val Loss: 5423.3739 | Optimizer: Adam\n",
      "Trial 195 | Epoch 27 | Train Loss: 6167.9849 | Val Loss: 6454.0800 | Optimizer: Adam\n",
      "Trial 195 | Epoch 28 | Train Loss: 5931.1780 | Val Loss: 5806.5584 | Optimizer: Adam\n",
      "Trial 195 | Epoch 29 | Train Loss: 5838.5254 | Val Loss: 5587.2520 | Optimizer: Adam\n",
      "Trial 195 | Epoch 30 | Train Loss: 5283.3125 | Val Loss: 5779.7774 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:01:59,226] Trial 195 finished with value: 5267.644483024691 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.31559826290558757, 'lr': 0.000908597757734247, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 4.9452302148085184e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 195 | Epoch 31 | Train Loss: 6417.3307 | Val Loss: 6991.9091 | Optimizer: Adam\n",
      "Trial 195 - Early stopping triggered at epoch 31\n",
      "Trial 196 | Epoch 01 | Train Loss: 18364.1840 | Val Loss: 11119.2442 | Optimizer: Adam\n",
      "Trial 196 | Epoch 02 | Train Loss: 10667.3506 | Val Loss: 9821.9940 | Optimizer: Adam\n",
      "Trial 196 | Epoch 03 | Train Loss: 10360.8446 | Val Loss: 8093.7889 | Optimizer: Adam\n",
      "Trial 196 | Epoch 04 | Train Loss: 9103.6873 | Val Loss: 6556.7596 | Optimizer: Adam\n",
      "Trial 196 | Epoch 05 | Train Loss: 8316.5043 | Val Loss: 8575.5481 | Optimizer: Adam\n",
      "Trial 196 | Epoch 06 | Train Loss: 8979.5716 | Val Loss: 5394.5377 | Optimizer: Adam\n",
      "Trial 196 | Epoch 07 | Train Loss: 7120.7205 | Val Loss: 6526.0136 | Optimizer: Adam\n",
      "Trial 196 | Epoch 08 | Train Loss: 8515.5673 | Val Loss: 7255.0742 | Optimizer: Adam\n",
      "Trial 196 | Epoch 09 | Train Loss: 7164.7964 | Val Loss: 5904.3199 | Optimizer: Adam\n",
      "Trial 196 | Epoch 10 | Train Loss: 7751.5309 | Val Loss: 7307.0133 | Optimizer: Adam\n",
      "Trial 196 | Epoch 11 | Train Loss: 7307.9103 | Val Loss: 6033.8595 | Optimizer: Adam\n",
      "Trial 196 | Epoch 12 | Train Loss: 6977.1932 | Val Loss: 5410.9246 | Optimizer: Adam\n",
      "Trial 196 | Epoch 13 | Train Loss: 6132.4284 | Val Loss: 5551.8662 | Optimizer: Adam\n",
      "Trial 196 | Epoch 14 | Train Loss: 6749.0720 | Val Loss: 6038.0775 | Optimizer: Adam\n",
      "Trial 196 | Epoch 15 | Train Loss: 6871.9721 | Val Loss: 5294.6885 | Optimizer: Adam\n",
      "Trial 196 | Epoch 16 | Train Loss: 6430.8359 | Val Loss: 5645.0313 | Optimizer: Adam\n",
      "Trial 196 | Epoch 17 | Train Loss: 5959.0501 | Val Loss: 7811.5214 | Optimizer: Adam\n",
      "Trial 196 | Epoch 18 | Train Loss: 8526.5589 | Val Loss: 7195.6546 | Optimizer: Adam\n",
      "Trial 196 | Epoch 19 | Train Loss: 7953.5727 | Val Loss: 5551.0497 | Optimizer: Adam\n",
      "Trial 196 | Epoch 20 | Train Loss: 6895.0992 | Val Loss: 5633.3044 | Optimizer: Adam\n",
      "Trial 196 | Epoch 21 | Train Loss: 6704.5847 | Val Loss: 5388.7229 | Optimizer: Adam\n",
      "Trial 196 | Epoch 22 | Train Loss: 7840.0351 | Val Loss: 5391.1167 | Optimizer: Adam\n",
      "Trial 196 | Epoch 23 | Train Loss: 6266.2959 | Val Loss: 5898.9842 | Optimizer: Adam\n",
      "Trial 196 | Epoch 24 | Train Loss: 6225.9573 | Val Loss: 5063.0000 | Optimizer: Adam\n",
      "Trial 196 | Epoch 25 | Train Loss: 5963.5237 | Val Loss: 5502.8091 | Optimizer: Adam\n",
      "Trial 196 | Epoch 26 | Train Loss: 5738.7420 | Val Loss: 5971.9978 | Optimizer: Adam\n",
      "Trial 196 | Epoch 27 | Train Loss: 6330.9680 | Val Loss: 5466.2759 | Optimizer: Adam\n",
      "Trial 196 | Epoch 28 | Train Loss: 5781.6607 | Val Loss: 5068.0894 | Optimizer: Adam\n",
      "Trial 196 | Epoch 29 | Train Loss: 5709.0659 | Val Loss: 5059.0456 | Optimizer: Adam\n",
      "Trial 196 | Epoch 30 | Train Loss: 5190.4422 | Val Loss: 5439.1685 | Optimizer: Adam\n",
      "Trial 196 | Epoch 31 | Train Loss: 6419.3221 | Val Loss: 5787.6727 | Optimizer: Adam\n",
      "Trial 196 | Epoch 32 | Train Loss: 6325.2920 | Val Loss: 5381.8632 | Optimizer: Adam\n",
      "Trial 196 | Epoch 33 | Train Loss: 7228.1626 | Val Loss: 5569.8227 | Optimizer: Adam\n",
      "Trial 196 | Epoch 34 | Train Loss: 5709.6893 | Val Loss: 5037.2319 | Optimizer: Adam\n",
      "Trial 196 | Epoch 35 | Train Loss: 5395.3500 | Val Loss: 5054.8583 | Optimizer: Adam\n",
      "Trial 196 | Epoch 36 | Train Loss: 5146.1119 | Val Loss: 5085.7468 | Optimizer: Adam\n",
      "Trial 196 | Epoch 37 | Train Loss: 5252.2114 | Val Loss: 5140.5131 | Optimizer: Adam\n",
      "Trial 196 | Epoch 38 | Train Loss: 4879.2423 | Val Loss: 5109.3481 | Optimizer: Adam\n",
      "Trial 196 | Epoch 39 | Train Loss: 4879.9716 | Val Loss: 5735.7563 | Optimizer: Adam\n",
      "Trial 196 | Epoch 40 | Train Loss: 5883.6407 | Val Loss: 5061.4652 | Optimizer: Adam\n",
      "Trial 196 | Epoch 41 | Train Loss: 6315.5277 | Val Loss: 5954.0870 | Optimizer: Adam\n",
      "Trial 196 | Epoch 42 | Train Loss: 6232.2140 | Val Loss: 5130.9626 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:01,838] Trial 196 finished with value: 5037.231948664159 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.29709481279179, 'lr': 0.0008234836530719138, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 7.993942580161632e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 196 | Epoch 43 | Train Loss: 5405.6200 | Val Loss: 5440.4912 | Optimizer: Adam\n",
      "Trial 196 | Epoch 44 | Train Loss: 7231.0648 | Val Loss: 7956.4268 | Optimizer: Adam\n",
      "Trial 196 - Early stopping triggered at epoch 44\n",
      "Trial 197 | Epoch 01 | Train Loss: 20625.8362 | Val Loss: 16670.1168 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:01,967] Trial 197 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 198 | Epoch 01 | Train Loss: 18132.7056 | Val Loss: 10205.8079 | Optimizer: Adam\n",
      "Trial 198 | Epoch 02 | Train Loss: 11012.0748 | Val Loss: 9261.8077 | Optimizer: Adam\n",
      "Trial 198 | Epoch 03 | Train Loss: 9414.1586 | Val Loss: 6663.4257 | Optimizer: Adam\n",
      "Trial 198 | Epoch 04 | Train Loss: 8184.6618 | Val Loss: 7124.8272 | Optimizer: Adam\n",
      "Trial 198 | Epoch 05 | Train Loss: 8515.9406 | Val Loss: 6975.1734 | Optimizer: Adam\n",
      "Trial 198 | Epoch 06 | Train Loss: 7372.6720 | Val Loss: 5944.9558 | Optimizer: Adam\n",
      "Trial 198 | Epoch 07 | Train Loss: 9734.8670 | Val Loss: 12140.6221 | Optimizer: Adam\n",
      "Trial 198 | Epoch 08 | Train Loss: 12073.1981 | Val Loss: 8651.4292 | Optimizer: Adam\n",
      "Trial 198 | Epoch 09 | Train Loss: 9109.5531 | Val Loss: 6243.8206 | Optimizer: Adam\n",
      "Trial 198 | Epoch 10 | Train Loss: 7056.8430 | Val Loss: 6759.0012 | Optimizer: Adam\n",
      "Trial 198 | Epoch 11 | Train Loss: 6917.4015 | Val Loss: 6289.2862 | Optimizer: Adam\n",
      "Trial 198 | Epoch 12 | Train Loss: 7046.9613 | Val Loss: 6120.8747 | Optimizer: Adam\n",
      "Trial 198 | Epoch 13 | Train Loss: 7267.5300 | Val Loss: 5585.2806 | Optimizer: Adam\n",
      "Trial 198 | Epoch 14 | Train Loss: 9041.1232 | Val Loss: 6627.4312 | Optimizer: Adam\n",
      "Trial 198 | Epoch 15 | Train Loss: 9188.4740 | Val Loss: 10726.8133 | Optimizer: Adam\n",
      "Trial 198 | Epoch 16 | Train Loss: 9924.4351 | Val Loss: 5845.3450 | Optimizer: Adam\n",
      "Trial 198 | Epoch 17 | Train Loss: 6922.7317 | Val Loss: 5979.1039 | Optimizer: Adam\n",
      "Trial 198 | Epoch 18 | Train Loss: 6536.6395 | Val Loss: 6273.1952 | Optimizer: Adam\n",
      "Trial 198 | Epoch 19 | Train Loss: 6573.0245 | Val Loss: 5314.1265 | Optimizer: Adam\n",
      "Trial 198 | Epoch 20 | Train Loss: 6068.3096 | Val Loss: 5326.6741 | Optimizer: Adam\n",
      "Trial 198 | Epoch 21 | Train Loss: 5821.7101 | Val Loss: 5415.7882 | Optimizer: Adam\n",
      "Trial 198 | Epoch 22 | Train Loss: 6421.3246 | Val Loss: 5531.9495 | Optimizer: Adam\n",
      "Trial 198 | Epoch 23 | Train Loss: 5990.0008 | Val Loss: 5244.7694 | Optimizer: Adam\n",
      "Trial 198 | Epoch 24 | Train Loss: 5723.9520 | Val Loss: 5619.0545 | Optimizer: Adam\n",
      "Trial 198 | Epoch 25 | Train Loss: 7551.6587 | Val Loss: 6172.2651 | Optimizer: Adam\n",
      "Trial 198 | Epoch 26 | Train Loss: 7297.6710 | Val Loss: 5328.8151 | Optimizer: Adam\n",
      "Trial 198 | Epoch 27 | Train Loss: 6951.5182 | Val Loss: 8161.0416 | Optimizer: Adam\n",
      "Trial 198 | Epoch 28 | Train Loss: 7091.8218 | Val Loss: 5486.3308 | Optimizer: Adam\n",
      "Trial 198 | Epoch 29 | Train Loss: 6358.5287 | Val Loss: 5304.7975 | Optimizer: Adam\n",
      "Trial 198 | Epoch 30 | Train Loss: 5886.1673 | Val Loss: 6232.5777 | Optimizer: Adam\n",
      "Trial 198 | Epoch 31 | Train Loss: 6587.4090 | Val Loss: 5535.6296 | Optimizer: Adam\n",
      "Trial 198 | Epoch 32 | Train Loss: 5837.4029 | Val Loss: 5326.5173 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:03,962] Trial 198 finished with value: 5244.769401644483 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.2994125965478684, 'lr': 0.0009937666224628348, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 7.540947300642986e-05}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:04,092] Trial 199 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 198 | Epoch 33 | Train Loss: 5644.0707 | Val Loss: 5275.9348 | Optimizer: Adam\n",
      "Trial 198 - Early stopping triggered at epoch 33\n",
      "Trial 199 | Epoch 01 | Train Loss: 18669.7435 | Val Loss: 11777.7686 | Optimizer: Adam\n",
      "Trial 200 | Epoch 01 | Train Loss: 18387.4872 | Val Loss: 10766.6513 | Optimizer: Adam\n",
      "Trial 200 | Epoch 02 | Train Loss: 11749.0690 | Val Loss: 10301.9983 | Optimizer: Adam\n",
      "Trial 200 | Epoch 03 | Train Loss: 10726.7039 | Val Loss: 8774.7303 | Optimizer: Adam\n",
      "Trial 200 | Epoch 04 | Train Loss: 9141.0470 | Val Loss: 8948.9572 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:04,389] Trial 200 pruned. \n",
      "[I 2025-09-05 19:02:04,518] Trial 201 pruned. \n",
      "[I 2025-09-05 19:02:04,648] Trial 202 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 201 | Epoch 01 | Train Loss: 19002.9175 | Val Loss: 12713.1858 | Optimizer: Adam\n",
      "Trial 202 | Epoch 01 | Train Loss: 18788.8590 | Val Loss: 12174.2095 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:04,889] Trial 203 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 203 | Epoch 01 | Train Loss: 18191.3410 | Val Loss: 10181.0700 | Optimizer: Adam\n",
      "Trial 203 | Epoch 02 | Train Loss: 11120.1895 | Val Loss: 10518.8500 | Optimizer: Adam\n",
      "Trial 203 | Epoch 03 | Train Loss: 12186.0038 | Val Loss: 12104.0592 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:05,104] Trial 204 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 204 | Epoch 01 | Train Loss: 18977.9654 | Val Loss: 11293.0762 | Optimizer: Adam\n",
      "Trial 204 | Epoch 02 | Train Loss: 11288.5478 | Val Loss: 10589.3151 | Optimizer: Adam\n",
      "Trial 205 | Epoch 01 | Train Loss: 20593.4113 | Val Loss: 16307.0874 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:05,232] Trial 205 pruned. \n",
      "[I 2025-09-05 19:02:05,479] Trial 206 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 206 | Epoch 01 | Train Loss: 18189.7866 | Val Loss: 10779.7276 | Optimizer: Adam\n",
      "Trial 206 | Epoch 02 | Train Loss: 12026.3505 | Val Loss: 10463.3409 | Optimizer: Adam\n",
      "Trial 206 | Epoch 03 | Train Loss: 11400.1703 | Val Loss: 10029.1436 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:05,723] Trial 207 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 207 | Epoch 01 | Train Loss: 18555.7575 | Val Loss: 10392.3114 | Optimizer: Adam\n",
      "Trial 207 | Epoch 02 | Train Loss: 11817.2035 | Val Loss: 11929.0407 | Optimizer: Adam\n",
      "Trial 207 | Epoch 03 | Train Loss: 12610.3599 | Val Loss: 11457.5626 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:05,916] Trial 208 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 208 | Epoch 01 | Train Loss: 18399.1423 | Val Loss: 11057.7358 | Optimizer: Adam\n",
      "Trial 208 | Epoch 02 | Train Loss: 11709.2420 | Val Loss: 10989.1017 | Optimizer: Adam\n",
      "Trial 209 | Epoch 01 | Train Loss: 18844.0600 | Val Loss: 12208.6230 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:06,050] Trial 209 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 210 | Epoch 01 | Train Loss: 18897.4985 | Val Loss: 11034.8893 | Optimizer: Adam\n",
      "Trial 210 | Epoch 02 | Train Loss: 12189.4882 | Val Loss: 10153.0879 | Optimizer: Adam\n",
      "Trial 210 | Epoch 03 | Train Loss: 10805.1599 | Val Loss: 8926.7141 | Optimizer: Adam\n",
      "Trial 210 | Epoch 04 | Train Loss: 10279.5198 | Val Loss: 6920.1262 | Optimizer: Adam\n",
      "Trial 210 | Epoch 05 | Train Loss: 7703.7503 | Val Loss: 5855.9888 | Optimizer: Adam\n",
      "Trial 210 | Epoch 06 | Train Loss: 8017.1413 | Val Loss: 7166.5569 | Optimizer: Adam\n",
      "Trial 210 | Epoch 07 | Train Loss: 9394.9519 | Val Loss: 5833.2313 | Optimizer: Adam\n",
      "Trial 210 | Epoch 08 | Train Loss: 9453.2328 | Val Loss: 6546.6274 | Optimizer: Adam\n",
      "Trial 210 | Epoch 09 | Train Loss: 9367.3999 | Val Loss: 9588.8586 | Optimizer: Adam\n",
      "Trial 210 | Epoch 10 | Train Loss: 8581.9306 | Val Loss: 7323.4477 | Optimizer: Adam\n",
      "Trial 210 | Epoch 11 | Train Loss: 9051.9522 | Val Loss: 5977.4634 | Optimizer: Adam\n",
      "Trial 210 | Epoch 12 | Train Loss: 8006.4468 | Val Loss: 6361.9740 | Optimizer: Adam\n",
      "Trial 210 | Epoch 13 | Train Loss: 6761.8239 | Val Loss: 7107.6059 | Optimizer: Adam\n",
      "Trial 210 | Epoch 14 | Train Loss: 7519.2538 | Val Loss: 6967.8424 | Optimizer: Adam\n",
      "Trial 210 | Epoch 15 | Train Loss: 8799.3838 | Val Loss: 7857.5894 | Optimizer: Adam\n",
      "Trial 210 | Epoch 16 | Train Loss: 7329.3312 | Val Loss: 6801.2431 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:07,150] Trial 210 finished with value: 5833.231285566165 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.31918680128550087, 'lr': 0.0008748531769544928, 'activation': 'GELU', 'optimizer': 'Adam', 'weight_decay': 3.3973619356154615e-05}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:07,274] Trial 211 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 210 | Epoch 17 | Train Loss: 7212.0149 | Val Loss: 6033.5476 | Optimizer: Adam\n",
      "Trial 210 - Early stopping triggered at epoch 17\n",
      "Trial 211 | Epoch 01 | Train Loss: 16410.0832 | Val Loss: 11728.5181 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:07,405] Trial 212 pruned. \n",
      "[I 2025-09-05 19:02:07,536] Trial 213 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 212 | Epoch 01 | Train Loss: 18937.1561 | Val Loss: 12671.3794 | Optimizer: Adam\n",
      "Trial 213 | Epoch 01 | Train Loss: 21156.6118 | Val Loss: 20876.9623 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:07,671] Trial 214 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 214 | Epoch 01 | Train Loss: 21103.0418 | Val Loss: 19324.9190 | Optimizer: Adam\n",
      "Trial 215 | Epoch 01 | Train Loss: 18713.8137 | Val Loss: 10804.7502 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 02 | Train Loss: 10865.8163 | Val Loss: 8114.6864 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 03 | Train Loss: 8103.5403 | Val Loss: 6668.2938 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 04 | Train Loss: 7783.7696 | Val Loss: 5787.8920 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 05 | Train Loss: 6757.6739 | Val Loss: 5489.2777 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 06 | Train Loss: 6605.4243 | Val Loss: 5521.5086 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 07 | Train Loss: 6657.9967 | Val Loss: 5396.3466 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 08 | Train Loss: 6457.2298 | Val Loss: 6453.7422 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 09 | Train Loss: 6497.4874 | Val Loss: 5466.3094 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 10 | Train Loss: 6507.5262 | Val Loss: 9136.4536 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 11 | Train Loss: 11018.1588 | Val Loss: 10206.5141 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 12 | Train Loss: 7876.6711 | Val Loss: 5514.4175 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 13 | Train Loss: 8804.2910 | Val Loss: 5744.2835 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 14 | Train Loss: 8383.2447 | Val Loss: 7192.8120 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 15 | Train Loss: 7348.7029 | Val Loss: 5447.5838 | Optimizer: AdamW\n",
      "Trial 215 | Epoch 16 | Train Loss: 6813.1853 | Val Loss: 5536.2241 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:09,161] Trial 215 finished with value: 5396.346625434027 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.3282735592940588, 'lr': 0.0007630632043811693, 'activation': 'GELU', 'optimizer': 'AdamW', 'weight_decay': 1.082295451662262e-06}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:09,285] Trial 216 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 215 | Epoch 17 | Train Loss: 6498.4315 | Val Loss: 5653.3785 | Optimizer: AdamW\n",
      "Trial 215 - Early stopping triggered at epoch 17\n",
      "Trial 216 | Epoch 01 | Train Loss: 18106.4958 | Val Loss: 11899.9482 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:09,408] Trial 217 pruned. \n",
      "[I 2025-09-05 19:02:09,539] Trial 218 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 217 | Epoch 01 | Train Loss: 20378.1645 | Val Loss: 17733.1807 | Optimizer: Adam\n",
      "Trial 218 | Epoch 01 | Train Loss: 20284.1252 | Val Loss: 16774.6554 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:09,667] Trial 219 pruned. \n",
      "[I 2025-09-05 19:02:09,823] Trial 220 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 219 | Epoch 01 | Train Loss: 20341.0391 | Val Loss: 16893.5310 | Optimizer: Adam\n",
      "Trial 220 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:09,949] Trial 221 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 221 | Epoch 01 | Train Loss: 18273.1359 | Val Loss: 11546.6635 | Optimizer: Adam\n",
      "Trial 222 | Epoch 01 | Train Loss: 17509.9614 | Val Loss: 10893.6417 | Optimizer: Adam\n",
      "Trial 222 | Epoch 02 | Train Loss: 10985.1339 | Val Loss: 10620.7929 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:10,143] Trial 222 pruned. \n",
      "[I 2025-09-05 19:02:10,381] Trial 223 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 223 | Epoch 01 | Train Loss: 17471.6782 | Val Loss: 10445.2095 | Optimizer: Adam\n",
      "Trial 223 | Epoch 02 | Train Loss: 10848.0212 | Val Loss: 10415.2364 | Optimizer: Adam\n",
      "Trial 223 | Epoch 03 | Train Loss: 11646.8471 | Val Loss: 9385.7979 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:10,514] Trial 224 pruned. \n",
      "[I 2025-09-05 19:02:10,638] Trial 225 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 224 | Epoch 01 | Train Loss: 16771.5374 | Val Loss: 12408.2897 | Optimizer: Adam\n",
      "Trial 225 | Epoch 01 | Train Loss: 20755.7657 | Val Loss: 17975.6339 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:10,759] Trial 226 pruned. \n",
      "[I 2025-09-05 19:02:10,918] Trial 227 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 226 | Epoch 01 | Train Loss: 18222.4094 | Val Loss: 11900.7897 | Optimizer: AdamW\n",
      "Trial 227 | Epoch 01 | Train Loss: 19607.8020 | Val Loss: 13741.7496 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:11,042] Trial 228 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 228 | Epoch 01 | Train Loss: 15042.6820 | Val Loss: 34372.2029 | Optimizer: RMSprop\n",
      "Trial 229 | Epoch 01 | Train Loss: 21906.6802 | Val Loss: 22278.4684 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:11,232] Trial 229 pruned. \n",
      "[I 2025-09-05 19:02:11,358] Trial 230 pruned. \n",
      "[I 2025-09-05 19:02:11,474] Trial 231 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 230 | Epoch 01 | Train Loss: 22326.9115 | Val Loss: 21449.3047 | Optimizer: AdamW\n",
      "Trial 231 | Epoch 01 | Train Loss: 53010.2509 | Val Loss: 15925.1882 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:11,600] Trial 232 pruned. \n",
      "[I 2025-09-05 19:02:11,724] Trial 233 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 232 | Epoch 01 | Train Loss: 18203.9677 | Val Loss: 12652.3283 | Optimizer: RMSprop\n",
      "Trial 233 | Epoch 01 | Train Loss: 14085.8315 | Val Loss: 13778.8794 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:11,847] Trial 234 pruned. \n",
      "[I 2025-09-05 19:02:11,989] Trial 235 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 234 | Epoch 01 | Train Loss: 16196.2571 | Val Loss: 132887.4437 | Optimizer: RMSprop\n",
      "Trial 235 | Epoch 01 | Train Loss: 17218.2828 | Val Loss: 13657.0872 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 01 | Train Loss: 18248.3631 | Val Loss: 10962.9138 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 02 | Train Loss: 11268.3573 | Val Loss: 9298.5212 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 03 | Train Loss: 9411.8636 | Val Loss: 7151.8907 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 04 | Train Loss: 8880.7224 | Val Loss: 95594.9114 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 05 | Train Loss: 28293.2512 | Val Loss: 8806.9236 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 06 | Train Loss: 9008.0923 | Val Loss: 6130.1852 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 07 | Train Loss: 7729.1256 | Val Loss: 6245.4925 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 08 | Train Loss: 7340.3458 | Val Loss: 6067.1176 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 09 | Train Loss: 7496.8041 | Val Loss: 5990.3684 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 10 | Train Loss: 7147.6104 | Val Loss: 5952.9291 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 11 | Train Loss: 7090.3181 | Val Loss: 6253.8057 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 12 | Train Loss: 6830.5956 | Val Loss: 7428.0531 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 13 | Train Loss: 7523.8683 | Val Loss: 5607.8926 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 14 | Train Loss: 6784.3346 | Val Loss: 5391.7625 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 15 | Train Loss: 6589.2993 | Val Loss: 7271.7359 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 16 | Train Loss: 6881.6670 | Val Loss: 6852.3117 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 17 | Train Loss: 6884.7617 | Val Loss: 5294.4356 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 18 | Train Loss: 6292.6672 | Val Loss: 7194.2957 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 19 | Train Loss: 6920.8683 | Val Loss: 5448.4068 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 20 | Train Loss: 6315.9543 | Val Loss: 5708.9002 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 21 | Train Loss: 6236.1854 | Val Loss: 6086.2831 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 22 | Train Loss: 6194.7478 | Val Loss: 5922.6737 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 23 | Train Loss: 6056.8461 | Val Loss: 9256.9633 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 24 | Train Loss: 7163.2620 | Val Loss: 9750.6643 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 25 | Train Loss: 7544.4693 | Val Loss: 5482.4915 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 26 | Train Loss: 6022.9851 | Val Loss: 5308.9685 | Optimizer: RMSprop\n",
      "Trial 236 | Epoch 27 | Train Loss: 6075.3222 | Val Loss: 5399.8465 | Optimizer: RMSprop\n",
      "Trial 236 - Early stopping triggered at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:13,461] Trial 236 finished with value: 5294.435598114391 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.15561410566186373, 'lr': 0.00043604025551845693, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 8.997255347967321e-06}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:13,607] Trial 237 pruned. \n",
      "[I 2025-09-05 19:02:13,727] Trial 238 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 237 | Epoch 01 | Train Loss: 21122.2166 | Val Loss: 20419.3068 | Optimizer: Adam\n",
      "Trial 238 | Epoch 01 | Train Loss: 18703.9238 | Val Loss: 11309.7987 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:13,858] Trial 239 pruned. \n",
      "[I 2025-09-05 19:02:14,015] Trial 240 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 239 | Epoch 01 | Train Loss: 20572.9886 | Val Loss: 13340.4843 | Optimizer: RMSprop\n",
      "Trial 240 | Epoch 01 | Train Loss: 19242.2725 | Val Loss: 14225.3696 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:14,290] Trial 241 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 241 | Epoch 01 | Train Loss: 17546.5618 | Val Loss: 10427.6503 | Optimizer: Adam\n",
      "Trial 241 | Epoch 02 | Train Loss: 11388.4100 | Val Loss: 10391.5522 | Optimizer: Adam\n",
      "Trial 241 | Epoch 03 | Train Loss: 11903.5318 | Val Loss: 11368.8623 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:14,428] Trial 242 pruned. \n",
      "[I 2025-09-05 19:02:14,554] Trial 243 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 242 | Epoch 01 | Train Loss: 17977.0853 | Val Loss: 12634.5727 | Optimizer: Adam\n",
      "Trial 243 | Epoch 01 | Train Loss: 17482.8335 | Val Loss: 11632.2704 | Optimizer: Adam\n",
      "Trial 244 | Epoch 01 | Train Loss: 16578.3783 | Val Loss: 10243.5313 | Optimizer: Adam\n",
      "Trial 244 | Epoch 02 | Train Loss: 10717.8481 | Val Loss: 8943.2134 | Optimizer: Adam\n",
      "Trial 244 | Epoch 03 | Train Loss: 9636.2426 | Val Loss: 7113.7477 | Optimizer: Adam\n",
      "Trial 244 | Epoch 04 | Train Loss: 9393.5823 | Val Loss: 6373.0008 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:14,980] Trial 244 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 244 | Epoch 05 | Train Loss: 7245.3442 | Val Loss: 8628.0067 | Optimizer: Adam\n",
      "Trial 244 | Epoch 06 | Train Loss: 8904.4922 | Val Loss: 7327.6669 | Optimizer: Adam\n",
      "Trial 245 | Epoch 01 | Train Loss: 18343.0229 | Val Loss: 12400.6547 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:15,110] Trial 245 pruned. \n",
      "[I 2025-09-05 19:02:15,258] Trial 246 pruned. \n",
      "[I 2025-09-05 19:02:15,384] Trial 247 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 246 | Epoch 01 | Train Loss: 18430.2045 | Val Loss: 14447.4981 | Optimizer: AdamW\n",
      "Trial 247 | Epoch 01 | Train Loss: 20219.3430 | Val Loss: 18351.0189 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:15,551] Trial 248 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 248 | Epoch 01 | Train Loss: 17609.3616 | Val Loss: 11127.8236 | Optimizer: Adam\n",
      "Trial 248 | Epoch 02 | Train Loss: 12132.1963 | Val Loss: 11110.5324 | Optimizer: Adam\n",
      "Trial 249 | Epoch 01 | Train Loss: 15356.6700 | Val Loss: 147721.5409 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:15,666] Trial 249 pruned. \n",
      "[I 2025-09-05 19:02:15,795] Trial 250 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 250 | Epoch 01 | Train Loss: 21702.5125 | Val Loss: 21667.8395 | Optimizer: Adam\n",
      "Trial 251 | Epoch 01 | Train Loss: 20912.8716 | Val Loss: 16944.1141 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:15,968] Trial 251 pruned. \n",
      "[I 2025-09-05 19:02:16,084] Trial 252 pruned. \n",
      "[I 2025-09-05 19:02:16,203] Trial 253 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 252 | Epoch 01 | Train Loss: 17135.5706 | Val Loss: 19986.3404 | Optimizer: RMSprop\n",
      "Trial 253 | Epoch 01 | Train Loss: 20390.4201 | Val Loss: 18524.2565 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:16,403] Trial 254 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 | Epoch 01 | Train Loss: 114887.1024 | Val Loss: 10660.8202 | Optimizer: RMSprop\n",
      "Trial 254 | Epoch 02 | Train Loss: 10940.3769 | Val Loss: 17523.0748 | Optimizer: RMSprop\n",
      "Trial 255 | Epoch 01 | Train Loss: 21321.5964 | Val Loss: 20380.6497 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:16,524] Trial 255 pruned. \n",
      "[I 2025-09-05 19:02:16,641] Trial 256 pruned. \n",
      "[I 2025-09-05 19:02:16,752] Trial 257 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 256 | Epoch 01 | Train Loss: 18000.0626 | Val Loss: 12197.9595 | Optimizer: AdamW\n",
      "Trial 257 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:16,875] Trial 258 pruned. \n",
      "[I 2025-09-05 19:02:16,992] Trial 259 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 258 | Epoch 01 | Train Loss: 15643.9521 | Val Loss: 13357.9835 | Optimizer: RMSprop\n",
      "Trial 259 | Epoch 01 | Train Loss: 19992.3421 | Val Loss: 17598.4042 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:17,133] Trial 260 pruned. \n",
      "[I 2025-09-05 19:02:17,253] Trial 261 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 260 | Epoch 01 | Train Loss: 30357.5870 | Val Loss: 12973.9839 | Optimizer: RMSprop\n",
      "Trial 261 | Epoch 01 | Train Loss: 18617.1756 | Val Loss: 12908.7732 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:17,385] Trial 262 pruned. \n",
      "[I 2025-09-05 19:02:17,546] Trial 263 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 262 | Epoch 01 | Train Loss: 19815.3374 | Val Loss: 17440.9907 | Optimizer: AdamW\n",
      "Trial 263 | Epoch 01 | Train Loss: 503734.0648 | Val Loss: 65669.6480 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:17,786] Trial 264 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 264 | Epoch 01 | Train Loss: 16848.0483 | Val Loss: 10690.4602 | Optimizer: Adam\n",
      "Trial 264 | Epoch 02 | Train Loss: 11932.7017 | Val Loss: 10274.5185 | Optimizer: Adam\n",
      "Trial 264 | Epoch 03 | Train Loss: 11290.6325 | Val Loss: 9289.6113 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:17,994] Trial 265 pruned. \n",
      "[I 2025-09-05 19:02:18,135] Trial 266 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 265 | Epoch 01 | Train Loss: 139425.7686 | Val Loss: 12610.3823 | Optimizer: RMSprop\n",
      "Trial 266 | Epoch 01 | Train Loss: 19585.8211 | Val Loss: 14033.6053 | Optimizer: Adam\n",
      "Trial 267 | Epoch 01 | Train Loss: 13443.2789 | Val Loss: 9321.4459 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 02 | Train Loss: 8739.5257 | Val Loss: 7228.1129 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 03 | Train Loss: 8010.5708 | Val Loss: 6188.0776 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 04 | Train Loss: 7083.8224 | Val Loss: 5913.8403 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 05 | Train Loss: 7370.5279 | Val Loss: 5674.6544 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 06 | Train Loss: 7161.8161 | Val Loss: 5487.8809 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 07 | Train Loss: 6663.9261 | Val Loss: 6875.6382 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 08 | Train Loss: 6761.2840 | Val Loss: 5369.7061 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 09 | Train Loss: 6655.0688 | Val Loss: 5712.7089 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 10 | Train Loss: 6787.5375 | Val Loss: 6186.7717 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 11 | Train Loss: 6610.6615 | Val Loss: 6761.3840 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 12 | Train Loss: 6702.6002 | Val Loss: 5913.0020 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 13 | Train Loss: 6920.3247 | Val Loss: 6275.1261 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 14 | Train Loss: 6325.2807 | Val Loss: 6569.9307 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 15 | Train Loss: 7006.0870 | Val Loss: 6150.8560 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 16 | Train Loss: 6637.8533 | Val Loss: 6762.3159 | Optimizer: RMSprop\n",
      "Trial 267 | Epoch 17 | Train Loss: 6808.9624 | Val Loss: 15885.8519 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:19,184] Trial 267 finished with value: 5369.706063729745 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3219525822206331, 'lr': 0.00033921892248462885, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 5.4306513618210684e-05}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:19,329] Trial 268 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 267 | Epoch 18 | Train Loss: 9228.0920 | Val Loss: 5424.3687 | Optimizer: RMSprop\n",
      "Trial 267 - Early stopping triggered at epoch 18\n",
      "Trial 268 | Epoch 01 | Train Loss: 20542.8609 | Val Loss: 17571.0853 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:19,456] Trial 269 pruned. \n",
      "[I 2025-09-05 19:02:19,574] Trial 270 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 269 | Epoch 01 | Train Loss: 861813.1552 | Val Loss: 21112.4490 | Optimizer: RMSprop\n",
      "Trial 270 | Epoch 01 | Train Loss: 20343.5731 | Val Loss: 18051.5918 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:19,692] Trial 271 pruned. \n",
      "[I 2025-09-05 19:02:19,826] Trial 272 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 271 | Epoch 01 | Train Loss: 16689.5963 | Val Loss: 11853.9574 | Optimizer: RMSprop\n",
      "Trial 272 | Epoch 01 | Train Loss: 21260.7112 | Val Loss: 20741.9164 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:19,994] Trial 273 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 273 | Epoch 01 | Train Loss: 17002.2195 | Val Loss: 11082.7693 | Optimizer: AdamW\n",
      "Trial 273 | Epoch 02 | Train Loss: 11989.3103 | Val Loss: 11076.0193 | Optimizer: AdamW\n",
      "Trial 274 | Epoch 01 | Train Loss: 24236930.0537 | Val Loss: 26678.3077 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:20,121] Trial 274 pruned. \n",
      "[I 2025-09-05 19:02:20,273] Trial 275 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 275 | Epoch 01 | Train Loss: 19636.2521 | Val Loss: 15129.7168 | Optimizer: Adam\n",
      "Trial 276 | Epoch 01 | Train Loss: 14851.8016 | Val Loss: 10461.1652 | Optimizer: RMSprop\n",
      "Trial 276 | Epoch 02 | Train Loss: 11132.8111 | Val Loss: 84840.8948 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:20,445] Trial 276 pruned. \n",
      "[I 2025-09-05 19:02:20,594] Trial 277 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 277 | Epoch 01 | Train Loss: 19149.0764 | Val Loss: 13973.2388 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:20,803] Trial 278 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 278 | Epoch 01 | Train Loss: 21584.2448 | Val Loss: 20969.0744 | Optimizer: AdamW\n",
      "Trial 279 | Epoch 01 | Train Loss: 14053.8428 | Val Loss: 10466.9963 | Optimizer: RMSprop\n",
      "Trial 279 | Epoch 02 | Train Loss: 11261.3177 | Val Loss: 9213.7938 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:21,198] Trial 279 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 279 | Epoch 03 | Train Loss: 9377.8389 | Val Loss: 6547.6734 | Optimizer: RMSprop\n",
      "Trial 279 | Epoch 04 | Train Loss: 7196.3386 | Val Loss: 6933.2247 | Optimizer: RMSprop\n",
      "Trial 279 | Epoch 05 | Train Loss: 7548.7375 | Val Loss: 14053.9581 | Optimizer: RMSprop\n",
      "Trial 279 | Epoch 06 | Train Loss: 10238.6708 | Val Loss: 6626.3954 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:21,331] Trial 280 pruned. \n",
      "[I 2025-09-05 19:02:21,447] Trial 281 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 280 | Epoch 01 | Train Loss: 19632.1177 | Val Loss: 16120.3430 | Optimizer: Adam\n",
      "Trial 281 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:21,594] Trial 282 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 282 | Epoch 01 | Train Loss: 17801.6575 | Val Loss: 14280.3079 | Optimizer: RMSprop\n",
      "Trial 283 | Epoch 01 | Train Loss: 17401.2240 | Val Loss: 11054.6772 | Optimizer: Adam\n",
      "Trial 283 | Epoch 02 | Train Loss: 12132.6584 | Val Loss: 10757.5648 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:21,783] Trial 283 pruned. \n",
      "[I 2025-09-05 19:02:21,922] Trial 284 pruned. \n",
      "[I 2025-09-05 19:02:22,049] Trial 285 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 284 | Epoch 01 | Train Loss: 432069.5837 | Val Loss: 13357.4175 | Optimizer: RMSprop\n",
      "Trial 285 | Epoch 01 | Train Loss: 18067.4123 | Val Loss: 11660.1955 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:22,199] Trial 286 pruned. \n",
      "[I 2025-09-05 19:02:22,327] Trial 287 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 286 | Epoch 01 | Train Loss: 21517.8025 | Val Loss: 20733.3221 | Optimizer: Adam\n",
      "Trial 287 | Epoch 01 | Train Loss: 21714.1601 | Val Loss: 41934.6001 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:22,454] Trial 288 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 288 | Epoch 01 | Train Loss: 18861.2185 | Val Loss: 13850.4645 | Optimizer: Adam\n",
      "Trial 289 | Epoch 01 | Train Loss: 28357.5394 | Val Loss: 10836.8206 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:22,666] Trial 289 pruned. \n",
      "[I 2025-09-05 19:02:22,819] Trial 290 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 289 | Epoch 02 | Train Loss: 12211.5343 | Val Loss: 13023.8728 | Optimizer: RMSprop\n",
      "Trial 290 | Epoch 01 | Train Loss: 20293.2814 | Val Loss: 17763.3812 | Optimizer: AdamW\n",
      "Trial 291 | Epoch 01 | Train Loss: 19917.8591 | Val Loss: 10595.0595 | Optimizer: Adam\n",
      "Trial 291 | Epoch 02 | Train Loss: 11242.9683 | Val Loss: 10118.3040 | Optimizer: Adam\n",
      "Trial 291 | Epoch 03 | Train Loss: 10531.8649 | Val Loss: 7558.6309 | Optimizer: Adam\n",
      "Trial 291 | Epoch 04 | Train Loss: 11073.6098 | Val Loss: 9769.3170 | Optimizer: Adam\n",
      "Trial 291 | Epoch 05 | Train Loss: 12856.4099 | Val Loss: 12365.5258 | Optimizer: Adam\n",
      "Trial 291 | Epoch 06 | Train Loss: 10963.4058 | Val Loss: 6468.6111 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:23,467] Trial 291 pruned. \n",
      "[I 2025-09-05 19:02:23,587] Trial 292 pruned. \n",
      "[I 2025-09-05 19:02:23,714] Trial 293 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 292 | Epoch 01 | Train Loss: 29343.6081 | Val Loss: 21919.3149 | Optimizer: RMSprop\n",
      "Trial 293 | Epoch 01 | Train Loss: 22076.5197 | Val Loss: 21092.9829 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:23,834] Trial 294 pruned. \n",
      "[I 2025-09-05 19:02:23,961] Trial 295 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 294 | Epoch 01 | Train Loss: 15463.6278 | Val Loss: 12971.8511 | Optimizer: RMSprop\n",
      "Trial 295 | Epoch 01 | Train Loss: 19321.4488 | Val Loss: 13467.5710 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:24,127] Trial 296 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 296 | Epoch 01 | Train Loss: 18548.3549 | Val Loss: 10985.2516 | Optimizer: RMSprop\n",
      "Trial 296 | Epoch 02 | Train Loss: 12168.8611 | Val Loss: 14088.8099 | Optimizer: RMSprop\n",
      "Trial 297 | Epoch 01 | Train Loss: 20303.3984 | Val Loss: 17285.9889 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:24,270] Trial 297 pruned. \n",
      "[I 2025-09-05 19:02:24,401] Trial 298 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 298 | Epoch 01 | Train Loss: 346120.1131 | Val Loss: 12868.2929 | Optimizer: RMSprop\n",
      "Trial 299 | Epoch 01 | Train Loss: 17289.2018 | Val Loss: 11205.3148 | Optimizer: Adam\n",
      "Trial 299 | Epoch 02 | Train Loss: 12239.9459 | Val Loss: 10527.5891 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:24,574] Trial 299 pruned. \n",
      "[I 2025-09-05 19:02:24,704] Trial 300 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 300 | Epoch 01 | Train Loss: 70785.5838 | Val Loss: 19950.4916 | Optimizer: RMSprop\n",
      "Trial 301 | Epoch 01 | Train Loss: 16963.0409 | Val Loss: 11122.6485 | Optimizer: Adam\n",
      "Trial 301 | Epoch 02 | Train Loss: 11549.7013 | Val Loss: 10534.8644 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:24,884] Trial 301 pruned. \n",
      "[I 2025-09-05 19:02:25,006] Trial 302 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 302 | Epoch 01 | Train Loss: 20218.0067 | Val Loss: 15196.1894 | Optimizer: AdamW\n",
      "Trial 303 | Epoch 01 | Train Loss: 16109.6353 | Val Loss: 10049.1668 | Optimizer: RMSprop\n",
      "Trial 303 | Epoch 02 | Train Loss: 10687.5286 | Val Loss: 10058.3086 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:25,221] Trial 303 pruned. \n",
      "[I 2025-09-05 19:02:25,361] Trial 304 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 303 | Epoch 03 | Train Loss: 9059.8668 | Val Loss: 36211.6619 | Optimizer: RMSprop\n",
      "Trial 304 | Epoch 01 | Train Loss: 20707.2009 | Val Loss: 18499.0564 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:25,538] Trial 305 pruned. \n",
      "[I 2025-09-05 19:02:25,662] Trial 306 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 305 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 306 | Epoch 01 | Train Loss: 18591.5750 | Val Loss: 14661.1825 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:25,790] Trial 307 pruned. \n",
      "[I 2025-09-05 19:02:25,942] Trial 308 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 307 | Epoch 01 | Train Loss: 20623.4798 | Val Loss: 19251.8705 | Optimizer: Adam\n",
      "Trial 308 | Epoch 01 | Train Loss: 22127.6465 | Val Loss: 22436.6610 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:26,125] Trial 309 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 309 | Epoch 01 | Train Loss: 15354.1284 | Val Loss: 10861.6243 | Optimizer: RMSprop\n",
      "Trial 309 | Epoch 02 | Train Loss: 11494.5843 | Val Loss: 51528.9548 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:26,275] Trial 310 pruned. \n",
      "[I 2025-09-05 19:02:26,401] Trial 311 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 310 | Epoch 01 | Train Loss: 20007.6812 | Val Loss: 14549.9024 | Optimizer: Adam\n",
      "Trial 311 | Epoch 01 | Train Loss: 18316.3569 | Val Loss: 14028.7693 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:26,559] Trial 312 pruned. \n",
      "[I 2025-09-05 19:02:26,716] Trial 313 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 312 | Epoch 01 | Train Loss: 20501.7291 | Val Loss: 17135.4320 | Optimizer: Adam\n",
      "Trial 313 | Epoch 01 | Train Loss: 19632.3359 | Val Loss: 13519.2971 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:26,843] Trial 314 pruned. \n",
      "[I 2025-09-05 19:02:27,000] Trial 315 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 314 | Epoch 01 | Train Loss: 17297.4549 | Val Loss: 18538.7596 | Optimizer: RMSprop\n",
      "Trial 315 | Epoch 01 | Train Loss: 20235.0354 | Val Loss: 15962.2070 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:27,134] Trial 316 pruned. \n",
      "[I 2025-09-05 19:02:27,259] Trial 317 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 316 | Epoch 01 | Train Loss: 14823.2933 | Val Loss: 12026.4774 | Optimizer: RMSprop\n",
      "Trial 317 | Epoch 01 | Train Loss: 19949.4821 | Val Loss: 15700.6808 | Optimizer: Adam\n",
      "Trial 318 | Epoch 01 | Train Loss: 19819.5169 | Val Loss: 10121.5555 | Optimizer: RMSprop\n",
      "Trial 318 | Epoch 02 | Train Loss: 10698.5253 | Val Loss: 9330.8656 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:27,701] Trial 318 pruned. \n",
      "[I 2025-09-05 19:02:27,834] Trial 319 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 318 | Epoch 03 | Train Loss: 8354.6614 | Val Loss: 13590.7790 | Optimizer: RMSprop\n",
      "Trial 319 | Epoch 01 | Train Loss: 18928.6574 | Val Loss: 14149.7176 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:28,032] Trial 320 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 320 | Epoch 01 | Train Loss: 17374.4949 | Val Loss: 11047.7465 | Optimizer: Adam\n",
      "Trial 320 | Epoch 02 | Train Loss: 13001.1329 | Val Loss: 11508.9485 | Optimizer: Adam\n",
      "Trial 321 | Epoch 01 | Train Loss: 450021.7537 | Val Loss: 13107.9264 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:28,155] Trial 321 pruned. \n",
      "[I 2025-09-05 19:02:28,276] Trial 322 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 322 | Epoch 01 | Train Loss: 20098.9651 | Val Loss: 18461.9680 | Optimizer: Adam\n",
      "Trial 323 | Epoch 01 | Train Loss: 15639.8737 | Val Loss: 10483.9216 | Optimizer: RMSprop\n",
      "Trial 323 | Epoch 02 | Train Loss: 10833.9101 | Val Loss: 9186.5901 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:28,551] Trial 323 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 323 | Epoch 03 | Train Loss: 9666.0677 | Val Loss: 8037.0731 | Optimizer: RMSprop\n",
      "Trial 323 | Epoch 04 | Train Loss: 8405.1920 | Val Loss: 11286.2783 | Optimizer: RMSprop\n",
      "Trial 324 | Epoch 01 | Train Loss: 19165.6247 | Val Loss: 14226.9010 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:28,681] Trial 324 pruned. \n",
      "[I 2025-09-05 19:02:28,800] Trial 325 pruned. \n",
      "[I 2025-09-05 19:02:28,918] Trial 326 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 325 | Epoch 01 | Train Loss: 19660.3953 | Val Loss: 15777.0814 | Optimizer: Adam\n",
      "Trial 326 | Epoch 01 | Train Loss: 15712.9958 | Val Loss: 14600.4224 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:29,052] Trial 327 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 327 | Epoch 01 | Train Loss: 27519.8036 | Val Loss: 24248.1513 | Optimizer: RMSprop\n",
      "Trial 328 | Epoch 01 | Train Loss: 18371.6269 | Val Loss: 10752.0478 | Optimizer: Adam\n",
      "Trial 328 | Epoch 02 | Train Loss: 12442.1130 | Val Loss: 10331.1587 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:29,298] Trial 328 pruned. \n",
      "[I 2025-09-05 19:02:29,427] Trial 329 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 328 | Epoch 03 | Train Loss: 11475.2464 | Val Loss: 10035.8403 | Optimizer: Adam\n",
      "Trial 329 | Epoch 01 | Train Loss: 21874.7000 | Val Loss: 20657.9609 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:29,548] Trial 330 pruned. \n",
      "[I 2025-09-05 19:02:29,668] Trial 331 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 330 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 331 | Epoch 01 | Train Loss: 18381.1393 | Val Loss: 15103.8157 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:29,880] Trial 332 pruned. \n",
      "[I 2025-09-05 19:02:30,037] Trial 333 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 332 | Epoch 01 | Train Loss: 21551.7202 | Val Loss: 20974.8258 | Optimizer: Adam\n",
      "Trial 333 | Epoch 01 | Train Loss: 13801.6752 | Val Loss: 13971.3820 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:30,197] Trial 334 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 334 | Epoch 01 | Train Loss: 19863.0251 | Val Loss: 16531.1624 | Optimizer: Adam\n",
      "Trial 335 | Epoch 01 | Train Loss: 14528.7377 | Val Loss: 10063.3987 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:30,539] Trial 335 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 335 | Epoch 02 | Train Loss: 10461.6712 | Val Loss: 33215.9587 | Optimizer: RMSprop\n",
      "Trial 335 | Epoch 03 | Train Loss: 16227.1760 | Val Loss: 8588.8954 | Optimizer: RMSprop\n",
      "Trial 335 | Epoch 04 | Train Loss: 9111.2823 | Val Loss: 8658.0550 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:30,694] Trial 336 pruned. \n",
      "[I 2025-09-05 19:02:30,827] Trial 337 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 336 | Epoch 01 | Train Loss: 19319.2555 | Val Loss: 12771.0387 | Optimizer: AdamW\n",
      "Trial 337 | Epoch 01 | Train Loss: 17552.1304 | Val Loss: 11700.1709 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:30,964] Trial 338 pruned. \n",
      "[I 2025-09-05 19:02:31,119] Trial 339 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 338 | Epoch 01 | Train Loss: 33071.0890 | Val Loss: 23913.2717 | Optimizer: RMSprop\n",
      "Trial 339 | Epoch 01 | Train Loss: 18664.3127 | Val Loss: 13411.5862 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:31,252] Trial 340 pruned. \n",
      "[I 2025-09-05 19:02:31,380] Trial 341 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 340 | Epoch 01 | Train Loss: 13824.9501 | Val Loss: 12632.3865 | Optimizer: RMSprop\n",
      "Trial 341 | Epoch 01 | Train Loss: 18063.2163 | Val Loss: 12501.7446 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:31,553] Trial 342 pruned. \n",
      "[I 2025-09-05 19:02:31,675] Trial 343 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 342 | Epoch 01 | Train Loss: 22137.8594 | Val Loss: 21824.8300 | Optimizer: AdamW\n",
      "Trial 343 | Epoch 01 | Train Loss: 18234.7665 | Val Loss: 12334.1011 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:31,824] Trial 344 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 344 | Epoch 01 | Train Loss: 21196.6947 | Val Loss: 19264.3876 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:32,051] Trial 345 pruned. \n",
      "[I 2025-09-05 19:02:32,177] Trial 346 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 345 | Epoch 01 | Train Loss: 1315857.5747 | Val Loss: 22084.0625 | Optimizer: RMSprop\n",
      "Trial 346 | Epoch 01 | Train Loss: 19521.9114 | Val Loss: 15936.5695 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:32,305] Trial 347 pruned. \n",
      "[I 2025-09-05 19:02:32,452] Trial 348 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 347 | Epoch 01 | Train Loss: 17782.9640 | Val Loss: 12060.3225 | Optimizer: AdamW\n",
      "Trial 348 | Epoch 01 | Train Loss: 672772.8934 | Val Loss: 20696.9576 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:32,598] Trial 349 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 349 | Epoch 01 | Train Loss: 17156.7112 | Val Loss: 11737.3827 | Optimizer: Adam\n",
      "Trial 350 | Epoch 01 | Train Loss: 16176.4456 | Val Loss: 10672.0209 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:32,825] Trial 350 pruned. \n",
      "[I 2025-09-05 19:02:32,950] Trial 351 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 350 | Epoch 02 | Train Loss: 15772.5718 | Val Loss: 13686.9843 | Optimizer: RMSprop\n",
      "Trial 351 | Epoch 01 | Train Loss: 19397.6705 | Val Loss: 14729.4171 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:33,070] Trial 352 pruned. \n",
      "[I 2025-09-05 19:02:33,203] Trial 353 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 352 | Epoch 01 | Train Loss: 19528.0591 | Val Loss: 18075.3983 | Optimizer: RMSprop\n",
      "Trial 353 | Epoch 01 | Train Loss: 18283.0065 | Val Loss: 11855.7749 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:33,338] Trial 354 pruned. \n",
      "[I 2025-09-05 19:02:33,468] Trial 355 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 354 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 355 | Epoch 01 | Train Loss: 17230.4485 | Val Loss: 11897.8171 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:33,707] Trial 356 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 356 | Epoch 01 | Train Loss: 15581.9762 | Val Loss: 11115.8775 | Optimizer: RMSprop\n",
      "Trial 356 | Epoch 02 | Train Loss: 11191.6068 | Val Loss: 9259.8383 | Optimizer: RMSprop\n",
      "Trial 356 | Epoch 03 | Train Loss: 10076.2886 | Val Loss: 13218.6616 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:33,872] Trial 357 pruned. \n",
      "[I 2025-09-05 19:02:33,995] Trial 358 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 357 | Epoch 01 | Train Loss: 678918.5303 | Val Loss: 16259.2180 | Optimizer: RMSprop\n",
      "Trial 358 | Epoch 01 | Train Loss: 21680.2384 | Val Loss: 21105.5972 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:34,196] Trial 359 pruned. \n",
      "[I 2025-09-05 19:02:34,342] Trial 360 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 359 | Epoch 01 | Train Loss: 18449.3282 | Val Loss: 22579.8048 | Optimizer: AdamW\n",
      "Trial 360 | Epoch 01 | Train Loss: 15360715.4119 | Val Loss: 18101.2458 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:34,472] Trial 361 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 361 | Epoch 01 | Train Loss: 19102.5209 | Val Loss: 14429.0926 | Optimizer: Adam\n",
      "Trial 362 | Epoch 01 | Train Loss: 14071.6082 | Val Loss: 10135.3028 | Optimizer: RMSprop\n",
      "Trial 362 | Epoch 02 | Train Loss: 11386.3843 | Val Loss: 10513.3175 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:34,711] Trial 362 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 362 | Epoch 03 | Train Loss: 8945.7230 | Val Loss: 23011.3110 | Optimizer: RMSprop\n",
      "Trial 363 | Epoch 01 | Train Loss: 17823.9352 | Val Loss: 11128.7632 | Optimizer: Adam\n",
      "Trial 363 | Epoch 02 | Train Loss: 11067.9636 | Val Loss: 9478.7793 | Optimizer: Adam\n",
      "Trial 363 | Epoch 03 | Train Loss: 10405.5669 | Val Loss: 7718.2218 | Optimizer: Adam\n",
      "Trial 363 | Epoch 04 | Train Loss: 8317.7906 | Val Loss: 5505.4126 | Optimizer: Adam\n",
      "Trial 363 | Epoch 05 | Train Loss: 8650.0590 | Val Loss: 7237.9419 | Optimizer: Adam\n",
      "Trial 363 | Epoch 06 | Train Loss: 7626.4796 | Val Loss: 7400.9225 | Optimizer: Adam\n",
      "Trial 363 | Epoch 07 | Train Loss: 7878.8068 | Val Loss: 8359.6709 | Optimizer: Adam\n",
      "Trial 363 | Epoch 08 | Train Loss: 8009.6941 | Val Loss: 6673.4183 | Optimizer: Adam\n",
      "Trial 363 | Epoch 09 | Train Loss: 7137.0060 | Val Loss: 5796.8677 | Optimizer: Adam\n",
      "Trial 363 | Epoch 10 | Train Loss: 9921.9285 | Val Loss: 8656.4324 | Optimizer: Adam\n",
      "Trial 363 | Epoch 11 | Train Loss: 7877.5315 | Val Loss: 6815.7835 | Optimizer: Adam\n",
      "Trial 363 | Epoch 12 | Train Loss: 7175.2438 | Val Loss: 5795.8896 | Optimizer: Adam\n",
      "Trial 363 | Epoch 13 | Train Loss: 6175.5709 | Val Loss: 6509.3237 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:35,671] Trial 363 finished with value: 5505.412591628086 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.2983420488396585, 'lr': 0.0009019076399644156, 'activation': 'Swish', 'optimizer': 'Adam', 'weight_decay': 1.0386234520938875e-05}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:35,788] Trial 364 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 363 | Epoch 14 | Train Loss: 7406.0689 | Val Loss: 6604.8557 | Optimizer: Adam\n",
      "Trial 363 - Early stopping triggered at epoch 14\n",
      "Trial 364 | Epoch 01 | Train Loss: 19987.5351 | Val Loss: 18534.8546 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:35,917] Trial 365 pruned. \n",
      "[I 2025-09-05 19:02:36,035] Trial 366 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 365 | Epoch 01 | Train Loss: 556282.8517 | Val Loss: 14825.5566 | Optimizer: RMSprop\n",
      "Trial 366 | Epoch 01 | Train Loss: 19803.6433 | Val Loss: 17478.7373 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:36,149] Trial 367 pruned. \n",
      "[I 2025-09-05 19:02:36,277] Trial 368 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 367 | Epoch 01 | Train Loss: 14487.9314 | Val Loss: 95880.3808 | Optimizer: RMSprop\n",
      "Trial 368 | Epoch 01 | Train Loss: 21245.9317 | Val Loss: 19333.2298 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:36,406] Trial 369 pruned. \n",
      "[I 2025-09-05 19:02:36,556] Trial 370 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 369 | Epoch 01 | Train Loss: 15584.7997 | Val Loss: 19010.0327 | Optimizer: RMSprop\n",
      "Trial 370 | Epoch 01 | Train Loss: 18343.9862 | Val Loss: 11826.8549 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:36,668] Trial 371 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 371 | Epoch 01 | Train Loss: 19447.8482 | Val Loss: 14115.3605 | Optimizer: Adam\n",
      "Trial 372 | Epoch 01 | Train Loss: 772472.6751 | Val Loss: 21773.4067 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:36,838] Trial 372 pruned. \n",
      "[I 2025-09-05 19:02:36,957] Trial 373 pruned. \n",
      "[I 2025-09-05 19:02:37,088] Trial 374 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 373 | Epoch 01 | Train Loss: 18463.7961 | Val Loss: 12517.7520 | Optimizer: Adam\n",
      "Trial 374 | Epoch 01 | Train Loss: 88339.2137 | Val Loss: 22791.4607 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:37,209] Trial 375 pruned. \n",
      "[I 2025-09-05 19:02:37,327] Trial 376 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 375 | Epoch 01 | Train Loss: 17036.3539 | Val Loss: 11418.5733 | Optimizer: AdamW\n",
      "Trial 376 | Epoch 01 | Train Loss: 18692.4688 | Val Loss: 12617.8076 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:37,452] Trial 377 pruned. \n",
      "[I 2025-09-05 19:02:37,598] Trial 378 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 377 | Epoch 01 | Train Loss: 15671.9298 | Val Loss: 14620.0868 | Optimizer: RMSprop\n",
      "Trial 378 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:37,719] Trial 379 pruned. \n",
      "[I 2025-09-05 19:02:37,860] Trial 380 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 379 | Epoch 01 | Train Loss: 17155.4159 | Val Loss: 11858.9985 | Optimizer: Adam\n",
      "Trial 380 | Epoch 01 | Train Loss: 21854.7793 | Val Loss: 21833.7311 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:37,985] Trial 381 pruned. \n",
      "[I 2025-09-05 19:02:38,112] Trial 382 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 381 | Epoch 01 | Train Loss: 22026.6496 | Val Loss: 20592.5810 | Optimizer: Adam\n",
      "Trial 382 | Epoch 01 | Train Loss: 21603.4001 | Val Loss: 13279.6728 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:38,417] Trial 383 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 383 | Epoch 01 | Train Loss: 18109.6189 | Val Loss: 10472.4436 | Optimizer: AdamW\n",
      "Trial 383 | Epoch 02 | Train Loss: 13122.2712 | Val Loss: 10096.8341 | Optimizer: AdamW\n",
      "Trial 383 | Epoch 03 | Train Loss: 11175.2562 | Val Loss: 10428.7539 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:38,542] Trial 384 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 384 | Epoch 01 | Train Loss: 21683.8581 | Val Loss: 20510.4135 | Optimizer: Adam\n",
      "Trial 385 | Epoch 01 | Train Loss: 921189.6970 | Val Loss: 20218.1502 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:38,744] Trial 385 pruned. \n",
      "[I 2025-09-05 19:02:38,895] Trial 386 pruned. \n",
      "[I 2025-09-05 19:02:39,022] Trial 387 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 386 | Epoch 01 | Train Loss: 2855614.8671 | Val Loss: 18103.0352 | Optimizer: RMSprop\n",
      "Trial 387 | Epoch 01 | Train Loss: 19183.4427 | Val Loss: 14065.7184 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:39,150] Trial 388 pruned. \n",
      "[I 2025-09-05 19:02:39,287] Trial 389 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 388 | Epoch 01 | Train Loss: 20404.7646 | Val Loss: 18272.8330 | Optimizer: AdamW\n",
      "Trial 389 | Epoch 01 | Train Loss: 23054.2778 | Val Loss: 12520.6761 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:39,413] Trial 390 pruned. \n",
      "[I 2025-09-05 19:02:39,539] Trial 391 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 390 | Epoch 01 | Train Loss: 20912.9568 | Val Loss: 17858.6903 | Optimizer: Adam\n",
      "Trial 391 | Epoch 01 | Train Loss: 18246.2133 | Val Loss: 11591.9996 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:39,682] Trial 392 pruned. \n",
      "[I 2025-09-05 19:02:39,809] Trial 393 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 392 | Epoch 01 | Train Loss: 19890.0351 | Val Loss: 16910.8132 | Optimizer: Adam\n",
      "Trial 393 | Epoch 01 | Train Loss: 20533.8501 | Val Loss: 16981.9572 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:39,966] Trial 394 pruned. \n",
      "[I 2025-09-05 19:02:40,102] Trial 395 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 394 | Epoch 01 | Train Loss: 982618.6021 | Val Loss: 23242.6632 | Optimizer: RMSprop\n",
      "Trial 395 | Epoch 01 | Train Loss: 19408.8002 | Val Loss: 14367.4773 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:40,342] Trial 396 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 396 | Epoch 01 | Train Loss: 13674.5215 | Val Loss: 11005.8738 | Optimizer: RMSprop\n",
      "Trial 396 | Epoch 02 | Train Loss: 12109.1538 | Val Loss: 9641.0951 | Optimizer: RMSprop\n",
      "Trial 396 | Epoch 03 | Train Loss: 10560.8794 | Val Loss: 9235.0865 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:40,493] Trial 397 pruned. \n",
      "[I 2025-09-05 19:02:40,624] Trial 398 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 397 | Epoch 01 | Train Loss: 20234.9710 | Val Loss: 15174.6061 | Optimizer: Adam\n",
      "Trial 398 | Epoch 01 | Train Loss: 32235.2472 | Val Loss: 20344.1567 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:40,836] Trial 399 pruned. \n",
      "[I 2025-09-05 19:02:40,982] Trial 400 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 399 | Epoch 01 | Train Loss: 21697.7632 | Val Loss: 20314.2646 | Optimizer: AdamW\n",
      "Trial 400 | Epoch 01 | Train Loss: 19465.2273 | Val Loss: 12182.9441 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:41,102] Trial 401 pruned. \n",
      "[I 2025-09-05 19:02:41,240] Trial 402 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 401 | Epoch 01 | Train Loss: 53132.5455 | Val Loss: 14048.3427 | Optimizer: RMSprop\n",
      "Trial 402 | Epoch 01 | Train Loss: 47717.2838 | Val Loss: 1141041.2647 | Optimizer: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:41,394] Trial 403 pruned. \n",
      "[I 2025-09-05 19:02:41,536] Trial 404 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 403 | Epoch 01 | Train Loss: 19947.0835 | Val Loss: 16835.5524 | Optimizer: Adam\n",
      "Trial 404 | Epoch 01 | Train Loss: 17442.5301 | Val Loss: 11835.7528 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:41,667] Trial 405 pruned. \n",
      "[I 2025-09-05 19:02:41,809] Trial 406 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 405 | Epoch 01 | Train Loss: 19063.0486 | Val Loss: 15097.2377 | Optimizer: AdamW\n",
      "Trial 406 | Epoch 01 | Train Loss: 20521.6620 | Val Loss: 14961.4041 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:41,940] Trial 407 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 407 | Epoch 01 | Train Loss: 20491.6168 | Val Loss: 11688.6980 | Optimizer: RMSprop\n",
      "Trial 408 | Epoch 01 | Train Loss: 17470.3295 | Val Loss: 10836.0961 | Optimizer: Adam\n",
      "Trial 408 | Epoch 02 | Train Loss: 12012.7828 | Val Loss: 10464.0830 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:42,122] Trial 408 pruned. \n",
      "[I 2025-09-05 19:02:42,345] Trial 409 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 409 | Epoch 01 | Train Loss: 48964.2982 | Val Loss: 10657.6992 | Optimizer: RMSprop\n",
      "Trial 409 | Epoch 02 | Train Loss: 12470.0178 | Val Loss: 11105.6378 | Optimizer: RMSprop\n",
      "Trial 410 | Epoch 01 | Train Loss: 20674.5398 | Val Loss: 18225.9950 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:42,469] Trial 410 pruned. \n",
      "[I 2025-09-05 19:02:42,632] Trial 411 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 411 | Epoch 01 | Train Loss: 20925.3773 | Val Loss: 19074.8858 | Optimizer: Adam\n",
      "Trial 412 | Epoch 01 | Train Loss: 17055.8921 | Val Loss: 11138.6221 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:43,003] Trial 412 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 412 | Epoch 02 | Train Loss: 9959.5900 | Val Loss: 8681.5267 | Optimizer: RMSprop\n",
      "Trial 412 | Epoch 03 | Train Loss: 8698.0071 | Val Loss: 12347.9154 | Optimizer: RMSprop\n",
      "Trial 412 | Epoch 04 | Train Loss: 9777.5332 | Val Loss: 10702.6901 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:43,182] Trial 413 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 413 | Epoch 01 | Train Loss: 16922.3101 | Val Loss: 10783.1028 | Optimizer: Adam\n",
      "Trial 413 | Epoch 02 | Train Loss: 12226.2113 | Val Loss: 10542.2138 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:43,380] Trial 414 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 414 | Epoch 01 | Train Loss: 882475605.4482 | Val Loss: 19335.2474 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 01 | Train Loss: 313656.0181 | Val Loss: 7948.5929 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 02 | Train Loss: 11206.5912 | Val Loss: 13049.9043 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 03 | Train Loss: 10619.4594 | Val Loss: 13204.2635 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 04 | Train Loss: 9182.6443 | Val Loss: 5955.8369 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 05 | Train Loss: 7519.5472 | Val Loss: 6170.0124 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 06 | Train Loss: 7081.0152 | Val Loss: 5535.4402 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 07 | Train Loss: 7332.7475 | Val Loss: 10266.2412 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 08 | Train Loss: 7365.0596 | Val Loss: 5741.3307 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 09 | Train Loss: 6297.5494 | Val Loss: 8018.8713 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 10 | Train Loss: 7014.2286 | Val Loss: 14137.7594 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 11 | Train Loss: 9359.0960 | Val Loss: 11520.6309 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 12 | Train Loss: 8779.5774 | Val Loss: 5490.7925 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 13 | Train Loss: 6631.2519 | Val Loss: 6101.7142 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 14 | Train Loss: 6590.7165 | Val Loss: 5418.1040 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 15 | Train Loss: 6207.1077 | Val Loss: 5636.9885 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 16 | Train Loss: 6742.6310 | Val Loss: 5623.3290 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 17 | Train Loss: 6811.0735 | Val Loss: 40970.9900 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 18 | Train Loss: 19925.2370 | Val Loss: 8947.9937 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 19 | Train Loss: 7691.1773 | Val Loss: 6025.9397 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 20 | Train Loss: 6644.3027 | Val Loss: 46078.6062 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 21 | Train Loss: 16501.2522 | Val Loss: 6870.0531 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 22 | Train Loss: 7562.0829 | Val Loss: 6899.2232 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:44,905] Trial 415 finished with value: 5418.104025004823 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.3182548181466011, 'lr': 0.000710957648467422, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 4.849503072519385e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 415 | Epoch 23 | Train Loss: 6451.4574 | Val Loss: 6525.3758 | Optimizer: RMSprop\n",
      "Trial 415 | Epoch 24 | Train Loss: 6987.8629 | Val Loss: 5938.9179 | Optimizer: RMSprop\n",
      "Trial 415 - Early stopping triggered at epoch 24\n",
      "Trial 416 | Epoch 01 | Train Loss: 19121.2168 | Val Loss: 14842.7705 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:45,022] Trial 416 pruned. \n",
      "[I 2025-09-05 19:02:45,143] Trial 417 pruned. \n",
      "[I 2025-09-05 19:02:45,270] Trial 418 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 417 | Epoch 01 | Train Loss: 19690.0919 | Val Loss: 14029.8380 | Optimizer: AdamW\n",
      "Trial 418 | Epoch 01 | Train Loss: 6927140.9367 | Val Loss: 22066.8309 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:45,393] Trial 419 pruned. \n",
      "[I 2025-09-05 19:02:45,522] Trial 420 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 419 | Epoch 01 | Train Loss: 20989.6955 | Val Loss: 17960.6886 | Optimizer: Adam\n",
      "Trial 420 | Epoch 01 | Train Loss: 22943.7516 | Val Loss: 12489.0036 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:45,640] Trial 421 pruned. \n",
      "[I 2025-09-05 19:02:45,760] Trial 422 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 421 | Epoch 01 | Train Loss: 20634.0804 | Val Loss: 18912.0655 | Optimizer: Adam\n",
      "Trial 422 | Epoch 01 | Train Loss: 21429.9390 | Val Loss: 20807.8908 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:45,979] Trial 423 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 423 | Epoch 01 | Train Loss: 16142.8358 | Val Loss: 10444.5770 | Optimizer: RMSprop\n",
      "Trial 423 | Epoch 02 | Train Loss: 12243.2891 | Val Loss: 12323.6678 | Optimizer: RMSprop\n",
      "Trial 424 | Epoch 01 | Train Loss: 18026.3863 | Val Loss: 12514.7039 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:46,093] Trial 424 pruned. \n",
      "[I 2025-09-05 19:02:46,220] Trial 425 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 425 | Epoch 01 | Train Loss: 17063.4774 | Val Loss: 13271.5534 | Optimizer: RMSprop\n",
      "Trial 426 | Epoch 01 | Train Loss: 16981.3267 | Val Loss: 10613.6521 | Optimizer: Adam\n",
      "Trial 426 | Epoch 02 | Train Loss: 12072.2858 | Val Loss: 10342.9676 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:46,449] Trial 426 pruned. \n",
      "[I 2025-09-05 19:02:46,589] Trial 427 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 426 | Epoch 03 | Train Loss: 11128.9317 | Val Loss: 9771.4458 | Optimizer: Adam\n",
      "Trial 427 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:46,733] Trial 428 pruned. \n",
      "[I 2025-09-05 19:02:46,860] Trial 429 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 428 | Epoch 01 | Train Loss: 20214.6259 | Val Loss: 17501.0627 | Optimizer: AdamW\n",
      "Trial 429 | Epoch 01 | Train Loss: 17638.6323 | Val Loss: 11549.2168 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:47,076] Trial 430 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 430 | Epoch 01 | Train Loss: 17817.0938 | Val Loss: 10604.9383 | Optimizer: Adam\n",
      "Trial 430 | Epoch 02 | Train Loss: 11479.5702 | Val Loss: 10540.9957 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:47,225] Trial 431 pruned. \n",
      "[I 2025-09-05 19:02:47,352] Trial 432 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 431 | Epoch 01 | Train Loss: 567513.6506 | Val Loss: 11484.2659 | Optimizer: RMSprop\n",
      "Trial 432 | Epoch 01 | Train Loss: 19432.8305 | Val Loss: 15742.6459 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:47,495] Trial 433 pruned. \n",
      "[I 2025-09-05 19:02:47,619] Trial 434 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 433 | Epoch 01 | Train Loss: 97928.8874 | Val Loss: 16617.8978 | Optimizer: RMSprop\n",
      "Trial 434 | Epoch 01 | Train Loss: 22132.1712 | Val Loss: 22437.8952 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:47,769] Trial 435 pruned. \n",
      "[I 2025-09-05 19:02:47,900] Trial 436 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 435 | Epoch 01 | Train Loss: 20150.1465 | Val Loss: 15096.1956 | Optimizer: Adam\n",
      "Trial 436 | Epoch 01 | Train Loss: 15907.4622 | Val Loss: 13629.3036 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:48,034] Trial 437 pruned. \n",
      "[I 2025-09-05 19:02:48,179] Trial 438 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 437 | Epoch 01 | Train Loss: 17502.5229 | Val Loss: 11606.6368 | Optimizer: Adam\n",
      "Trial 438 | Epoch 01 | Train Loss: 66197.2717 | Val Loss: 13273.4667 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:48,397] Trial 439 pruned. \n",
      "[I 2025-09-05 19:02:48,557] Trial 440 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 439 | Epoch 01 | Train Loss: 21177.3482 | Val Loss: 21027.7068 | Optimizer: AdamW\n",
      "Trial 440 | Epoch 01 | Train Loss: 19954.1033 | Val Loss: 16120.6145 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:48,677] Trial 441 pruned. \n",
      "[I 2025-09-05 19:02:48,826] Trial 442 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 441 | Epoch 01 | Train Loss: 17986.7140 | Val Loss: 13092.0398 | Optimizer: RMSprop\n",
      "Trial 442 | Epoch 01 | Train Loss: 20703.6530 | Val Loss: 19711.7662 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:48,957] Trial 443 pruned. \n",
      "[I 2025-09-05 19:02:49,106] Trial 444 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 443 | Epoch 01 | Train Loss: 29559.9611 | Val Loss: 11989.9083 | Optimizer: RMSprop\n",
      "Trial 444 | Epoch 01 | Train Loss: 19963.3853 | Val Loss: 14170.2503 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:49,236] Trial 445 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 445 | Epoch 01 | Train Loss: 19591.9102 | Val Loss: 14922.0603 | Optimizer: Adam\n",
      "Trial 446 | Epoch 01 | Train Loss: 14049.9050 | Val Loss: 10338.0672 | Optimizer: RMSprop\n",
      "Trial 446 | Epoch 02 | Train Loss: 11083.2931 | Val Loss: 10961.1154 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:49,480] Trial 446 pruned. \n",
      "[I 2025-09-05 19:02:49,642] Trial 447 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 446 | Epoch 03 | Train Loss: 10047.5642 | Val Loss: 9161.3921 | Optimizer: RMSprop\n",
      "Trial 447 | Epoch 01 | Train Loss: 15082.9081 | Val Loss: 13013.0538 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:49,769] Trial 448 pruned. \n",
      "[I 2025-09-05 19:02:49,913] Trial 449 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 448 | Epoch 01 | Train Loss: 18567.4185 | Val Loss: 13186.3395 | Optimizer: Adam\n",
      "Trial 449 | Epoch 01 | Train Loss: 54474.4862 | Val Loss: 21008.6134 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:50,051] Trial 450 pruned. \n",
      "[I 2025-09-05 19:02:50,177] Trial 451 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 450 | Epoch 01 | Train Loss: 19811.9063 | Val Loss: 15501.1204 | Optimizer: AdamW\n",
      "Trial 451 | Epoch 01 | Train Loss: 19985.5272 | Val Loss: 16463.6069 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:50,286] Trial 452 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 452 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:50,500] Trial 453 pruned. \n",
      "[I 2025-09-05 19:02:50,650] Trial 454 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 453 | Epoch 01 | Train Loss: 3151154427.4798 | Val Loss: 49502.6782 | Optimizer: RMSprop\n",
      "Trial 454 | Epoch 01 | Train Loss: 20807.4376 | Val Loss: 18630.7283 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:50,792] Trial 455 pruned. \n",
      "[I 2025-09-05 19:02:50,946] Trial 456 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 455 | Epoch 01 | Train Loss: 47530.0684 | Val Loss: 19349.9471 | Optimizer: RMSprop\n",
      "Trial 456 | Epoch 01 | Train Loss: 21484.5310 | Val Loss: 19669.4056 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:51,074] Trial 457 pruned. \n",
      "[I 2025-09-05 19:02:51,199] Trial 458 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 457 | Epoch 01 | Train Loss: 17510.7870 | Val Loss: 11489.2513 | Optimizer: AdamW\n",
      "Trial 458 | Epoch 01 | Train Loss: 14078.6226 | Val Loss: 15975.7721 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:51,349] Trial 459 pruned. \n",
      "[I 2025-09-05 19:02:51,473] Trial 460 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 459 | Epoch 01 | Train Loss: 20833.4550 | Val Loss: 19410.5042 | Optimizer: Adam\n",
      "Trial 460 | Epoch 01 | Train Loss: 17564.3294 | Val Loss: 21357.3512 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:51,602] Trial 461 pruned. \n",
      "[I 2025-09-05 19:02:51,750] Trial 462 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 461 | Epoch 01 | Train Loss: 17841.0308 | Val Loss: 11486.2934 | Optimizer: Adam\n",
      "Trial 462 | Epoch 01 | Train Loss: 19503.5414 | Val Loss: 13709.7753 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:51,887] Trial 463 pruned. \n",
      "[I 2025-09-05 19:02:52,047] Trial 464 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 463 | Epoch 01 | Train Loss: 46075.0574 | Val Loss: 14297.3160 | Optimizer: RMSprop\n",
      "Trial 464 | Epoch 01 | Train Loss: 19519.8641 | Val Loss: 16447.5707 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:52,174] Trial 465 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 465 | Epoch 01 | Train Loss: 17088.5373 | Val Loss: 24523.0212 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:52,386] Trial 466 pruned. \n",
      "[I 2025-09-05 19:02:52,517] Trial 467 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 466 | Epoch 01 | Train Loss: 20733.9155 | Val Loss: 18902.9271 | Optimizer: Adam\n",
      "Trial 467 | Epoch 01 | Train Loss: 17371.2961 | Val Loss: 13201.9035 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:52,665] Trial 468 pruned. \n",
      "[I 2025-09-05 19:02:52,795] Trial 469 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 468 | Epoch 01 | Train Loss: 22123.1109 | Val Loss: 21140.9785 | Optimizer: AdamW\n",
      "Trial 469 | Epoch 01 | Train Loss: 19131.6481 | Val Loss: 13975.0886 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:53,015] Trial 470 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 470 | Epoch 01 | Train Loss: 19200.1664 | Val Loss: 10474.0841 | Optimizer: RMSprop\n",
      "Trial 470 | Epoch 02 | Train Loss: 14709.6573 | Val Loss: 13108.5065 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:53,177] Trial 471 pruned. \n",
      "[I 2025-09-05 19:02:53,300] Trial 472 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 471 | Epoch 01 | Train Loss: 18104.7244 | Val Loss: 11465.1886 | Optimizer: Adam\n",
      "Trial 472 | Epoch 01 | Train Loss: 16365.1780 | Val Loss: 12007.0356 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:53,444] Trial 473 pruned. \n",
      "[I 2025-09-05 19:02:53,574] Trial 474 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 473 | Epoch 01 | Train Loss: 19579.1827 | Val Loss: 14818.0841 | Optimizer: AdamW\n",
      "Trial 474 | Epoch 01 | Train Loss: 20020.3593 | Val Loss: 15990.3615 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:53,699] Trial 475 pruned. \n",
      "[I 2025-09-05 19:02:53,826] Trial 476 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 475 | Epoch 01 | Train Loss: 19395.2614 | Val Loss: 11329.7566 | Optimizer: RMSprop\n",
      "Trial 476 | Epoch 01 | Train Loss: 15759.6687 | Val Loss: 14685.2968 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:53,973] Trial 477 pruned. \n",
      "[I 2025-09-05 19:02:54,077] Trial 478 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 477 | Epoch 01 | Train Loss: 19191.8382 | Val Loss: 11777.0488 | Optimizer: Adam\n",
      "Trial 478 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:54,293] Trial 479 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 479 | Epoch 01 | Train Loss: 21407.7751 | Val Loss: 19417.8028 | Optimizer: AdamW\n",
      "Trial 480 | Epoch 01 | Train Loss: 16467.3043 | Val Loss: 10215.6424 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:54,587] Trial 480 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 480 | Epoch 02 | Train Loss: 15516.6734 | Val Loss: 9948.8730 | Optimizer: RMSprop\n",
      "Trial 480 | Epoch 03 | Train Loss: 10207.2206 | Val Loss: 8958.8877 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:54,719] Trial 481 pruned. \n",
      "[I 2025-09-05 19:02:54,840] Trial 482 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 481 | Epoch 01 | Train Loss: 21197.7139 | Val Loss: 19102.3527 | Optimizer: Adam\n",
      "Trial 482 | Epoch 01 | Train Loss: 14712.7221 | Val Loss: 15550.7482 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:55,059] Trial 483 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 483 | Epoch 01 | Train Loss: 17619.1758 | Val Loss: 11065.0186 | Optimizer: Adam\n",
      "Trial 483 | Epoch 02 | Train Loss: 12298.9632 | Val Loss: 10432.2364 | Optimizer: Adam\n",
      "Trial 484 | Epoch 01 | Train Loss: 16254.6614 | Val Loss: 10559.5865 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:55,250] Trial 484 pruned. \n",
      "[I 2025-09-05 19:02:55,395] Trial 485 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 484 | Epoch 02 | Train Loss: 10446.2865 | Val Loss: 33440.1571 | Optimizer: RMSprop\n",
      "Trial 485 | Epoch 01 | Train Loss: 21533.5677 | Val Loss: 20523.7933 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:55,540] Trial 486 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 486 | Epoch 01 | Train Loss: 18260.3350 | Val Loss: 12622.2245 | Optimizer: Adam\n",
      "Trial 487 | Epoch 01 | Train Loss: 17496.1654 | Val Loss: 10662.8003 | Optimizer: RMSprop\n",
      "Trial 487 | Epoch 02 | Train Loss: 11485.6056 | Val Loss: 917309.1836 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:55,732] Trial 487 pruned. \n",
      "[I 2025-09-05 19:02:55,880] Trial 488 pruned. \n",
      "[I 2025-09-05 19:02:56,009] Trial 489 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 488 | Epoch 01 | Train Loss: 20144.4587 | Val Loss: 16888.5273 | Optimizer: Adam\n",
      "Trial 489 | Epoch 01 | Train Loss: 13074.4175 | Val Loss: 319072.2427 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:56,138] Trial 490 pruned. \n",
      "[I 2025-09-05 19:02:56,281] Trial 491 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 490 | Epoch 01 | Train Loss: 17658.6940 | Val Loss: 12266.3059 | Optimizer: AdamW\n",
      "Trial 491 | Epoch 01 | Train Loss: 22033.6211 | Val Loss: 21407.1154 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:56,409] Trial 492 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 492 | Epoch 01 | Train Loss: 14928.2606 | Val Loss: 12358.5637 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:56,625] Trial 493 pruned. \n",
      "[I 2025-09-05 19:02:56,774] Trial 494 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 493 | Epoch 01 | Train Loss: 22086.6880 | Val Loss: 22374.0117 | Optimizer: Adam\n",
      "Trial 494 | Epoch 01 | Train Loss: 830372.3325 | Val Loss: 17104.0325 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:56,936] Trial 495 pruned. \n",
      "[I 2025-09-05 19:02:57,066] Trial 496 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 495 | Epoch 01 | Train Loss: 20401.5231 | Val Loss: 17402.3127 | Optimizer: Adam\n",
      "Trial 496 | Epoch 01 | Train Loss: 15009.9131 | Val Loss: 16932.2611 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:57,215] Trial 497 pruned. \n",
      "[I 2025-09-05 19:02:57,358] Trial 498 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 497 | Epoch 01 | Train Loss: 18760.5982 | Val Loss: 12662.2908 | Optimizer: AdamW\n",
      "Trial 498 | Epoch 01 | Train Loss: 21005.9745 | Val Loss: 17780.8857 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:57,489] Trial 499 pruned. \n",
      "[I 2025-09-05 19:02:57,613] Trial 500 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 499 | Epoch 01 | Train Loss: 20098.2969 | Val Loss: 13110.3758 | Optimizer: RMSprop\n",
      "Trial 500 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:57,743] Trial 501 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 501 | Epoch 01 | Train Loss: 20722.5494 | Val Loss: 19875.4007 | Optimizer: Adam\n",
      "Trial 502 | Epoch 01 | Train Loss: 14850.8268 | Val Loss: 9653.5749 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 02 | Train Loss: 10252.0666 | Val Loss: 8331.3972 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 03 | Train Loss: 8084.6461 | Val Loss: 7511.7724 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 04 | Train Loss: 7666.2938 | Val Loss: 8145.4561 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 05 | Train Loss: 7547.4993 | Val Loss: 5830.4732 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 06 | Train Loss: 6927.4719 | Val Loss: 6291.9877 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 07 | Train Loss: 7329.3205 | Val Loss: 6119.3794 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 08 | Train Loss: 6874.7661 | Val Loss: 10462.2897 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 09 | Train Loss: 7544.9836 | Val Loss: 5299.7919 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 10 | Train Loss: 6331.2730 | Val Loss: 20941.1791 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 11 | Train Loss: 10949.9861 | Val Loss: 7615.0575 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 12 | Train Loss: 7063.1507 | Val Loss: 6209.5397 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 13 | Train Loss: 6279.8297 | Val Loss: 8396.5704 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 14 | Train Loss: 8229.9469 | Val Loss: 5436.4831 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 15 | Train Loss: 6318.5026 | Val Loss: 7310.1525 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 16 | Train Loss: 7104.1536 | Val Loss: 5315.4355 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 17 | Train Loss: 6188.2144 | Val Loss: 20163.1179 | Optimizer: RMSprop\n",
      "Trial 502 | Epoch 18 | Train Loss: 8955.7764 | Val Loss: 15723.2906 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:58,946] Trial 502 finished with value: 5299.791850525656 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.32602427200325795, 'lr': 0.000371872705182012, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 1.00623368463843e-05}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:02:59,084] Trial 503 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 502 | Epoch 19 | Train Loss: 7981.8732 | Val Loss: 5304.4687 | Optimizer: RMSprop\n",
      "Trial 502 - Early stopping triggered at epoch 19\n",
      "Trial 503 | Epoch 01 | Train Loss: 20082.9014 | Val Loss: 18072.9267 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:02:59,210] Trial 504 pruned. \n",
      "[I 2025-09-05 19:02:59,354] Trial 505 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 504 | Epoch 01 | Train Loss: 22105.2518 | Val Loss: 21701.8143 | Optimizer: Adam\n",
      "Trial 505 | Epoch 01 | Train Loss: 21692.9275 | Val Loss: 12352.3257 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 01 | Train Loss: 23066.4261 | Val Loss: 10238.1714 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 02 | Train Loss: 13434.1191 | Val Loss: 10862.1466 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 03 | Train Loss: 10239.6658 | Val Loss: 6527.1265 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 04 | Train Loss: 7879.8190 | Val Loss: 6173.7509 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 05 | Train Loss: 7881.7178 | Val Loss: 6484.3798 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 06 | Train Loss: 8201.6477 | Val Loss: 6239.8651 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 07 | Train Loss: 7424.0125 | Val Loss: 14569.1042 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 08 | Train Loss: 10327.9491 | Val Loss: 6496.5314 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 09 | Train Loss: 6896.6380 | Val Loss: 98285.6486 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:00,099] Trial 506 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 506 | Epoch 10 | Train Loss: 34558.8015 | Val Loss: 13044.9665 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 11 | Train Loss: 11458.2569 | Val Loss: 6800.6103 | Optimizer: RMSprop\n",
      "Trial 506 | Epoch 12 | Train Loss: 7911.6321 | Val Loss: 8917.1638 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:00,293] Trial 507 pruned. \n",
      "[I 2025-09-05 19:03:00,422] Trial 508 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 507 | Epoch 01 | Train Loss: 21799.2938 | Val Loss: 20331.1551 | Optimizer: Adam\n",
      "Trial 508 | Epoch 01 | Train Loss: 16713.1183 | Val Loss: 11412.2278 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:00,637] Trial 509 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 509 | Epoch 01 | Train Loss: 16952.4849 | Val Loss: 10727.5011 | Optimizer: RMSprop\n",
      "Trial 509 | Epoch 02 | Train Loss: 11856.5137 | Val Loss: 14979.5334 | Optimizer: RMSprop\n",
      "Trial 510 | Epoch 01 | Train Loss: 18885.2502 | Val Loss: 13924.1632 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:00,773] Trial 510 pruned. \n",
      "[I 2025-09-05 19:03:00,904] Trial 511 pruned. \n",
      "[I 2025-09-05 19:03:01,048] Trial 512 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 511 | Epoch 01 | Train Loss: 17750.2841 | Val Loss: 26239.6583 | Optimizer: RMSprop\n",
      "Trial 512 | Epoch 01 | Train Loss: 20680.4698 | Val Loss: 18386.9592 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:01,181] Trial 513 pruned. \n",
      "[I 2025-09-05 19:03:01,331] Trial 514 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 513 | Epoch 01 | Train Loss: 19088.7106 | Val Loss: 14344.6514 | Optimizer: AdamW\n",
      "Trial 514 | Epoch 01 | Train Loss: 16730.8485 | Val Loss: 12979.3521 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:01,613] Trial 515 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 515 | Epoch 01 | Train Loss: 15674.6513 | Val Loss: 10718.9553 | Optimizer: Adam\n",
      "Trial 515 | Epoch 02 | Train Loss: 11644.7324 | Val Loss: 10184.1284 | Optimizer: Adam\n",
      "Trial 515 | Epoch 03 | Train Loss: 11194.1967 | Val Loss: 9180.0780 | Optimizer: Adam\n",
      "Trial 516 | Epoch 01 | Train Loss: 14926.4351 | Val Loss: 10698.1825 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 02 | Train Loss: 12484.6149 | Val Loss: 6756.2537 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 03 | Train Loss: 9424.8374 | Val Loss: 6818.9677 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 04 | Train Loss: 8563.2683 | Val Loss: 5678.3304 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 05 | Train Loss: 8709.6742 | Val Loss: 6121.8911 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 06 | Train Loss: 7670.3954 | Val Loss: 6623.9914 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 07 | Train Loss: 7495.5690 | Val Loss: 6086.7915 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 08 | Train Loss: 7374.0738 | Val Loss: 51001.2869 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 09 | Train Loss: 23315.8607 | Val Loss: 6177.7178 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 10 | Train Loss: 7281.9671 | Val Loss: 5489.2152 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 11 | Train Loss: 6865.8068 | Val Loss: 7820.0506 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 12 | Train Loss: 6925.9264 | Val Loss: 5356.4779 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 13 | Train Loss: 6485.8153 | Val Loss: 5365.4081 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 14 | Train Loss: 6368.8842 | Val Loss: 7229.7385 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 15 | Train Loss: 6359.3903 | Val Loss: 5270.6828 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 16 | Train Loss: 6169.2301 | Val Loss: 5947.9761 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 17 | Train Loss: 6299.8939 | Val Loss: 5850.4949 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 18 | Train Loss: 5980.1469 | Val Loss: 5623.7613 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 19 | Train Loss: 5917.8206 | Val Loss: 12904.3629 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 20 | Train Loss: 7837.0638 | Val Loss: 6436.5053 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 21 | Train Loss: 6349.1093 | Val Loss: 7194.7344 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 22 | Train Loss: 6324.0926 | Val Loss: 4841.8236 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 23 | Train Loss: 5690.4336 | Val Loss: 4839.5763 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 24 | Train Loss: 5879.9214 | Val Loss: 5582.4135 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 25 | Train Loss: 6690.4438 | Val Loss: 4979.8970 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 26 | Train Loss: 6092.7681 | Val Loss: 10569.4979 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 27 | Train Loss: 6347.1606 | Val Loss: 4997.6702 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 28 | Train Loss: 5654.0405 | Val Loss: 5225.9439 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 29 | Train Loss: 5583.7331 | Val Loss: 4858.3245 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 30 | Train Loss: 5719.5543 | Val Loss: 20913.3137 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 31 | Train Loss: 10587.8599 | Val Loss: 4819.4216 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 32 | Train Loss: 5623.8811 | Val Loss: 5217.2012 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 33 | Train Loss: 6189.9856 | Val Loss: 4824.6257 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 34 | Train Loss: 5479.9704 | Val Loss: 6468.6375 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 35 | Train Loss: 5635.8314 | Val Loss: 8154.8220 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 36 | Train Loss: 5837.8545 | Val Loss: 36239.8049 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 37 | Train Loss: 15872.7977 | Val Loss: 6697.2473 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 38 | Train Loss: 6376.0666 | Val Loss: 5297.4826 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 39 | Train Loss: 5763.7835 | Val Loss: 5170.9581 | Optimizer: RMSprop\n",
      "Trial 516 | Epoch 40 | Train Loss: 5499.5109 | Val Loss: 5742.9141 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:04,107] Trial 516 finished with value: 4819.421615788966 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3536014184065482, 'lr': 0.0005807500950925079, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.0517333884700056e-05}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:03:04,253] Trial 517 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 516 | Epoch 41 | Train Loss: 5973.5514 | Val Loss: 5073.4262 | Optimizer: RMSprop\n",
      "Trial 516 - Early stopping triggered at epoch 41\n",
      "Trial 517 | Epoch 01 | Train Loss: 15624.4119 | Val Loss: 13650.4099 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:04,380] Trial 518 pruned. \n",
      "[I 2025-09-05 19:03:04,513] Trial 519 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 518 | Epoch 01 | Train Loss: 16035.5356 | Val Loss: 12015.9773 | Optimizer: RMSprop\n",
      "Trial 519 | Epoch 01 | Train Loss: 73139.8082 | Val Loss: 18297.9869 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:04,646] Trial 520 pruned. \n",
      "[I 2025-09-05 19:03:04,775] Trial 521 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 520 | Epoch 01 | Train Loss: 15348.9496 | Val Loss: 12226.1014 | Optimizer: RMSprop\n",
      "Trial 521 | Epoch 01 | Train Loss: 15530.9750 | Val Loss: 11387.0743 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:04,908] Trial 522 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 522 | Epoch 01 | Train Loss: 15097.6936 | Val Loss: 15829.8978 | Optimizer: RMSprop\n",
      "Trial 523 | Epoch 01 | Train Loss: 16333.6699 | Val Loss: 10923.1281 | Optimizer: RMSprop\n",
      "Trial 523 | Epoch 02 | Train Loss: 11547.0741 | Val Loss: 12748.5705 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:05,102] Trial 523 pruned. \n",
      "[I 2025-09-05 19:03:05,359] Trial 524 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 524 | Epoch 01 | Train Loss: 14882.8579 | Val Loss: 10175.8171 | Optimizer: RMSprop\n",
      "Trial 524 | Epoch 02 | Train Loss: 10297.3813 | Val Loss: 8790.3664 | Optimizer: RMSprop\n",
      "Trial 524 | Epoch 03 | Train Loss: 12712.6860 | Val Loss: 10298.6173 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:05,508] Trial 525 pruned. \n",
      "[I 2025-09-05 19:03:05,649] Trial 526 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 525 | Epoch 01 | Train Loss: 23044.5627 | Val Loss: 15732.5232 | Optimizer: RMSprop\n",
      "Trial 526 | Epoch 01 | Train Loss: 13727.7833 | Val Loss: 11143.3266 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:05,777] Trial 527 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 527 | Epoch 01 | Train Loss: 20889.5076 | Val Loss: 20009.8186 | Optimizer: AdamW\n",
      "Trial 528 | Epoch 01 | Train Loss: 15633.3042 | Val Loss: 10455.5833 | Optimizer: RMSprop\n",
      "Trial 528 | Epoch 02 | Train Loss: 11607.6869 | Val Loss: 11883.7366 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:05,969] Trial 528 pruned. \n",
      "[I 2025-09-05 19:03:06,190] Trial 529 pruned. \n",
      "[I 2025-09-05 19:03:06,299] Trial 530 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 529 | Epoch 01 | Train Loss: 17713.9697 | Val Loss: 13947.6582 | Optimizer: RMSprop\n",
      "Trial 530 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:06,437] Trial 531 pruned. \n",
      "[I 2025-09-05 19:03:06,568] Trial 532 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 531 | Epoch 01 | Train Loss: 19807.1322 | Val Loss: 13828.6357 | Optimizer: RMSprop\n",
      "Trial 532 | Epoch 01 | Train Loss: 18030.4085 | Val Loss: 13179.3389 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:06,697] Trial 533 pruned. \n",
      "[I 2025-09-05 19:03:06,842] Trial 534 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 533 | Epoch 01 | Train Loss: 14896.1435 | Val Loss: 13764.3208 | Optimizer: RMSprop\n",
      "Trial 534 | Epoch 01 | Train Loss: 17395.3853 | Val Loss: 12404.7089 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:06,986] Trial 535 pruned. \n",
      "[I 2025-09-05 19:03:07,113] Trial 536 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 535 | Epoch 01 | Train Loss: 18924.7089 | Val Loss: 14584.8931 | Optimizer: AdamW\n",
      "Trial 536 | Epoch 01 | Train Loss: 18000.3682 | Val Loss: 12700.9755 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:07,323] Trial 537 pruned. \n",
      "[I 2025-09-05 19:03:07,457] Trial 538 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 537 | Epoch 01 | Train Loss: 19950.3620 | Val Loss: 12907.5197 | Optimizer: RMSprop\n",
      "Trial 538 | Epoch 01 | Train Loss: 16178.3618 | Val Loss: 12768.4780 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:07,590] Trial 539 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 539 | Epoch 01 | Train Loss: 18325.4591 | Val Loss: 11842.9122 | Optimizer: AdamW\n",
      "Trial 540 | Epoch 01 | Train Loss: 14746.7258 | Val Loss: 11016.1653 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 02 | Train Loss: 10674.3407 | Val Loss: 9968.4486 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 03 | Train Loss: 9218.5488 | Val Loss: 6846.7232 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 04 | Train Loss: 7838.5874 | Val Loss: 9266.7267 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 05 | Train Loss: 8256.4017 | Val Loss: 6504.1739 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 06 | Train Loss: 7351.2800 | Val Loss: 6039.7328 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 07 | Train Loss: 7645.2929 | Val Loss: 7799.8271 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 08 | Train Loss: 7287.3957 | Val Loss: 42086.8455 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 09 | Train Loss: 14781.9904 | Val Loss: 5874.4953 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 10 | Train Loss: 6833.6287 | Val Loss: 5465.3761 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 11 | Train Loss: 6716.8237 | Val Loss: 6359.2629 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 12 | Train Loss: 6790.2096 | Val Loss: 8622.9038 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 13 | Train Loss: 7338.8957 | Val Loss: 5853.1767 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 14 | Train Loss: 6307.0043 | Val Loss: 7937.9087 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 15 | Train Loss: 7018.0251 | Val Loss: 5539.2953 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 16 | Train Loss: 6351.4232 | Val Loss: 6143.5843 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 17 | Train Loss: 6469.6782 | Val Loss: 13083.9289 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 18 | Train Loss: 7744.8994 | Val Loss: 5506.3357 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 19 | Train Loss: 6054.0088 | Val Loss: 5392.6871 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 20 | Train Loss: 6024.6308 | Val Loss: 7485.1216 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 21 | Train Loss: 6676.5086 | Val Loss: 11547.5105 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 22 | Train Loss: 7984.6514 | Val Loss: 9131.6185 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 23 | Train Loss: 6879.4406 | Val Loss: 5461.5175 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 24 | Train Loss: 5957.0493 | Val Loss: 5317.8927 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 25 | Train Loss: 5855.6562 | Val Loss: 7791.7283 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 26 | Train Loss: 6823.4411 | Val Loss: 5343.8751 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 27 | Train Loss: 5937.1074 | Val Loss: 5310.3237 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 28 | Train Loss: 5879.5858 | Val Loss: 11263.7041 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 29 | Train Loss: 6558.3551 | Val Loss: 5421.4519 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 30 | Train Loss: 5674.9788 | Val Loss: 6075.0077 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 31 | Train Loss: 6248.7514 | Val Loss: 5744.0980 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 32 | Train Loss: 5923.8325 | Val Loss: 5106.3726 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 33 | Train Loss: 5811.6148 | Val Loss: 5242.9745 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 34 | Train Loss: 5827.1360 | Val Loss: 6730.0156 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 35 | Train Loss: 6070.6803 | Val Loss: 5069.2451 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 36 | Train Loss: 5562.0558 | Val Loss: 11006.7579 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 37 | Train Loss: 8481.2637 | Val Loss: 7090.1157 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 38 | Train Loss: 6162.8285 | Val Loss: 5925.4524 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 39 | Train Loss: 5753.1199 | Val Loss: 6000.5694 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 40 | Train Loss: 5991.1872 | Val Loss: 5319.2154 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 41 | Train Loss: 5836.5933 | Val Loss: 5036.8283 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 42 | Train Loss: 5550.3064 | Val Loss: 6623.5044 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 43 | Train Loss: 6268.7661 | Val Loss: 5316.7350 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 44 | Train Loss: 5600.5191 | Val Loss: 5324.0644 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 45 | Train Loss: 5508.6565 | Val Loss: 5350.0902 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 46 | Train Loss: 5691.6555 | Val Loss: 4973.1640 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 47 | Train Loss: 5524.5053 | Val Loss: 5005.7827 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 48 | Train Loss: 5512.1785 | Val Loss: 4956.0101 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 49 | Train Loss: 5544.4420 | Val Loss: 5075.4464 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 50 | Train Loss: 5581.2800 | Val Loss: 7149.7150 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 51 | Train Loss: 6175.6381 | Val Loss: 6405.9386 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 52 | Train Loss: 5909.1784 | Val Loss: 14114.7255 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 53 | Train Loss: 8193.3820 | Val Loss: 5503.1622 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 54 | Train Loss: 5698.4318 | Val Loss: 6221.5228 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 55 | Train Loss: 5640.7406 | Val Loss: 5121.1293 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:10,939] Trial 540 finished with value: 4956.010054976852 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.29415873851214674, 'lr': 0.00028883148927072525, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 7.036298126223104e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 540 | Epoch 56 | Train Loss: 5313.6641 | Val Loss: 8504.6650 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 57 | Train Loss: 6665.7366 | Val Loss: 5065.8995 | Optimizer: RMSprop\n",
      "Trial 540 | Epoch 58 | Train Loss: 5531.6255 | Val Loss: 5554.6261 | Optimizer: RMSprop\n",
      "Trial 540 - Early stopping triggered at epoch 58\n",
      "Trial 541 | Epoch 01 | Train Loss: 15598.6739 | Val Loss: 10056.9224 | Optimizer: RMSprop\n",
      "Trial 541 | Epoch 02 | Train Loss: 11043.7771 | Val Loss: 13278.0110 | Optimizer: RMSprop\n",
      "Trial 541 | Epoch 03 | Train Loss: 11086.1016 | Val Loss: 7058.3096 | Optimizer: RMSprop\n",
      "Trial 541 | Epoch 04 | Train Loss: 8477.7011 | Val Loss: 12011.3496 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:11,359] Trial 541 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 541 | Epoch 05 | Train Loss: 9514.4083 | Val Loss: 6822.2706 | Optimizer: RMSprop\n",
      "Trial 541 | Epoch 06 | Train Loss: 8017.9127 | Val Loss: 9796.7261 | Optimizer: RMSprop\n",
      "Trial 542 | Epoch 01 | Train Loss: 14442.2809 | Val Loss: 12101.7834 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:11,498] Trial 542 pruned. \n",
      "[I 2025-09-05 19:03:11,613] Trial 543 pruned. \n",
      "[I 2025-09-05 19:03:11,738] Trial 544 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 543 | Epoch 01 | Train Loss: 19407.5187 | Val Loss: 15990.3774 | Optimizer: AdamW\n",
      "Trial 544 | Epoch 01 | Train Loss: 20282.1322 | Val Loss: 17331.8719 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:11,867] Trial 545 pruned. \n",
      "[I 2025-09-05 19:03:12,003] Trial 546 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 545 | Epoch 01 | Train Loss: 18288.4493 | Val Loss: 13179.3287 | Optimizer: RMSprop\n",
      "Trial 546 | Epoch 01 | Train Loss: 20838.3558 | Val Loss: 19301.5781 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:12,324] Trial 547 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 547 | Epoch 01 | Train Loss: 97079.4666 | Val Loss: 10439.9861 | Optimizer: RMSprop\n",
      "Trial 547 | Epoch 02 | Train Loss: 11819.0496 | Val Loss: 10423.7437 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:12,454] Trial 548 pruned. \n",
      "[I 2025-09-05 19:03:12,584] Trial 549 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 548 | Epoch 01 | Train Loss: 20609.7587 | Val Loss: 17110.9302 | Optimizer: AdamW\n",
      "Trial 549 | Epoch 01 | Train Loss: 15076.6111 | Val Loss: 11988.8863 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:12,739] Trial 550 pruned. \n",
      "[I 2025-09-05 19:03:12,852] Trial 551 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 550 | Epoch 01 | Train Loss: 21373.9357 | Val Loss: 19122.9270 | Optimizer: Adam\n",
      "Trial 551 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:12,972] Trial 552 pruned. \n",
      "[I 2025-09-05 19:03:13,099] Trial 553 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 552 | Epoch 01 | Train Loss: 13790.2228 | Val Loss: 87380.1299 | Optimizer: RMSprop\n",
      "Trial 553 | Epoch 01 | Train Loss: 20818.5606 | Val Loss: 17733.2485 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:13,237] Trial 554 pruned. \n",
      "[I 2025-09-05 19:03:13,368] Trial 555 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 554 | Epoch 01 | Train Loss: 16039.9872 | Val Loss: 11495.9577 | Optimizer: RMSprop\n",
      "Trial 555 | Epoch 01 | Train Loss: 17458.7390 | Val Loss: 11550.7928 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:13,510] Trial 556 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 556 | Epoch 01 | Train Loss: 21108.9909 | Val Loss: 19142.2071 | Optimizer: Adam\n",
      "Trial 557 | Epoch 01 | Train Loss: 16169.2577 | Val Loss: 10436.2665 | Optimizer: RMSprop\n",
      "Trial 557 | Epoch 02 | Train Loss: 10490.7115 | Val Loss: 13558.8920 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:13,682] Trial 557 pruned. \n",
      "[I 2025-09-05 19:03:13,892] Trial 558 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 558 | Epoch 01 | Train Loss: 16326.7642 | Val Loss: 10882.3534 | Optimizer: Adam\n",
      "Trial 558 | Epoch 02 | Train Loss: 11928.9869 | Val Loss: 10360.2705 | Optimizer: Adam\n",
      "Trial 559 | Epoch 01 | Train Loss: 16901.3093 | Val Loss: 11474.0220 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:14,027] Trial 559 pruned. \n",
      "[I 2025-09-05 19:03:14,148] Trial 560 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 560 | Epoch 01 | Train Loss: 21066.9825 | Val Loss: 19448.7095 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:14,365] Trial 561 pruned. \n",
      "[I 2025-09-05 19:03:14,496] Trial 562 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 561 | Epoch 01 | Train Loss: 354517747.2025 | Val Loss: 30837.8747 | Optimizer: RMSprop\n",
      "Trial 562 | Epoch 01 | Train Loss: 20658.5058 | Val Loss: 18390.9496 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:14,643] Trial 563 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 563 | Epoch 01 | Train Loss: 18382.2492 | Val Loss: 12094.1261 | Optimizer: RMSprop\n",
      "Trial 564 | Epoch 01 | Train Loss: 17936.2538 | Val Loss: 11055.1966 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:14,840] Trial 564 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 564 | Epoch 02 | Train Loss: 12646.1736 | Val Loss: 10894.4291 | Optimizer: Adam\n",
      "Trial 565 | Epoch 01 | Train Loss: 17728.6258 | Val Loss: 11010.0391 | Optimizer: RMSprop\n",
      "Trial 565 | Epoch 02 | Train Loss: 10551.5178 | Val Loss: 10386.8455 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:15,027] Trial 565 pruned. \n",
      "[I 2025-09-05 19:03:15,204] Trial 566 pruned. \n",
      "[I 2025-09-05 19:03:15,331] Trial 567 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 566 | Epoch 01 | Train Loss: 19090.9197 | Val Loss: 12443.4155 | Optimizer: AdamW\n",
      "Trial 567 | Epoch 01 | Train Loss: 20289.8885 | Val Loss: 18960.4391 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:15,456] Trial 568 pruned. \n",
      "[I 2025-09-05 19:03:15,604] Trial 569 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 568 | Epoch 01 | Train Loss: 16881.3255 | Val Loss: 60053.2686 | Optimizer: RMSprop\n",
      "Trial 569 | Epoch 01 | Train Loss: 19578.4217 | Val Loss: 15926.3874 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:15,738] Trial 570 pruned. \n",
      "[I 2025-09-05 19:03:15,885] Trial 571 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 570 | Epoch 01 | Train Loss: 17960.4748 | Val Loss: 13986.9195 | Optimizer: RMSprop\n",
      "Trial 571 | Epoch 01 | Train Loss: 162313.8252 | Val Loss: 346639.6292 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:16,013] Trial 572 pruned. \n",
      "[I 2025-09-05 19:03:16,155] Trial 573 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 572 | Epoch 01 | Train Loss: 20794.7913 | Val Loss: 17528.2222 | Optimizer: AdamW\n",
      "Trial 573 | Epoch 01 | Train Loss: 20721.2906 | Val Loss: 16964.9412 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:16,292] Trial 574 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 574 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:16,523] Trial 575 pruned. \n",
      "[I 2025-09-05 19:03:16,678] Trial 576 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 575 | Epoch 01 | Train Loss: 1828553423.0946 | Val Loss: 36631.6944 | Optimizer: RMSprop\n",
      "Trial 576 | Epoch 01 | Train Loss: 19538.7589 | Val Loss: 13244.7981 | Optimizer: Adam\n",
      "Trial 577 | Epoch 01 | Train Loss: 15321.7265 | Val Loss: 10677.8624 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 02 | Train Loss: 10872.6369 | Val Loss: 6774.3689 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 03 | Train Loss: 9243.2033 | Val Loss: 9139.2280 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 04 | Train Loss: 8833.5976 | Val Loss: 5876.2525 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 05 | Train Loss: 8142.2684 | Val Loss: 8576.4223 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 06 | Train Loss: 8943.3431 | Val Loss: 10123.4742 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 07 | Train Loss: 9692.8938 | Val Loss: 9175.1169 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 08 | Train Loss: 7808.6355 | Val Loss: 9506.1906 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 09 | Train Loss: 7965.1097 | Val Loss: 7129.6489 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 10 | Train Loss: 7387.0983 | Val Loss: 5517.3439 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 11 | Train Loss: 6925.9797 | Val Loss: 10700.0306 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 12 | Train Loss: 8406.0576 | Val Loss: 6116.7220 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 13 | Train Loss: 6397.7497 | Val Loss: 8977.2203 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 14 | Train Loss: 7358.3438 | Val Loss: 9526.3138 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 15 | Train Loss: 7302.4825 | Val Loss: 5312.7244 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 16 | Train Loss: 6378.8314 | Val Loss: 5253.9135 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 17 | Train Loss: 6038.4407 | Val Loss: 5716.2568 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 18 | Train Loss: 6451.2183 | Val Loss: 5784.3148 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 19 | Train Loss: 6667.7069 | Val Loss: 7215.8063 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 20 | Train Loss: 6555.6304 | Val Loss: 9294.7624 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 21 | Train Loss: 7300.8419 | Val Loss: 8660.3368 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 22 | Train Loss: 6799.1193 | Val Loss: 5642.2971 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 23 | Train Loss: 6068.2807 | Val Loss: 5551.2900 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 24 | Train Loss: 5891.1143 | Val Loss: 5513.6085 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 25 | Train Loss: 6044.7470 | Val Loss: 5119.8756 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 26 | Train Loss: 5751.4883 | Val Loss: 5491.2814 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 27 | Train Loss: 5934.7896 | Val Loss: 11688.5259 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 28 | Train Loss: 7631.2663 | Val Loss: 5120.5916 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 29 | Train Loss: 5501.2967 | Val Loss: 6633.3998 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 30 | Train Loss: 6173.0529 | Val Loss: 5099.3861 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 31 | Train Loss: 5581.5186 | Val Loss: 8209.4233 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 32 | Train Loss: 6785.7998 | Val Loss: 25815.3168 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 33 | Train Loss: 10691.0863 | Val Loss: 7899.3912 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 34 | Train Loss: 6693.5092 | Val Loss: 5844.1654 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 35 | Train Loss: 5619.8034 | Val Loss: 5007.0810 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 36 | Train Loss: 5737.3870 | Val Loss: 9742.0495 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 37 | Train Loss: 7481.6813 | Val Loss: 5415.5125 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 38 | Train Loss: 5930.2504 | Val Loss: 7191.5872 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 39 | Train Loss: 6045.2211 | Val Loss: 5138.4856 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 40 | Train Loss: 5694.0952 | Val Loss: 7463.4844 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 41 | Train Loss: 5946.3339 | Val Loss: 5437.4389 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 42 | Train Loss: 5573.4322 | Val Loss: 6142.5144 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 43 | Train Loss: 5707.4122 | Val Loss: 5166.4577 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 44 | Train Loss: 5511.5071 | Val Loss: 4961.2665 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 45 | Train Loss: 5134.8474 | Val Loss: 13509.5043 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 46 | Train Loss: 8983.1715 | Val Loss: 5735.1958 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 47 | Train Loss: 5584.0891 | Val Loss: 4867.7322 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 48 | Train Loss: 5280.6401 | Val Loss: 5036.6026 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 49 | Train Loss: 5465.9737 | Val Loss: 5729.1170 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 50 | Train Loss: 5508.9663 | Val Loss: 4831.1077 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 51 | Train Loss: 5219.6972 | Val Loss: 5767.1535 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 52 | Train Loss: 5406.2873 | Val Loss: 5899.3262 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 53 | Train Loss: 5859.5837 | Val Loss: 9480.2659 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 54 | Train Loss: 6322.0182 | Val Loss: 5472.8854 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 55 | Train Loss: 5416.8249 | Val Loss: 4970.7343 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 56 | Train Loss: 5455.9803 | Val Loss: 4854.8112 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 57 | Train Loss: 5437.6297 | Val Loss: 5214.7710 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 58 | Train Loss: 5274.3366 | Val Loss: 4874.8925 | Optimizer: RMSprop\n",
      "Trial 577 | Epoch 59 | Train Loss: 5191.7999 | Val Loss: 4869.6941 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:20,280] Trial 577 finished with value: 4831.10770821277 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3364214942279832, 'lr': 0.00044000773544044614, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 1.4446258720835799e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 577 | Epoch 60 | Train Loss: 5361.0138 | Val Loss: 5002.2312 | Optimizer: RMSprop\n",
      "Trial 577 - Early stopping triggered at epoch 60\n",
      "Trial 578 | Epoch 01 | Train Loss: 16082.0487 | Val Loss: 10109.1581 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 02 | Train Loss: 10539.5897 | Val Loss: 8737.1627 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 03 | Train Loss: 11609.5741 | Val Loss: 8438.3760 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 04 | Train Loss: 7864.5160 | Val Loss: 6336.6063 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 05 | Train Loss: 8204.2999 | Val Loss: 5850.3690 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 06 | Train Loss: 6537.2700 | Val Loss: 21959.2675 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 07 | Train Loss: 11049.9983 | Val Loss: 9592.7458 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 08 | Train Loss: 8493.9995 | Val Loss: 5935.6988 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 09 | Train Loss: 6844.9027 | Val Loss: 6264.2808 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 10 | Train Loss: 6759.1719 | Val Loss: 5798.0803 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 11 | Train Loss: 6207.3007 | Val Loss: 13333.6336 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 12 | Train Loss: 8934.8397 | Val Loss: 5874.2210 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 13 | Train Loss: 6536.0861 | Val Loss: 7346.5343 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 14 | Train Loss: 6753.9836 | Val Loss: 7753.4209 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 15 | Train Loss: 6993.3877 | Val Loss: 5949.6811 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 16 | Train Loss: 6596.4004 | Val Loss: 8036.0441 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:21,316] Trial 578 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 578 | Epoch 17 | Train Loss: 7037.6732 | Val Loss: 12944.8794 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 18 | Train Loss: 9409.8068 | Val Loss: 7428.6300 | Optimizer: RMSprop\n",
      "Trial 578 | Epoch 19 | Train Loss: 6587.5587 | Val Loss: 9313.1781 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:21,509] Trial 579 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 579 | Epoch 01 | Train Loss: 14750.7603 | Val Loss: 11086.8951 | Optimizer: RMSprop\n",
      "Trial 579 | Epoch 02 | Train Loss: 11913.0468 | Val Loss: 13764.0677 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:21,640] Trial 580 pruned. \n",
      "[I 2025-09-05 19:03:21,762] Trial 581 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 580 | Epoch 01 | Train Loss: 18521.9482 | Val Loss: 13392.2332 | Optimizer: RMSprop\n",
      "Trial 581 | Epoch 01 | Train Loss: 14470.5322 | Val Loss: 13603.1953 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:21,942] Trial 582 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 582 | Epoch 01 | Train Loss: 14896.9300 | Val Loss: 10704.5203 | Optimizer: RMSprop\n",
      "Trial 582 | Epoch 02 | Train Loss: 10834.3063 | Val Loss: 10769.6166 | Optimizer: RMSprop\n",
      "Trial 583 | Epoch 01 | Train Loss: 16353.9942 | Val Loss: 12174.8478 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:22,068] Trial 583 pruned. \n",
      "[I 2025-09-05 19:03:22,195] Trial 584 pruned. \n",
      "[I 2025-09-05 19:03:22,316] Trial 585 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 584 | Epoch 01 | Train Loss: 14683.8571 | Val Loss: 13297.7789 | Optimizer: RMSprop\n",
      "Trial 585 | Epoch 01 | Train Loss: 14552.2242 | Val Loss: 11919.5020 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:22,441] Trial 586 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 586 | Epoch 01 | Train Loss: 17317.7948 | Val Loss: 14064.6259 | Optimizer: RMSprop\n",
      "Trial 587 | Epoch 01 | Train Loss: 27865.9551 | Val Loss: 13008.6031 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:22,612] Trial 587 pruned. \n",
      "[I 2025-09-05 19:03:22,744] Trial 588 pruned. \n",
      "[I 2025-09-05 19:03:22,881] Trial 589 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 588 | Epoch 01 | Train Loss: 21648.1116 | Val Loss: 21009.2161 | Optimizer: RMSprop\n",
      "Trial 589 | Epoch 01 | Train Loss: 21665.4494 | Val Loss: 20953.0475 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:23,079] Trial 590 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 590 | Epoch 01 | Train Loss: 14863.0458 | Val Loss: 10958.2169 | Optimizer: RMSprop\n",
      "Trial 590 | Epoch 02 | Train Loss: 11692.0472 | Val Loss: 12333.8511 | Optimizer: RMSprop\n",
      "Trial 591 | Epoch 01 | Train Loss: 15678.9432 | Val Loss: 9998.6629 | Optimizer: RMSprop\n",
      "Trial 591 | Epoch 02 | Train Loss: 13395.8095 | Val Loss: 11166.8933 | Optimizer: RMSprop\n",
      "Trial 591 | Epoch 03 | Train Loss: 9782.0762 | Val Loss: 7556.1173 | Optimizer: RMSprop\n",
      "Trial 591 | Epoch 04 | Train Loss: 8173.3707 | Val Loss: 6943.5522 | Optimizer: RMSprop\n",
      "Trial 591 | Epoch 05 | Train Loss: 7871.0762 | Val Loss: 6468.0138 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:23,538] Trial 591 pruned. \n",
      "[I 2025-09-05 19:03:23,669] Trial 592 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 591 | Epoch 06 | Train Loss: 7415.7532 | Val Loss: 66425.9384 | Optimizer: RMSprop\n",
      "Trial 592 | Epoch 01 | Train Loss: 21020.7823 | Val Loss: 18695.7921 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:23,802] Trial 593 pruned. \n",
      "[I 2025-09-05 19:03:23,959] Trial 594 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 593 | Epoch 01 | Train Loss: 13885.1220 | Val Loss: 12044.1134 | Optimizer: RMSprop\n",
      "Trial 594 | Epoch 01 | Train Loss: 14740.0583 | Val Loss: 15541.0391 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:24,165] Trial 595 pruned. \n",
      "[I 2025-09-05 19:03:24,299] Trial 596 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 595 | Epoch 01 | Train Loss: 1826807.6094 | Val Loss: 18754.1543 | Optimizer: RMSprop\n",
      "Trial 596 | Epoch 01 | Train Loss: 19042.1931 | Val Loss: 15836.9136 | Optimizer: AdamW\n",
      "Trial 597 | Epoch 01 | Train Loss: 14751.5890 | Val Loss: 9817.4796 | Optimizer: RMSprop\n",
      "Trial 597 | Epoch 02 | Train Loss: 10320.9201 | Val Loss: 9688.4760 | Optimizer: RMSprop\n",
      "Trial 597 | Epoch 03 | Train Loss: 9402.6436 | Val Loss: 8197.2932 | Optimizer: RMSprop\n",
      "Trial 597 | Epoch 04 | Train Loss: 8535.1984 | Val Loss: 8087.1468 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:24,599] Trial 597 pruned. \n",
      "[I 2025-09-05 19:03:24,732] Trial 598 pruned. \n",
      "[I 2025-09-05 19:03:24,867] Trial 599 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 598 | Epoch 01 | Train Loss: 18679.8583 | Val Loss: 12512.1103 | Optimizer: RMSprop\n",
      "Trial 599 | Epoch 01 | Train Loss: 18591.7908 | Val Loss: 13840.3272 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:25,001] Trial 600 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 600 | Epoch 01 | Train Loss: 20317.2823 | Val Loss: 16212.8386 | Optimizer: AdamW\n",
      "Trial 601 | Epoch 01 | Train Loss: 14473.5482 | Val Loss: 9975.3040 | Optimizer: RMSprop\n",
      "Trial 601 | Epoch 02 | Train Loss: 10589.3833 | Val Loss: 35349.7407 | Optimizer: RMSprop\n",
      "Trial 601 | Epoch 03 | Train Loss: 14653.7492 | Val Loss: 7385.4816 | Optimizer: RMSprop\n",
      "Trial 601 | Epoch 04 | Train Loss: 8034.1132 | Val Loss: 11881.7014 | Optimizer: RMSprop\n",
      "Trial 601 | Epoch 05 | Train Loss: 8513.9265 | Val Loss: 6796.3949 | Optimizer: RMSprop\n",
      "Trial 601 | Epoch 06 | Train Loss: 7412.1590 | Val Loss: 9858.4540 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:25,438] Trial 601 pruned. \n",
      "[I 2025-09-05 19:03:25,551] Trial 602 pruned. \n",
      "[I 2025-09-05 19:03:25,685] Trial 603 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 602 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 603 | Epoch 01 | Train Loss: 54261.9848 | Val Loss: 16795.5841 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:25,821] Trial 604 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 604 | Epoch 01 | Train Loss: 19936.9982 | Val Loss: 15952.9930 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:26,029] Trial 605 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 605 | Epoch 01 | Train Loss: 38112199.6891 | Val Loss: 1887765.4907 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 01 | Train Loss: 14456.0812 | Val Loss: 8681.1086 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 02 | Train Loss: 8860.2880 | Val Loss: 10831.0176 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 03 | Train Loss: 8584.7942 | Val Loss: 136778.6405 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 04 | Train Loss: 34420.1142 | Val Loss: 6924.7616 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 05 | Train Loss: 7581.5047 | Val Loss: 5883.4581 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 06 | Train Loss: 6879.8024 | Val Loss: 5877.4006 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 07 | Train Loss: 6954.1597 | Val Loss: 5825.0639 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 08 | Train Loss: 6872.6830 | Val Loss: 6456.1000 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 09 | Train Loss: 6858.7756 | Val Loss: 6100.4575 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 10 | Train Loss: 6680.2791 | Val Loss: 6117.1464 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 11 | Train Loss: 6717.9601 | Val Loss: 5607.4674 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 12 | Train Loss: 6450.3538 | Val Loss: 6937.4564 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 13 | Train Loss: 7046.2040 | Val Loss: 5578.4517 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 14 | Train Loss: 6504.7917 | Val Loss: 5553.8270 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 15 | Train Loss: 6021.1156 | Val Loss: 5421.3738 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 16 | Train Loss: 6324.8674 | Val Loss: 5506.5726 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 17 | Train Loss: 6771.4948 | Val Loss: 7631.4830 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 18 | Train Loss: 7088.7837 | Val Loss: 5327.9394 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 19 | Train Loss: 6144.7595 | Val Loss: 5412.5366 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 20 | Train Loss: 6307.9411 | Val Loss: 5334.3797 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 21 | Train Loss: 6097.4120 | Val Loss: 5560.3884 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 22 | Train Loss: 6145.2741 | Val Loss: 9589.4922 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 23 | Train Loss: 7318.1047 | Val Loss: 5739.2538 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 24 | Train Loss: 6207.3443 | Val Loss: 5505.7133 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 25 | Train Loss: 5780.9462 | Val Loss: 19257.4148 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 26 | Train Loss: 10408.1240 | Val Loss: 5229.7583 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 27 | Train Loss: 6197.1093 | Val Loss: 10106.2739 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 28 | Train Loss: 7195.3921 | Val Loss: 6808.5843 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 29 | Train Loss: 6890.2952 | Val Loss: 5343.3695 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 30 | Train Loss: 6250.5343 | Val Loss: 6103.5036 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 31 | Train Loss: 6281.6241 | Val Loss: 5250.4563 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 32 | Train Loss: 6340.3752 | Val Loss: 6426.1488 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 33 | Train Loss: 6169.5125 | Val Loss: 6096.6300 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 34 | Train Loss: 5884.9506 | Val Loss: 5436.5164 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 35 | Train Loss: 5929.4276 | Val Loss: 5185.6533 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 36 | Train Loss: 6492.3989 | Val Loss: 5285.0005 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 37 | Train Loss: 5660.7835 | Val Loss: 5643.7874 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 38 | Train Loss: 6281.6118 | Val Loss: 5222.6944 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 39 | Train Loss: 5874.6100 | Val Loss: 5153.4959 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 40 | Train Loss: 5828.8700 | Val Loss: 5465.7114 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 41 | Train Loss: 5983.6434 | Val Loss: 6355.1717 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 42 | Train Loss: 6004.0942 | Val Loss: 5119.7880 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 43 | Train Loss: 6092.7598 | Val Loss: 5639.7397 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 44 | Train Loss: 5785.1184 | Val Loss: 5952.2891 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 45 | Train Loss: 6631.6031 | Val Loss: 5784.6035 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 46 | Train Loss: 5806.6697 | Val Loss: 6584.7687 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 47 | Train Loss: 6834.1467 | Val Loss: 6808.1268 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 48 | Train Loss: 6364.2311 | Val Loss: 5811.0738 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 49 | Train Loss: 5994.5663 | Val Loss: 5611.4512 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 50 | Train Loss: 5974.5046 | Val Loss: 5216.5971 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 51 | Train Loss: 5686.9441 | Val Loss: 5087.9174 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 52 | Train Loss: 5626.3790 | Val Loss: 11240.9451 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 53 | Train Loss: 6426.9269 | Val Loss: 5357.0134 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 54 | Train Loss: 5916.8368 | Val Loss: 5188.3232 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 55 | Train Loss: 6017.6651 | Val Loss: 8939.0014 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 56 | Train Loss: 6774.9495 | Val Loss: 5375.5241 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 57 | Train Loss: 5780.7557 | Val Loss: 5003.1517 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 58 | Train Loss: 5584.2741 | Val Loss: 4968.9241 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 59 | Train Loss: 6040.5290 | Val Loss: 4944.3451 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 60 | Train Loss: 5539.7105 | Val Loss: 5205.3528 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 61 | Train Loss: 5684.9557 | Val Loss: 11813.2173 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 62 | Train Loss: 9110.2339 | Val Loss: 10246.0783 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 63 | Train Loss: 6629.4485 | Val Loss: 5999.1312 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 64 | Train Loss: 5723.0158 | Val Loss: 5032.7318 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 65 | Train Loss: 5069.7512 | Val Loss: 4882.3649 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 66 | Train Loss: 5513.3796 | Val Loss: 9708.4061 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 67 | Train Loss: 7789.9252 | Val Loss: 6573.3373 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 68 | Train Loss: 6222.8429 | Val Loss: 5229.6821 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 69 | Train Loss: 5546.0383 | Val Loss: 12935.1015 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 70 | Train Loss: 9017.0404 | Val Loss: 5616.0450 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:29,928] Trial 606 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 606 | Epoch 71 | Train Loss: 5527.4145 | Val Loss: 5922.6814 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 72 | Train Loss: 5638.0335 | Val Loss: 6906.2319 | Optimizer: RMSprop\n",
      "Trial 606 | Epoch 73 | Train Loss: 6187.3338 | Val Loss: 5868.1589 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:30,085] Trial 607 pruned. \n",
      "[I 2025-09-05 19:03:30,207] Trial 608 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 607 | Epoch 01 | Train Loss: 14847.5758 | Val Loss: 11983.2447 | Optimizer: RMSprop\n",
      "Trial 608 | Epoch 01 | Train Loss: 20564.8606 | Val Loss: 19325.4919 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:30,334] Trial 609 pruned. \n",
      "[I 2025-09-05 19:03:30,457] Trial 610 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 609 | Epoch 01 | Train Loss: 19909.4051 | Val Loss: 16450.1697 | Optimizer: RMSprop\n",
      "Trial 610 | Epoch 01 | Train Loss: 18601.1790 | Val Loss: 13145.0791 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:30,587] Trial 611 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 611 | Epoch 01 | Train Loss: 16388.8280 | Val Loss: 16535.2745 | Optimizer: RMSprop\n",
      "Trial 612 | Epoch 01 | Train Loss: 15006.3950 | Val Loss: 11087.1640 | Optimizer: RMSprop\n",
      "Trial 612 | Epoch 02 | Train Loss: 11825.3717 | Val Loss: 8531.6308 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:30,880] Trial 612 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 612 | Epoch 03 | Train Loss: 11635.6761 | Val Loss: 11513.1407 | Optimizer: RMSprop\n",
      "Trial 612 | Epoch 04 | Train Loss: 9325.4534 | Val Loss: 11916.5762 | Optimizer: RMSprop\n",
      "Trial 613 | Epoch 01 | Train Loss: 21349.1217 | Val Loss: 20713.2042 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:31,004] Trial 613 pruned. \n",
      "[I 2025-09-05 19:03:31,175] Trial 614 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 614 | Epoch 01 | Train Loss: 22044.1655 | Val Loss: 22395.1644 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:31,386] Trial 615 pruned. \n",
      "[I 2025-09-05 19:03:31,517] Trial 616 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 615 | Epoch 01 | Train Loss: 1644850.5075 | Val Loss: 21882.4610 | Optimizer: RMSprop\n",
      "Trial 616 | Epoch 01 | Train Loss: 20270.9818 | Val Loss: 17175.4125 | Optimizer: Adam\n",
      "Trial 617 | Epoch 01 | Train Loss: 15015.6187 | Val Loss: 10422.2253 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 02 | Train Loss: 10681.3967 | Val Loss: 8830.7348 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 03 | Train Loss: 9346.7667 | Val Loss: 7198.2948 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 04 | Train Loss: 8085.6843 | Val Loss: 10494.2564 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 05 | Train Loss: 11256.3638 | Val Loss: 6124.4372 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 06 | Train Loss: 7125.4101 | Val Loss: 6092.8477 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 07 | Train Loss: 7697.5212 | Val Loss: 5680.7689 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 08 | Train Loss: 6918.0908 | Val Loss: 12126.9268 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 09 | Train Loss: 9567.1308 | Val Loss: 7245.6954 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 10 | Train Loss: 6717.0409 | Val Loss: 7006.0951 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 11 | Train Loss: 6672.4696 | Val Loss: 34888.1383 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 12 | Train Loss: 11537.3765 | Val Loss: 5968.0654 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 13 | Train Loss: 6577.5605 | Val Loss: 6396.4295 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 14 | Train Loss: 6499.9071 | Val Loss: 6365.7447 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 15 | Train Loss: 7230.2588 | Val Loss: 12988.4655 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 16 | Train Loss: 8079.3919 | Val Loss: 5254.9489 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 17 | Train Loss: 6373.4643 | Val Loss: 5289.6669 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 18 | Train Loss: 6120.2624 | Val Loss: 9778.6109 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 19 | Train Loss: 7843.7399 | Val Loss: 5159.9445 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 20 | Train Loss: 6452.9347 | Val Loss: 6338.0640 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 21 | Train Loss: 6313.0523 | Val Loss: 5434.2402 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 22 | Train Loss: 6303.2289 | Val Loss: 6003.0053 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 23 | Train Loss: 6239.4548 | Val Loss: 5179.9006 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 24 | Train Loss: 6018.7933 | Val Loss: 5503.7918 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 25 | Train Loss: 6079.9004 | Val Loss: 5306.3601 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 26 | Train Loss: 5926.9699 | Val Loss: 7498.9249 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 27 | Train Loss: 6473.9568 | Val Loss: 5110.1457 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 28 | Train Loss: 5812.3728 | Val Loss: 5141.8924 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 29 | Train Loss: 6307.6274 | Val Loss: 5280.4171 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 30 | Train Loss: 5698.8713 | Val Loss: 5834.6940 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 31 | Train Loss: 6254.2713 | Val Loss: 5087.3217 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 32 | Train Loss: 5631.0358 | Val Loss: 5121.2137 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 33 | Train Loss: 5871.5542 | Val Loss: 5624.3782 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 34 | Train Loss: 6107.3843 | Val Loss: 5404.0107 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 35 | Train Loss: 5602.4375 | Val Loss: 13167.9801 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 36 | Train Loss: 7540.9040 | Val Loss: 11349.3565 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 37 | Train Loss: 6630.7506 | Val Loss: 6356.2876 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 38 | Train Loss: 6051.8983 | Val Loss: 5165.6962 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:33,812] Trial 617 finished with value: 5087.321653766397 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.34170640026473564, 'lr': 0.0002767472118280528, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.1981811416746035e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 617 | Epoch 39 | Train Loss: 5594.1694 | Val Loss: 6223.6655 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 40 | Train Loss: 6046.8387 | Val Loss: 6166.5188 | Optimizer: RMSprop\n",
      "Trial 617 | Epoch 41 | Train Loss: 5718.8829 | Val Loss: 6391.3479 | Optimizer: RMSprop\n",
      "Trial 617 - Early stopping triggered at epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:33,950] Trial 618 pruned. \n",
      "[I 2025-09-05 19:03:34,074] Trial 619 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 618 | Epoch 01 | Train Loss: 16855.3153 | Val Loss: 14724.3652 | Optimizer: RMSprop\n",
      "Trial 619 | Epoch 01 | Train Loss: 20499.6584 | Val Loss: 17749.5821 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:34,313] Trial 620 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 620 | Epoch 01 | Train Loss: 14427.4341 | Val Loss: 10114.0930 | Optimizer: RMSprop\n",
      "Trial 620 | Epoch 02 | Train Loss: 10738.3147 | Val Loss: 11869.3199 | Optimizer: RMSprop\n",
      "Trial 620 | Epoch 03 | Train Loss: 10235.9966 | Val Loss: 10474.8977 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:34,442] Trial 621 pruned. \n",
      "[I 2025-09-05 19:03:34,591] Trial 622 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 621 | Epoch 01 | Train Loss: 21420.6712 | Val Loss: 20529.9822 | Optimizer: Adam\n",
      "Trial 622 | Epoch 01 | Train Loss: 27485.8198 | Val Loss: 12558.0050 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:34,746] Trial 623 pruned. \n",
      "[I 2025-09-05 19:03:34,863] Trial 624 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 623 | Epoch 01 | Train Loss: 20680.1806 | Val Loss: 18005.8005 | Optimizer: Adam\n",
      "Trial 624 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:34,993] Trial 625 pruned. \n",
      "[I 2025-09-05 19:03:35,142] Trial 626 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 625 | Epoch 01 | Train Loss: 15152.4951 | Val Loss: 11968.7792 | Optimizer: RMSprop\n",
      "Trial 626 | Epoch 01 | Train Loss: 20861.0526 | Val Loss: 19212.1594 | Optimizer: AdamW\n",
      "Trial 627 | Epoch 01 | Train Loss: 14971.5661 | Val Loss: 9722.1265 | Optimizer: RMSprop\n",
      "Trial 627 | Epoch 02 | Train Loss: 10058.7589 | Val Loss: 10048.7616 | Optimizer: RMSprop\n",
      "Trial 627 | Epoch 03 | Train Loss: 9945.5176 | Val Loss: 6702.8065 | Optimizer: RMSprop\n",
      "Trial 627 | Epoch 04 | Train Loss: 7692.9870 | Val Loss: 8500.0494 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:35,561] Trial 627 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 627 | Epoch 05 | Train Loss: 7829.6591 | Val Loss: 12985.6883 | Optimizer: RMSprop\n",
      "Trial 627 | Epoch 06 | Train Loss: 9660.0512 | Val Loss: 8010.2097 | Optimizer: RMSprop\n",
      "Trial 628 | Epoch 01 | Train Loss: 21240.3821 | Val Loss: 18305.7682 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:35,685] Trial 628 pruned. \n",
      "[I 2025-09-05 19:03:35,838] Trial 629 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 629 | Epoch 01 | Train Loss: 4970962.8642 | Val Loss: 19084.4878 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:36,054] Trial 630 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 630 | Epoch 01 | Train Loss: 19068.6768 | Val Loss: 11449.4256 | Optimizer: Adam\n",
      "Trial 631 | Epoch 01 | Train Loss: 17669.6439 | Val Loss: 11738.2174 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:36,215] Trial 631 pruned. \n",
      "[I 2025-09-05 19:03:36,345] Trial 632 pruned. \n",
      "[I 2025-09-05 19:03:36,495] Trial 633 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 632 | Epoch 01 | Train Loss: 15401.6988 | Val Loss: 11703.2566 | Optimizer: RMSprop\n",
      "Trial 633 | Epoch 01 | Train Loss: 891047.8078 | Val Loss: 73382.0532 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:36,625] Trial 634 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 634 | Epoch 01 | Train Loss: 22848.4626 | Val Loss: 22853.3240 | Optimizer: Adam\n",
      "Trial 635 | Epoch 01 | Train Loss: 14324.5308 | Val Loss: 10568.9424 | Optimizer: RMSprop\n",
      "Trial 635 | Epoch 02 | Train Loss: 11170.1742 | Val Loss: 10105.6302 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:36,978] Trial 635 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 635 | Epoch 03 | Train Loss: 10667.9162 | Val Loss: 8020.7082 | Optimizer: RMSprop\n",
      "Trial 635 | Epoch 04 | Train Loss: 8552.4920 | Val Loss: 7584.2572 | Optimizer: RMSprop\n",
      "Trial 635 | Epoch 05 | Train Loss: 7970.1854 | Val Loss: 12507.5256 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:37,128] Trial 636 pruned. \n",
      "[I 2025-09-05 19:03:37,261] Trial 637 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 636 | Epoch 01 | Train Loss: 18308.8231 | Val Loss: 12306.1837 | Optimizer: Adam\n",
      "Trial 637 | Epoch 01 | Train Loss: 20543.2772 | Val Loss: 17205.2287 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:37,417] Trial 638 pruned. \n",
      "[I 2025-09-05 19:03:37,582] Trial 639 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 638 | Epoch 01 | Train Loss: 17777.8351 | Val Loss: 13510.8955 | Optimizer: RMSprop\n",
      "Trial 639 | Epoch 01 | Train Loss: 86948.2325 | Val Loss: 32999.3027 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:37,716] Trial 640 pruned. \n",
      "[I 2025-09-05 19:03:37,850] Trial 641 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 640 | Epoch 01 | Train Loss: 21674.0840 | Val Loss: 21900.7488 | Optimizer: Adam\n",
      "Trial 641 | Epoch 01 | Train Loss: 15277.3213 | Val Loss: 13157.3661 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:38,072] Trial 642 pruned. \n",
      "[I 2025-09-05 19:03:38,206] Trial 643 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 642 | Epoch 01 | Train Loss: 18784.7060 | Val Loss: 11431.3040 | Optimizer: AdamW\n",
      "Trial 643 | Epoch 01 | Train Loss: 20884.9061 | Val Loss: 20064.9015 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:38,369] Trial 644 pruned. \n",
      "[I 2025-09-05 19:03:38,502] Trial 645 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 644 | Epoch 01 | Train Loss: 17673.4460 | Val Loss: 11493.4067 | Optimizer: RMSprop\n",
      "Trial 645 | Epoch 01 | Train Loss: 16704.4246 | Val Loss: 15082.6316 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:38,652] Trial 646 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 646 | Epoch 01 | Train Loss: 19573.4355 | Val Loss: 16098.8441 | Optimizer: Adam\n",
      "Trial 647 | Epoch 01 | Train Loss: 15789.5314 | Val Loss: 9698.6031 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:38,945] Trial 647 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 647 | Epoch 02 | Train Loss: 9692.7270 | Val Loss: 10902.3524 | Optimizer: RMSprop\n",
      "Trial 647 | Epoch 03 | Train Loss: 9619.6364 | Val Loss: 18711.5203 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:39,105] Trial 648 pruned. \n",
      "[I 2025-09-05 19:03:39,220] Trial 649 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 648 | Epoch 01 | Train Loss: 21386.3181 | Val Loss: 20834.5420 | Optimizer: AdamW\n",
      "Trial 649 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:39,366] Trial 650 pruned. \n",
      "[I 2025-09-05 19:03:39,530] Trial 651 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 650 | Epoch 01 | Train Loss: 19936.5849 | Val Loss: 16501.2365 | Optimizer: Adam\n",
      "Trial 651 | Epoch 01 | Train Loss: 5378172.9173 | Val Loss: 21569.4263 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:39,730] Trial 652 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 652 | Epoch 01 | Train Loss: 15968.2495 | Val Loss: 10456.2254 | Optimizer: RMSprop\n",
      "Trial 652 | Epoch 02 | Train Loss: 9926.9929 | Val Loss: 24638.5450 | Optimizer: RMSprop\n",
      "Trial 653 | Epoch 01 | Train Loss: 19439.4911 | Val Loss: 16706.7959 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:39,870] Trial 653 pruned. \n",
      "[I 2025-09-05 19:03:40,062] Trial 654 pruned. \n",
      "[I 2025-09-05 19:03:40,198] Trial 655 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 654 | Epoch 01 | Train Loss: 19018.3639 | Val Loss: 11499.0925 | Optimizer: AdamW\n",
      "Trial 655 | Epoch 01 | Train Loss: 55705.1427 | Val Loss: 14207.3947 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:40,339] Trial 656 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 656 | Epoch 01 | Train Loss: 18083.9074 | Val Loss: 13265.1690 | Optimizer: Adam\n",
      "Trial 657 | Epoch 01 | Train Loss: 232136.5430 | Val Loss: 11005.6239 | Optimizer: RMSprop\n",
      "Trial 657 | Epoch 02 | Train Loss: 12037.5447 | Val Loss: 9936.6980 | Optimizer: RMSprop\n",
      "Trial 657 | Epoch 03 | Train Loss: 9230.3288 | Val Loss: 12057.5043 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:40,774] Trial 657 pruned. \n",
      "[I 2025-09-05 19:03:40,914] Trial 658 pruned. \n",
      "[I 2025-09-05 19:03:41,038] Trial 659 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 658 | Epoch 01 | Train Loss: 18550.7810 | Val Loss: 12680.9841 | Optimizer: RMSprop\n",
      "Trial 659 | Epoch 01 | Train Loss: 21793.4579 | Val Loss: 21222.5743 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:41,164] Trial 660 pruned. \n",
      "[I 2025-09-05 19:03:41,288] Trial 661 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 660 | Epoch 01 | Train Loss: 18861.7611 | Val Loss: 13168.8835 | Optimizer: AdamW\n",
      "Trial 661 | Epoch 01 | Train Loss: 20704.6250 | Val Loss: 11822.3932 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:41,449] Trial 662 pruned. \n",
      "[I 2025-09-05 19:03:41,579] Trial 663 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 662 | Epoch 01 | Train Loss: 19369.4050 | Val Loss: 13628.2085 | Optimizer: Adam\n",
      "Trial 663 | Epoch 01 | Train Loss: 15191.9113 | Val Loss: 13037.5621 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:41,705] Trial 664 pruned. \n",
      "[I 2025-09-05 19:03:41,839] Trial 665 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 664 | Epoch 01 | Train Loss: 17931.9638 | Val Loss: 11132.5676 | Optimizer: RMSprop\n",
      "Trial 665 | Epoch 01 | Train Loss: 18009.8008 | Val Loss: 11151.4231 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:42,011] Trial 666 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 666 | Epoch 01 | Train Loss: 16872.6534 | Val Loss: 10620.0151 | Optimizer: Adam\n",
      "Trial 666 | Epoch 02 | Train Loss: 12086.3735 | Val Loss: 10547.5209 | Optimizer: Adam\n",
      "Trial 667 | Epoch 01 | Train Loss: 13269.2788 | Val Loss: 10057.0087 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 02 | Train Loss: 9225.1476 | Val Loss: 6944.4279 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 03 | Train Loss: 8045.4343 | Val Loss: 9328.9872 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 04 | Train Loss: 8220.6300 | Val Loss: 5562.5098 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 05 | Train Loss: 7127.3376 | Val Loss: 10853.7517 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 06 | Train Loss: 7517.4618 | Val Loss: 5440.7618 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 07 | Train Loss: 6955.4422 | Val Loss: 48242.9912 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 08 | Train Loss: 18020.5396 | Val Loss: 6384.4719 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 09 | Train Loss: 7286.7009 | Val Loss: 6159.5901 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 10 | Train Loss: 6935.5960 | Val Loss: 5854.4502 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 11 | Train Loss: 6872.2075 | Val Loss: 7000.1695 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 12 | Train Loss: 7022.5706 | Val Loss: 5766.4947 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 13 | Train Loss: 6595.2679 | Val Loss: 5412.9631 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 14 | Train Loss: 6421.8400 | Val Loss: 5378.1074 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 15 | Train Loss: 6421.3916 | Val Loss: 6421.4163 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 16 | Train Loss: 6507.7992 | Val Loss: 7547.6691 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 17 | Train Loss: 6276.4709 | Val Loss: 6563.5179 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 18 | Train Loss: 6357.6085 | Val Loss: 8381.3976 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 19 | Train Loss: 7222.6792 | Val Loss: 11092.8967 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 20 | Train Loss: 6807.2216 | Val Loss: 5749.4394 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 21 | Train Loss: 6202.6173 | Val Loss: 7207.7489 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 22 | Train Loss: 6564.5263 | Val Loss: 5865.2942 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 23 | Train Loss: 6650.6009 | Val Loss: 5351.9921 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 24 | Train Loss: 6235.5894 | Val Loss: 5235.9849 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 25 | Train Loss: 5899.1850 | Val Loss: 5189.0502 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 26 | Train Loss: 5885.8649 | Val Loss: 5314.7784 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 27 | Train Loss: 5967.4789 | Val Loss: 12128.5679 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 28 | Train Loss: 8666.9205 | Val Loss: 6054.9201 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 29 | Train Loss: 6421.1293 | Val Loss: 14999.1321 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 30 | Train Loss: 8652.0540 | Val Loss: 7019.7507 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 31 | Train Loss: 6554.8779 | Val Loss: 5478.6778 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 32 | Train Loss: 5677.0633 | Val Loss: 5893.1305 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 33 | Train Loss: 6460.6985 | Val Loss: 5299.1296 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 34 | Train Loss: 5844.9631 | Val Loss: 5177.0901 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 35 | Train Loss: 5567.6156 | Val Loss: 5283.3164 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 36 | Train Loss: 5927.5034 | Val Loss: 5095.7293 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 37 | Train Loss: 5701.3702 | Val Loss: 5031.7678 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 38 | Train Loss: 5641.2621 | Val Loss: 5084.8097 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 39 | Train Loss: 5656.0033 | Val Loss: 7207.1269 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 40 | Train Loss: 6266.9741 | Val Loss: 10239.6254 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 41 | Train Loss: 7000.6511 | Val Loss: 5177.3502 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 42 | Train Loss: 5411.7977 | Val Loss: 5092.3212 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 43 | Train Loss: 5553.8093 | Val Loss: 5016.2590 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 44 | Train Loss: 5678.4098 | Val Loss: 14899.3827 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 45 | Train Loss: 8728.0263 | Val Loss: 7502.7296 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 46 | Train Loss: 6274.7202 | Val Loss: 5020.1877 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 47 | Train Loss: 5542.9287 | Val Loss: 5131.7949 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 48 | Train Loss: 5578.3489 | Val Loss: 8803.0770 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 49 | Train Loss: 6492.7316 | Val Loss: 5835.0761 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 50 | Train Loss: 5836.2015 | Val Loss: 7149.9442 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 51 | Train Loss: 6361.1711 | Val Loss: 5370.5301 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 52 | Train Loss: 5543.0029 | Val Loss: 4915.9317 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 53 | Train Loss: 5445.0624 | Val Loss: 5548.9353 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 54 | Train Loss: 5459.3868 | Val Loss: 9513.7198 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 55 | Train Loss: 6378.9411 | Val Loss: 5343.4645 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 56 | Train Loss: 5525.2136 | Val Loss: 6261.4926 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 57 | Train Loss: 5882.8659 | Val Loss: 5799.9153 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 58 | Train Loss: 5305.8808 | Val Loss: 10591.3328 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 59 | Train Loss: 6976.7541 | Val Loss: 5469.5811 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 60 | Train Loss: 5540.6768 | Val Loss: 6018.2835 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 61 | Train Loss: 5516.4102 | Val Loss: 4852.7954 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 62 | Train Loss: 5101.2838 | Val Loss: 5979.6856 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 63 | Train Loss: 5579.1059 | Val Loss: 4802.7219 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 64 | Train Loss: 5216.3300 | Val Loss: 5688.1364 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 65 | Train Loss: 5326.7460 | Val Loss: 4879.1787 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 66 | Train Loss: 5178.3921 | Val Loss: 10494.2477 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 67 | Train Loss: 6790.4908 | Val Loss: 14720.1455 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 68 | Train Loss: 7510.8539 | Val Loss: 5210.8247 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 69 | Train Loss: 5205.0560 | Val Loss: 5007.2724 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 70 | Train Loss: 5492.2896 | Val Loss: 5282.2772 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 71 | Train Loss: 5429.9811 | Val Loss: 5810.6161 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 72 | Train Loss: 5658.6926 | Val Loss: 4929.3360 | Optimizer: RMSprop\n",
      "Trial 667 | Epoch 73 | Train Loss: 5490.1032 | Val Loss: 6055.1913 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:48,641] Trial 667 finished with value: 4802.72193287037 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3532681364666606, 'lr': 0.0002944650323372676, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 9.844838873258651e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 667 - Early stopping triggered at epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:48,864] Trial 668 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 668 | Epoch 01 | Train Loss: 15438.6982 | Val Loss: 12478.7919 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:49,110] Trial 669 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 669 | Epoch 01 | Train Loss: 20520.3824 | Val Loss: 18551.8212 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:49,415] Trial 670 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 670 | Epoch 01 | Train Loss: 14467.8838 | Val Loss: 31498.9433 | Optimizer: RMSprop\n",
      "Trial 671 | Epoch 01 | Train Loss: 20822.0297 | Val Loss: 18918.4966 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:49,627] Trial 671 pruned. \n",
      "[I 2025-09-05 19:03:49,972] Trial 672 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 672 | Epoch 01 | Train Loss: 21167.5101 | Val Loss: 17932.8529 | Optimizer: RMSprop\n",
      "Trial 673 | Epoch 01 | Train Loss: 21105.4521 | Val Loss: 18865.8458 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:50,174] Trial 673 pruned. \n",
      "[I 2025-09-05 19:03:50,354] Trial 674 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 674 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 675 | Epoch 01 | Train Loss: 14282.7108 | Val Loss: 27461.0255 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:50,554] Trial 675 pruned. \n",
      "[I 2025-09-05 19:03:50,773] Trial 676 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 676 | Epoch 01 | Train Loss: 19691.2718 | Val Loss: 16709.1191 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:51,009] Trial 677 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 677 | Epoch 01 | Train Loss: 1280076.7379 | Val Loss: 17676.9660 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:51,306] Trial 678 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 678 | Epoch 01 | Train Loss: 17668.9683 | Val Loss: 11874.0524 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:51,545] Trial 679 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 679 | Epoch 01 | Train Loss: 22255.2894 | Val Loss: 21568.1259 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:51,762] Trial 680 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 680 | Epoch 01 | Train Loss: 21081.2112 | Val Loss: 19683.3859 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:52,031] Trial 681 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 681 | Epoch 01 | Train Loss: 2353282.5920 | Val Loss: 12904.3382 | Optimizer: RMSprop\n",
      "Trial 682 | Epoch 01 | Train Loss: 14259.6937 | Val Loss: 10024.1192 | Optimizer: RMSprop\n",
      "Trial 682 | Epoch 02 | Train Loss: 9479.6675 | Val Loss: 16251.4853 | Optimizer: RMSprop\n",
      "Trial 682 | Epoch 03 | Train Loss: 11814.6886 | Val Loss: 8670.3626 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:52,576] Trial 682 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 682 | Epoch 04 | Train Loss: 7952.8161 | Val Loss: 10842.4358 | Optimizer: RMSprop\n",
      "Trial 683 | Epoch 01 | Train Loss: 18469.8568 | Val Loss: 12982.8210 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:52,787] Trial 683 pruned. \n",
      "[I 2025-09-05 19:03:53,194] Trial 684 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 684 | Epoch 01 | Train Loss: 21241.9556 | Val Loss: 19196.6907 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:53,426] Trial 685 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 685 | Epoch 01 | Train Loss: 16183.5026 | Val Loss: 12295.2009 | Optimizer: RMSprop\n",
      "Trial 686 | Epoch 01 | Train Loss: 19912.3114 | Val Loss: 16837.4280 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:53,650] Trial 686 pruned. \n",
      "[I 2025-09-05 19:03:53,863] Trial 687 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 687 | Epoch 01 | Train Loss: 15063.8515 | Val Loss: 23244.5913 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:54,114] Trial 688 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 688 | Epoch 01 | Train Loss: 21172.6336 | Val Loss: 20702.5100 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:54,431] Trial 689 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 689 | Epoch 01 | Train Loss: 18698.3938 | Val Loss: 11028.6540 | Optimizer: RMSprop\n",
      "Trial 689 | Epoch 02 | Train Loss: 10565.5761 | Val Loss: 16073.6728 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:54,719] Trial 690 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 690 | Epoch 01 | Train Loss: 17899.8125 | Val Loss: 13282.8272 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:54,974] Trial 691 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 691 | Epoch 01 | Train Loss: 14093.9459 | Val Loss: 12954.8947 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:55,193] Trial 692 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 692 | Epoch 01 | Train Loss: 20762.4619 | Val Loss: 17639.4889 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:55,417] Trial 693 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 693 | Epoch 01 | Train Loss: 17829.8389 | Val Loss: 16580.0158 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:55,656] Trial 694 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 694 | Epoch 01 | Train Loss: 19113.3489 | Val Loss: 12643.3802 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:55,885] Trial 695 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 695 | Epoch 01 | Train Loss: 19414.6451 | Val Loss: 17568.5312 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:56,137] Trial 696 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 696 | Epoch 01 | Train Loss: 21515.2606 | Val Loss: 21162.2427 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:56,426] Trial 697 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 697 | Epoch 01 | Train Loss: 20622.4498 | Val Loss: 3548757.9012 | Optimizer: SGD\n",
      "Trial 698 | Epoch 01 | Train Loss: 87658206.5047 | Val Loss: 10664.1549 | Optimizer: RMSprop\n",
      "Trial 698 | Epoch 02 | Train Loss: 11208.1882 | Val Loss: 7840.0196 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:57,195] Trial 698 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 698 | Epoch 03 | Train Loss: 8564.0252 | Val Loss: 85235.3833 | Optimizer: RMSprop\n",
      "Trial 698 | Epoch 04 | Train Loss: 27140.1932 | Val Loss: 13841.9086 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:57,413] Trial 699 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 699 | Epoch 01 | Train Loss: 21172.4162 | Val Loss: 20492.3449 | Optimizer: Adam\n",
      "Trial 700 | Epoch 01 | Train Loss: 41519.9057 | Val Loss: 19412.8614 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:57,613] Trial 700 pruned. \n",
      "[I 2025-09-05 19:03:57,832] Trial 701 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 701 | Epoch 01 | Train Loss: 20414.1567 | Val Loss: 16121.3601 | Optimizer: AdamW\n",
      "Trial 702 | Epoch 01 | Train Loss: 20500.5469 | Val Loss: 18834.1403 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:58,039] Trial 702 pruned. \n",
      "[I 2025-09-05 19:03:58,340] Trial 703 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 703 | Epoch 01 | Train Loss: 20552.7320 | Val Loss: 18455.4078 | Optimizer: Adam\n",
      "Trial 704 | Epoch 01 | Train Loss: 15203.9228 | Val Loss: 10779.2415 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:58,591] Trial 704 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 704 | Epoch 02 | Train Loss: 11388.0039 | Val Loss: 13246.8591 | Optimizer: RMSprop\n",
      "Trial 705 | Epoch 01 | Train Loss: 17133.8810 | Val Loss: 10599.5532 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:58,904] Trial 705 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 705 | Epoch 02 | Train Loss: 12462.3850 | Val Loss: 10428.8734 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:59,136] Trial 706 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 706 | Epoch 01 | Train Loss: 16454.9071 | Val Loss: 11464.3309 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:59,370] Trial 707 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 707 | Epoch 01 | Train Loss: 18588.7251 | Val Loss: 11880.7747 | Optimizer: AdamW\n",
      "Trial 708 | Epoch 01 | Train Loss: 19320.6036 | Val Loss: 10458.3789 | Optimizer: RMSprop\n",
      "Trial 708 | Epoch 02 | Train Loss: 11051.4497 | Val Loss: 9625.4544 | Optimizer: RMSprop\n",
      "Trial 708 | Epoch 03 | Train Loss: 10262.1233 | Val Loss: 12641.1578 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:03:59,912] Trial 708 pruned. \n",
      "[I 2025-09-05 19:04:00,235] Trial 709 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 709 | Epoch 01 | Train Loss: 20872.0446 | Val Loss: 17422.6195 | Optimizer: Adam\n",
      "Trial 710 | Epoch 01 | Train Loss: 14975.2299 | Val Loss: 10690.3187 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:00,558] Trial 710 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 710 | Epoch 02 | Train Loss: 11903.9367 | Val Loss: 15159.0802 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:00,912] Trial 711 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 711 | Epoch 01 | Train Loss: 17158.0328 | Val Loss: 12700.6451 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:01,154] Trial 712 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 712 | Epoch 01 | Train Loss: 19682.4181 | Val Loss: 16448.0204 | Optimizer: Adam\n",
      "Trial 713 | Epoch 01 | Train Loss: 20465.9202 | Val Loss: 10407.8062 | Optimizer: RMSprop\n",
      "Trial 713 | Epoch 02 | Train Loss: 11323.8896 | Val Loss: 9724.6140 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:01,605] Trial 713 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 713 | Epoch 03 | Train Loss: 9495.5371 | Val Loss: 15806.4767 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:01,907] Trial 714 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 714 | Epoch 01 | Train Loss: 19735.4188 | Val Loss: 14119.4186 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:02,209] Trial 715 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 715 | Epoch 01 | Train Loss: 18073.6177 | Val Loss: 12011.0818 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:02,448] Trial 716 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 716 | Epoch 01 | Train Loss: 22027.4664 | Val Loss: 21629.2943 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:02,720] Trial 717 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 717 | Epoch 01 | Train Loss: 19780.0229 | Val Loss: 15269.7380 | Optimizer: AdamW\n",
      "Trial 718 | Epoch 01 | Train Loss: 15308.5652 | Val Loss: 9988.0007 | Optimizer: RMSprop\n",
      "Trial 718 | Epoch 02 | Train Loss: 11917.6048 | Val Loss: 11203.6822 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:03,184] Trial 718 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 718 | Epoch 03 | Train Loss: 9523.2749 | Val Loss: 10759.7534 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:03,429] Trial 719 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 719 | Epoch 01 | Train Loss: 19917.0169 | Val Loss: 17585.1515 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:03,930] Trial 720 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 720 | Epoch 01 | Train Loss: 19085.5202 | Val Loss: 10654.4048 | Optimizer: RMSprop\n",
      "Trial 720 | Epoch 02 | Train Loss: 11744.4600 | Val Loss: 14370.5865 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:04,288] Trial 721 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 721 | Epoch 01 | Train Loss: 17987.6798 | Val Loss: 10445.8900 | Optimizer: Adam\n",
      "Trial 721 | Epoch 02 | Train Loss: 11287.4049 | Val Loss: 10408.7403 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:04,502] Trial 722 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 722 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 723 | Epoch 01 | Train Loss: 35005.0740 | Val Loss: 10942.0973 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:04,806] Trial 723 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 723 | Epoch 02 | Train Loss: 10654.0194 | Val Loss: 12488.3055 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:05,036] Trial 724 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 724 | Epoch 01 | Train Loss: 21542.8432 | Val Loss: 20608.6488 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:05,364] Trial 725 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 | Epoch 01 | Train Loss: 17129.9298 | Val Loss: 15465.1948 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:05,653] Trial 726 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 726 | Epoch 01 | Train Loss: 19516.2077 | Val Loss: 16692.1994 | Optimizer: Adam\n",
      "Trial 727 | Epoch 01 | Train Loss: 131572.3547 | Val Loss: 17550.0954 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:05,872] Trial 727 pruned. \n",
      "[I 2025-09-05 19:04:06,119] Trial 728 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 728 | Epoch 01 | Train Loss: 20437.1553 | Val Loss: 17402.4984 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:06,338] Trial 729 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 729 | Epoch 01 | Train Loss: 19812.7496 | Val Loss: 17951.0634 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:06,574] Trial 730 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 730 | Epoch 01 | Train Loss: 533385.0652 | Val Loss: 22598.0363 | Optimizer: RMSprop\n",
      "Trial 731 | Epoch 01 | Train Loss: 15378.2275 | Val Loss: 11707.4460 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:06,785] Trial 731 pruned. \n",
      "[I 2025-09-05 19:04:07,025] Trial 732 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 732 | Epoch 01 | Train Loss: 18881.9902 | Val Loss: 11726.4837 | Optimizer: Adam\n",
      "Trial 733 | Epoch 01 | Train Loss: 15214.0998 | Val Loss: 9037.3514 | Optimizer: RMSprop\n",
      "Trial 733 | Epoch 02 | Train Loss: 11680.1733 | Val Loss: 7188.2972 | Optimizer: RMSprop\n",
      "Trial 733 | Epoch 03 | Train Loss: 11951.5126 | Val Loss: 7906.6003 | Optimizer: RMSprop\n",
      "Trial 733 | Epoch 04 | Train Loss: 9170.1908 | Val Loss: 24730.3090 | Optimizer: RMSprop\n",
      "Trial 733 | Epoch 05 | Train Loss: 11747.3745 | Val Loss: 7342.7641 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:07,827] Trial 733 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 733 | Epoch 06 | Train Loss: 8688.6298 | Val Loss: 6350.6752 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:08,060] Trial 734 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 734 | Epoch 01 | Train Loss: 19900.5074 | Val Loss: 16156.7553 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:08,309] Trial 735 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 735 | Epoch 01 | Train Loss: 19497.7316 | Val Loss: 14136.2615 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:08,629] Trial 736 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 736 | Epoch 01 | Train Loss: 17801.3958 | Val Loss: 10704.0109 | Optimizer: RMSprop\n",
      "Trial 736 | Epoch 02 | Train Loss: 11399.8525 | Val Loss: 11300.3420 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:08,846] Trial 737 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 737 | Epoch 01 | Train Loss: 15657.5945 | Val Loss: 12969.1985 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:09,239] Trial 738 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 738 | Epoch 01 | Train Loss: 20673.4413 | Val Loss: 17203.3567 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:09,475] Trial 739 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 739 | Epoch 01 | Train Loss: 990342.8072 | Val Loss: 19335.7381 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:09,708] Trial 740 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 740 | Epoch 01 | Train Loss: 17319.6687 | Val Loss: 11611.0380 | Optimizer: AdamW\n",
      "Trial 741 | Epoch 01 | Train Loss: 17330.3316 | Val Loss: 11040.8443 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:09,902] Trial 741 pruned. \n",
      "[I 2025-09-05 19:04:10,149] Trial 742 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 742 | Epoch 01 | Train Loss: 19333.9855 | Val Loss: 14926.4089 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:10,464] Trial 743 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 743 | Epoch 01 | Train Loss: 16184.0821 | Val Loss: 10719.3676 | Optimizer: RMSprop\n",
      "Trial 743 | Epoch 02 | Train Loss: 11426.7287 | Val Loss: 14159.9711 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:10,754] Trial 744 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 744 | Epoch 01 | Train Loss: 20872.9307 | Val Loss: 18577.4906 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:10,962] Trial 745 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 745 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:11,215] Trial 746 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 746 | Epoch 01 | Train Loss: 175947.0044 | Val Loss: 24281.0738 | Optimizer: RMSprop\n",
      "Trial 747 | Epoch 01 | Train Loss: 21259.7387 | Val Loss: 19948.2041 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:11,446] Trial 747 pruned. \n",
      "[I 2025-09-05 19:04:11,672] Trial 748 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 748 | Epoch 01 | Train Loss: 20848.2603 | Val Loss: 18663.5234 | Optimizer: Adam\n",
      "Trial 749 | Epoch 01 | Train Loss: 14934.7548 | Val Loss: 10371.6073 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:12,102] Trial 749 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 749 | Epoch 02 | Train Loss: 11527.7075 | Val Loss: 9585.1772 | Optimizer: RMSprop\n",
      "Trial 749 | Epoch 03 | Train Loss: 8512.9373 | Val Loss: 9961.9304 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:12,368] Trial 750 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 750 | Epoch 01 | Train Loss: 161527.6521 | Val Loss: 13938.1981 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:12,792] Trial 751 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 751 | Epoch 01 | Train Loss: 18892.8411 | Val Loss: 21846.4048 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:13,015] Trial 752 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 752 | Epoch 01 | Train Loss: 18885.7790 | Val Loss: 12910.6872 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:13,240] Trial 753 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 753 | Epoch 01 | Train Loss: 18170.7615 | Val Loss: 11227.8094 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:13,467] Trial 754 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 754 | Epoch 01 | Train Loss: 20542.8118 | Val Loss: 17602.5406 | Optimizer: Adam\n",
      "Trial 755 | Epoch 01 | Train Loss: 16452.0187 | Val Loss: 12627.1959 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:13,658] Trial 755 pruned. \n",
      "[I 2025-09-05 19:04:13,864] Trial 756 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 756 | Epoch 01 | Train Loss: 39509.7078 | Val Loss: 29529.9848 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:14,107] Trial 757 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 757 | Epoch 01 | Train Loss: 20723.7992 | Val Loss: 17275.1621 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:14,406] Trial 758 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 758 | Epoch 01 | Train Loss: 20440.4605 | Val Loss: 15853.1175 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:14,632] Trial 759 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 759 | Epoch 01 | Train Loss: 15020.3696 | Val Loss: 11422.9737 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:14,897] Trial 760 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 760 | Epoch 01 | Train Loss: 46765.7173 | Val Loss: 14921.2090 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:15,134] Trial 761 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 761 | Epoch 01 | Train Loss: 22223.1938 | Val Loss: 21492.0092 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:15,375] Trial 762 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 762 | Epoch 01 | Train Loss: 14944.8511 | Val Loss: 16283.9963 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:15,644] Trial 763 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 763 | Epoch 01 | Train Loss: 17746.9387 | Val Loss: 13063.7943 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:15,966] Trial 764 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 764 | Epoch 01 | Train Loss: 19967.2168 | Val Loss: 13436.6923 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:16,316] Trial 765 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 765 | Epoch 01 | Train Loss: 92864.8920 | Val Loss: 60227.2759 | Optimizer: RMSprop\n",
      "Trial 766 | Epoch 01 | Train Loss: 16043.1555 | Val Loss: 19124.5920 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:16,535] Trial 766 pruned. \n",
      "[I 2025-09-05 19:04:16,766] Trial 767 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 767 | Epoch 01 | Train Loss: 20742.4170 | Val Loss: 18077.9679 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:17,014] Trial 768 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 768 | Epoch 01 | Train Loss: 20242.4548 | Val Loss: 16948.5919 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:17,270] Trial 769 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 769 | Epoch 01 | Train Loss: 17736.3595 | Val Loss: 18555.2357 | Optimizer: RMSprop\n",
      "Trial 770 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:17,461] Trial 770 pruned. \n",
      "[I 2025-09-05 19:04:17,775] Trial 771 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 771 | Epoch 01 | Train Loss: 18068.4953 | Val Loss: 12298.2481 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:18,034] Trial 772 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 772 | Epoch 01 | Train Loss: 16962.3173 | Val Loss: 16204.0106 | Optimizer: RMSprop\n",
      "Trial 773 | Epoch 01 | Train Loss: 17515.0913 | Val Loss: 12705.1738 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:18,256] Trial 773 pruned. \n",
      "[I 2025-09-05 19:04:18,485] Trial 774 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 774 | Epoch 01 | Train Loss: 20303.6580 | Val Loss: 17136.1705 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:18,851] Trial 775 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 775 | Epoch 01 | Train Loss: 17874.7662 | Val Loss: 11435.1849 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:19,085] Trial 776 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 776 | Epoch 01 | Train Loss: 17965.4374 | Val Loss: 12312.2487 | Optimizer: RMSprop\n",
      "Trial 777 | Epoch 01 | Train Loss: 20280.2150 | Val Loss: 17030.0135 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:19,289] Trial 777 pruned. \n",
      "[I 2025-09-05 19:04:19,639] Trial 778 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 778 | Epoch 01 | Train Loss: 1837105911.9057 | Val Loss: 16847.3015 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:19,855] Trial 779 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 779 | Epoch 01 | Train Loss: 106409.5487 | Val Loss: 21562.7412 | Optimizer: RMSprop\n",
      "Trial 780 | Epoch 01 | Train Loss: 19067.2263 | Val Loss: 14751.7245 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:20,063] Trial 780 pruned. \n",
      "[I 2025-09-05 19:04:20,274] Trial 781 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 781 | Epoch 01 | Train Loss: 22047.3392 | Val Loss: 22160.9652 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:20,488] Trial 782 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 782 | Epoch 01 | Train Loss: 16361.1380 | Val Loss: 11163.1755 | Optimizer: RMSprop\n",
      "Trial 783 | Epoch 01 | Train Loss: 20724.3349 | Val Loss: 18836.9446 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:20,696] Trial 783 pruned. \n",
      "[I 2025-09-05 19:04:20,927] Trial 784 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 784 | Epoch 01 | Train Loss: 79992.1655 | Val Loss: 12446.0847 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:21,315] Trial 785 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 785 | Epoch 01 | Train Loss: 16292.1552 | Val Loss: 10809.3242 | Optimizer: RMSprop\n",
      "Trial 785 | Epoch 02 | Train Loss: 10431.6816 | Val Loss: 15573.2778 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:21,559] Trial 786 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 786 | Epoch 01 | Train Loss: 19036.7406 | Val Loss: 13983.0193 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:21,791] Trial 787 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 787 | Epoch 01 | Train Loss: 18030.4707 | Val Loss: 12245.0834 | Optimizer: Adam\n",
      "Trial 788 | Epoch 01 | Train Loss: 14007.6156 | Val Loss: 10298.0906 | Optimizer: RMSprop\n",
      "Trial 788 | Epoch 02 | Train Loss: 10366.3113 | Val Loss: 9676.6010 | Optimizer: RMSprop\n",
      "Trial 788 | Epoch 03 | Train Loss: 8613.0766 | Val Loss: 10051.6112 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:22,231] Trial 788 pruned. \n",
      "[I 2025-09-05 19:04:22,597] Trial 789 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 789 | Epoch 01 | Train Loss: 18313.4958 | Val Loss: 10485.1200 | Optimizer: Adam\n",
      "Trial 789 | Epoch 02 | Train Loss: 12069.8466 | Val Loss: 12056.6038 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:22,839] Trial 790 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 790 | Epoch 01 | Train Loss: 14287.2518 | Val Loss: 12513.9793 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:23,246] Trial 791 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 791 | Epoch 01 | Train Loss: 20239.5511 | Val Loss: 13912.3868 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:23,474] Trial 792 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 792 | Epoch 01 | Train Loss: 21345.6903 | Val Loss: 18573.9239 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:23,720] Trial 793 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 793 | Epoch 01 | Train Loss: 20246.0268 | Val Loss: 17882.2265 | Optimizer: Adam\n",
      "Trial 794 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:23,910] Trial 794 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 795 | Epoch 01 | Train Loss: 28324.6788 | Val Loss: 9715.1777 | Optimizer: RMSprop\n",
      "Trial 795 | Epoch 02 | Train Loss: 11673.3285 | Val Loss: 9008.4191 | Optimizer: RMSprop\n",
      "Trial 795 | Epoch 03 | Train Loss: 9004.7617 | Val Loss: 10886.3895 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:24,318] Trial 795 pruned. \n",
      "[I 2025-09-05 19:04:24,521] Trial 796 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 796 | Epoch 01 | Train Loss: 18490.3963 | Val Loss: 12460.1711 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:24,767] Trial 797 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 797 | Epoch 01 | Train Loss: 16601.6861 | Val Loss: 1494662.8673 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:25,142] Trial 798 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 798 | Epoch 01 | Train Loss: 17072.8940 | Val Loss: 10994.5031 | Optimizer: AdamW\n",
      "Trial 798 | Epoch 02 | Train Loss: 12259.6087 | Val Loss: 10569.4772 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:25,459] Trial 799 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 799 | Epoch 01 | Train Loss: 14313.9261 | Val Loss: 10322.2551 | Optimizer: RMSprop\n",
      "Trial 799 | Epoch 02 | Train Loss: 9958.3681 | Val Loss: 12661.2854 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:25,692] Trial 800 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 800 | Epoch 01 | Train Loss: 19648.4993 | Val Loss: 15913.1357 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:25,938] Trial 801 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 801 | Epoch 01 | Train Loss: 21317.2592 | Val Loss: 20914.9406 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:26,182] Trial 802 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 802 | Epoch 01 | Train Loss: 19306.2093 | Val Loss: 15061.9815 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:26,421] Trial 803 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 803 | Epoch 01 | Train Loss: 19738.9857 | Val Loss: 16341.7477 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:26,738] Trial 804 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 804 | Epoch 01 | Train Loss: 20367.8840 | Val Loss: 18568.0880 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:27,073] Trial 805 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 805 | Epoch 01 | Train Loss: 2096545532.3558 | Val Loss: 33322.3380 | Optimizer: RMSprop\n",
      "Trial 806 | Epoch 01 | Train Loss: 19902.1689 | Val Loss: 16845.4596 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:27,271] Trial 806 pruned. \n",
      "[I 2025-09-05 19:04:27,507] Trial 807 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 807 | Epoch 01 | Train Loss: 16382.0005 | Val Loss: 310002.7766 | Optimizer: RMSprop\n",
      "Trial 808 | Epoch 01 | Train Loss: 16947.8993 | Val Loss: 10443.6575 | Optimizer: RMSprop\n",
      "Trial 808 | Epoch 02 | Train Loss: 10034.8030 | Val Loss: 9917.2818 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:27,994] Trial 808 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 808 | Epoch 03 | Train Loss: 9524.7617 | Val Loss: 32451.4152 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:28,242] Trial 809 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 809 | Epoch 01 | Train Loss: 19947.1587 | Val Loss: 15823.1189 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:28,549] Trial 810 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 810 | Epoch 01 | Train Loss: 20235.2420 | Val Loss: 17425.0424 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:28,811] Trial 811 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 811 | Epoch 01 | Train Loss: 16741.2061 | Val Loss: 11589.0695 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:29,042] Trial 812 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 812 | Epoch 01 | Train Loss: 18872.9502 | Val Loss: 13977.3499 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:29,277] Trial 813 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 813 | Epoch 01 | Train Loss: 32172.9383 | Val Loss: 19007.4711 | Optimizer: RMSprop\n",
      "Trial 814 | Epoch 01 | Train Loss: 16831.5819 | Val Loss: 10921.9200 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:29,572] Trial 814 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 814 | Epoch 02 | Train Loss: 12458.7581 | Val Loss: 10845.9483 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:29,836] Trial 815 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 815 | Epoch 01 | Train Loss: 22918.5674 | Val Loss: 12349.9461 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:30,124] Trial 816 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 816 | Epoch 01 | Train Loss: 20414.3534 | Val Loss: 19096.3959 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:30,364] Trial 817 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 817 | Epoch 01 | Train Loss: 18142.7638 | Val Loss: 13187.1815 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:30,710] Trial 818 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 818 | Epoch 01 | Train Loss: 20301.9706 | Val Loss: 16343.8071 | Optimizer: Adam\n",
      "Trial 819 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:30,887] Trial 819 pruned. \n",
      "[I 2025-09-05 19:04:31,136] Trial 820 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 820 | Epoch 01 | Train Loss: 107323.0716 | Val Loss: 15699.7959 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:31,490] Trial 821 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 821 | Epoch 01 | Train Loss: 15388.4681 | Val Loss: 10712.0965 | Optimizer: AdamW\n",
      "Trial 821 | Epoch 02 | Train Loss: 12219.0247 | Val Loss: 10765.1274 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:31,786] Trial 822 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 822 | Epoch 01 | Train Loss: 14643.0370 | Val Loss: 22481.2904 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:32,065] Trial 823 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 823 | Epoch 01 | Train Loss: 19541.3653 | Val Loss: 15757.6287 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:32,413] Trial 824 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 824 | Epoch 01 | Train Loss: 14730.3623 | Val Loss: 10330.3164 | Optimizer: RMSprop\n",
      "Trial 824 | Epoch 02 | Train Loss: 13793.2844 | Val Loss: 10881.5426 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:32,652] Trial 825 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 825 | Epoch 01 | Train Loss: 19873.0891 | Val Loss: 14766.7997 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:32,924] Trial 826 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 826 | Epoch 01 | Train Loss: 19919.3799 | Val Loss: 14513.0970 | Optimizer: RMSprop\n",
      "Trial 827 | Epoch 01 | Train Loss: 17527.6403 | Val Loss: 11843.5444 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:33,144] Trial 827 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 828 | Epoch 01 | Train Loss: 17254.1822 | Val Loss: 10812.0950 | Optimizer: RMSprop\n",
      "Trial 828 | Epoch 02 | Train Loss: 10724.8270 | Val Loss: 9987.9402 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:33,689] Trial 828 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 828 | Epoch 03 | Train Loss: 9961.4852 | Val Loss: 10674.2188 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:34,043] Trial 829 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 829 | Epoch 01 | Train Loss: 18642.1806 | Val Loss: 12345.9358 | Optimizer: Adam\n",
      "Trial 830 | Epoch 01 | Train Loss: 13202.1482 | Val Loss: 16042.9498 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:34,270] Trial 830 pruned. \n",
      "[I 2025-09-05 19:04:34,644] Trial 831 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 831 | Epoch 01 | Train Loss: 19218.0248 | Val Loss: 10695.3057 | Optimizer: AdamW\n",
      "Trial 831 | Epoch 02 | Train Loss: 10376.0010 | Val Loss: 12482.5598 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:34,877] Trial 832 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 832 | Epoch 01 | Train Loss: 19485.9821 | Val Loss: 15308.3354 | Optimizer: Adam\n",
      "Trial 833 | Epoch 01 | Train Loss: 15821.4581 | Val Loss: 11139.5027 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:35,083] Trial 833 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 834 | Epoch 01 | Train Loss: 17475.0516 | Val Loss: 10024.9072 | Optimizer: RMSprop\n",
      "Trial 834 | Epoch 02 | Train Loss: 10275.9588 | Val Loss: 12945.8416 | Optimizer: RMSprop\n",
      "Trial 834 | Epoch 03 | Train Loss: 10028.6917 | Val Loss: 12970.8384 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:35,556] Trial 834 pruned. \n",
      "[I 2025-09-05 19:04:35,780] Trial 835 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 835 | Epoch 01 | Train Loss: 18736.2786 | Val Loss: 13707.4333 | Optimizer: Adam\n",
      "Trial 836 | Epoch 01 | Train Loss: 17881.8029 | Val Loss: 13165.7396 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:36,006] Trial 836 pruned. \n",
      "[I 2025-09-05 19:04:36,225] Trial 837 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 837 | Epoch 01 | Train Loss: 18305.4500 | Val Loss: 11467.2720 | Optimizer: AdamW\n",
      "Trial 838 | Epoch 01 | Train Loss: 14352.0694 | Val Loss: 12399.6680 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:36,418] Trial 838 pruned. \n",
      "[I 2025-09-05 19:04:36,619] Trial 839 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 839 | Epoch 01 | Train Loss: 18456.7044 | Val Loss: 13083.9487 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:36,853] Trial 840 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 840 | Epoch 01 | Train Loss: 18126.9680 | Val Loss: 12015.5415 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:37,160] Trial 841 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 841 | Epoch 01 | Train Loss: 20621.2495 | Val Loss: 18063.2232 | Optimizer: Adam\n",
      "Trial 842 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:37,349] Trial 842 pruned. \n",
      "[I 2025-09-05 19:04:37,570] Trial 843 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 843 | Epoch 01 | Train Loss: 36069.8791 | Val Loss: 17011.6962 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:37,913] Trial 844 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 844 | Epoch 01 | Train Loss: 17608.4314 | Val Loss: 10442.8691 | Optimizer: AdamW\n",
      "Trial 844 | Epoch 02 | Train Loss: 11624.2956 | Val Loss: 10533.1679 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:38,253] Trial 845 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 845 | Epoch 01 | Train Loss: 35039.0284 | Val Loss: 17918.0839 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:38,487] Trial 846 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 846 | Epoch 01 | Train Loss: 20891.2402 | Val Loss: 18509.4116 | Optimizer: Adam\n",
      "Trial 847 | Epoch 01 | Train Loss: 18710.7472 | Val Loss: 13101.7971 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:38,682] Trial 847 pruned. \n",
      "[I 2025-09-05 19:04:39,001] Trial 848 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 848 | Epoch 01 | Train Loss: 21181.6603 | Val Loss: 20311.0445 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:39,231] Trial 849 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 849 | Epoch 01 | Train Loss: 15385.3817 | Val Loss: 15283.4274 | Optimizer: RMSprop\n",
      "Trial 850 | Epoch 01 | Train Loss: 19604.6347 | Val Loss: 15757.0730 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:39,440] Trial 850 pruned. \n",
      "[I 2025-09-05 19:04:39,672] Trial 851 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 851 | Epoch 01 | Train Loss: 15839.9304 | Val Loss: 11663.4104 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:39,929] Trial 852 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 852 | Epoch 01 | Train Loss: 19408.8742 | Val Loss: 12416.8397 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:40,154] Trial 853 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 853 | Epoch 01 | Train Loss: 15602.6797 | Val Loss: 24145.2894 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:40,422] Trial 854 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 854 | Epoch 01 | Train Loss: 19846.0102 | Val Loss: 16224.4369 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:40,748] Trial 855 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 855 | Epoch 01 | Train Loss: 20773.1734 | Val Loss: 18929.7786 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:40,974] Trial 856 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 856 | Epoch 01 | Train Loss: 14977.2319 | Val Loss: 13351.1489 | Optimizer: RMSprop\n",
      "Trial 857 | Epoch 01 | Train Loss: 13904.8676 | Val Loss: 9902.0591 | Optimizer: RMSprop\n",
      "Trial 857 | Epoch 02 | Train Loss: 11039.0433 | Val Loss: 6860.4351 | Optimizer: RMSprop\n",
      "Trial 857 | Epoch 03 | Train Loss: 10248.1361 | Val Loss: 10494.8273 | Optimizer: RMSprop\n",
      "Trial 857 | Epoch 04 | Train Loss: 8979.7161 | Val Loss: 6925.4260 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:41,707] Trial 857 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 857 | Epoch 05 | Train Loss: 7711.1772 | Val Loss: 16327.0113 | Optimizer: RMSprop\n",
      "Trial 857 | Epoch 06 | Train Loss: 11746.8361 | Val Loss: 7677.4686 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:42,061] Trial 858 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 858 | Epoch 01 | Train Loss: 18253.5400 | Val Loss: 34334.1852 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:42,425] Trial 859 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 859 | Epoch 01 | Train Loss: 17454.8028 | Val Loss: 10479.7122 | Optimizer: RMSprop\n",
      "Trial 859 | Epoch 02 | Train Loss: 11199.0892 | Val Loss: 11092.1675 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:42,706] Trial 860 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 860 | Epoch 01 | Train Loss: 19360.6028 | Val Loss: 14723.5504 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:42,952] Trial 861 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 861 | Epoch 01 | Train Loss: 20694.5996 | Val Loss: 18761.4056 | Optimizer: Adam\n",
      "Trial 862 | Epoch 01 | Train Loss: 35599895.4873 | Val Loss: 8879.9487 | Optimizer: RMSprop\n",
      "Trial 862 | Epoch 02 | Train Loss: 10245.1850 | Val Loss: 13055.0882 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:43,385] Trial 862 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 862 | Epoch 03 | Train Loss: 8966.7165 | Val Loss: 12672.3823 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:43,602] Trial 863 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 863 | Epoch 01 | Train Loss: 16115.5955 | Val Loss: 11769.7988 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:43,839] Trial 864 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 864 | Epoch 01 | Train Loss: 20593.0041 | Val Loss: 19078.1763 | Optimizer: Adam\n",
      "Trial 865 | Epoch 01 | Train Loss: 31924.9650 | Val Loss: 10023.7583 | Optimizer: RMSprop\n",
      "Trial 865 | Epoch 02 | Train Loss: 14029.2187 | Val Loss: 10186.2497 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:44,320] Trial 865 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 865 | Epoch 03 | Train Loss: 9365.3853 | Val Loss: 11659.5866 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:44,554] Trial 866 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 866 | Epoch 01 | Train Loss: 18989.3089 | Val Loss: 14330.1181 | Optimizer: AdamW\n",
      "Trial 867 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:44,725] Trial 867 pruned. \n",
      "[I 2025-09-05 19:04:44,940] Trial 868 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 868 | Epoch 01 | Train Loss: 19472.5134 | Val Loss: 17022.1422 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:45,189] Trial 869 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 869 | Epoch 01 | Train Loss: 16965.7504 | Val Loss: 70803.2708 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:45,431] Trial 870 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 870 | Epoch 01 | Train Loss: 279535.3179 | Val Loss: 15106.6372 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:45,695] Trial 871 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 871 | Epoch 01 | Train Loss: 20867.8589 | Val Loss: 18000.4704 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:46,090] Trial 872 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 872 | Epoch 01 | Train Loss: 21351.3594 | Val Loss: 16484.4659 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:46,321] Trial 873 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 873 | Epoch 01 | Train Loss: 20210.3999 | Val Loss: 18786.7324 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:46,590] Trial 874 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 874 | Epoch 01 | Train Loss: 20008.3784 | Val Loss: 16853.6895 | Optimizer: Adam\n",
      "Trial 875 | Epoch 01 | Train Loss: 17175.9530 | Val Loss: 13155.8445 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:46,819] Trial 875 pruned. \n",
      "[I 2025-09-05 19:04:47,036] Trial 876 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 876 | Epoch 01 | Train Loss: 22578.5726 | Val Loss: 11948.3560 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:47,294] Trial 877 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 877 | Epoch 01 | Train Loss: 18353.9747 | Val Loss: 12547.9836 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:47,604] Trial 878 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 878 | Epoch 01 | Train Loss: 20383.7178 | Val Loss: 17863.8149 | Optimizer: AdamW\n",
      "Trial 879 | Epoch 01 | Train Loss: 14923.0260 | Val Loss: 10483.9618 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 02 | Train Loss: 10788.3151 | Val Loss: 5885.2212 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 03 | Train Loss: 8288.7960 | Val Loss: 12209.6626 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 04 | Train Loss: 9931.0933 | Val Loss: 10283.4126 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 05 | Train Loss: 9178.1347 | Val Loss: 6956.4304 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 06 | Train Loss: 7792.0904 | Val Loss: 7930.3247 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 07 | Train Loss: 8191.1948 | Val Loss: 7452.5722 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 08 | Train Loss: 7155.4817 | Val Loss: 9265.4528 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 09 | Train Loss: 8061.3627 | Val Loss: 13438.2254 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 10 | Train Loss: 11182.7749 | Val Loss: 7328.9789 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:48,976] Trial 879 finished with value: 5885.221242645641 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.22501934635058246, 'lr': 0.00047533136982912534, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 1.0961905546072748e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 879 | Epoch 11 | Train Loss: 6773.4996 | Val Loss: 7557.1571 | Optimizer: RMSprop\n",
      "Trial 879 | Epoch 12 | Train Loss: 7118.8849 | Val Loss: 10043.7386 | Optimizer: RMSprop\n",
      "Trial 879 - Early stopping triggered at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:49,231] Trial 880 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 880 | Epoch 01 | Train Loss: 18129.3009 | Val Loss: 11540.1184 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:49,558] Trial 881 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 881 | Epoch 01 | Train Loss: 16842.4523 | Val Loss: 10828.9738 | Optimizer: Adam\n",
      "Trial 881 | Epoch 02 | Train Loss: 11896.6653 | Val Loss: 10338.2617 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:49,866] Trial 882 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 882 | Epoch 01 | Train Loss: 75844.9275 | Val Loss: 15240.5332 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:50,107] Trial 883 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 883 | Epoch 01 | Train Loss: 20198.3905 | Val Loss: 17197.8143 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:50,357] Trial 884 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 884 | Epoch 01 | Train Loss: 20612.6571 | Val Loss: 18164.6377 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:50,665] Trial 885 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 885 | Epoch 01 | Train Loss: 19451.5752 | Val Loss: 15433.5793 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:50,891] Trial 886 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 886 | Epoch 01 | Train Loss: 17035.9661 | Val Loss: 13771.8237 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:51,148] Trial 887 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 887 | Epoch 01 | Train Loss: 18879.6112 | Val Loss: 13526.0849 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:51,455] Trial 888 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 888 | Epoch 01 | Train Loss: 16513.6010 | Val Loss: 12312.5239 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:51,699] Trial 889 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 889 | Epoch 01 | Train Loss: 19238.6908 | Val Loss: 13667.4151 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:51,941] Trial 890 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 890 | Epoch 01 | Train Loss: 19535.7468 | Val Loss: 14941.9942 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:52,183] Trial 891 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 891 | Epoch 01 | Train Loss: 15384.8145 | Val Loss: 35226.0159 | Optimizer: RMSprop\n",
      "Trial 892 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:52,368] Trial 892 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 893 | Epoch 01 | Train Loss: 15161.9076 | Val Loss: 9784.5274 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 02 | Train Loss: 11503.1779 | Val Loss: 47972.8537 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 03 | Train Loss: 18706.0969 | Val Loss: 8136.2439 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 04 | Train Loss: 8866.8084 | Val Loss: 6540.9231 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 05 | Train Loss: 7693.3959 | Val Loss: 6351.3532 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 06 | Train Loss: 7507.5020 | Val Loss: 5945.1679 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 07 | Train Loss: 7482.2828 | Val Loss: 5853.2262 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 08 | Train Loss: 7356.0603 | Val Loss: 6505.5417 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 09 | Train Loss: 7285.3920 | Val Loss: 7215.3259 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 10 | Train Loss: 7439.8037 | Val Loss: 16763.5802 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 11 | Train Loss: 9198.9365 | Val Loss: 5631.8204 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 12 | Train Loss: 7079.1043 | Val Loss: 5819.7407 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 13 | Train Loss: 6552.8079 | Val Loss: 5781.3437 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 14 | Train Loss: 6933.1081 | Val Loss: 6076.1959 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 15 | Train Loss: 6803.9848 | Val Loss: 6147.9924 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 16 | Train Loss: 7050.8761 | Val Loss: 5373.9103 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 17 | Train Loss: 6807.0409 | Val Loss: 5730.4512 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 18 | Train Loss: 6629.3738 | Val Loss: 7428.6105 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 19 | Train Loss: 7082.6472 | Val Loss: 5885.0641 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 20 | Train Loss: 6799.1265 | Val Loss: 7958.2514 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 21 | Train Loss: 7465.5381 | Val Loss: 5365.7961 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 22 | Train Loss: 6308.7495 | Val Loss: 5884.6890 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 23 | Train Loss: 6354.5022 | Val Loss: 6146.1778 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 24 | Train Loss: 6375.8212 | Val Loss: 6554.8431 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 25 | Train Loss: 6731.1337 | Val Loss: 5115.7498 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 26 | Train Loss: 6194.0237 | Val Loss: 10871.2082 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 27 | Train Loss: 6540.9255 | Val Loss: 5232.3771 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 28 | Train Loss: 5843.8054 | Val Loss: 5369.2109 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 29 | Train Loss: 6190.3804 | Val Loss: 5753.3909 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 30 | Train Loss: 6290.7418 | Val Loss: 8248.8629 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 31 | Train Loss: 6543.4077 | Val Loss: 8479.0364 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 32 | Train Loss: 7190.1496 | Val Loss: 5713.1330 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 33 | Train Loss: 6173.2384 | Val Loss: 10916.9663 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 34 | Train Loss: 6783.4577 | Val Loss: 5187.3637 | Optimizer: RMSprop\n",
      "Trial 893 | Epoch 35 | Train Loss: 5888.6076 | Val Loss: 5416.5416 | Optimizer: RMSprop\n",
      "Trial 893 - Early stopping triggered at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:55,999] Trial 893 finished with value: 5115.749789014275 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.30747638832015994, 'lr': 0.0003602123566462975, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 1.24468158429244e-06}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:04:56,403] Trial 894 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 894 | Epoch 01 | Train Loss: 17001.5641 | Val Loss: 10505.4649 | Optimizer: RMSprop\n",
      "Trial 894 | Epoch 02 | Train Loss: 11187.8095 | Val Loss: 15102.7993 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:56,618] Trial 895 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 895 | Epoch 01 | Train Loss: 19434.8780 | Val Loss: 15798.0801 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:56,863] Trial 896 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 896 | Epoch 01 | Train Loss: 19692.4188 | Val Loss: 16521.4245 | Optimizer: AdamW\n",
      "Trial 897 | Epoch 01 | Train Loss: 43022.4755 | Val Loss: 12355.9737 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:57,081] Trial 897 pruned. \n",
      "[I 2025-09-05 19:04:57,310] Trial 898 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 898 | Epoch 01 | Train Loss: 19790.9376 | Val Loss: 15589.7210 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:57,637] Trial 899 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 899 | Epoch 01 | Train Loss: 242160.9272 | Val Loss: 21874.5008 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:57,951] Trial 900 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 900 | Epoch 01 | Train Loss: 16343.2492 | Val Loss: 11823.7084 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:58,393] Trial 901 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 901 | Epoch 01 | Train Loss: 19163.4052 | Val Loss: 13681.6651 | Optimizer: Adam\n",
      "Trial 902 | Epoch 01 | Train Loss: 18022.4446 | Val Loss: 12556.0854 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:58,596] Trial 902 pruned. \n",
      "[I 2025-09-05 19:04:58,801] Trial 903 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 903 | Epoch 01 | Train Loss: 18915.0846 | Val Loss: 13442.9971 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:59,039] Trial 904 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 904 | Epoch 01 | Train Loss: 18879.4078 | Val Loss: 11820.8701 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:59,269] Trial 905 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 905 | Epoch 01 | Train Loss: 16287.1591 | Val Loss: 13246.8075 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:59,603] Trial 906 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 906 | Epoch 01 | Train Loss: 17806.7447 | Val Loss: 10824.3802 | Optimizer: RMSprop\n",
      "Trial 906 | Epoch 02 | Train Loss: 10691.9112 | Val Loss: 10239.8347 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:04:59,943] Trial 907 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 907 | Epoch 01 | Train Loss: 18912.4836 | Val Loss: 12074.8422 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:00,170] Trial 908 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 908 | Epoch 01 | Train Loss: 19921.8068 | Val Loss: 18345.4809 | Optimizer: Adam\n",
      "Trial 909 | Epoch 01 | Train Loss: 15162.3350 | Val Loss: 13917.9409 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:00,367] Trial 909 pruned. \n",
      "[I 2025-09-05 19:05:00,627] Trial 910 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 910 | Epoch 01 | Train Loss: 20786.7729 | Val Loss: 17597.5725 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:00,892] Trial 911 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 911 | Epoch 01 | Train Loss: 16173.2586 | Val Loss: 11737.6277 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:01,307] Trial 912 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 912 | Epoch 01 | Train Loss: 20967.0401 | Val Loss: 18646.0479 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:01,579] Trial 913 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 913 | Epoch 01 | Train Loss: 16177.9450 | Val Loss: 19602.4571 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:01,870] Trial 914 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 914 | Epoch 01 | Train Loss: 19189.0480 | Val Loss: 13020.3509 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:02,127] Trial 915 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 915 | Epoch 01 | Train Loss: 17560.6406 | Val Loss: 13713.0191 | Optimizer: RMSprop\n",
      "Trial 916 | Epoch 01 | Train Loss: 19784.7450 | Val Loss: 15152.8059 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:02,330] Trial 916 pruned. \n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\optuna\\pruners\\_percentile.py:21: RuntimeWarning:\n",
      "\n",
      "All-NaN slice encountered\n",
      "\n",
      "[I 2025-09-05 19:05:02,583] Trial 917 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 917 | Epoch 01 | Train Loss: 1884893555230.9006 | Val Loss: nan | Optimizer: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:02,822] Trial 918 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 918 | Epoch 01 | Train Loss: 17577.2798 | Val Loss: 12988.7986 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:03,062] Trial 919 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 919 | Epoch 01 | Train Loss: 20146.1506 | Val Loss: 16999.5047 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:03,318] Trial 920 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 920 | Epoch 01 | Train Loss: 18102.3982 | Val Loss: 18148.9614 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:03,605] Trial 921 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 921 | Epoch 01 | Train Loss: 18263.7203 | Val Loss: 13514.5702 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:03,869] Trial 922 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 922 | Epoch 01 | Train Loss: 16598.6859 | Val Loss: 13953.6659 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:04,118] Trial 923 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 923 | Epoch 01 | Train Loss: 19533.7393 | Val Loss: 17066.4248 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:04,525] Trial 924 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 924 | Epoch 01 | Train Loss: 16033.9789 | Val Loss: 10564.5406 | Optimizer: RMSprop\n",
      "Trial 924 | Epoch 02 | Train Loss: 10687.4932 | Val Loss: 10836.1382 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:04,978] Trial 925 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 925 | Epoch 01 | Train Loss: 18488.2607 | Val Loss: 10498.7520 | Optimizer: AdamW\n",
      "Trial 925 | Epoch 02 | Train Loss: 12163.6193 | Val Loss: 10513.4165 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:05,378] Trial 926 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 926 | Epoch 01 | Train Loss: 125162.8852 | Val Loss: 11964.2583 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:05,621] Trial 927 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 927 | Epoch 01 | Train Loss: 21994.5297 | Val Loss: 22207.7836 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:05,864] Trial 928 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 928 | Epoch 01 | Train Loss: 22189.2950 | Val Loss: 11054.4280 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:06,122] Trial 929 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 929 | Epoch 01 | Train Loss: 18775.4812 | Val Loss: 13408.3730 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:06,363] Trial 930 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 930 | Epoch 01 | Train Loss: 78542.4798 | Val Loss: 26484.8404 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:06,603] Trial 931 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 931 | Epoch 01 | Train Loss: 21268.5298 | Val Loss: 20233.3109 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:06,954] Trial 932 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 932 | Epoch 01 | Train Loss: 21366.2695 | Val Loss: 13520.1513 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:07,197] Trial 933 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 933 | Epoch 01 | Train Loss: 19212.3774 | Val Loss: 16148.1427 | Optimizer: Adam\n",
      "Trial 934 | Epoch 01 | Train Loss: 15545.1297 | Val Loss: 9954.3704 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 02 | Train Loss: 10763.6812 | Val Loss: 8280.9560 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 03 | Train Loss: 9280.7663 | Val Loss: 6494.7896 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 04 | Train Loss: 7765.6863 | Val Loss: 7304.9552 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 05 | Train Loss: 7513.2184 | Val Loss: 6580.1978 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 06 | Train Loss: 7827.2440 | Val Loss: 6122.3203 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 07 | Train Loss: 6943.7589 | Val Loss: 5559.8285 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 08 | Train Loss: 6795.8177 | Val Loss: 40811.9629 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 09 | Train Loss: 15855.4185 | Val Loss: 6411.3268 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 10 | Train Loss: 7226.7186 | Val Loss: 6044.8057 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 11 | Train Loss: 6918.2909 | Val Loss: 8019.2582 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 12 | Train Loss: 7241.3545 | Val Loss: 9743.9280 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 13 | Train Loss: 8445.9669 | Val Loss: 5684.5721 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 14 | Train Loss: 6606.2295 | Val Loss: 5381.0495 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 15 | Train Loss: 6488.2259 | Val Loss: 5479.1299 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 16 | Train Loss: 6311.0275 | Val Loss: 6000.9834 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 17 | Train Loss: 6541.8198 | Val Loss: 5242.2454 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 18 | Train Loss: 6036.7702 | Val Loss: 5823.3396 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 19 | Train Loss: 6212.0798 | Val Loss: 6672.4712 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 20 | Train Loss: 6292.5614 | Val Loss: 5385.9408 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 21 | Train Loss: 6011.1644 | Val Loss: 5350.9471 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 22 | Train Loss: 5781.0178 | Val Loss: 5265.5313 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 23 | Train Loss: 6058.9145 | Val Loss: 9956.5653 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 24 | Train Loss: 7594.1673 | Val Loss: 6241.0963 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 25 | Train Loss: 6049.2727 | Val Loss: 6730.2497 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:10,114] Trial 934 finished with value: 5242.245439694251 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.2356472472027058, 'lr': 0.00035318855638677394, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 7.722394303366339e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 934 | Epoch 26 | Train Loss: 5943.7506 | Val Loss: 6036.6782 | Optimizer: RMSprop\n",
      "Trial 934 | Epoch 27 | Train Loss: 5817.3368 | Val Loss: 5870.9657 | Optimizer: RMSprop\n",
      "Trial 934 - Early stopping triggered at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:10,356] Trial 935 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 935 | Epoch 01 | Train Loss: 20574.6296 | Val Loss: 16417.7366 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:10,586] Trial 936 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 936 | Epoch 01 | Train Loss: 20305.2649 | Val Loss: 12645.2974 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:10,819] Trial 937 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 937 | Epoch 01 | Train Loss: 17390.3278 | Val Loss: 11936.0016 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:11,072] Trial 938 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 938 | Epoch 01 | Train Loss: 16678.1006 | Val Loss: 16382.9067 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:11,427] Trial 939 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 939 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:11,654] Trial 940 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 940 | Epoch 01 | Train Loss: 18787.5102 | Val Loss: 11954.9228 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:11,911] Trial 941 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 941 | Epoch 01 | Train Loss: 56501.4446 | Val Loss: 12146.1246 | Optimizer: RMSprop\n",
      "Trial 942 | Epoch 01 | Train Loss: 19192.2143 | Val Loss: 13810.5364 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:12,128] Trial 942 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 943 | Epoch 01 | Train Loss: 15188.8539 | Val Loss: 10466.3034 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 02 | Train Loss: 10671.4624 | Val Loss: 7135.3183 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 03 | Train Loss: 11239.4806 | Val Loss: 11092.4375 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 04 | Train Loss: 8882.0279 | Val Loss: 6413.5807 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 05 | Train Loss: 7507.4597 | Val Loss: 6126.1440 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 06 | Train Loss: 7248.2941 | Val Loss: 11141.7263 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 07 | Train Loss: 9461.2095 | Val Loss: 49323.2989 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 08 | Train Loss: 18324.0844 | Val Loss: 7153.7370 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 09 | Train Loss: 7215.6089 | Val Loss: 5683.1533 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 10 | Train Loss: 6656.9612 | Val Loss: 6130.5439 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 11 | Train Loss: 7053.5978 | Val Loss: 5839.6999 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 12 | Train Loss: 6850.9324 | Val Loss: 5600.4560 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 13 | Train Loss: 6555.9185 | Val Loss: 5611.1501 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 14 | Train Loss: 6528.3336 | Val Loss: 5324.1111 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 15 | Train Loss: 6431.5664 | Val Loss: 5713.6162 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 16 | Train Loss: 6619.3422 | Val Loss: 6578.5205 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 17 | Train Loss: 6474.0276 | Val Loss: 6056.9040 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 18 | Train Loss: 6689.9902 | Val Loss: 5972.5989 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 19 | Train Loss: 6669.2994 | Val Loss: 5959.3119 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 20 | Train Loss: 6192.2588 | Val Loss: 13131.9271 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 21 | Train Loss: 10728.2684 | Val Loss: 7191.0199 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 22 | Train Loss: 6754.2476 | Val Loss: 5611.2016 | Optimizer: RMSprop\n",
      "Trial 943 | Epoch 23 | Train Loss: 6342.3666 | Val Loss: 5533.4166 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:14,748] Trial 943 finished with value: 5324.111117139275 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3156806308784189, 'lr': 0.00036756550873636974, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 4.211468226295477e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 943 | Epoch 24 | Train Loss: 6163.3372 | Val Loss: 11186.2527 | Optimizer: RMSprop\n",
      "Trial 943 - Early stopping triggered at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:14,994] Trial 944 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 944 | Epoch 01 | Train Loss: 21355.0405 | Val Loss: 19216.7666 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:15,236] Trial 945 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 945 | Epoch 01 | Train Loss: 16666.7405 | Val Loss: 17391.7694 | Optimizer: RMSprop\n",
      "Trial 946 | Epoch 01 | Train Loss: 19298.8791 | Val Loss: 15138.4661 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:15,460] Trial 946 pruned. \n",
      "[I 2025-09-05 19:05:15,781] Trial 947 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 947 | Epoch 01 | Train Loss: 26369.8692 | Val Loss: 14756.3073 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:16,028] Trial 948 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 948 | Epoch 01 | Train Loss: 17942.1489 | Val Loss: 12192.5980 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:16,256] Trial 949 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 949 | Epoch 01 | Train Loss: 32147.3868 | Val Loss: 22811.8030 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:16,511] Trial 950 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 950 | Epoch 01 | Train Loss: 19597.3413 | Val Loss: 11152.5164 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:16,746] Trial 951 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 951 | Epoch 01 | Train Loss: 18075.3114 | Val Loss: 12089.8394 | Optimizer: RMSprop\n",
      "Trial 952 | Epoch 01 | Train Loss: 17526.2534 | Val Loss: 10088.4279 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 02 | Train Loss: 10674.5652 | Val Loss: 7522.5190 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 03 | Train Loss: 9242.1665 | Val Loss: 7278.2816 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 04 | Train Loss: 7912.6569 | Val Loss: 7756.1624 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 05 | Train Loss: 8257.5509 | Val Loss: 6449.2799 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 06 | Train Loss: 7378.9244 | Val Loss: 5460.8926 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 07 | Train Loss: 6723.0463 | Val Loss: 5842.9420 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 08 | Train Loss: 6482.1959 | Val Loss: 5433.7421 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 09 | Train Loss: 6289.4619 | Val Loss: 5524.5575 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 10 | Train Loss: 5836.2522 | Val Loss: 5441.7455 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 11 | Train Loss: 5851.1249 | Val Loss: 6993.2558 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 12 | Train Loss: 6897.2586 | Val Loss: 5337.8242 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 13 | Train Loss: 8635.8282 | Val Loss: 9669.7075 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 14 | Train Loss: 8096.5453 | Val Loss: 5350.3707 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 15 | Train Loss: 6221.4582 | Val Loss: 6896.7894 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 16 | Train Loss: 7442.9212 | Val Loss: 6316.2089 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 17 | Train Loss: 5483.7832 | Val Loss: 7067.4423 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 18 | Train Loss: 7133.2709 | Val Loss: 5762.7000 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 19 | Train Loss: 6191.8392 | Val Loss: 5832.1823 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 20 | Train Loss: 5656.3979 | Val Loss: 5218.6084 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 21 | Train Loss: 5536.3325 | Val Loss: 5331.4589 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 22 | Train Loss: 5007.0734 | Val Loss: 5257.5727 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 23 | Train Loss: 5170.4212 | Val Loss: 5255.4781 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 24 | Train Loss: 4982.4701 | Val Loss: 5691.6050 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 25 | Train Loss: 5875.6492 | Val Loss: 7321.8170 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 26 | Train Loss: 8348.1317 | Val Loss: 6923.9379 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 27 | Train Loss: 6126.2867 | Val Loss: 6730.8145 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 28 | Train Loss: 5795.9171 | Val Loss: 5393.4941 | Optimizer: AdamW\n",
      "Trial 952 | Epoch 29 | Train Loss: 5512.6990 | Val Loss: 6707.3988 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:20,618] Trial 952 finished with value: 5218.608419536073 and parameters: {'gnn_dim': 1024, 'hidden_dim': 512, 'dropout_rate': 0.33047213169404904, 'lr': 0.0009932402556021248, 'activation': 'GELU', 'optimizer': 'AdamW', 'weight_decay': 8.211888300046772e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 952 | Epoch 30 | Train Loss: 5969.8293 | Val Loss: 7013.4251 | Optimizer: AdamW\n",
      "Trial 952 - Early stopping triggered at epoch 30\n",
      "Trial 953 | Epoch 01 | Train Loss: 19723.4096 | Val Loss: 16648.6976 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:20,826] Trial 953 pruned. \n",
      "[I 2025-09-05 19:05:21,041] Trial 954 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 954 | Epoch 01 | Train Loss: 20431.0191 | Val Loss: 16967.2809 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:21,273] Trial 955 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 955 | Epoch 01 | Train Loss: 33355.8167 | Val Loss: 14334.6514 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:21,491] Trial 956 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 956 | Epoch 01 | Train Loss: 18832.6390 | Val Loss: 14368.6636 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:21,713] Trial 957 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 957 | Epoch 01 | Train Loss: 14028.7798 | Val Loss: 47415.2327 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:22,034] Trial 958 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 958 | Epoch 01 | Train Loss: 21693.3447 | Val Loss: 21693.7844 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:22,272] Trial 959 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 959 | Epoch 01 | Train Loss: 22298.6408 | Val Loss: 22470.7391 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:22,510] Trial 960 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 960 | Epoch 01 | Train Loss: 16915.1124 | Val Loss: 12172.3514 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:22,762] Trial 961 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 961 | Epoch 01 | Train Loss: 17961.9041 | Val Loss: 11036.8866 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:23,085] Trial 962 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 962 | Epoch 01 | Train Loss: 16822.9853 | Val Loss: 10866.1535 | Optimizer: Adam\n",
      "Trial 962 | Epoch 02 | Train Loss: 12021.2678 | Val Loss: 11639.5270 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:23,385] Trial 963 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 963 | Epoch 01 | Train Loss: 18924.8074 | Val Loss: 11398.9140 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:23,627] Trial 964 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 964 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:23,874] Trial 965 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 965 | Epoch 01 | Train Loss: 21222.5802 | Val Loss: 19987.9533 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:24,128] Trial 966 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 966 | Epoch 01 | Train Loss: 20690.3683 | Val Loss: 17009.7174 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:24,482] Trial 967 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 967 | Epoch 01 | Train Loss: 17934.5471 | Val Loss: 15821.7145 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:24,711] Trial 968 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 968 | Epoch 01 | Train Loss: 40895.6647 | Val Loss: 15665.8964 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:25,056] Trial 969 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 969 | Epoch 01 | Train Loss: 18420.8264 | Val Loss: 11225.9793 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:25,306] Trial 970 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 970 | Epoch 01 | Train Loss: 21629.3217 | Val Loss: 21064.5607 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:25,544] Trial 971 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 971 | Epoch 01 | Train Loss: 14630.6102 | Val Loss: 12809.2896 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:25,776] Trial 972 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 972 | Epoch 01 | Train Loss: 30443.5042 | Val Loss: 13986.8185 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:26,054] Trial 973 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 973 | Epoch 01 | Train Loss: 20316.9248 | Val Loss: 17744.9274 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:26,320] Trial 974 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 974 | Epoch 01 | Train Loss: 197822.3421 | Val Loss: 22127.7296 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:26,611] Trial 975 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 975 | Epoch 01 | Train Loss: 18521.3465 | Val Loss: 14453.5742 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:26,870] Trial 976 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 976 | Epoch 01 | Train Loss: 18286.1126 | Val Loss: 11815.9124 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:27,107] Trial 977 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 977 | Epoch 01 | Train Loss: 15771.0175 | Val Loss: 11545.4889 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:27,462] Trial 978 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 978 | Epoch 01 | Train Loss: 16087.0436 | Val Loss: 10646.1526 | Optimizer: RMSprop\n",
      "Trial 978 | Epoch 02 | Train Loss: 11138.1322 | Val Loss: 10214.0024 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:27,850] Trial 979 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 979 | Epoch 01 | Train Loss: 20461.8413 | Val Loss: 16714.1649 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:28,131] Trial 980 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 980 | Epoch 01 | Train Loss: 22744.6691 | Val Loss: 21775.0590 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:28,427] Trial 981 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 981 | Epoch 01 | Train Loss: 18075.4514 | Val Loss: 12859.6300 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:28,661] Trial 982 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 982 | Epoch 01 | Train Loss: 17881.1176 | Val Loss: 12204.0859 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:28,928] Trial 983 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 983 | Epoch 01 | Train Loss: 20240.7816 | Val Loss: 11796.5414 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:29,151] Trial 984 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 984 | Epoch 01 | Train Loss: 17964.7506 | Val Loss: 12314.9186 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:29,375] Trial 985 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 985 | Epoch 01 | Train Loss: 19832.0024 | Val Loss: 17677.1610 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:29,626] Trial 986 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 986 | Epoch 01 | Train Loss: 20993.1460 | Val Loss: 19223.1909 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:29,940] Trial 987 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 987 | Epoch 01 | Train Loss: 17073.2050 | Val Loss: 11268.5087 | Optimizer: AdamW\n",
      "Trial 988 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:30,113] Trial 988 pruned. \n",
      "[I 2025-09-05 19:05:30,372] Trial 989 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 989 | Epoch 01 | Train Loss: 20737.8592 | Val Loss: 18963.8684 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:30,609] Trial 990 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 990 | Epoch 01 | Train Loss: 16768.4623 | Val Loss: 13277.7616 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:30,883] Trial 991 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 991 | Epoch 01 | Train Loss: 91868.8322 | Val Loss: 49063.9589 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:31,114] Trial 992 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 992 | Epoch 01 | Train Loss: 20076.1369 | Val Loss: 17486.4092 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:31,585] Trial 993 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 993 | Epoch 01 | Train Loss: 17622.8018 | Val Loss: 10998.6895 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:31,816] Trial 994 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 994 | Epoch 01 | Train Loss: 28288.5026 | Val Loss: 13450.8727 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:32,072] Trial 995 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 995 | Epoch 01 | Train Loss: 20158.9787 | Val Loss: 17620.9690 | Optimizer: Adam\n",
      "Trial 996 | Epoch 01 | Train Loss: 13576.5584 | Val Loss: 9164.9611 | Optimizer: RMSprop\n",
      "Trial 996 | Epoch 02 | Train Loss: 13214.6032 | Val Loss: 10877.1731 | Optimizer: RMSprop\n",
      "Trial 996 | Epoch 03 | Train Loss: 9193.2863 | Val Loss: 7697.1523 | Optimizer: RMSprop\n",
      "Trial 996 | Epoch 04 | Train Loss: 7749.9317 | Val Loss: 6405.5669 | Optimizer: RMSprop\n",
      "Trial 996 | Epoch 05 | Train Loss: 7383.2547 | Val Loss: 9882.1072 | Optimizer: RMSprop\n",
      "Trial 996 | Epoch 06 | Train Loss: 7924.9200 | Val Loss: 10045.9414 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:32,787] Trial 996 pruned. \n",
      "[I 2025-09-05 19:05:33,005] Trial 997 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 997 | Epoch 01 | Train Loss: 16237.2098 | Val Loss: 12541.1616 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:33,340] Trial 998 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 998 | Epoch 01 | Train Loss: 22041.6323 | Val Loss: 21545.2697 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:33,666] Trial 999 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 999 | Epoch 01 | Train Loss: 17589.7199 | Val Loss: 10770.1389 | Optimizer: AdamW\n",
      "Trial 999 | Epoch 02 | Train Loss: 12525.2012 | Val Loss: 10630.7679 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:33,915] Trial 1000 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1000 | Epoch 01 | Train Loss: 31298.9490 | Val Loss: 15699.3954 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:34,185] Trial 1001 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1001 | Epoch 01 | Train Loss: 19165.3410 | Val Loss: 13288.0102 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:34,418] Trial 1002 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1002 | Epoch 01 | Train Loss: 15068.9277 | Val Loss: 11061.2049 | Optimizer: RMSprop\n",
      "Trial 1003 | Epoch 01 | Train Loss: 15926.3787 | Val Loss: 10876.5372 | Optimizer: RMSprop\n",
      "Trial 1003 | Epoch 02 | Train Loss: 10697.6247 | Val Loss: 8969.8967 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:34,949] Trial 1003 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1003 | Epoch 03 | Train Loss: 9644.7380 | Val Loss: 12730.3746 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:35,207] Trial 1004 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1004 | Epoch 01 | Train Loss: 18148.9730 | Val Loss: 12873.1958 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:35,539] Trial 1005 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1005 | Epoch 01 | Train Loss: 19236.8035 | Val Loss: 13998.5351 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:36,062] Trial 1006 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1006 | Epoch 01 | Train Loss: 3903347961.2721 | Val Loss: 1233437.1975 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:36,311] Trial 1007 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1007 | Epoch 01 | Train Loss: 15537.3765 | Val Loss: 15436.8820 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:36,607] Trial 1008 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1008 | Epoch 01 | Train Loss: 20075.2747 | Val Loss: 17021.2109 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:36,846] Trial 1009 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1009 | Epoch 01 | Train Loss: 20891.7772 | Val Loss: 20194.7064 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:37,160] Trial 1010 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1010 | Epoch 01 | Train Loss: 16756.4209 | Val Loss: 10115.1466 | Optimizer: RMSprop\n",
      "Trial 1010 | Epoch 02 | Train Loss: 10879.7130 | Val Loss: 11349.3459 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:37,387] Trial 1011 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1011 | Epoch 01 | Train Loss: 16940.2550 | Val Loss: 11414.1233 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:37,594] Trial 1012 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1012 | Epoch 01 | Train Loss: 18086.6530 | Val Loss: 11198.0446 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:37,870] Trial 1013 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1013 | Epoch 01 | Train Loss: 25402.8554 | Val Loss: 11528.7734 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:38,156] Trial 1014 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1014 | Epoch 01 | Train Loss: 20781.9827 | Val Loss: 18531.7041 | Optimizer: Adam\n",
      "Trial 1015 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:38,328] Trial 1015 pruned. \n",
      "[I 2025-09-05 19:05:38,594] Trial 1016 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1016 | Epoch 01 | Train Loss: 19995.0941 | Val Loss: 15181.2021 | Optimizer: AdamW\n",
      "Trial 1017 | Epoch 01 | Train Loss: 14691.1023 | Val Loss: 12517.8491 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:38,810] Trial 1017 pruned. \n",
      "[I 2025-09-05 19:05:39,005] Trial 1018 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1018 | Epoch 01 | Train Loss: 18927.6037 | Val Loss: 13932.8638 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:39,323] Trial 1019 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1019 | Epoch 01 | Train Loss: 191266981.4439 | Val Loss: 19093.7717 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:39,626] Trial 1020 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1020 | Epoch 01 | Train Loss: 54574.7241 | Val Loss: 23832.8667 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:39,905] Trial 1021 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1021 | Epoch 01 | Train Loss: 22954.8859 | Val Loss: 23281.7551 | Optimizer: Adam\n",
      "Trial 1022 | Epoch 01 | Train Loss: 21651.9991 | Val Loss: 20194.4487 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:40,129] Trial 1022 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1023 | Epoch 01 | Train Loss: 14817.2620 | Val Loss: 10154.9506 | Optimizer: RMSprop\n",
      "Trial 1023 | Epoch 02 | Train Loss: 11652.4601 | Val Loss: 7881.7030 | Optimizer: RMSprop\n",
      "Trial 1023 | Epoch 03 | Train Loss: 8298.3522 | Val Loss: 11037.0112 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:40,654] Trial 1023 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1023 | Epoch 04 | Train Loss: 7910.7451 | Val Loss: 10664.6271 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:40,917] Trial 1024 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1024 | Epoch 01 | Train Loss: 18295.5480 | Val Loss: 11125.8241 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:41,164] Trial 1025 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1025 | Epoch 01 | Train Loss: 14863.3520 | Val Loss: 11443.2188 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:41,481] Trial 1026 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1026 | Epoch 01 | Train Loss: 15815.7878 | Val Loss: 14530.3041 | Optimizer: RMSprop\n",
      "Trial 1027 | Epoch 01 | Train Loss: 16656.4292 | Val Loss: 10426.5722 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 02 | Train Loss: 10925.8552 | Val Loss: 8948.6177 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 03 | Train Loss: 9074.8877 | Val Loss: 6499.3331 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 04 | Train Loss: 7317.7517 | Val Loss: 6014.8223 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 05 | Train Loss: 7087.3853 | Val Loss: 5624.0257 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 06 | Train Loss: 6796.4138 | Val Loss: 5949.6068 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 07 | Train Loss: 7273.6758 | Val Loss: 7814.0520 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 08 | Train Loss: 10547.3099 | Val Loss: 6717.5093 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 09 | Train Loss: 7310.5323 | Val Loss: 6844.8951 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 10 | Train Loss: 9651.2467 | Val Loss: 7716.6950 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 11 | Train Loss: 8406.8934 | Val Loss: 5417.7504 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 12 | Train Loss: 6636.0706 | Val Loss: 5546.3610 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 13 | Train Loss: 6467.2757 | Val Loss: 5586.8120 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 14 | Train Loss: 6081.2374 | Val Loss: 5725.2484 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 15 | Train Loss: 7515.8755 | Val Loss: 5974.7067 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 16 | Train Loss: 6493.2494 | Val Loss: 5685.8508 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 17 | Train Loss: 6368.4108 | Val Loss: 6832.3021 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 18 | Train Loss: 7169.4472 | Val Loss: 5351.5045 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 19 | Train Loss: 5594.5411 | Val Loss: 5490.3969 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 20 | Train Loss: 8242.0709 | Val Loss: 7117.8199 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 21 | Train Loss: 6607.0395 | Val Loss: 7459.1168 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 22 | Train Loss: 6516.7744 | Val Loss: 6595.4048 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 23 | Train Loss: 6241.5805 | Val Loss: 5328.1333 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 24 | Train Loss: 5787.3382 | Val Loss: 5371.1328 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 25 | Train Loss: 5767.0908 | Val Loss: 5501.0496 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 26 | Train Loss: 5698.3546 | Val Loss: 5849.0476 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 27 | Train Loss: 6975.5355 | Val Loss: 5228.0823 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 28 | Train Loss: 5827.5051 | Val Loss: 5398.3993 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 29 | Train Loss: 6256.8196 | Val Loss: 5573.8583 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 30 | Train Loss: 5757.9470 | Val Loss: 5470.4223 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 31 | Train Loss: 5396.9907 | Val Loss: 5393.3934 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 32 | Train Loss: 5228.0505 | Val Loss: 9677.2002 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 33 | Train Loss: 8881.9432 | Val Loss: 7732.7210 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 34 | Train Loss: 6883.3546 | Val Loss: 5265.0228 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 35 | Train Loss: 6480.4729 | Val Loss: 5754.6704 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 36 | Train Loss: 7409.7982 | Val Loss: 7228.5521 | Optimizer: AdamW\n",
      "Trial 1027 | Epoch 37 | Train Loss: 5993.5748 | Val Loss: 5891.5124 | Optimizer: AdamW\n",
      "Trial 1027 - Early stopping triggered at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:45,270] Trial 1027 finished with value: 5228.082293475116 and parameters: {'gnn_dim': 512, 'hidden_dim': 512, 'dropout_rate': 0.3435266874531593, 'lr': 0.000996906913932373, 'activation': 'Swish', 'optimizer': 'AdamW', 'weight_decay': 9.538159587544366e-06}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:05:45,505] Trial 1028 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1028 | Epoch 01 | Train Loss: 18536.1005 | Val Loss: 13010.6876 | Optimizer: Adam\n",
      "Trial 1029 | Epoch 01 | Train Loss: 15196.8314 | Val Loss: 10407.6386 | Optimizer: RMSprop\n",
      "Trial 1029 | Epoch 02 | Train Loss: 11246.9577 | Val Loss: 7326.8392 | Optimizer: RMSprop\n",
      "Trial 1029 | Epoch 03 | Train Loss: 12361.3625 | Val Loss: 7701.9130 | Optimizer: RMSprop\n",
      "Trial 1029 | Epoch 04 | Train Loss: 8667.7985 | Val Loss: 6421.0304 | Optimizer: RMSprop\n",
      "Trial 1029 | Epoch 05 | Train Loss: 8417.4170 | Val Loss: 7182.9714 | Optimizer: RMSprop\n",
      "Trial 1029 | Epoch 06 | Train Loss: 7808.6333 | Val Loss: 9234.9994 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:46,175] Trial 1029 pruned. \n",
      "[I 2025-09-05 19:05:46,430] Trial 1030 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1030 | Epoch 01 | Train Loss: 21288.4783 | Val Loss: 19264.1847 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:46,677] Trial 1031 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1031 | Epoch 01 | Train Loss: 16022.5604 | Val Loss: 20183.6902 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:47,038] Trial 1032 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1032 | Epoch 01 | Train Loss: 21291.9903 | Val Loss: 20390.2689 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:47,268] Trial 1033 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1033 | Epoch 01 | Train Loss: 15244.5914 | Val Loss: 13801.4392 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:47,513] Trial 1034 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1034 | Epoch 01 | Train Loss: 21242.6338 | Val Loss: 20119.1831 | Optimizer: Adam\n",
      "Trial 1035 | Epoch 01 | Train Loss: 14752.2552 | Val Loss: 15755.7592 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:47,710] Trial 1035 pruned. \n",
      "[I 2025-09-05 19:05:47,887] Trial 1036 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1036 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:48,133] Trial 1037 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1037 | Epoch 01 | Train Loss: 18626.7631 | Val Loss: 11706.1904 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:48,407] Trial 1038 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1038 | Epoch 01 | Train Loss: 17619.6402 | Val Loss: 12754.0964 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:48,691] Trial 1039 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1039 | Epoch 01 | Train Loss: 20526.8964 | Val Loss: 19652.5567 | Optimizer: AdamW\n",
      "Trial 1040 | Epoch 01 | Train Loss: 14511.9089 | Val Loss: 9324.7001 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:49,117] Trial 1040 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1040 | Epoch 02 | Train Loss: 12750.3873 | Val Loss: 9284.8943 | Optimizer: RMSprop\n",
      "Trial 1040 | Epoch 03 | Train Loss: 9439.9951 | Val Loss: 14284.3787 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:49,350] Trial 1041 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1041 | Epoch 01 | Train Loss: 19756.0721 | Val Loss: 15966.3034 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:49,607] Trial 1042 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1042 | Epoch 01 | Train Loss: 17638.9757 | Val Loss: 12163.2207 | Optimizer: RMSprop\n",
      "Trial 1043 | Epoch 01 | Train Loss: 17201.6923 | Val Loss: 11521.6420 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:49,798] Trial 1043 pruned. \n",
      "[I 2025-09-05 19:05:50,056] Trial 1044 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1044 | Epoch 01 | Train Loss: 87569.0776 | Val Loss: 14329.2651 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:50,386] Trial 1045 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1045 | Epoch 01 | Train Loss: 19303.7497 | Val Loss: 13207.6987 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:50,627] Trial 1046 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1046 | Epoch 01 | Train Loss: 20711.4395 | Val Loss: 11538.4516 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:50,955] Trial 1047 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1047 | Epoch 01 | Train Loss: 21538.3019 | Val Loss: 19773.7191 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:51,198] Trial 1048 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1048 | Epoch 01 | Train Loss: 21236.4534 | Val Loss: 21386.1107 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:51,465] Trial 1049 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1049 | Epoch 01 | Train Loss: 21117.0339 | Val Loss: 18759.9972 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:51,716] Trial 1050 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1050 | Epoch 01 | Train Loss: 21824.5149 | Val Loss: 21806.6601 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:52,040] Trial 1051 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1051 | Epoch 01 | Train Loss: 21827.4405 | Val Loss: 21026.1415 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:52,292] Trial 1052 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1052 | Epoch 01 | Train Loss: 749503.3985 | Val Loss: 16030.2186 | Optimizer: RMSprop\n",
      "Trial 1053 | Epoch 01 | Train Loss: 20550.7975 | Val Loss: 17689.6650 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:52,491] Trial 1053 pruned. \n",
      "[I 2025-09-05 19:05:52,718] Trial 1054 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1054 | Epoch 01 | Train Loss: 15532.6611 | Val Loss: 11024.5678 | Optimizer: RMSprop\n",
      "Trial 1055 | Epoch 01 | Train Loss: 18213.5233 | Val Loss: 10824.4495 | Optimizer: AdamW\n",
      "Trial 1055 | Epoch 02 | Train Loss: 11422.5471 | Val Loss: 9584.8450 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:53,239] Trial 1055 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1055 | Epoch 03 | Train Loss: 11022.6182 | Val Loss: 8669.7535 | Optimizer: AdamW\n",
      "Trial 1056 | Epoch 01 | Train Loss: 17539.6762 | Val Loss: 11254.7227 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:53,464] Trial 1056 pruned. \n",
      "[I 2025-09-05 19:05:53,771] Trial 1057 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1057 | Epoch 01 | Train Loss: 21217.5883 | Val Loss: 17898.3616 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:54,111] Trial 1058 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1058 | Epoch 01 | Train Loss: 14540.6826 | Val Loss: 10812.4522 | Optimizer: RMSprop\n",
      "Trial 1058 | Epoch 02 | Train Loss: 12005.5819 | Val Loss: 10101.4411 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:54,327] Trial 1059 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1059 | Epoch 01 | Train Loss: 20163.7411 | Val Loss: 17355.6331 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:54,584] Trial 1060 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1060 | Epoch 01 | Train Loss: 19196.7677 | Val Loss: 15700.2257 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:54,863] Trial 1061 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1061 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:55,148] Trial 1062 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1062 | Epoch 01 | Train Loss: 18756.0641 | Val Loss: 13943.5826 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:55,450] Trial 1063 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1063 | Epoch 01 | Train Loss: 15156.9134 | Val Loss: 11857.5887 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:55,682] Trial 1064 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1064 | Epoch 01 | Train Loss: 20522.4093 | Val Loss: 18589.7850 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:55,925] Trial 1065 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1065 | Epoch 01 | Train Loss: 17386.7684 | Val Loss: 12712.2164 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:56,153] Trial 1066 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1066 | Epoch 01 | Train Loss: 20816.9527 | Val Loss: 19008.7132 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:56,435] Trial 1067 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1067 | Epoch 01 | Train Loss: 1615983.4610 | Val Loss: 14861.0887 | Optimizer: RMSprop\n",
      "Trial 1068 | Epoch 01 | Train Loss: 18612.0831 | Val Loss: 13174.9829 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:05:56,656] Trial 1068 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1069 | Epoch 01 | Train Loss: 15201.3007 | Val Loss: 10463.3354 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 02 | Train Loss: 10668.9376 | Val Loss: 7179.9418 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 03 | Train Loss: 9830.3953 | Val Loss: 11378.9769 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 04 | Train Loss: 8828.5375 | Val Loss: 8250.5913 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 05 | Train Loss: 8858.2414 | Val Loss: 5693.5631 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 06 | Train Loss: 7080.3155 | Val Loss: 7765.1986 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 07 | Train Loss: 7655.9088 | Val Loss: 5442.8439 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 08 | Train Loss: 7249.8504 | Val Loss: 7248.7792 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 09 | Train Loss: 6954.9160 | Val Loss: 13389.1665 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 10 | Train Loss: 9072.9673 | Val Loss: 5795.0903 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 11 | Train Loss: 6449.7213 | Val Loss: 6385.7031 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 12 | Train Loss: 6117.2938 | Val Loss: 6635.0656 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 13 | Train Loss: 7034.2276 | Val Loss: 21578.6781 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 14 | Train Loss: 9281.5817 | Val Loss: 8667.4783 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 15 | Train Loss: 7594.1064 | Val Loss: 5909.0788 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 16 | Train Loss: 6378.8555 | Val Loss: 5428.3284 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 17 | Train Loss: 6090.4416 | Val Loss: 5740.2749 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 18 | Train Loss: 6244.5057 | Val Loss: 7365.0674 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 19 | Train Loss: 6413.4050 | Val Loss: 5291.2742 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 20 | Train Loss: 5976.0192 | Val Loss: 5271.6019 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 21 | Train Loss: 6174.6461 | Val Loss: 6594.6688 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 22 | Train Loss: 6086.6486 | Val Loss: 18815.3397 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 23 | Train Loss: 9160.9411 | Val Loss: 6919.4236 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 24 | Train Loss: 6565.8976 | Val Loss: 5286.7652 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 25 | Train Loss: 6211.5077 | Val Loss: 9108.7596 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 26 | Train Loss: 6244.6516 | Val Loss: 6482.0020 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 27 | Train Loss: 6238.2572 | Val Loss: 21385.8002 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 28 | Train Loss: 11092.5169 | Val Loss: 5129.7497 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 29 | Train Loss: 5751.6472 | Val Loss: 5248.7223 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 30 | Train Loss: 5927.6749 | Val Loss: 5226.2370 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 31 | Train Loss: 5898.7744 | Val Loss: 6384.9431 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 32 | Train Loss: 6193.3132 | Val Loss: 5158.8479 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 33 | Train Loss: 5906.5038 | Val Loss: 5327.7977 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 34 | Train Loss: 6094.6510 | Val Loss: 5139.1636 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 35 | Train Loss: 5794.0786 | Val Loss: 5355.8611 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 36 | Train Loss: 5932.7554 | Val Loss: 5288.5243 | Optimizer: RMSprop\n",
      "Trial 1069 | Epoch 37 | Train Loss: 5838.9118 | Val Loss: 5215.2723 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:00,823] Trial 1069 finished with value: 5129.749701605902 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.3101512038984424, 'lr': 0.0002973523335303899, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 1.3324497345310381e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1069 | Epoch 38 | Train Loss: 5788.0793 | Val Loss: 5148.0851 | Optimizer: RMSprop\n",
      "Trial 1069 - Early stopping triggered at epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:01,051] Trial 1070 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1070 | Epoch 01 | Train Loss: 15755.8040 | Val Loss: 12923.7633 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:01,289] Trial 1071 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1071 | Epoch 01 | Train Loss: 15991.3508 | Val Loss: 11074.9381 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:01,538] Trial 1072 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1072 | Epoch 01 | Train Loss: 14109.1309 | Val Loss: 12075.4400 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:01,796] Trial 1073 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1073 | Epoch 01 | Train Loss: 19791.7876 | Val Loss: 17525.3515 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:02,196] Trial 1074 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1074 | Epoch 01 | Train Loss: 14853.8470 | Val Loss: 10226.7130 | Optimizer: RMSprop\n",
      "Trial 1074 | Epoch 02 | Train Loss: 10229.1329 | Val Loss: 14328.7365 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:02,605] Trial 1075 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1075 | Epoch 01 | Train Loss: 15213.1334 | Val Loss: 10120.4495 | Optimizer: RMSprop\n",
      "Trial 1075 | Epoch 02 | Train Loss: 12124.9862 | Val Loss: 10351.9332 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:02,844] Trial 1076 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1076 | Epoch 01 | Train Loss: 14770.3963 | Val Loss: 11314.1499 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:03,091] Trial 1077 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1077 | Epoch 01 | Train Loss: 486709.4915 | Val Loss: 22069.4442 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:03,334] Trial 1078 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1078 | Epoch 01 | Train Loss: 13360.3183 | Val Loss: 43320.9277 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:03,613] Trial 1079 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1079 | Epoch 01 | Train Loss: 16640.5961 | Val Loss: 11898.1306 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:03,885] Trial 1080 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1080 | Epoch 01 | Train Loss: 165431.8766 | Val Loss: 15003.5074 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:04,214] Trial 1081 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1081 | Epoch 01 | Train Loss: 15314.9874 | Val Loss: 10689.4504 | Optimizer: RMSprop\n",
      "Trial 1081 | Epoch 02 | Train Loss: 11164.3776 | Val Loss: 11705.2327 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:04,459] Trial 1082 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1082 | Epoch 01 | Train Loss: 12765.6328 | Val Loss: 10988.5677 | Optimizer: RMSprop\n",
      "Trial 1083 | Epoch 01 | Train Loss: 106937.1647 | Val Loss: 17762.5491 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:04,681] Trial 1083 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1084 | Epoch 01 | Train Loss: 14431.2411 | Val Loss: 10707.6158 | Optimizer: RMSprop\n",
      "Trial 1084 | Epoch 02 | Train Loss: 11792.9321 | Val Loss: 8912.5799 | Optimizer: RMSprop\n",
      "Trial 1084 | Epoch 03 | Train Loss: 11478.2076 | Val Loss: 7132.4724 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:05,333] Trial 1084 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1084 | Epoch 04 | Train Loss: 7820.8186 | Val Loss: 150785.1100 | Optimizer: RMSprop\n",
      "Trial 1084 | Epoch 05 | Train Loss: 40478.4307 | Val Loss: 7601.3397 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:05,652] Trial 1085 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1085 | Epoch 01 | Train Loss: 14837.6089 | Val Loss: 12574.9736 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:05,871] Trial 1086 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1086 | Epoch 01 | Train Loss: 15068.7874 | Val Loss: 174953.1987 | Optimizer: RMSprop\n",
      "Trial 1087 | Epoch 01 | Train Loss: 19089.9567 | Val Loss: 9068.6793 | Optimizer: RMSprop\n",
      "Trial 1087 | Epoch 02 | Train Loss: 14214.8570 | Val Loss: 9475.1222 | Optimizer: RMSprop\n",
      "Trial 1087 | Epoch 03 | Train Loss: 11710.1988 | Val Loss: 8782.9482 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:06,274] Trial 1087 pruned. \n",
      "[I 2025-09-05 19:06:06,525] Trial 1088 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1088 | Epoch 01 | Train Loss: 18488.0631 | Val Loss: 12894.6520 | Optimizer: Adam\n",
      "Trial 1089 | Epoch 01 | Train Loss: 17927.2294 | Val Loss: 9989.5473 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:06,835] Trial 1089 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1089 | Epoch 02 | Train Loss: 11058.6286 | Val Loss: 14557.1481 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:07,082] Trial 1090 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1090 | Epoch 01 | Train Loss: 18768.3317 | Val Loss: 11312.9282 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:07,379] Trial 1091 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1091 | Epoch 01 | Train Loss: 17691.5274 | Val Loss: 11651.0637 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:07,634] Trial 1092 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1092 | Epoch 01 | Train Loss: 23339.0660 | Val Loss: 14581.2780 | Optimizer: RMSprop\n",
      "Trial 1093 | Epoch 01 | Train Loss: 100394.8185 | Val Loss: 13308.4752 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:07,851] Trial 1093 pruned. \n",
      "[I 2025-09-05 19:06:08,093] Trial 1094 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1094 | Epoch 01 | Train Loss: 21260.7581 | Val Loss: 21214.1705 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:08,454] Trial 1095 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1095 | Epoch 01 | Train Loss: 15425.2124 | Val Loss: 10656.7037 | Optimizer: RMSprop\n",
      "Trial 1095 | Epoch 02 | Train Loss: 10798.2393 | Val Loss: 10669.4580 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:08,738] Trial 1096 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1096 | Epoch 01 | Train Loss: 17888.4392 | Val Loss: 12198.5009 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:09,115] Trial 1097 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1097 | Epoch 01 | Train Loss: 14211.6142 | Val Loss: 12499.5131 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:09,416] Trial 1098 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1098 | Epoch 01 | Train Loss: 28056.9967 | Val Loss: 16106.8441 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:09,819] Trial 1099 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1099 | Epoch 01 | Train Loss: 20593.0554 | Val Loss: 18657.9021 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:10,067] Trial 1100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1100 | Epoch 01 | Train Loss: 14791.0075 | Val Loss: 12694.2485 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:10,314] Trial 1101 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1101 | Epoch 01 | Train Loss: 29467.7286 | Val Loss: 13424.6959 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:10,593] Trial 1102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1102 | Epoch 01 | Train Loss: 18845.7403 | Val Loss: 11807.6006 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:10,876] Trial 1103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1103 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:11,126] Trial 1104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1104 | Epoch 01 | Train Loss: 18156.7128 | Val Loss: 17739.6121 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:11,374] Trial 1105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1105 | Epoch 01 | Train Loss: 21098.8357 | Val Loss: 18455.2402 | Optimizer: Adam\n",
      "Trial 1106 | Epoch 01 | Train Loss: 132369.2436 | Val Loss: 9515.4912 | Optimizer: RMSprop\n",
      "Trial 1106 | Epoch 02 | Train Loss: 14626.0817 | Val Loss: 13332.1262 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:11,864] Trial 1106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1106 | Epoch 03 | Train Loss: 11908.7108 | Val Loss: 9684.4103 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:12,119] Trial 1107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1107 | Epoch 01 | Train Loss: 16258.8257 | Val Loss: 17503.7112 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:12,437] Trial 1108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1108 | Epoch 01 | Train Loss: 18149.0682 | Val Loss: 12167.7335 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:12,672] Trial 1109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1109 | Epoch 01 | Train Loss: 16811.8567 | Val Loss: 11595.0982 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:12,911] Trial 1110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1110 | Epoch 01 | Train Loss: 20433.2760 | Val Loss: 17874.5309 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:13,239] Trial 1111 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1111 | Epoch 01 | Train Loss: 16203.3095 | Val Loss: 10849.1089 | Optimizer: RMSprop\n",
      "Trial 1111 | Epoch 02 | Train Loss: 12400.4860 | Val Loss: 13765.6757 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:13,470] Trial 1112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1112 | Epoch 01 | Train Loss: 18406.7667 | Val Loss: 14845.0334 | Optimizer: RMSprop\n",
      "Trial 1113 | Epoch 01 | Train Loss: 18074.5148 | Val Loss: 10464.5722 | Optimizer: Adam\n",
      "Trial 1113 | Epoch 02 | Train Loss: 11408.9392 | Val Loss: 10185.1329 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:13,912] Trial 1113 pruned. \n",
      "[I 2025-09-05 19:06:14,164] Trial 1114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1114 | Epoch 01 | Train Loss: 19726.9124 | Val Loss: 16292.9089 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:14,423] Trial 1115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1115 | Epoch 01 | Train Loss: 17396.3106 | Val Loss: 15739.5564 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:14,696] Trial 1116 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1116 | Epoch 01 | Train Loss: 21947.2040 | Val Loss: 22090.5856 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:14,938] Trial 1117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1117 | Epoch 01 | Train Loss: 15419.3224 | Val Loss: 84701.9772 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:15,186] Trial 1118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1118 | Epoch 01 | Train Loss: 21270.9809 | Val Loss: 19151.1967 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:15,447] Trial 1119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1119 | Epoch 01 | Train Loss: 14916.1915 | Val Loss: 12794.0162 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:15,789] Trial 1120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1120 | Epoch 01 | Train Loss: 4067273.4212 | Val Loss: 24025.9910 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:16,033] Trial 1121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1121 | Epoch 01 | Train Loss: 19815.4993 | Val Loss: 15608.9070 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:16,243] Trial 1122 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1122 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:16,526] Trial 1123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1123 | Epoch 01 | Train Loss: 187392.1625 | Val Loss: 14368.6054 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:16,757] Trial 1124 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1124 | Epoch 01 | Train Loss: 13298.1433 | Val Loss: 94150.6979 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:17,128] Trial 1125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1125 | Epoch 01 | Train Loss: 22218.0026 | Val Loss: 21897.1775 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:17,457] Trial 1126 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1126 | Epoch 01 | Train Loss: 16477.0517 | Val Loss: 14207.6296 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:17,827] Trial 1127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1127 | Epoch 01 | Train Loss: 20329.9714 | Val Loss: 16271.5601 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:18,043] Trial 1128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1128 | Epoch 01 | Train Loss: 43049.1337 | Val Loss: 20524.2932 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:18,273] Trial 1129 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1129 | Epoch 01 | Train Loss: 14235.9709 | Val Loss: 11145.3424 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:18,510] Trial 1130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1130 | Epoch 01 | Train Loss: 20166.8870 | Val Loss: 17826.4916 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:18,817] Trial 1131 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1131 | Epoch 01 | Train Loss: 135373.7212 | Val Loss: 25904.6258 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:19,058] Trial 1132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1132 | Epoch 01 | Train Loss: 29002.1138 | Val Loss: 15193.8110 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:19,283] Trial 1133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1133 | Epoch 01 | Train Loss: 19432.2509 | Val Loss: 15459.4395 | Optimizer: Adam\n",
      "Trial 1134 | Epoch 01 | Train Loss: 1982562.2190 | Val Loss: 8821.2546 | Optimizer: RMSprop\n",
      "Trial 1134 | Epoch 02 | Train Loss: 9394.4725 | Val Loss: 18332.0416 | Optimizer: RMSprop\n",
      "Trial 1134 | Epoch 03 | Train Loss: 10541.3042 | Val Loss: 10622.9796 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:19,718] Trial 1134 pruned. \n",
      "[I 2025-09-05 19:06:19,967] Trial 1135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1135 | Epoch 01 | Train Loss: 18106.4256 | Val Loss: 12456.6788 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:20,215] Trial 1136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1136 | Epoch 01 | Train Loss: 15627.0069 | Val Loss: 11542.3009 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:20,543] Trial 1137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1137 | Epoch 01 | Train Loss: 433605.2354 | Val Loss: 14587.6915 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:20,766] Trial 1138 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1138 | Epoch 01 | Train Loss: 19697.2346 | Val Loss: 16568.5274 | Optimizer: Adam\n",
      "Trial 1139 | Epoch 01 | Train Loss: 14174.0898 | Val Loss: 20570.4674 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:20,990] Trial 1139 pruned. \n",
      "[I 2025-09-05 19:06:21,326] Trial 1140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1140 | Epoch 01 | Train Loss: 16325.0889 | Val Loss: 10550.9601 | Optimizer: RMSprop\n",
      "Trial 1140 | Epoch 02 | Train Loss: 15177.6031 | Val Loss: 12755.8634 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:21,591] Trial 1141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1141 | Epoch 01 | Train Loss: 20707.9636 | Val Loss: 17866.7956 | Optimizer: Adam\n",
      "Trial 1142 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:21,772] Trial 1142 pruned. \n",
      "[I 2025-09-05 19:06:22,109] Trial 1143 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1143 | Epoch 01 | Train Loss: 14397.4415 | Val Loss: 16380.7817 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:22,469] Trial 1144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1144 | Epoch 01 | Train Loss: 18722.4197 | Val Loss: 10598.9225 | Optimizer: Adam\n",
      "Trial 1144 | Epoch 02 | Train Loss: 11870.2568 | Val Loss: 10617.2395 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:22,722] Trial 1145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1145 | Epoch 01 | Train Loss: 14451.4806 | Val Loss: 14165.7086 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:22,961] Trial 1146 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1146 | Epoch 01 | Train Loss: 18899.9109 | Val Loss: 15299.4198 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:23,203] Trial 1147 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1147 | Epoch 01 | Train Loss: 19994.9746 | Val Loss: 17750.8316 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:23,461] Trial 1148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1148 | Epoch 01 | Train Loss: 16140.0831 | Val Loss: 14130.1750 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:23,790] Trial 1149 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1149 | Epoch 01 | Train Loss: 16813.9225 | Val Loss: 11334.1706 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:24,021] Trial 1150 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1150 | Epoch 01 | Train Loss: 18713.0140 | Val Loss: 12074.3171 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:24,294] Trial 1151 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1151 | Epoch 01 | Train Loss: 14887.8564 | Val Loss: 10926.6834 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:24,596] Trial 1152 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1152 | Epoch 01 | Train Loss: 18295.2785 | Val Loss: 10994.5818 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:24,887] Trial 1153 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1153 | Epoch 01 | Train Loss: 19551.6881 | Val Loss: 16103.8741 | Optimizer: RMSprop\n",
      "Trial 1154 | Epoch 01 | Train Loss: 14769.8588 | Val Loss: 10272.4294 | Optimizer: RMSprop\n",
      "Trial 1154 | Epoch 02 | Train Loss: 9890.5816 | Val Loss: 115534.8764 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:25,403] Trial 1154 pruned. \n",
      "[I 2025-09-05 19:06:25,787] Trial 1155 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1155 | Epoch 01 | Train Loss: 20811.9637 | Val Loss: 17955.5306 | Optimizer: Adam\n",
      "Trial 1156 | Epoch 01 | Train Loss: 13479.4077 | Val Loss: 10148.3754 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:26,084] Trial 1156 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1156 | Epoch 02 | Train Loss: 10756.5130 | Val Loss: 11016.9062 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:26,324] Trial 1157 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1157 | Epoch 01 | Train Loss: 20741.5569 | Val Loss: 17512.7175 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:26,563] Trial 1158 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1158 | Epoch 01 | Train Loss: 532343.0614 | Val Loss: 15759.7574 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:26,787] Trial 1159 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1159 | Epoch 01 | Train Loss: 15484.6790 | Val Loss: 11398.5247 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:27,105] Trial 1160 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1160 | Epoch 01 | Train Loss: 17478.6535 | Val Loss: 11439.1688 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:27,344] Trial 1161 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1161 | Epoch 01 | Train Loss: 15702.6947 | Val Loss: 11246.7603 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:27,585] Trial 1162 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1162 | Epoch 01 | Train Loss: 199345.2649 | Val Loss: 630199.2832 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:27,822] Trial 1163 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1163 | Epoch 01 | Train Loss: 20310.1815 | Val Loss: 17782.4895 | Optimizer: Adam\n",
      "Trial 1164 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:27,994] Trial 1164 pruned. \n",
      "[I 2025-09-05 19:06:28,251] Trial 1165 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1165 | Epoch 01 | Train Loss: 122829.5523 | Val Loss: 19596.0017 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:28,573] Trial 1166 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1166 | Epoch 01 | Train Loss: 19633.6348 | Val Loss: 14901.7666 | Optimizer: Adam\n",
      "Trial 1167 | Epoch 01 | Train Loss: 13860.4331 | Val Loss: 9459.1837 | Optimizer: RMSprop\n",
      "Trial 1167 | Epoch 02 | Train Loss: 11852.7500 | Val Loss: 12212.8056 | Optimizer: RMSprop\n",
      "Trial 1167 | Epoch 03 | Train Loss: 9857.5857 | Val Loss: 33603.4035 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:29,005] Trial 1167 pruned. \n",
      "[I 2025-09-05 19:06:29,285] Trial 1168 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1168 | Epoch 01 | Train Loss: 20279.3384 | Val Loss: 11342.0293 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:29,540] Trial 1169 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1169 | Epoch 01 | Train Loss: 21582.3782 | Val Loss: 21652.5071 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:29,803] Trial 1170 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1170 | Epoch 01 | Train Loss: 17429.4068 | Val Loss: 12390.5422 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:30,067] Trial 1171 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1171 | Epoch 01 | Train Loss: 22269.9116 | Val Loss: 11798.4294 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:30,425] Trial 1172 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1172 | Epoch 01 | Train Loss: 18515.9026 | Val Loss: 13349.9726 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:30,810] Trial 1173 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1173 | Epoch 01 | Train Loss: 19352.0365 | Val Loss: 16365.9599 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:31,031] Trial 1174 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1174 | Epoch 01 | Train Loss: 17545.3632 | Val Loss: 11594.4485 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:31,260] Trial 1175 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1175 | Epoch 01 | Train Loss: 19108.1128 | Val Loss: 11067.0442 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:31,503] Trial 1176 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1176 | Epoch 01 | Train Loss: 15547.3046 | Val Loss: 14404.4075 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:31,785] Trial 1177 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1177 | Epoch 01 | Train Loss: 20714.3140 | Val Loss: 17844.8466 | Optimizer: Adam\n",
      "Trial 1178 | Epoch 01 | Train Loss: 15851.6804 | Val Loss: 10715.9112 | Optimizer: RMSprop\n",
      "Trial 1178 | Epoch 02 | Train Loss: 11635.9566 | Val Loss: 9034.0652 | Optimizer: RMSprop\n",
      "Trial 1178 | Epoch 03 | Train Loss: 9464.0522 | Val Loss: 7835.9532 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:32,297] Trial 1178 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1178 | Epoch 04 | Train Loss: 8222.2748 | Val Loss: 8562.0728 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:32,541] Trial 1179 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1179 | Epoch 01 | Train Loss: 22207.8545 | Val Loss: 12274.2894 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:32,776] Trial 1180 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1180 | Epoch 01 | Train Loss: 18062.9366 | Val Loss: 11276.3833 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:33,110] Trial 1181 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1181 | Epoch 01 | Train Loss: 15381.0088 | Val Loss: 10479.3136 | Optimizer: RMSprop\n",
      "Trial 1181 | Epoch 02 | Train Loss: 10198.5882 | Val Loss: 13515.9018 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:33,433] Trial 1182 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1182 | Epoch 01 | Train Loss: 18473.3120 | Val Loss: 13159.1414 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:33,830] Trial 1183 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1183 | Epoch 01 | Train Loss: 19073.3178 | Val Loss: 10658.5087 | Optimizer: RMSprop\n",
      "Trial 1183 | Epoch 02 | Train Loss: 11466.3462 | Val Loss: 11454.4783 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:34,057] Trial 1184 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1184 | Epoch 01 | Train Loss: 22756.6342 | Val Loss: 20958.8584 | Optimizer: RMSprop\n",
      "Trial 1185 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:34,238] Trial 1185 pruned. \n",
      "[I 2025-09-05 19:06:34,520] Trial 1186 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1186 | Epoch 01 | Train Loss: 20231.0466 | Val Loss: 18133.7940 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:34,766] Trial 1187 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1187 | Epoch 01 | Train Loss: 15146.3561 | Val Loss: 14415.8126 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:35,125] Trial 1188 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1188 | Epoch 01 | Train Loss: 20477.9817 | Val Loss: 10634.4412 | Optimizer: RMSprop\n",
      "Trial 1188 | Epoch 02 | Train Loss: 11441.3799 | Val Loss: 10284.0963 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:35,446] Trial 1189 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1189 | Epoch 01 | Train Loss: 18751.7579 | Val Loss: 11207.1659 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:35,657] Trial 1190 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1190 | Epoch 01 | Train Loss: 30264.6179 | Val Loss: 14605.4873 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:35,893] Trial 1191 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1191 | Epoch 01 | Train Loss: 19341.6209 | Val Loss: 15242.6073 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:36,134] Trial 1192 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1192 | Epoch 01 | Train Loss: 21301.3935 | Val Loss: 21556.7142 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:36,397] Trial 1193 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1193 | Epoch 01 | Train Loss: 71137.8940 | Val Loss: 19353.9912 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:36,671] Trial 1194 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1194 | Epoch 01 | Train Loss: 15828.9123 | Val Loss: 11357.7972 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:36,961] Trial 1195 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1195 | Epoch 01 | Train Loss: 20326.3726 | Val Loss: 16991.8657 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:37,212] Trial 1196 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1196 | Epoch 01 | Train Loss: 15224.0650 | Val Loss: 102434.2401 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:37,500] Trial 1197 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1197 | Epoch 01 | Train Loss: 21620.1977 | Val Loss: 21221.8670 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:37,744] Trial 1198 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1198 | Epoch 01 | Train Loss: 19843.0867 | Val Loss: 17478.3798 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:38,036] Trial 1199 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1199 | Epoch 01 | Train Loss: 15518.2919 | Val Loss: 11254.8420 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:38,510] Trial 1200 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1200 | Epoch 01 | Train Loss: 19450.2044 | Val Loss: 15649.5190 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:38,800] Trial 1201 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1201 | Epoch 01 | Train Loss: 18870.9987 | Val Loss: 14889.7544 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:39,039] Trial 1202 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1202 | Epoch 01 | Train Loss: 16137.6419 | Val Loss: 11755.8448 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:39,295] Trial 1203 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1203 | Epoch 01 | Train Loss: 41483.3797 | Val Loss: 18703.6552 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:39,558] Trial 1204 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1204 | Epoch 01 | Train Loss: 19593.1419 | Val Loss: 14262.1597 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:39,883] Trial 1205 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1205 | Epoch 01 | Train Loss: 19940.3072 | Val Loss: 16158.7389 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:40,110] Trial 1206 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1206 | Epoch 01 | Train Loss: 16862.0109 | Val Loss: 11090.0402 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:40,367] Trial 1207 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1207 | Epoch 01 | Train Loss: 18855.9903 | Val Loss: 11671.3086 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:40,577] Trial 1208 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1208 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 1209 | Epoch 01 | Train Loss: 14814.7444 | Val Loss: 9884.1709 | Optimizer: RMSprop\n",
      "Trial 1209 | Epoch 02 | Train Loss: 11021.6908 | Val Loss: 9419.4341 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:41,060] Trial 1209 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1209 | Epoch 03 | Train Loss: 8938.6961 | Val Loss: 8757.2760 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:41,410] Trial 1210 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1210 | Epoch 01 | Train Loss: 2403019.5707 | Val Loss: 13799.3009 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:41,660] Trial 1211 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1211 | Epoch 01 | Train Loss: 17467.2266 | Val Loss: 10911.6847 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:41,918] Trial 1212 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1212 | Epoch 01 | Train Loss: 15050.8128 | Val Loss: 62972.5972 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:42,213] Trial 1213 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1213 | Epoch 01 | Train Loss: 18402.9141 | Val Loss: 12935.1005 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:42,578] Trial 1214 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1214 | Epoch 01 | Train Loss: 1243413.1967 | Val Loss: 19715.8159 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:42,897] Trial 1215 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1215 | Epoch 01 | Train Loss: 20170.6713 | Val Loss: 17231.5874 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:43,149] Trial 1216 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1216 | Epoch 01 | Train Loss: 14511.6481 | Val Loss: 11585.9232 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:43,381] Trial 1217 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1217 | Epoch 01 | Train Loss: 20570.7061 | Val Loss: 16649.1995 | Optimizer: Adam\n",
      "Trial 1218 | Epoch 01 | Train Loss: 14606.5310 | Val Loss: 11159.2190 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:43,607] Trial 1218 pruned. \n",
      "[I 2025-09-05 19:06:43,846] Trial 1219 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1219 | Epoch 01 | Train Loss: 19783.1661 | Val Loss: 12383.6956 | Optimizer: RMSprop\n",
      "Trial 1220 | Epoch 01 | Train Loss: 19046.9712 | Val Loss: 13107.0292 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:44,066] Trial 1220 pruned. \n",
      "[I 2025-09-05 19:06:44,388] Trial 1221 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1221 | Epoch 01 | Train Loss: 20142.7045 | Val Loss: 16768.4735 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:44,635] Trial 1222 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1222 | Epoch 01 | Train Loss: 15630.1571 | Val Loss: 12804.2435 | Optimizer: RMSprop\n",
      "Trial 1223 | Epoch 01 | Train Loss: 15256.9783 | Val Loss: 31188.5421 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:44,857] Trial 1223 pruned. \n",
      "[I 2025-09-05 19:06:45,080] Trial 1224 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1224 | Epoch 01 | Train Loss: 21012.1482 | Val Loss: 18921.6536 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:45,339] Trial 1225 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1225 | Epoch 01 | Train Loss: 80046.0575 | Val Loss: 25621.6057 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:45,589] Trial 1226 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1226 | Epoch 01 | Train Loss: 19063.2063 | Val Loss: 13981.1642 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:45,912] Trial 1227 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1227 | Epoch 01 | Train Loss: 18881.2151 | Val Loss: 12958.4356 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:46,218] Trial 1228 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1228 | Epoch 01 | Train Loss: 37641.9715 | Val Loss: 16000.3700 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:46,461] Trial 1229 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1229 | Epoch 01 | Train Loss: 14436.7533 | Val Loss: 11996.0691 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:46,706] Trial 1230 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1230 | Epoch 01 | Train Loss: 19889.5231 | Val Loss: 17775.2358 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:46,991] Trial 1231 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1231 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:47,268] Trial 1232 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1232 | Epoch 01 | Train Loss: 14655.8322 | Val Loss: 11330.9669 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:47,630] Trial 1233 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1233 | Epoch 01 | Train Loss: 14693.1300 | Val Loss: 13576.6312 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:47,913] Trial 1234 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1234 | Epoch 01 | Train Loss: 18244.6882 | Val Loss: 11131.6273 | Optimizer: Adam\n",
      "Trial 1235 | Epoch 01 | Train Loss: 16678.3484 | Val Loss: 10585.9300 | Optimizer: AdamW\n",
      "Trial 1235 | Epoch 02 | Train Loss: 11000.7548 | Val Loss: 9681.1859 | Optimizer: AdamW\n",
      "Trial 1235 | Epoch 03 | Train Loss: 9933.6762 | Val Loss: 6991.8118 | Optimizer: AdamW\n",
      "Trial 1235 | Epoch 04 | Train Loss: 9147.6520 | Val Loss: 6534.6312 | Optimizer: AdamW\n",
      "Trial 1235 | Epoch 05 | Train Loss: 8105.2292 | Val Loss: 7883.4870 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:48,758] Trial 1235 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1235 | Epoch 06 | Train Loss: 11224.3220 | Val Loss: 11995.9574 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:49,008] Trial 1236 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1236 | Epoch 01 | Train Loss: 17742.4758 | Val Loss: 13008.5565 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:49,283] Trial 1237 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1237 | Epoch 01 | Train Loss: 19825.0422 | Val Loss: 16561.2488 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:49,592] Trial 1238 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1238 | Epoch 01 | Train Loss: 42953.3448 | Val Loss: 14449.5351 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:49,823] Trial 1239 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1239 | Epoch 01 | Train Loss: 15722.0279 | Val Loss: 30400.2437 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:50,056] Trial 1240 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1240 | Epoch 01 | Train Loss: 18008.2383 | Val Loss: 12557.9540 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:50,299] Trial 1241 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1241 | Epoch 01 | Train Loss: 20961.9161 | Val Loss: 19061.9708 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:50,531] Trial 1242 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1242 | Epoch 01 | Train Loss: 22015.0573 | Val Loss: 11764.8683 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:50,861] Trial 1243 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1243 | Epoch 01 | Train Loss: 15001.9784 | Val Loss: 14202.7039 | Optimizer: RMSprop\n",
      "Trial 1244 | Epoch 01 | Train Loss: 17527.0607 | Val Loss: 11415.5058 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:51,083] Trial 1244 pruned. \n",
      "[I 2025-09-05 19:06:51,315] Trial 1245 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1245 | Epoch 01 | Train Loss: 15191.2229 | Val Loss: 18334.6780 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:51,600] Trial 1246 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1246 | Epoch 01 | Train Loss: 21111.4537 | Val Loss: 18623.0000 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:51,853] Trial 1247 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1247 | Epoch 01 | Train Loss: 16450.7164 | Val Loss: 14202.7571 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:52,109] Trial 1248 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1248 | Epoch 01 | Train Loss: 19261.5215 | Val Loss: 14963.0246 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:52,455] Trial 1249 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1249 | Epoch 01 | Train Loss: 17746.5215 | Val Loss: 13667.6593 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:52,724] Trial 1250 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1250 | Epoch 01 | Train Loss: 17739.4218 | Val Loss: 11943.0911 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:52,967] Trial 1251 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1251 | Epoch 01 | Train Loss: 14508.3411 | Val Loss: 25318.0057 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:53,240] Trial 1252 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1252 | Epoch 01 | Train Loss: 28707.1638 | Val Loss: 14223.8037 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:53,547] Trial 1253 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1253 | Epoch 01 | Train Loss: 18404.1861 | Val Loss: 11447.3418 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:53,922] Trial 1254 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1254 | Epoch 01 | Train Loss: 14738.6774 | Val Loss: 11301.9448 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:54,220] Trial 1255 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1255 | Epoch 01 | Train Loss: 17637.0335 | Val Loss: 11295.7527 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:54,596] Trial 1256 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1256 | Epoch 01 | Train Loss: 18209.9018 | Val Loss: 12551.6293 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:54,815] Trial 1257 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1257 | Epoch 01 | NaN loss detected so pruning trial\n",
      "Trial 1258 | Epoch 01 | Train Loss: 16284.4985 | Val Loss: 11004.1610 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:55,038] Trial 1258 pruned. \n",
      "[I 2025-09-05 19:06:55,362] Trial 1259 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1259 | Epoch 01 | Train Loss: 25260.8949 | Val Loss: 31674.2287 | Optimizer: RMSprop\n",
      "Trial 1260 | Epoch 01 | Train Loss: 20595.8804 | Val Loss: 17600.3880 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:55,572] Trial 1260 pruned. \n",
      "[I 2025-09-05 19:06:55,929] Trial 1261 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1261 | Epoch 01 | Train Loss: 15555.6176 | Val Loss: 12305.6275 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:56,186] Trial 1262 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1262 | Epoch 01 | Train Loss: 18007.0870 | Val Loss: 11738.6690 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:56,442] Trial 1263 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1263 | Epoch 01 | Train Loss: 21590.1566 | Val Loss: 21138.4448 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:56,682] Trial 1264 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1264 | Epoch 01 | Train Loss: 16181.4286 | Val Loss: 12030.3018 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:57,099] Trial 1265 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1265 | Epoch 01 | Train Loss: 17477.4575 | Val Loss: 10619.6301 | Optimizer: RMSprop\n",
      "Trial 1265 | Epoch 02 | Train Loss: 10955.5727 | Val Loss: 10470.9817 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:57,343] Trial 1266 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1266 | Epoch 01 | Train Loss: 19907.2694 | Val Loss: 16551.3063 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:57,608] Trial 1267 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1267 | Epoch 01 | Train Loss: 18680.9189 | Val Loss: 13000.3659 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:57,877] Trial 1268 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1268 | Epoch 01 | Train Loss: 13429.4311 | Val Loss: 22099.6608 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:58,132] Trial 1269 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1269 | Epoch 01 | Train Loss: 19359.9580 | Val Loss: 16893.0374 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:58,578] Trial 1270 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1270 | Epoch 01 | Train Loss: 20061.9693 | Val Loss: 17043.5044 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:58,830] Trial 1271 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1271 | Epoch 01 | Train Loss: 23376.5160 | Val Loss: 20052.3141 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:59,077] Trial 1272 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1272 | Epoch 01 | Train Loss: 18714.4406 | Val Loss: 13689.2426 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:59,325] Trial 1273 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1273 | Epoch 01 | Train Loss: 111885.9760 | Val Loss: 20485.2318 | Optimizer: RMSprop\n",
      "Trial 1274 | Epoch 01 | Train Loss: 15762.6591 | Val Loss: 15401.9497 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:06:59,553] Trial 1274 pruned. \n",
      "[I 2025-09-05 19:06:59,867] Trial 1275 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1275 | Epoch 01 | Train Loss: 18615.6602 | Val Loss: 14148.0528 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:00,131] Trial 1276 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1276 | Epoch 01 | Train Loss: 21306.8217 | Val Loss: 21540.0107 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:00,369] Trial 1277 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1277 | Epoch 01 | Train Loss: 19092.0923 | Val Loss: 14062.8105 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:00,592] Trial 1278 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1278 | Epoch 01 | Train Loss: 21044.2549 | Val Loss: 11158.1219 | Optimizer: RMSprop\n",
      "Trial 1279 | Epoch 01 | Train Loss: 20024.2719 | Val Loss: 17086.0424 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:00,809] Trial 1279 pruned. \n",
      "[I 2025-09-05 19:07:01,063] Trial 1280 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1280 | Epoch 01 | Train Loss: 2970493.5538 | Val Loss: 16137.9621 | Optimizer: RMSprop\n",
      "Trial 1281 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:01,267] Trial 1281 pruned. \n",
      "[I 2025-09-05 19:07:01,596] Trial 1282 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1282 | Epoch 01 | Train Loss: 18624.5387 | Val Loss: 13894.4446 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:01,870] Trial 1283 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1283 | Epoch 01 | Train Loss: 24503.2173 | Val Loss: 18482.7488 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:02,106] Trial 1284 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1284 | Epoch 01 | Train Loss: 21453.2950 | Val Loss: 18442.2262 | Optimizer: AdamW\n",
      "Trial 1285 | Epoch 01 | Train Loss: 56249.7394 | Val Loss: 9701.1605 | Optimizer: RMSprop\n",
      "Trial 1285 | Epoch 02 | Train Loss: 16201.2089 | Val Loss: 12726.0056 | Optimizer: RMSprop\n",
      "Trial 1285 | Epoch 03 | Train Loss: 11652.4758 | Val Loss: 13977.8280 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:02,562] Trial 1285 pruned. \n",
      "[I 2025-09-05 19:07:02,791] Trial 1286 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1286 | Epoch 01 | Train Loss: 18001.3497 | Val Loss: 12638.5174 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:03,076] Trial 1287 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1287 | Epoch 01 | Train Loss: 39127.3611 | Val Loss: 12629.3695 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:03,381] Trial 1288 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1288 | Epoch 01 | Train Loss: 29525.5502 | Val Loss: 11777.1733 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:03,627] Trial 1289 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1289 | Epoch 01 | Train Loss: 18564.6640 | Val Loss: 14320.1084 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:03,904] Trial 1290 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1290 | Epoch 01 | Train Loss: 20577.9139 | Val Loss: 17603.3220 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:04,191] Trial 1291 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1291 | Epoch 01 | Train Loss: 14002.0250 | Val Loss: 11493.2621 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:04,539] Trial 1292 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1292 | Epoch 01 | Train Loss: 21317.4789 | Val Loss: 19561.6586 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:04,871] Trial 1293 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1293 | Epoch 01 | Train Loss: 15137.7270 | Val Loss: 13565.6630 | Optimizer: RMSprop\n",
      "Trial 1294 | Epoch 01 | Train Loss: 349294.7680 | Val Loss: 10168.6108 | Optimizer: RMSprop\n",
      "Trial 1294 | Epoch 02 | Train Loss: 149159.0282 | Val Loss: 9610.1167 | Optimizer: RMSprop\n",
      "Trial 1294 | Epoch 03 | Train Loss: 10583.3509 | Val Loss: 15709.6487 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:05,340] Trial 1294 pruned. \n",
      "[I 2025-09-05 19:07:05,583] Trial 1295 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1295 | Epoch 01 | Train Loss: 17779.2217 | Val Loss: 12359.0094 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:05,834] Trial 1296 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1296 | Epoch 01 | Train Loss: 16371.8919 | Val Loss: 14489.3092 | Optimizer: RMSprop\n",
      "Trial 1297 | Epoch 01 | Train Loss: 19929.0979 | Val Loss: 14705.9109 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:06,037] Trial 1297 pruned. \n",
      "[I 2025-09-05 19:07:06,309] Trial 1298 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1298 | Epoch 01 | Train Loss: 24434.4296 | Val Loss: 13750.9538 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:06,611] Trial 1299 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1299 | Epoch 01 | Train Loss: 19580.0898 | Val Loss: 15359.9849 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:06,879] Trial 1300 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1300 | Epoch 01 | Train Loss: 16649.5665 | Val Loss: 14738.8578 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:07,145] Trial 1301 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1301 | Epoch 01 | Train Loss: 21932.0011 | Val Loss: 21626.8676 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:07,388] Trial 1302 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1302 | Epoch 01 | Train Loss: 53579.7735 | Val Loss: 14997.1644 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:07,658] Trial 1303 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1303 | Epoch 01 | Train Loss: 14966.2273 | Val Loss: 10949.9908 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:07,985] Trial 1304 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1304 | Epoch 01 | Train Loss: 20796.0396 | Val Loss: 19065.6513 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:08,285] Trial 1305 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1305 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:08,570] Trial 1306 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1306 | Epoch 01 | Train Loss: 18117.8073 | Val Loss: 12052.4815 | Optimizer: Adam\n",
      "Trial 1307 | Epoch 01 | Train Loss: 14219.3135 | Val Loss: 10740.3246 | Optimizer: RMSprop\n",
      "Trial 1307 | Epoch 02 | Train Loss: 10981.0256 | Val Loss: 9735.3124 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:09,068] Trial 1307 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1307 | Epoch 03 | Train Loss: 9782.3686 | Val Loss: 12864.9329 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:09,330] Trial 1308 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1308 | Epoch 01 | Train Loss: 19208.3909 | Val Loss: 11351.7901 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:09,575] Trial 1309 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1309 | Epoch 01 | Train Loss: 18630.9731 | Val Loss: 13546.4193 | Optimizer: Adam\n",
      "Trial 1310 | Epoch 01 | Train Loss: 13850.8927 | Val Loss: 7929.1024 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 02 | Train Loss: 18110.2865 | Val Loss: 11169.7864 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 03 | Train Loss: 10766.0869 | Val Loss: 7450.3912 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 04 | Train Loss: 8816.0972 | Val Loss: 6114.5530 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 05 | Train Loss: 7665.1272 | Val Loss: 6846.7509 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 06 | Train Loss: 8526.3251 | Val Loss: 7146.2494 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 07 | Train Loss: 7783.7005 | Val Loss: 8776.8914 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 08 | Train Loss: 8530.7624 | Val Loss: 8985.1097 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 09 | Train Loss: 7870.2162 | Val Loss: 7584.2532 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 10 | Train Loss: 7594.6379 | Val Loss: 6322.8355 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 11 | Train Loss: 7431.9365 | Val Loss: 7922.0053 | Optimizer: RMSprop\n",
      "Trial 1310 | Epoch 12 | Train Loss: 7168.4606 | Val Loss: 10959.9352 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:10,924] Trial 1310 pruned. \n",
      "[I 2025-09-05 19:07:11,183] Trial 1311 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1311 | Epoch 01 | Train Loss: 20363.0976 | Val Loss: 17826.6413 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:11,430] Trial 1312 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1312 | Epoch 01 | Train Loss: 19179.8859 | Val Loss: 15244.9080 | Optimizer: AdamW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:11,771] Trial 1313 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1313 | Epoch 01 | Train Loss: 15660.0409 | Val Loss: 10787.2139 | Optimizer: RMSprop\n",
      "Trial 1313 | Epoch 02 | Train Loss: 49087.8256 | Val Loss: 17156.8696 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:12,056] Trial 1314 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1314 | Epoch 01 | Train Loss: 14711.0517 | Val Loss: 11562.2450 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:12,374] Trial 1315 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1315 | Epoch 01 | Train Loss: 21901.0664 | Val Loss: 22160.2597 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:12,640] Trial 1316 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1316 | Epoch 01 | Train Loss: 16419.9816 | Val Loss: 15364.7670 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 01 | Train Loss: 14577.5682 | Val Loss: 9394.3287 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 02 | Train Loss: 11037.7718 | Val Loss: 12606.4360 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 03 | Train Loss: 9954.5905 | Val Loss: 5936.3602 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 04 | Train Loss: 8556.9297 | Val Loss: 7676.4389 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 05 | Train Loss: 7536.0607 | Val Loss: 14875.0247 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 06 | Train Loss: 12593.9355 | Val Loss: 7089.8410 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 07 | Train Loss: 7713.9601 | Val Loss: 5901.6753 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 08 | Train Loss: 7125.6873 | Val Loss: 11314.2215 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 09 | Train Loss: 8374.5123 | Val Loss: 5974.5799 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 10 | Train Loss: 6902.7898 | Val Loss: 8460.4751 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 11 | Train Loss: 7849.0127 | Val Loss: 5416.2255 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 12 | Train Loss: 6675.5654 | Val Loss: 5403.2806 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 13 | Train Loss: 6753.7767 | Val Loss: 7047.5315 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 14 | Train Loss: 7173.3458 | Val Loss: 5302.8905 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 15 | Train Loss: 6689.2169 | Val Loss: 5248.8480 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 16 | Train Loss: 6368.7605 | Val Loss: 5343.7688 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 17 | Train Loss: 6438.4582 | Val Loss: 6222.8795 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 18 | Train Loss: 6405.3110 | Val Loss: 5392.6286 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 19 | Train Loss: 6357.0889 | Val Loss: 5458.0043 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 20 | Train Loss: 6225.0432 | Val Loss: 5692.7617 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 21 | Train Loss: 6163.5569 | Val Loss: 5564.2742 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 22 | Train Loss: 6010.0120 | Val Loss: 5227.8789 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 23 | Train Loss: 6249.0026 | Val Loss: 5627.0151 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 24 | Train Loss: 6013.8439 | Val Loss: 5426.2620 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 25 | Train Loss: 6140.4280 | Val Loss: 5227.8251 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 26 | Train Loss: 6094.7858 | Val Loss: 8152.9728 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 27 | Train Loss: 6988.8341 | Val Loss: 27382.8307 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 28 | Train Loss: 9107.2709 | Val Loss: 5614.7259 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 29 | Train Loss: 6118.9469 | Val Loss: 5369.8576 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 30 | Train Loss: 5974.3110 | Val Loss: 6122.9985 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 31 | Train Loss: 6453.0265 | Val Loss: 6016.1660 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 32 | Train Loss: 6278.2876 | Val Loss: 5385.7918 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 33 | Train Loss: 5750.0686 | Val Loss: 5119.1143 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 34 | Train Loss: 5580.7592 | Val Loss: 7521.0545 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 35 | Train Loss: 6452.4616 | Val Loss: 5073.5385 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 36 | Train Loss: 5800.9182 | Val Loss: 5610.0571 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 37 | Train Loss: 5671.4185 | Val Loss: 5549.1192 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 38 | Train Loss: 5849.6205 | Val Loss: 5168.5989 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 39 | Train Loss: 5449.6198 | Val Loss: 9066.6158 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 40 | Train Loss: 6611.7448 | Val Loss: 8437.9721 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 41 | Train Loss: 6524.9274 | Val Loss: 28915.0015 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 42 | Train Loss: 11634.9368 | Val Loss: 5195.2941 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 43 | Train Loss: 5922.6518 | Val Loss: 5066.5852 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 44 | Train Loss: 5542.3948 | Val Loss: 5174.0238 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 45 | Train Loss: 5488.1853 | Val Loss: 5261.2642 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 46 | Train Loss: 5693.9548 | Val Loss: 5229.2517 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 47 | Train Loss: 5685.3442 | Val Loss: 5380.7238 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 48 | Train Loss: 5719.3691 | Val Loss: 5949.2083 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 49 | Train Loss: 5530.5711 | Val Loss: 5411.0788 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 50 | Train Loss: 5587.4337 | Val Loss: 8956.7462 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 51 | Train Loss: 6878.3640 | Val Loss: 5421.0365 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 52 | Train Loss: 5538.4032 | Val Loss: 5032.3494 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 53 | Train Loss: 5081.8015 | Val Loss: 4940.3293 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 54 | Train Loss: 5297.5884 | Val Loss: 4978.7083 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 55 | Train Loss: 5662.3875 | Val Loss: 5642.1817 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 56 | Train Loss: 5437.3500 | Val Loss: 5489.6663 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 57 | Train Loss: 5576.3342 | Val Loss: 6452.2102 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 58 | Train Loss: 5632.6182 | Val Loss: 11837.6693 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 59 | Train Loss: 6641.4154 | Val Loss: 5420.1793 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 60 | Train Loss: 5452.3587 | Val Loss: 4887.3895 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 61 | Train Loss: 5266.4246 | Val Loss: 6484.7204 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 62 | Train Loss: 5753.4216 | Val Loss: 4920.9436 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 63 | Train Loss: 5431.2500 | Val Loss: 5019.4674 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 64 | Train Loss: 5625.9323 | Val Loss: 11134.3287 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 65 | Train Loss: 7330.9552 | Val Loss: 5095.9109 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 66 | Train Loss: 5329.0612 | Val Loss: 4953.5395 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 67 | Train Loss: 5143.8241 | Val Loss: 11688.8995 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 68 | Train Loss: 8533.5615 | Val Loss: 5326.5724 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:20,021] Trial 1317 finished with value: 4887.389500747492 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.2508482945382593, 'lr': 0.0003086044457037687, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 7.198592945322516e-06}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1317 | Epoch 69 | Train Loss: 5632.2341 | Val Loss: 7611.6605 | Optimizer: RMSprop\n",
      "Trial 1317 | Epoch 70 | Train Loss: 5945.1837 | Val Loss: 5472.8566 | Optimizer: RMSprop\n",
      "Trial 1317 - Early stopping triggered at epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:20,276] Trial 1318 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1318 | Epoch 01 | Train Loss: 15110.0087 | Val Loss: 14906.4877 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:20,550] Trial 1319 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1319 | Epoch 01 | Train Loss: 13682.9984 | Val Loss: 47490.7012 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:20,876] Trial 1320 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1320 | Epoch 01 | Train Loss: 14761.7149 | Val Loss: 12213.7683 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:21,144] Trial 1321 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1321 | Epoch 01 | Train Loss: 15430.4253 | Val Loss: 11109.5711 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 01 | Train Loss: 16675.2189 | Val Loss: 10124.5514 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 02 | Train Loss: 9776.9660 | Val Loss: 8392.2256 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 03 | Train Loss: 8927.3142 | Val Loss: 7549.6333 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 04 | Train Loss: 9090.0245 | Val Loss: 6375.8464 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 05 | Train Loss: 6977.9973 | Val Loss: 7558.5923 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 06 | Train Loss: 7398.6037 | Val Loss: 5669.9337 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 07 | Train Loss: 6793.3315 | Val Loss: 5419.0797 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 08 | Train Loss: 6809.5412 | Val Loss: 9826.3135 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 09 | Train Loss: 7843.2569 | Val Loss: 6048.3913 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 10 | Train Loss: 6846.1966 | Val Loss: 5407.0563 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 11 | Train Loss: 6782.1117 | Val Loss: 22001.6641 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 12 | Train Loss: 11304.0984 | Val Loss: 9598.0620 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 13 | Train Loss: 7297.1368 | Val Loss: 7028.3011 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 14 | Train Loss: 6600.7788 | Val Loss: 5391.9527 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 15 | Train Loss: 6243.4595 | Val Loss: 5851.6557 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 16 | Train Loss: 6371.0507 | Val Loss: 5751.6078 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 17 | Train Loss: 6059.2356 | Val Loss: 5562.9380 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 18 | Train Loss: 6045.0479 | Val Loss: 7424.4944 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 19 | Train Loss: 6387.9015 | Val Loss: 7227.2519 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 20 | Train Loss: 6320.1591 | Val Loss: 6074.7243 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 21 | Train Loss: 6061.2879 | Val Loss: 5169.1671 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 22 | Train Loss: 6006.4290 | Val Loss: 5467.7117 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 23 | Train Loss: 5779.2639 | Val Loss: 7762.9521 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 24 | Train Loss: 6563.3525 | Val Loss: 6659.4039 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 25 | Train Loss: 6360.2027 | Val Loss: 5448.4351 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 26 | Train Loss: 5775.5499 | Val Loss: 6178.2549 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 27 | Train Loss: 6051.0668 | Val Loss: 6564.0334 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 28 | Train Loss: 6330.6000 | Val Loss: 5670.9458 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 29 | Train Loss: 5818.5552 | Val Loss: 5650.5165 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 30 | Train Loss: 5858.2608 | Val Loss: 6708.8592 | Optimizer: RMSprop\n",
      "Trial 1322 | Epoch 31 | Train Loss: 6124.9231 | Val Loss: 5575.8084 | Optimizer: RMSprop\n",
      "Trial 1322 - Early stopping triggered at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:24,441] Trial 1322 finished with value: 5169.167127821181 and parameters: {'gnn_dim': 256, 'hidden_dim': 384, 'dropout_rate': 0.17869377686842736, 'lr': 0.0002653762920438415, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 7.775029978833429e-06}. Best is trial 134 with value: 4556.067195939429.\n",
      "[I 2025-09-05 19:07:24,688] Trial 1323 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1323 | Epoch 01 | Train Loss: 14629.6266 | Val Loss: 11782.0968 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:25,043] Trial 1324 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1324 | Epoch 01 | Train Loss: 16004.9007 | Val Loss: 10481.1960 | Optimizer: RMSprop\n",
      "Trial 1324 | Epoch 02 | Train Loss: 10406.3863 | Val Loss: 12756.2638 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:25,405] Trial 1325 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1325 | Epoch 01 | Train Loss: 14406.6441 | Val Loss: 10733.8986 | Optimizer: RMSprop\n",
      "Trial 1325 | Epoch 02 | Train Loss: 10428.0971 | Val Loss: 15960.9218 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:25,648] Trial 1326 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1326 | Epoch 01 | Train Loss: 14141.1750 | Val Loss: 13401.8237 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:26,020] Trial 1327 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1327 | Epoch 01 | Train Loss: 20871.7075 | Val Loss: 19458.2283 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:26,300] Trial 1328 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1328 | Epoch 01 | Train Loss: 14351.3284 | Val Loss: 20390.8433 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:26,577] Trial 1329 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1329 | Epoch 01 | Train Loss: 14740.9391 | Val Loss: 33012.8365 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:26,875] Trial 1330 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1330 | Epoch 01 | Train Loss: 14227.4966 | Val Loss: 13350.0774 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:27,255] Trial 1331 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1331 | Epoch 01 | Train Loss: 16641.4965 | Val Loss: 10522.4943 | Optimizer: RMSprop\n",
      "Trial 1331 | Epoch 02 | Train Loss: 10726.9228 | Val Loss: 10684.2335 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:27,584] Trial 1332 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1332 | Epoch 01 | Train Loss: 14496.2615 | Val Loss: 173057.8202 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:27,828] Trial 1333 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1333 | Epoch 01 | Train Loss: 14247.2777 | Val Loss: 11958.8357 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:28,169] Trial 1334 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1334 | Epoch 01 | Train Loss: 16262.3064 | Val Loss: 10505.3623 | Optimizer: RMSprop\n",
      "Trial 1334 | Epoch 02 | Train Loss: 10897.8919 | Val Loss: 11277.3801 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:28,404] Trial 1335 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1335 | Epoch 01 | Train Loss: 25837.9487 | Val Loss: 18479.3125 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:28,741] Trial 1336 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1336 | Epoch 01 | Train Loss: 20236.3161 | Val Loss: 10426.9577 | Optimizer: RMSprop\n",
      "Trial 1336 | Epoch 02 | Train Loss: 14493.6090 | Val Loss: 15728.5290 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:29,233] Trial 1337 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1337 | Epoch 01 | Train Loss: 15899.1368 | Val Loss: 10695.0670 | Optimizer: RMSprop\n",
      "Trial 1337 | Epoch 02 | Train Loss: 16490.4347 | Val Loss: 14243.3473 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:29,574] Trial 1338 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1338 | Epoch 01 | Train Loss: 14336.1887 | Val Loss: 10727.6626 | Optimizer: RMSprop\n",
      "Trial 1338 | Epoch 02 | Train Loss: 10105.8248 | Val Loss: 10600.6011 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:29,798] Trial 1339 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1339 | Epoch 01 | Train Loss: 17004.6321 | Val Loss: 12724.5713 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:30,077] Trial 1340 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1340 | Epoch 01 | Train Loss: 19450.7812 | Val Loss: 15742.0102 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:30,326] Trial 1341 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1341 | Epoch 01 | Train Loss: 15187.1467 | Val Loss: 11159.9483 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:30,646] Trial 1342 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1342 | Epoch 01 | Train Loss: 16209.6595 | Val Loss: 14252.7462 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:30,883] Trial 1343 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1343 | Epoch 01 | Train Loss: 18221.0741 | Val Loss: 11620.0170 | Optimizer: Adam\n",
      "Trial 1344 | Epoch 01 | Train Loss: 16399.9167 | Val Loss: 10125.7845 | Optimizer: RMSprop\n",
      "Trial 1344 | Epoch 02 | Train Loss: 10710.3988 | Val Loss: 8943.1800 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:31,417] Trial 1344 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1344 | Epoch 03 | Train Loss: 9297.8663 | Val Loss: 14490.4373 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:31,646] Trial 1345 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1345 | Epoch 01 | Train Loss: 1240668.1186 | Val Loss: 15718.5512 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:31,898] Trial 1346 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1346 | Epoch 01 | Train Loss: 21059.9529 | Val Loss: 19014.9415 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:32,225] Trial 1347 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1347 | Epoch 01 | Train Loss: 15467.5444 | Val Loss: 12881.8524 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:32,468] Trial 1348 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1348 | Epoch 01 | Train Loss: 19340.4852 | Val Loss: 14219.1232 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:32,712] Trial 1349 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1349 | Epoch 01 | Train Loss: 18107.4683 | Val Loss: 13095.4925 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:32,947] Trial 1350 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1350 | Epoch 01 | Train Loss: 19879.4141 | Val Loss: 15614.7157 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:33,165] Trial 1351 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1351 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:33,511] Trial 1352 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1352 | Epoch 01 | Train Loss: 17649.8217 | Val Loss: 11500.2994 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:33,795] Trial 1353 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1353 | Epoch 01 | Train Loss: 21467.8472 | Val Loss: 20974.8176 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:34,211] Trial 1354 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1354 | Epoch 01 | Train Loss: 19733.3810 | Val Loss: 10509.3287 | Optimizer: RMSprop\n",
      "Trial 1354 | Epoch 02 | Train Loss: 11808.7577 | Val Loss: 10480.6190 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:34,450] Trial 1355 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1355 | Epoch 01 | Train Loss: 21893.3157 | Val Loss: 21740.4878 | Optimizer: Adam\n",
      "Trial 1356 | Epoch 01 | Train Loss: 16036.2074 | Val Loss: 10461.5168 | Optimizer: RMSprop\n",
      "Trial 1356 | Epoch 02 | Train Loss: 10862.6337 | Val Loss: 8066.5262 | Optimizer: RMSprop\n",
      "Trial 1356 | Epoch 03 | Train Loss: 8694.8468 | Val Loss: 7117.3281 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:35,147] Trial 1356 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1356 | Epoch 04 | Train Loss: 8072.3911 | Val Loss: 18852.0158 | Optimizer: RMSprop\n",
      "Trial 1356 | Epoch 05 | Train Loss: 10409.3477 | Val Loss: 15993.8905 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:35,381] Trial 1357 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1357 | Epoch 01 | Train Loss: 14821.7520 | Val Loss: 14897.7870 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:35,636] Trial 1358 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1358 | Epoch 01 | Train Loss: 19500.6309 | Val Loss: 15592.4151 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:35,868] Trial 1359 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1359 | Epoch 01 | Train Loss: 27673.1640 | Val Loss: 18611.5795 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:36,166] Trial 1360 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1360 | Epoch 01 | Train Loss: 18893.1491 | Val Loss: 14604.3150 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:36,624] Trial 1361 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1361 | Epoch 01 | Train Loss: 16524.3003 | Val Loss: 10645.7064 | Optimizer: RMSprop\n",
      "Trial 1361 | Epoch 02 | Train Loss: 11065.4081 | Val Loss: 13082.7534 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:36,867] Trial 1362 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1362 | Epoch 01 | Train Loss: 16713.1487 | Val Loss: 10986.9038 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:37,127] Trial 1363 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1363 | Epoch 01 | Train Loss: 18096.6275 | Val Loss: 11520.6601 | Optimizer: Adam\n",
      "Trial 1364 | Epoch 01 | Train Loss: 14251.5233 | Val Loss: 9748.3689 | Optimizer: RMSprop\n",
      "Trial 1364 | Epoch 02 | Train Loss: 10311.8360 | Val Loss: 8856.1736 | Optimizer: RMSprop\n",
      "Trial 1364 | Epoch 03 | Train Loss: 9090.0809 | Val Loss: 23384.3376 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:37,570] Trial 1364 pruned. \n",
      "[I 2025-09-05 19:07:37,816] Trial 1365 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1365 | Epoch 01 | Train Loss: 14710.4750 | Val Loss: 11069.7683 | Optimizer: RMSprop\n",
      "Trial 1366 | Epoch 01 | Train Loss: 18704.4936 | Val Loss: 13540.7901 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:38,007] Trial 1366 pruned. \n",
      "[I 2025-09-05 19:07:38,454] Trial 1367 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1367 | Epoch 01 | Train Loss: 18146.3086 | Val Loss: 10757.6797 | Optimizer: RMSprop\n",
      "Trial 1367 | Epoch 02 | Train Loss: 10839.5028 | Val Loss: 11216.5704 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:38,878] Trial 1368 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1368 | Epoch 01 | Train Loss: 17122.6353 | Val Loss: 10662.6244 | Optimizer: RMSprop\n",
      "Trial 1368 | Epoch 02 | Train Loss: 10670.4133 | Val Loss: 71845.9810 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:39,117] Trial 1369 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1369 | Epoch 01 | Train Loss: 18388.1494 | Val Loss: 13362.8128 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:39,353] Trial 1370 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1370 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:39,607] Trial 1371 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1371 | Epoch 01 | Train Loss: 19994.8630 | Val Loss: 14929.7025 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:39,944] Trial 1372 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1372 | Epoch 01 | Train Loss: 17292.1796 | Val Loss: 10932.6621 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:40,174] Trial 1373 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1373 | Epoch 01 | Train Loss: 17677.9498 | Val Loss: 20040.3448 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:40,419] Trial 1374 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1374 | Epoch 01 | Train Loss: 16831.6527 | Val Loss: 12328.0930 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:40,689] Trial 1375 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1375 | Epoch 01 | Train Loss: 17116.8309 | Val Loss: 11564.1786 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:40,983] Trial 1376 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1376 | Epoch 01 | Train Loss: 18716.3293 | Val Loss: 14645.7224 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:41,490] Trial 1377 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1377 | Epoch 01 | Train Loss: 15215.0723 | Val Loss: 9947.8295 | Optimizer: RMSprop\n",
      "Trial 1377 | Epoch 02 | Train Loss: 13838.2475 | Val Loss: 11163.0895 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:41,759] Trial 1378 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1378 | Epoch 01 | Train Loss: 18142.6620 | Val Loss: 12262.3538 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:41,990] Trial 1379 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1379 | Epoch 01 | Train Loss: 16904.1193 | Val Loss: 11815.2902 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:42,230] Trial 1380 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1380 | Epoch 01 | Train Loss: 15873.7048 | Val Loss: 12114.7577 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:42,475] Trial 1381 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1381 | Epoch 01 | Train Loss: 20794.6420 | Val Loss: 18569.6871 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:42,811] Trial 1382 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1382 | Epoch 01 | Train Loss: 19779.5576 | Val Loss: 11913.6571 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:43,168] Trial 1383 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1383 | Epoch 01 | Train Loss: 16981.8059 | Val Loss: 10785.9993 | Optimizer: Adam\n",
      "Trial 1383 | Epoch 02 | Train Loss: 11775.2295 | Val Loss: 10452.7918 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:43,450] Trial 1384 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1384 | Epoch 01 | Train Loss: 19463.6654 | Val Loss: 12890.8690 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:44,082] Trial 1385 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1385 | Epoch 01 | Train Loss: 21179.0079 | Val Loss: 19964.1863 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:44,359] Trial 1386 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1386 | Epoch 01 | Train Loss: 20544.7227 | Val Loss: 18249.1381 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:44,679] Trial 1387 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1387 | Epoch 01 | Train Loss: 14775.5385 | Val Loss: 12392.3298 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:45,027] Trial 1388 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1388 | Epoch 01 | Train Loss: 15516.4277 | Val Loss: 10543.4453 | Optimizer: RMSprop\n",
      "Trial 1388 | Epoch 02 | Train Loss: 136726.8796 | Val Loss: 15527.8557 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:45,283] Trial 1389 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1389 | Epoch 01 | Train Loss: 21184.1216 | Val Loss: 18968.4449 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:45,524] Trial 1390 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1390 | Epoch 01 | Train Loss: 73152.3561 | Val Loss: 13639.0788 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:45,766] Trial 1391 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1391 | Epoch 01 | Train Loss: 17823.1403 | Val Loss: 18950.6869 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:46,030] Trial 1392 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1392 | Epoch 01 | Train Loss: 19462.9572 | Val Loss: 16107.3248 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:46,339] Trial 1393 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1393 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:46,642] Trial 1394 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1394 | Epoch 01 | Train Loss: 15985.8468 | Val Loss: 10899.3911 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:46,954] Trial 1395 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1395 | Epoch 01 | Train Loss: 20842.4790 | Val Loss: 20085.5173 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:47,258] Trial 1396 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1396 | Epoch 01 | Train Loss: 15467.8646 | Val Loss: 10945.2858 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:47,562] Trial 1397 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1397 | Epoch 01 | Train Loss: 37839.3445 | Val Loss: 26335.3550 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:47,951] Trial 1398 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1398 | Epoch 01 | Train Loss: 20275.0583 | Val Loss: 16797.6879 | Optimizer: Adam\n",
      "Trial 1399 | Epoch 01 | Train Loss: 14646.3719 | Val Loss: 9459.0959 | Optimizer: RMSprop\n",
      "Trial 1399 | Epoch 02 | Train Loss: 10775.9707 | Val Loss: 14160.0726 | Optimizer: RMSprop\n",
      "Trial 1399 | Epoch 03 | Train Loss: 11730.5512 | Val Loss: 12716.1852 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:48,362] Trial 1399 pruned. \n",
      "[I 2025-09-05 19:07:48,631] Trial 1400 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1400 | Epoch 01 | Train Loss: 20130.7599 | Val Loss: 18565.2963 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:48,868] Trial 1401 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1401 | Epoch 01 | Train Loss: 19098.5238 | Val Loss: 13677.2091 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:49,149] Trial 1402 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1402 | Epoch 01 | Train Loss: 116462.3071 | Val Loss: 37737.5477 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:49,465] Trial 1403 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1403 | Epoch 01 | Train Loss: 18235.2205 | Val Loss: 12924.1769 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:49,763] Trial 1404 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1404 | Epoch 01 | Train Loss: 20367.7616 | Val Loss: 16610.7802 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:50,033] Trial 1405 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1405 | Epoch 01 | Train Loss: 16318.9489 | Val Loss: 10970.2416 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:50,342] Trial 1406 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1406 | Epoch 01 | Train Loss: 19723.0174 | Val Loss: 17575.0007 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:50,765] Trial 1407 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1407 | Epoch 01 | Train Loss: 21494.2080 | Val Loss: 21297.0190 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:51,005] Trial 1408 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1408 | Epoch 01 | Train Loss: 23340.4284 | Val Loss: 20043.9328 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:51,344] Trial 1409 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1409 | Epoch 01 | Train Loss: 21524.2493 | Val Loss: 20814.1903 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:51,677] Trial 1410 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1410 | Epoch 01 | Train Loss: 19610.3975 | Val Loss: 10514.6600 | Optimizer: RMSprop\n",
      "Trial 1410 | Epoch 02 | Train Loss: 10896.7010 | Val Loss: 19538.7409 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:51,926] Trial 1411 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1411 | Epoch 01 | Train Loss: 14340.1406 | Val Loss: 12631.4447 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:52,211] Trial 1412 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1412 | Epoch 01 | Train Loss: 17907.6011 | Val Loss: 11355.8098 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:52,533] Trial 1413 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1413 | Epoch 01 | Train Loss: 14431.6077 | Val Loss: 10575.8276 | Optimizer: RMSprop\n",
      "Trial 1413 | Epoch 02 | Train Loss: 13707.5977 | Val Loss: 10936.3652 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:52,880] Trial 1414 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1414 | Epoch 01 | Train Loss: 4227904.6627 | Val Loss: 18688.3075 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:53,136] Trial 1415 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1415 | Epoch 01 | Train Loss: 19245.1998 | Val Loss: 15704.5881 | Optimizer: Adam\n",
      "Trial 1416 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:53,338] Trial 1416 pruned. \n",
      "[I 2025-09-05 19:07:53,572] Trial 1417 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1417 | Epoch 01 | Train Loss: 17741.8013 | Val Loss: 13034.3399 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:53,837] Trial 1418 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1418 | Epoch 01 | Train Loss: 19213.3368 | Val Loss: 12333.4331 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:54,104] Trial 1419 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1419 | Epoch 01 | Train Loss: 16443.3839 | Val Loss: 26918.3705 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:54,419] Trial 1420 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1420 | Epoch 01 | Train Loss: 43861.5906 | Val Loss: 20683.3480 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:54,662] Trial 1421 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1421 | Epoch 01 | Train Loss: 22224.9675 | Val Loss: 22416.1660 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:54,916] Trial 1422 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1422 | Epoch 01 | Train Loss: 485482.8890 | Val Loss: 15976.4044 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:55,167] Trial 1423 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1423 | Epoch 01 | Train Loss: 15617.3951 | Val Loss: 13144.8468 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:55,401] Trial 1424 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1424 | Epoch 01 | Train Loss: 20137.6833 | Val Loss: 17428.4611 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:55,744] Trial 1425 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1425 | Epoch 01 | Train Loss: 13691.9557 | Val Loss: 13909.0320 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:56,081] Trial 1426 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1426 | Epoch 01 | Train Loss: 19606.0512 | Val Loss: 16005.1189 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:56,486] Trial 1427 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1427 | Epoch 01 | Train Loss: 19457.4119 | Val Loss: 12939.6727 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:56,738] Trial 1428 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1428 | Epoch 01 | Train Loss: 15922.7145 | Val Loss: 11706.5995 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:56,986] Trial 1429 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1429 | Epoch 01 | Train Loss: 17558.4966 | Val Loss: 12282.2738 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:57,320] Trial 1430 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1430 | Epoch 01 | Train Loss: 21034.2793 | Val Loss: 20723.2811 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:57,595] Trial 1431 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1431 | Epoch 01 | Train Loss: 14555.1048 | Val Loss: 11851.8510 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:07:57,848] Trial 1432 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1432 | Epoch 01 | Train Loss: 20067.4175 | Val Loss: 16218.0322 | Optimizer: Adam\n",
      "Trial 1433 | Epoch 01 | Train Loss: 662200.1612 | Val Loss: 8741.8551 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 02 | Train Loss: 13055.8242 | Val Loss: 25550.5201 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 03 | Train Loss: 12256.0256 | Val Loss: 6191.7387 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 04 | Train Loss: 7294.5827 | Val Loss: 6525.9173 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 05 | Train Loss: 7456.0547 | Val Loss: 7240.9898 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 06 | Train Loss: 6997.6531 | Val Loss: 5993.8241 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 07 | Train Loss: 6702.3108 | Val Loss: 6096.0129 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 08 | Train Loss: 6922.3764 | Val Loss: 6366.6395 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 09 | Train Loss: 6852.3299 | Val Loss: 8020.7039 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 10 | Train Loss: 7310.5761 | Val Loss: 7952.2510 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 11 | Train Loss: 7030.7723 | Val Loss: 5838.4636 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 12 | Train Loss: 6301.6364 | Val Loss: 12898.8147 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 13 | Train Loss: 9756.5304 | Val Loss: 5560.7846 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 14 | Train Loss: 6946.8443 | Val Loss: 8846.1851 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 15 | Train Loss: 7670.0662 | Val Loss: 5802.8868 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 16 | Train Loss: 7182.6720 | Val Loss: 11745.0622 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 17 | Train Loss: 7271.4860 | Val Loss: 6436.7465 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 18 | Train Loss: 6783.4402 | Val Loss: 6304.2590 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 19 | Train Loss: 6323.8701 | Val Loss: 5735.0813 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 20 | Train Loss: 6502.6639 | Val Loss: 5517.8668 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 21 | Train Loss: 6162.7802 | Val Loss: 8922.4870 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 22 | Train Loss: 7276.2373 | Val Loss: 7374.5159 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 23 | Train Loss: 7049.7466 | Val Loss: 8545.1754 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 24 | Train Loss: 7220.4057 | Val Loss: 5391.0568 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 25 | Train Loss: 6799.5129 | Val Loss: 5415.4061 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 26 | Train Loss: 6283.7239 | Val Loss: 5405.8562 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 27 | Train Loss: 6245.7098 | Val Loss: 6453.1041 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 28 | Train Loss: 6453.1486 | Val Loss: 6344.4581 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 29 | Train Loss: 7329.6420 | Val Loss: 7256.9662 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 30 | Train Loss: 6431.4743 | Val Loss: 5465.1674 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 31 | Train Loss: 6163.6673 | Val Loss: 5242.8046 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 32 | Train Loss: 6042.9596 | Val Loss: 5515.8245 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 33 | Train Loss: 5984.2849 | Val Loss: 10204.0693 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 34 | Train Loss: 7480.4038 | Val Loss: 5270.4633 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 35 | Train Loss: 6214.8120 | Val Loss: 8520.4459 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 36 | Train Loss: 6883.0124 | Val Loss: 5391.9216 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 37 | Train Loss: 6311.5881 | Val Loss: 14094.9051 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 38 | Train Loss: 7805.0941 | Val Loss: 5263.5172 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 39 | Train Loss: 6012.3594 | Val Loss: 5308.3607 | Optimizer: RMSprop\n",
      "Trial 1433 | Epoch 40 | Train Loss: 6309.4164 | Val Loss: 7985.3248 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:02,192] Trial 1433 finished with value: 5242.804612147956 and parameters: {'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.32030727141327664, 'lr': 0.0009236011011224121, 'activation': 'GELU', 'optimizer': 'RMSprop', 'weight_decay': 3.8232930216781765e-05}. Best is trial 134 with value: 4556.067195939429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1433 | Epoch 41 | Train Loss: 7381.9126 | Val Loss: 9043.8335 | Optimizer: RMSprop\n",
      "Trial 1433 - Early stopping triggered at epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:02,500] Trial 1434 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1434 | Epoch 01 | Train Loss: 29308.8777 | Val Loss: 12038.0162 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:02,800] Trial 1435 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1435 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:03,071] Trial 1436 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1436 | Epoch 01 | Train Loss: 18217.2815 | Val Loss: 12782.9575 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:03,410] Trial 1437 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1437 | Epoch 01 | Train Loss: 15537.8466 | Val Loss: 10376.9972 | Optimizer: RMSprop\n",
      "Trial 1437 | Epoch 02 | Train Loss: 11143.6221 | Val Loss: 22065.1976 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:03,792] Trial 1438 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1438 | Epoch 01 | Train Loss: 30950.9791 | Val Loss: 13281.6161 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:04,044] Trial 1439 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1439 | Epoch 01 | Train Loss: 20157.1629 | Val Loss: 16701.3284 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:04,291] Trial 1440 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1440 | Epoch 01 | Train Loss: 19223.5211 | Val Loss: 14642.2410 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:04,703] Trial 1441 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1441 | Epoch 01 | Train Loss: 5436402.1012 | Val Loss: 20300.3184 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:04,978] Trial 1442 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1442 | Epoch 01 | Train Loss: 20575.4506 | Val Loss: 17870.6042 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:05,252] Trial 1443 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1443 | Epoch 01 | Train Loss: 272394.4988 | Val Loss: 17682.3611 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:05,517] Trial 1444 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1444 | Epoch 01 | Train Loss: 18492.5351 | Val Loss: 12784.7609 | Optimizer: Adam\n",
      "Trial 1445 | Epoch 01 | Train Loss: 14641.4826 | Val Loss: 11036.6444 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:05,724] Trial 1445 pruned. \n",
      "[I 2025-09-05 19:08:06,134] Trial 1446 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1446 | Epoch 01 | Train Loss: 15198.4684 | Val Loss: 10495.3627 | Optimizer: RMSprop\n",
      "Trial 1446 | Epoch 02 | Train Loss: 11243.3957 | Val Loss: 13414.8017 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:06,388] Trial 1447 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1447 | Epoch 01 | Train Loss: 20101.8403 | Val Loss: 16433.6566 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:06,757] Trial 1448 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1448 | Epoch 01 | Train Loss: 15406.0983 | Val Loss: 11089.9701 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:07,026] Trial 1449 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1449 | Epoch 01 | Train Loss: 15624.7219 | Val Loss: 11136.5883 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:07,296] Trial 1450 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1450 | Epoch 01 | Train Loss: 18138.5003 | Val Loss: 11281.8854 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:07,613] Trial 1451 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1451 | Epoch 01 | Train Loss: 93359.2450 | Val Loss: 39574.7591 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:08,024] Trial 1452 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1452 | Epoch 01 | Train Loss: 14775.9911 | Val Loss: 17513.0261 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:08,298] Trial 1453 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1453 | Epoch 01 | Train Loss: 20850.5299 | Val Loss: 18172.3704 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:08,595] Trial 1454 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1454 | Epoch 01 | Train Loss: 14864.6022 | Val Loss: 13344.4290 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:08,997] Trial 1455 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1455 | Epoch 01 | Train Loss: 18815.7008 | Val Loss: 11209.3536 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:09,332] Trial 1456 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1456 | Epoch 01 | Train Loss: 30319.8881 | Val Loss: 20948.4630 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:09,583] Trial 1457 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1457 | Epoch 01 | Train Loss: 14035.0804 | Val Loss: 13143.3287 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:09,836] Trial 1458 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1458 | Epoch 01 | Train Loss: 19911.3086 | Val Loss: 14156.5371 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:10,080] Trial 1459 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1459 | Epoch 01 | Train Loss: 17887.6566 | Val Loss: 12162.3950 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:10,336] Trial 1460 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1460 | Epoch 01 | Train Loss: 17248.7535 | Val Loss: 12388.1056 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:10,578] Trial 1461 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1461 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:10,949] Trial 1462 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1462 | Epoch 01 | Train Loss: 20491.1335 | Val Loss: 19560.8793 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:11,426] Trial 1463 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1463 | Epoch 01 | Train Loss: 2298311816.5839 | Val Loss: 555729.9745 | Optimizer: RMSprop\n",
      "Trial 1464 | Epoch 01 | Train Loss: 515609.2959 | Val Loss: 8185.4614 | Optimizer: RMSprop\n",
      "Trial 1464 | Epoch 02 | Train Loss: 13643.5425 | Val Loss: 10880.2089 | Optimizer: RMSprop\n",
      "Trial 1464 | Epoch 03 | Train Loss: 9578.6959 | Val Loss: 8811.6266 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:11,960] Trial 1464 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1464 | Epoch 04 | Train Loss: 8779.8665 | Val Loss: 10736.2067 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:12,221] Trial 1465 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1465 | Epoch 01 | Train Loss: 18994.2007 | Val Loss: 13397.2772 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:12,480] Trial 1466 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1466 | Epoch 01 | Train Loss: 15641.9168 | Val Loss: 15214.0386 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:12,794] Trial 1467 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1467 | Epoch 01 | Train Loss: 18649.9106 | Val Loss: 13984.1701 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:13,059] Trial 1468 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1468 | Epoch 01 | Train Loss: 23758.5320 | Val Loss: 14582.3644 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:13,323] Trial 1469 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1469 | Epoch 01 | Train Loss: 19226.7233 | Val Loss: 12484.1215 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:13,579] Trial 1470 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1470 | Epoch 01 | Train Loss: 20211.6925 | Val Loss: 16822.0178 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:13,830] Trial 1471 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1471 | Epoch 01 | Train Loss: 17372.8525 | Val Loss: 12492.9893 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:14,163] Trial 1472 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1472 | Epoch 01 | Train Loss: 16868.9434 | Val Loss: 11041.6793 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:14,425] Trial 1473 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1473 | Epoch 01 | Train Loss: 20667.9115 | Val Loss: 17291.5703 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:14,689] Trial 1474 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1474 | Epoch 01 | Train Loss: 21251.1334 | Val Loss: 14557.3532 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:14,955] Trial 1475 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1475 | Epoch 01 | Train Loss: 19647.0107 | Val Loss: 13984.4861 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:15,232] Trial 1476 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1476 | Epoch 01 | Train Loss: 20527.9572 | Val Loss: 18226.6162 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:15,570] Trial 1477 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1477 | Epoch 01 | Train Loss: 17078.2542 | Val Loss: 13784.7452 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:15,923] Trial 1478 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1478 | Epoch 01 | Train Loss: 15929.0577 | Val Loss: 10734.3109 | Optimizer: Adam\n",
      "Trial 1478 | Epoch 02 | Train Loss: 12729.1911 | Val Loss: 11058.6375 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:16,179] Trial 1479 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1479 | Epoch 01 | NaN loss detected so pruning trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:16,492] Trial 1480 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1480 | Epoch 01 | Train Loss: 269483.5642 | Val Loss: 18545.0640 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:16,771] Trial 1481 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1481 | Epoch 01 | Train Loss: 15230.7311 | Val Loss: 11909.2021 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:17,139] Trial 1482 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1482 | Epoch 01 | Train Loss: 20116.5448 | Val Loss: 17861.0220 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:17,442] Trial 1483 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1483 | Epoch 01 | Train Loss: 21786.5906 | Val Loss: 12799.4933 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:17,870] Trial 1484 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1484 | Epoch 01 | Train Loss: 60716.7922 | Val Loss: 16254.1712 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:18,144] Trial 1485 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1485 | Epoch 01 | Train Loss: 17197.3163 | Val Loss: 11015.6555 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:18,416] Trial 1486 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1486 | Epoch 01 | Train Loss: 19326.5176 | Val Loss: 16265.7303 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:18,779] Trial 1487 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1487 | Epoch 01 | Train Loss: 15680.0840 | Val Loss: 12234.2624 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:19,158] Trial 1488 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1488 | Epoch 01 | Train Loss: 20715.7121 | Val Loss: 18931.7451 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:19,439] Trial 1489 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1489 | Epoch 01 | Train Loss: 1548032.3762 | Val Loss: 26806.7775 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:19,705] Trial 1490 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1490 | Epoch 01 | Train Loss: 18949.5631 | Val Loss: 15651.7555 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:19,997] Trial 1491 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1491 | Epoch 01 | Train Loss: 14357.8883 | Val Loss: 11434.7730 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:20,367] Trial 1492 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1492 | Epoch 01 | Train Loss: 17174.7284 | Val Loss: 13700.1237 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:20,624] Trial 1493 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1493 | Epoch 01 | Train Loss: 19468.3810 | Val Loss: 16095.0691 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:20,880] Trial 1494 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1494 | Epoch 01 | Train Loss: 20974.8970 | Val Loss: 18115.7079 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:21,141] Trial 1495 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1495 | Epoch 01 | Train Loss: 17771.7714 | Val Loss: 13951.3197 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:21,432] Trial 1496 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1496 | Epoch 01 | Train Loss: 19763.8200 | Val Loss: 16371.3264 | Optimizer: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:21,804] Trial 1497 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1497 | Epoch 01 | Train Loss: 16110.4355 | Val Loss: 26811.7570 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:22,158] Trial 1498 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1498 | Epoch 01 | Train Loss: 22824.5520 | Val Loss: 20012.0282 | Optimizer: RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 19:08:22,425] Trial 1499 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1499 | Epoch 01 | Train Loss: 19507.4005 | Val Loss: 16001.9156 | Optimizer: Adam\n",
      "{'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.34404144200017467, 'lr': 0.0005555079210176292, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 9.056299733554687e-06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          6,
          8,
          12,
          16,
          57,
          64,
          66,
          81,
          82,
          83,
          134,
          135,
          138,
          143,
          145,
          149,
          150,
          152,
          155,
          156,
          172,
          188,
          189,
          190,
          194,
          195,
          196,
          198,
          210,
          215,
          236,
          267,
          363,
          415,
          502,
          516,
          540,
          577,
          617,
          667,
          879,
          893,
          934,
          943,
          952,
          1027,
          1069,
          1317,
          1322,
          1433
         ],
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499
         ],
         "y": [
          5197.783649209105,
          5052.430064260224,
          5052.430064260224,
          5052.430064260224,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4895.3238691165125,
          4888.95108748071,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4636.191819179206,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429,
          4556.067195939429
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "hidden_dim (CategoricalDistribution): 0.0028602114490254293<extra></extra>",
          "gnn_dim (CategoricalDistribution): 0.024608182635411698<extra></extra>",
          "activation (CategoricalDistribution): 0.025101398477464967<extra></extra>",
          "weight_decay (FloatDistribution): 0.03531742614566006<extra></extra>",
          "lr (FloatDistribution): 0.1264497467873633<extra></extra>",
          "dropout_rate (FloatDistribution): 0.13904856626615772<extra></extra>",
          "optimizer (CategoricalDistribution): 0.6466144682389167<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "0.02",
          "0.03",
          "0.04",
          "0.13",
          "0.14",
          "0.65"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0028602114490254293,
          0.024608182635411698,
          0.025101398477464967,
          0.03531742614566006,
          0.1264497467873633,
          0.13904856626615772,
          0.6466144682389167
         ],
         "y": [
          "hidden_dim",
          "gnn_dim",
          "activation",
          "weight_decay",
          "lr",
          "dropout_rate",
          "optimizer"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial0",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70
         ],
         "y": [
          21130.459044656636,
          18284.158444251545,
          10764.121895495757,
          10290.900197723766,
          9036.373824508102,
          10554.174678096066,
          8638.234760802468,
          8065.113926263503,
          7044.745599440586,
          7842.9243405189045,
          6498.429877387152,
          6362.244936342592,
          10151.112702546296,
          9062.97040171682,
          6256.006181881751,
          6804.726550443673,
          6389.500298394098,
          6850.132040895061,
          6044.416461709105,
          5958.092092255016,
          6063.027690369406,
          6266.6359622154705,
          5747.283103660301,
          5734.271824966242,
          5617.02209020544,
          5615.481960720486,
          5841.179684485918,
          5553.118604118441,
          5512.874285662616,
          5615.773654513889,
          5369.684814453125,
          5412.031370563272,
          5936.291648582176,
          6305.355791256751,
          5289.382444782022,
          5768.602906780478,
          7926.3174732349535,
          6106.298834153164,
          5514.347315658758,
          5599.137713396991,
          5756.351282190393,
          5330.026101948302,
          5282.262858072917,
          5362.62740825135,
          5464.0448163821375,
          5502.818799430941,
          5288.452284071181,
          5730.805371696566,
          5506.482458043982,
          5304.5914472415125,
          5634.2154224537035,
          5250.3598873939045,
          5324.108395423418,
          5741.418276186342,
          5415.240068600501,
          5258.515682267554,
          5202.207296489198,
          5373.393714433835,
          5503.284975405092,
          5197.783649209105,
          5730.798213252315,
          5304.779052734375,
          5441.780592930169,
          5572.647168571566,
          5984.694206331983,
          8724.453860435957,
          5468.744583695023,
          5447.841929494599,
          8130.544813368056,
          5354.331214433835
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48
         ],
         "y": [
          13732.5399727527,
          10173.125265239198,
          9593.901584201389,
          8103.350875289352,
          7833.393307532793,
          7152.483820408951,
          6746.556960117669,
          6321.312457802855,
          6901.493983892747,
          8169.69677734375,
          5942.3489824459875,
          6177.006022135417,
          7537.081446518133,
          9223.15363980517,
          7358.6395580150465,
          6228.552059220679,
          5562.085244261189,
          5451.015956548997,
          5281.004632643711,
          5288.632643711419,
          5155.12589216821,
          5220.568748191551,
          5337.365825135031,
          5451.971399377893,
          5220.132031852816,
          5113.931640625,
          5246.82406804591,
          5806.925151306906,
          5296.68709611304,
          5146.295774860147,
          5262.785599320023,
          5550.739025728202,
          5312.188277633102,
          5055.3495038821375,
          5719.273108965085,
          5171.554832175926,
          5213.852225597994,
          5052.430064260224,
          5214.967330367477,
          5395.171862943673,
          5125.516390576775,
          5133.605507933064,
          5337.50850272473,
          5105.699544270833,
          5115.053325135031,
          5320.265986689815,
          5193.482427903164,
          5198.209002459491
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial2",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65
         ],
         "y": [
          22543.503411940586,
          22414.076159818673,
          22379.308991608796,
          22353.14131221065,
          22327.39151716821,
          22298.944733796296,
          22263.821301118827,
          22223.258439429013,
          22187.527247299382,
          22152.49341724537,
          22112.9139298804,
          22069.554337866513,
          22018.593002507718,
          21965.222861207563,
          21909.79938271605,
          21835.612654320987,
          21742.777355806327,
          21644.275800540123,
          21529.724127121914,
          21389.78888165509,
          21229.3603515625,
          21031.75849971065,
          20772.90577980324,
          20496.561800733023,
          20190.312427662036,
          19859.3126326196,
          19474.678228684414,
          18963.624638310186,
          18430.28061101466,
          17931.530623070987,
          17358.251856674382,
          16762.003918306327,
          16165.600634162809,
          15539.96721884645,
          14966.213541666666,
          14437.14665316358,
          13893.228244357639,
          13540.659517264661,
          13320.872685185184,
          13134.573049286266,
          13010.213433159723,
          12946.00823447145,
          12890.209972993827,
          12846.46654369213,
          12828.640251253859,
          12829.824905960648,
          12844.085370852623,
          12862.447603202161,
          12875.333791473766,
          12876.217508198302,
          12852.345425829475,
          12844.124782986111,
          12854.036361882716,
          12841.010790412809,
          12828.505365065586,
          12843.51592640818,
          12841.432460455248,
          12829.085021219136,
          12831.547369309414,
          12856.414460358796,
          12872.554337866512,
          12867.04352334105,
          12868.358121141975,
          12941.921838831018,
          12978.93822337963
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial3",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56
         ],
         "y": [
          20547.843086902005,
          19040.59705343364,
          17618.543233989196,
          15874.334225501543,
          13387.792233314043,
          10640.47511574074,
          10541.794343171296,
          9569.072337962964,
          9736.461449893905,
          8944.388864776234,
          8303.275270061727,
          7918.353184076003,
          7483.863269193673,
          7300.00131413966,
          7087.7779224537035,
          6963.3062427662035,
          7417.460816936728,
          6724.798617139275,
          7745.822741849923,
          7226.702793451003,
          6457.806896821952,
          6301.074062017747,
          6128.3434003665125,
          6050.236587336034,
          5742.883608217592,
          5493.670669367284,
          5336.760793426891,
          5507.7913652584875,
          5327.966025270061,
          5850.54972029321,
          5654.392698688272,
          5313.628574701003,
          5729.499059606482,
          5367.4969165943285,
          5572.23951099537,
          5405.55830741223,
          5580.503933376736,
          5433.42638708044,
          6264.460147810571,
          5599.216423128858,
          5624.173210238233,
          5157.1023853443285,
          5489.182403187693,
          5565.759241174768,
          5214.076123649691,
          5137.008415316358,
          5255.089711130401,
          5243.33585310571,
          5227.518762659143,
          6529.274130738811,
          5793.2319094810955,
          5265.019256968557,
          5362.804087697724,
          5236.615478515625,
          5484.938346956983,
          5247.796914183064
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial4",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91
         ],
         "y": [
          19509.742513020832,
          17643.96600115741,
          15954.925998263889,
          14300.6932930652,
          12741.515884211034,
          11324.374963831018,
          10338.092435860339,
          10124.386031539352,
          9763.871250482252,
          9580.676275559414,
          9291.10419077932,
          8748.958526234568,
          8641.562102141204,
          8130.43334056713,
          8014.168728298611,
          7983.801281587577,
          7819.410740981867,
          7459.690285011574,
          7274.9217363522375,
          7213.669722945602,
          7214.158582899306,
          7121.602249710648,
          6835.581325954861,
          6661.291672694831,
          6472.233169367284,
          6328.011212384259,
          6190.235270182292,
          6025.221239631559,
          5938.543381679206,
          6097.195321542245,
          5622.267421392747,
          5610.625394844715,
          5717.650939187886,
          5603.858512972608,
          5583.980405454283,
          5533.303150318287,
          5531.959686656057,
          5777.371753833912,
          5570.2801830150465,
          5534.607840832369,
          5525.696937090085,
          5635.630895543982,
          5617.241331500772,
          5655.354275173611,
          5492.276795187114,
          5587.445200978974,
          5593.252911603009,
          5513.683283299576,
          5423.774673273534,
          5651.53628351659,
          5367.351809654707,
          5368.419502917631,
          5409.496265552662,
          5252.346911771798,
          5866.723539375965,
          6720.0188229407795,
          5646.989185474537,
          5728.544186439043,
          5298.840398341049,
          5234.1190019772375,
          5314.9003574701,
          5175.78136754919,
          5131.583622685185,
          5168.237756799768,
          5263.237178096065,
          5140.667287567516,
          5079.907268759645,
          5039.80025981385,
          5210.09297538098,
          5067.871865354939,
          5073.9891191647375,
          5020.402548707561,
          5013.791066864391,
          5256.896511501736,
          4916.266592520255,
          5961.515989703897,
          5623.082326630016,
          5214.751220703125,
          5033.337863498264,
          4903.129340277777,
          4895.3238691165125,
          5040.679994936342,
          5118.320737485533,
          5118.418698157793,
          4940.702395592207,
          5616.150468991126,
          4935.144100236304,
          5254.773859471451,
          5885.759663146219,
          5104.121747805749,
          4906.721815321181
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial5",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial6",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          17058.36222029321,
          10888.674581645448,
          9876.51715615355,
          10083.352647569445,
          8681.162929205248,
          9445.030671296296,
          8663.28303433642,
          8164.911247347608,
          7794.460087528935,
          7732.686029128086,
          7813.111297984182,
          7226.413857542439,
          7310.607066213349,
          7415.373046875,
          7372.272147472994,
          5955.07396556713,
          5688.390124662423,
          7210.531825689622,
          5952.262918354552,
          5819.228777850116,
          6825.961130401234,
          5880.826382860725,
          5512.525670934607,
          5251.736584321952,
          5173.171805676119,
          5613.328498746142,
          5477.383963879244,
          5476.782723885995,
          5451.038209514853,
          5214.413022641783,
          5183.321864752122,
          5261.549391758294,
          5353.090564115548,
          7917.655936535494,
          5990.662356529707
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial7",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "y": [
          12275.058473186727,
          10389.447157118055,
          9423.606975790895,
          9244.970263069059,
          8118.779730902777,
          6046.502498673804,
          6178.368323808835,
          5613.028257016783,
          5843.842315297068,
          5699.854715229552,
          6468.595335407022,
          6101.6251386477625,
          6349.6920482494215,
          5297.958140432099,
          5373.180733386381,
          6272.090187355324,
          5288.069456500772,
          5243.661259403935,
          5678.463146821952,
          5209.748604480131,
          5215.582878206983,
          5122.947328920717,
          5592.740644290124,
          5327.947527850116,
          5158.090946903935,
          5041.545129846643,
          6251.0351803626545,
          8250.165883005402,
          7480.335220148534,
          6773.676721643518,
          5243.637656129436,
          5108.57376362365,
          7580.842562451775,
          5393.010085117669,
          5242.07255196277,
          5084.126317153742
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial9",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          12629.296905140818,
          13156.957326630016,
          12765.74520158179
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial10",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21476.44684365355
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial11",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22584.6427107446
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial12",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          16345.153537326389,
          13088.452015817902,
          8550.414448302468,
          15311.116560570988,
          8351.200557002316,
          6383.970516251929,
          6144.934003665124,
          8554.869821807484,
          7402.305507330247,
          23018.76863908179,
          7034.75619695216,
          6263.936577690973,
          7553.680772569444,
          40830.07426697531,
          8125.193467881944,
          6458.262478298611,
          6187.651572145061
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial13",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22018.97576678241
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial14",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22098.07396556713
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial15",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21905.33576871142
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial16",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24
         ],
         "y": [
          14331.0536446277,
          10821.908564814816,
          10153.527006172839,
          9712.366506317516,
          8725.559371383102,
          7857.847204137732,
          6892.072771990741,
          6131.882505063658,
          5829.605523003473,
          5830.597713517554,
          5868.3436445071375,
          7672.444534866898,
          5573.867214626736,
          5304.862024377893,
          5355.657401379244,
          5850.941855348186,
          8328.53360701196,
          5609.131166811342,
          5970.717074170525,
          5360.644920066551,
          5508.3218828366125,
          5464.33736918885,
          7189.908172984182,
          5637.168821735147
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial17",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16
         ],
         "y": [
          11520.324315200618,
          10112.73853443287,
          9112.56177662037,
          9564.383252555941,
          8047.5243236400465,
          8117.714626736111,
          7198.639437451775,
          7143.04711009838,
          6904.932798032408,
          7627.7845293209875,
          6686.367066936728,
          8407.682581018518,
          8328.618037471066,
          10707.82468894676,
          9094.413381317516,
          7213.273497781636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial18",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22195.294355227623
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial19",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19968.06524884259
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial20",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          13885.356704523534,
          10417.547815393518,
          9843.540304301698,
          10242.675166377316,
          9899.936631944445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial21",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11665.287965374227,
          10970.842580536266,
          10653.904345100309
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial22",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14609.0360665027,
          11068.674491222993,
          10328.702606577932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial23",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18053.784384645063
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial24",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          15835.66779996142,
          10532.276343074845,
          10112.936716338734,
          9368.04929832176,
          8512.64372347608,
          8248.684039834105,
          7499.568781346451,
          9402.406979407793,
          7660.963559751158
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial25",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19246.31716579861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial26",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial27",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14728.246576003086,
          10520.706229504243,
          14888.918113425925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial28",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20785.44093605324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial29",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          91311.28607253087
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial30",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18904.986171392746
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial31",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20752.993610146605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial32",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21699.43401572145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial33",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21536.407853491513
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial34",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial35",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17818.452425733023
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial36",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial37",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22361.06756365741
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial38",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18043.488715277777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial39",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24857.85954378858
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial40",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22005.157636477623
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial41",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14458.290858892748,
          10284.417353877316,
          11899.628683207948
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial42",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11584.878068335262,
          10815.60203269676,
          11586.1464180652
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial43",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          16182.003303433641,
          13130.732602719907
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial44",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22058.86077353395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial45",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21620.472583912036
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial46",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial47",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14020.889485677084,
          12012.06231312693,
          10473.582790798611
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial48",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          15457.352189429012,
          10371.60126109182,
          10099.546248070988,
          10341.499572000386,
          10575.033824025848
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial49",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          12855.96647738233,
          11574.62958140432,
          10795.34031394676
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial50",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22055.172405478395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial51",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21427.52586082176
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial52",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21406.201111593364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial53",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20662.409456983023
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial54",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18851.039882330246
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial55",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21345.07384500386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial56",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20731.787121431327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial57",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          10029.48492959105,
          10761.607789592977,
          7536.236912856867,
          34195.063368055555,
          7386.005304783951,
          6407.871316792052,
          6124.606728636189,
          7831.525595582561,
          13881.560474537036,
          5805.001742139275,
          5803.771969642168,
          5684.650420765818,
          17455.448338638118,
          5981.935227382331,
          5972.366415895061,
          5678.424069251543,
          6473.958502121914,
          5396.922625506366,
          5370.617841555749,
          10105.503122588734,
          49512.516975308645,
          7528.33315851659,
          5412.256353684414,
          10079.007486979166,
          11521.247757523148,
          9408.581452546296,
          6635.041787229939,
          12870.670102719907,
          6119.774480372299
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial58",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          13324.988799672068,
          10286.077992380402,
          11517.52840470679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial59",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20198.457597897377
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial60",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          4044656.7067901236
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial61",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          13757.890444155093,
          10500.235737364968,
          10304.775993441359
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial62",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          11939.151252652391,
          12430.753930362655,
          9976.399775752316,
          10202.913483796296,
          9299.626711998457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial63",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21124.96135947145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial64",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26
         ],
         "y": [
          11762.432140962577,
          10569.985448013118,
          9488.332579812886,
          7711.590217496142,
          7533.444818190586,
          5625.641580463927,
          5503.011417341821,
          6224.273738908179,
          7746.31039617091,
          9147.68758439429,
          12409.902223186727,
          5925.68979070216,
          5973.9124590084875,
          6371.606134862076,
          5381.152901355131,
          5154.686996648341,
          6303.248215663581,
          5261.3783938560955,
          5409.640908323689,
          5331.125415943287,
          5667.136797116126,
          6301.523720823689,
          5708.11238908179,
          5334.29647111304,
          5399.921293282215,
          5161.772135416667
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial65",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          12189.583387586805,
          10806.129062982252,
          10465.51936246142
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial66",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
         ],
         "y": [
          15085.739782262732,
          10440.45108748071,
          9827.891625675155,
          8790.709936824845,
          7963.415708188658,
          5758.542197145061,
          6821.237624180169,
          5601.968828366126,
          6169.623866705247,
          5767.393051335841,
          6001.266547309027,
          5900.547055844908,
          5749.388708043982,
          6231.244357638889,
          6957.389576099537,
          10413.589023919752,
          6420.907338083526,
          6324.129828559027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial67",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12035.804970823689,
          11823.537459008488
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial68",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18782.699423707563
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial69",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19656.68844039352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial70",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17353.31329571759
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial71",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21981.19396219136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial72",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11187.677662037036,
          11887.2392578125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial73",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14355.167842158566,
          10596.860387731482,
          10658.591399016204
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial74",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19830.682978877314
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial75",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          28918.26936246142
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial76",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16159.756088445216
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial77",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial78",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22061.49924045139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial79",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          15637.024389949845,
          11411.970703125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial80",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16796.655719521605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial81",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25
         ],
         "y": [
          11322.819215374227,
          7680.284704137732,
          305281.9222608025,
          14665.968171296296,
          8259.759651089891,
          6207.634141710069,
          5659.168984495564,
          6085.776659553434,
          5471.852361231674,
          5655.082622010031,
          5620.912160614391,
          5496.001630618249,
          5397.322976948302,
          8429.078179253473,
          5256.830708068094,
          8166.196596498842,
          5402.538685739776,
          5394.814998673804,
          6226.440709997107,
          5672.627025462963,
          5376.235999590085,
          9457.693082079475,
          6004.11841724537,
          6411.167763792439,
          5962.839662905092
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial82",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43
         ],
         "y": [
          12809.956410349152,
          9024.608030719523,
          10740.598439911266,
          22035.29911747685,
          7830.876597463349,
          6076.301685474537,
          5909.925736038773,
          6337.357060185185,
          5856.3487865306715,
          11116.6944022473,
          8718.26368995949,
          5893.569366078318,
          7010.186999662423,
          6624.540702160494,
          8280.635802469136,
          5545.919156298225,
          7931.51968195409,
          5430.932894483025,
          13063.495105131173,
          8464.81056495949,
          23817.573543595678,
          7696.701967592592,
          5373.85570384838,
          5245.832172911844,
          5805.343466676311,
          14160.074098186727,
          6400.533444251543,
          5170.782341097608,
          5570.327166521991,
          5095.006362726659,
          4992.451265311535,
          5711.124906563465,
          4888.95108748071,
          5101.396906346451,
          5275.738781587577,
          7772.215946903935,
          9270.750753520448,
          7926.841025270061,
          5656.729052131559,
          7047.985303337191,
          5170.898145134066,
          7644.882107204861,
          7252.276397328318
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial83",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62
         ],
         "y": [
          10787.802842881945,
          11357.822163146218,
          6371.137918354552,
          14557.438639322916,
          6880.959346064815,
          6957.557674455054,
          5929.688783998842,
          5958.103298611111,
          7723.766613618827,
          5734.88626362365,
          6641.430067274306,
          11313.984429253473,
          6831.028326340664,
          6059.999147014853,
          8495.67531105324,
          20040.585358796296,
          5574.970660927855,
          6200.016179591049,
          5561.175841531636,
          5903.749590084876,
          5422.9427173755785,
          5535.264491705247,
          8017.052625868056,
          5743.376148365162,
          6556.2820879147375,
          12112.84595630787,
          6059.246208285108,
          5502.793824749228,
          6487.027211130401,
          6648.728690441744,
          5113.460608965085,
          5454.660674672068,
          5210.883855372299,
          5264.566786024306,
          9983.916883680555,
          5350.786735628858,
          6004.026035638503,
          4950.5632565345295,
          5445.970202787423,
          5492.784776475694,
          17000.103515625,
          6185.3706295814045,
          5106.416889708719,
          4778.93627025463,
          23891.720027970678,
          5558.842887972608,
          5081.90490270544,
          4898.072316864391,
          6166.5225995852625,
          4725.681740089699,
          10476.69987581983,
          4636.191819179206,
          6357.802234037423,
          9268.03076171875,
          4960.5667408130785,
          9933.651071807484,
          5033.438259548611,
          12458.597794897762,
          5306.101230951003,
          4860.767071759259,
          5212.944257571374,
          5432.117865668402
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial84",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          9257.543131510416,
          17223.761875482254,
          8308.220914110725,
          9842.25518422068,
          13174.758837287809
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial85",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          10238.987702546296,
          9592.83154296875,
          6227.6544355227625,
          5918.182029441551,
          14784.076774691359,
          7329.286862220293,
          7449.894253954475,
          38495.387008101854,
          7584.752700617284,
          10507.2763671875,
          5842.225528669946,
          7804.798333815586,
          5951.294258777006,
          8310.323423032407,
          8055.027759693287,
          5805.379626615548,
          9698.746937692902,
          10191.640088493441,
          7385.420042438272,
          11973.876121238425,
          6835.12875554591,
          5308.872986593364,
          5328.3724048755785,
          6225.950240523727,
          5411.143114631559,
          6914.09048273534,
          5334.074598524306,
          11895.549455054012,
          5771.2227466724535,
          10106.704107590664,
          21528.84100115741
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial86",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          216959.43094135803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial87",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16615.924599729937
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial88",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15159.549563560957
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial89",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14659.018892264661
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial90",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14547.707609953704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial91",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10535.264202353395,
          12343.69654224537,
          10191.729516300155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial92",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14571.530008198302
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial93",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          10709.2764334973,
          10866.52757884838,
          8798.206940827546,
          13009.793746383102,
          142528.8811728395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial94",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10801.973536361882,
          10422.76163435571,
          8131.815966194059,
          9363.406400704089,
          355547.775462963,
          12173.727991174768
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial95",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14248.398955922068,
          10552.555591724536,
          10696.458357445988
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial96",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17007.302059220678
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial97",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21053.07914978781
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial98",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9957.325472608025,
          9022.271610966434,
          10138.25974754051,
          7210.075213396991,
          7291.1439525462965,
          22627.972752700618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial99",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial100",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12411.983006606868,
          11306.336070119598
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial101",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18865.987039448304
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial102",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12419.281605661652,
          10837.880027488425
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial103",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17259.662567515432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial104",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          14041.705023871527,
          10657.264877507716,
          11252.654610339507
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial105",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17869.44871238426
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial106",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10725.954788773148,
          11302.875795717593,
          14461.644772376543
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial107",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17003.976863908178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial108",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          12845.786699459877,
          10246.63234230324,
          10899.379219714507
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial109",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18758.117091049382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial110",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19539.649715470678
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial111",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16445.688319830246
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial112",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          13159.00927734375,
          10776.16045765818,
          12554.854552469136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial113",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18571.803469810955
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial114",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11089.3154296875,
          12105.887514467593
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial115",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11829.692611882716,
          9947.300576292439,
          10804.520097897377
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial116",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17149.86234085648
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial117",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial118",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16634.082863136573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial119",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21344.204210069445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial120",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21885.537338445218
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial121",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15287.674008969907
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial122",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          13944.570264274691,
          10087.502338927468,
          9764.157238618827,
          8043.674358603395,
          6997.975857204861,
          7706.365686487268
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial123",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "y": [
          10306.21535011574,
          11050.253411940586,
          9745.042185088734,
          6863.445414978781,
          7854.630545910494,
          6469.23917341821,
          7016.7040684076,
          10610.628677179784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial124",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          12801.671838831018,
          10173.907009548611,
          10607.152602961034
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial125",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13808.175118152007,
          14092.023714795525
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial126",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          13886.796881028164,
          10554.820071373457,
          10415.385175540123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial127",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          13947.062469859182,
          11016.163923852238
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial128",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16582.75407503858
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial129",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15138.580222800925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial130",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14737.689079378859
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial131",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          1686043.1064814816
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial132",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14575.556110146605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial133",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          11772.553807388118,
          10164.779134114584,
          8566.746714650848,
          11707.576714409723,
          7848.238136574074,
          8556.121190200618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial134",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90
         ],
         "y": [
          8704.355830439816,
          12590.539888358411,
          11617.284818672839,
          6198.976315345293,
          8532.232470100309,
          9890.7285819348,
          6453.990511670525,
          8148.423369984568,
          7975.898322964892,
          20123.493176118827,
          6664.892032576196,
          6064.596257716049,
          8020.419186439043,
          7425.310661410108,
          26942.271074459877,
          6880.7391673900465,
          5795.965030623071,
          5295.087013527199,
          5770.888286072531,
          5647.922652633102,
          12512.00262827932,
          8475.457157841434,
          5169.785463686342,
          10367.168559510032,
          5716.68189380787,
          5373.861406491126,
          9245.086986400464,
          5485.297550154321,
          5112.765058352624,
          31924.60669849537,
          5930.329333646798,
          6603.751320167824,
          5071.148362147956,
          5004.229335455247,
          5869.447413315008,
          5795.353120780285,
          7377.830210744599,
          6371.885374469522,
          5808.805308400849,
          5126.632215711806,
          4921.395471643518,
          5181.7151120032795,
          6164.679440345293,
          42472.92619116513,
          5760.221260730131,
          15423.894290123457,
          5298.969364872685,
          5215.087489752122,
          6643.214415750386,
          5123.058367693866,
          4753.603615089699,
          5014.129521122685,
          6721.150547357253,
          6867.462390287423,
          4676.450846354167,
          6004.545169029707,
          4874.570393880208,
          4777.870930989583,
          5186.7743085696375,
          5981.708695023148,
          5104.229344497492,
          4700.374813126929,
          6062.595691068673,
          5867.312289014275,
          4657.862111786266,
          7100.884030189043,
          48894.98384452161,
          5105.573947482639,
          4917.234884379823,
          4873.992796344522,
          5001.395534939236,
          5648.115336853781,
          4643.751820505401,
          4712.398292824074,
          4951.048207224151,
          23225.234676408178,
          4806.604281201775,
          4638.79414725598,
          7833.525523244599,
          4556.067195939429,
          8296.547628520448,
          4645.462176287616,
          4751.192310474537,
          4680.698070384838,
          4729.145040629823,
          7634.598994502315,
          4705.92456958912,
          10358.461281105325,
          4781.425389419367,
          7402.118869357639
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial135",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
         ],
         "y": [
          12667.310944733796,
          10829.19987581983,
          7933.134343653549,
          7438.936155719522,
          8939.978606047454,
          5711.649221161266,
          7392.762490354939,
          10801.487196180555,
          6528.551194179206,
          8084.3983470775465,
          9723.978286554784,
          45753.48779899691,
          6780.967405719522,
          6517.115252459491,
          5577.422604407793,
          7216.995587384259,
          5529.453779055749,
          7104.5086835696375,
          6592.506576726466,
          6020.860194830247,
          8246.303313078704,
          5474.370358314043,
          5597.458761332948,
          5531.325671537423,
          6893.004430700232,
          6855.518976658951,
          5678.456753954475,
          5108.875099464699,
          6891.615951726466,
          5270.248658733603,
          7798.392608265818,
          5273.05142023534,
          6178.561113522376,
          10067.89374156057,
          8441.918854890046,
          5546.262966579861,
          22537.588517554013,
          6593.159053096065
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial136",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10476.091772762345,
          8031.4585865162035,
          11620.60498046875,
          8908.634765625,
          7814.602099006559,
          13383.546278211805
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial137",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10830.197470582561,
          14976.142795138889
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial138",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26
         ],
         "y": [
          12997.55534456983,
          9672.78143687307,
          7498.737624180169,
          7434.652307581018,
          15479.386477623457,
          6189.5673586998455,
          5938.839825665509,
          6475.9952558352625,
          5702.868441358025,
          10681.438524787809,
          5926.781644844715,
          8187.984549816744,
          6410.000223042052,
          8864.317057291666,
          5410.636664496527,
          5304.720594618056,
          5335.986765166859,
          11250.557954764661,
          5354.328342013889,
          5875.531454957561,
          5348.3095944251545,
          6095.523967978395,
          9175.100435233411,
          6796.497769579475,
          31934.002989969136,
          6023.524896315586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial139",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14851.043565538195
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial140",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          68072.55796682098
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial141",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10844.223608699845,
          9299.959587191359,
          56033.299430941355,
          7919.432412229939,
          7479.790491174768,
          8168.536868248457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial142",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11803.503647038966,
          13032.932689525464
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial143",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
         ],
         "y": [
          10449.294475790895,
          8761.63794849537,
          7349.977587287809,
          10041.219823013118,
          6557.205686969522,
          8759.649148823302,
          6981.950547960069,
          5845.8910228587965,
          15096.465000482252,
          6115.782443576389,
          6970.426507643711,
          5463.100908444251,
          8490.54241415895,
          11072.299225983796,
          5976.650396653164,
          5507.781907069831,
          5502.275062090085,
          28903.972077546296,
          5333.859573929398,
          5354.770730854552,
          13250.638466917439,
          5624.7463620032795,
          5217.774314597801,
          12729.122679157023,
          6714.917338806906,
          5445.025348427855,
          5948.983534071181,
          5611.061689211999,
          8147.969461323302,
          5528.198356722608,
          5421.827311197917,
          6072.119939356674,
          8989.907172309027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial144",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          12223.737895447532,
          35156.33907214506
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial145",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54
         ],
         "y": [
          11393.064025125386,
          9393.169126157407,
          7012.694010416667,
          6811.590157214506,
          5707.769814573689,
          5606.936716338734,
          20942.352647569445,
          6835.137339650849,
          6062.404278790509,
          6439.623758198302,
          5484.031759379823,
          5409.550030743634,
          7309.174744405864,
          5404.434133270641,
          6006.412347487461,
          5973.259379822531,
          6619.802354600694,
          6205.575749903549,
          5998.207187982253,
          13133.246069637345,
          5481.099916811342,
          5266.665310329861,
          5821.5315182532795,
          8044.847378954475,
          10311.659294222609,
          5882.456720799576,
          5215.952452859761,
          5232.750620900849,
          5158.291669680749,
          22140.143494405864,
          5443.491530430169,
          5310.942690248842,
          5177.44686173804,
          5079.509400921103,
          5070.963375892168,
          5996.406792534723,
          13310.56517650463,
          7309.519892939815,
          6360.595112364969,
          5216.336811583719,
          5356.8550045814045,
          5240.649025245949,
          5487.444456500772,
          4909.3860104407795,
          5661.487949701003,
          11234.310486593364,
          8029.237196180556,
          5265.322645399306,
          7468.729522328318,
          6581.543209876543,
          5515.299307364005,
          5080.862135898919,
          5442.991551528742,
          5064.625813802083
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial146",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13515.062451774691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial147",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13252.428632571373
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial148",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14824.222397038966
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial149",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          10175.68524546682,
          612614.4726080247,
          9623.120557243441,
          7025.638123312114,
          6749.896812909915,
          5739.676576967592,
          7216.685953776042,
          5586.379325207369,
          5386.708568431713,
          5755.285108024691,
          5408.545235339506,
          5901.956521870177,
          6035.709285783179,
          6037.687710985725,
          5408.032781153549,
          5803.100718557099,
          5950.990927613811,
          5544.102948977624,
          6108.417176046489
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial150",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32
         ],
         "y": [
          9269.157383294752,
          13505.676896460262,
          32213.166039737655,
          6843.114670741706,
          6258.149881245177,
          5983.260383511767,
          5649.18729805652,
          7292.871943721065,
          7126.701370804398,
          5472.337664568866,
          5689.25789689429,
          5490.47592351466,
          6798.175238715277,
          5805.379014756944,
          5398.015459225501,
          7507.514684606482,
          5519.111979166667,
          6610.359827112268,
          5353.413715880594,
          7281.262261284723,
          7291.475522641783,
          5208.045373987268,
          5892.136357060185,
          5928.004376446759,
          6356.166624469522,
          7830.970142505787,
          8738.97046802662,
          6473.158269434799,
          5223.030674310378,
          5274.477551118827,
          9158.233729986498,
          5308.094991801698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial151",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10550.3075508777,
          7251.244785638503,
          7905.709774064429,
          8631.798418209877,
          19380.252049575618,
          7967.081295814043
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial152",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62
         ],
         "y": [
          11223.326388888889,
          8445.415943287036,
          6188.599078896605,
          5826.371937692901,
          5908.48227117091,
          5556.91665461034,
          6237.602361231674,
          5561.812207634066,
          39634.490788966046,
          7780.985007957176,
          6128.766242886767,
          5661.727111062886,
          5317.546703197338,
          5760.68100163966,
          16103.255762924382,
          5397.980480806327,
          5328.575499734761,
          7704.723940248842,
          5367.652636115934,
          5186.537669994213,
          5267.26889226466,
          8998.032099971066,
          5348.314239125193,
          5305.9792721595295,
          6843.573923369984,
          5191.993646315586,
          5111.52108048804,
          6350.331853419174,
          5076.790777512539,
          5814.779134114583,
          5023.566786024306,
          7270.109784915124,
          6303.905873239776,
          9942.720443913966,
          8840.020266685957,
          9108.379430700232,
          5198.362645278742,
          5385.229254075039,
          5003.41365861304,
          5801.135874807099,
          5032.236686800733,
          5020.339515215085,
          7580.186619888117,
          18313.62053915895,
          5333.978172019676,
          5865.8320644049,
          11487.230685763889,
          5340.502911603009,
          4925.179214289159,
          4949.808367693866,
          5130.2908769772375,
          4899.03860737365,
          5685.349681712963,
          4900.759340639467,
          5055.661663290895,
          5171.587336033951,
          6095.641170548804,
          5115.706497757523,
          4990.118091724537,
          8276.006637008102,
          5020.331238546489,
          5472.025348427855
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial153",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13033.322277681327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial154",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          11801.656322337964,
          9896.60563753858,
          9472.919704861111,
          10000.000054253473,
          10928.020688657407
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial155",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42
         ],
         "y": [
          10072.605143229166,
          8547.627555941359,
          99696.45920138889,
          8334.70049672068,
          6689.0490963782795,
          5858.724901740934,
          6215.0522702064045,
          5512.588641131366,
          6303.368405189043,
          6650.608621479552,
          5437.914532696759,
          5582.803499951775,
          7305.588541666667,
          6524.313057605131,
          5389.496358989198,
          5364.141396604939,
          8714.598572530864,
          5268.797402464314,
          15192.436957465277,
          5396.987554856289,
          15538.498709972993,
          5340.365767867477,
          5181.064817828897,
          5493.052300347223,
          5570.886851369599,
          5692.927674093364,
          6132.844518590857,
          5137.109806013696,
          43155.24937307099,
          5415.975890359761,
          5724.58243513696,
          5036.295765817901,
          6329.44847728588,
          5140.310914592978,
          5107.575330946181,
          5336.414942611883,
          5072.087589216821,
          6064.230230637539,
          5641.580958236883,
          5155.17049455054,
          5731.379219714506,
          5928.291476779514
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial156",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
         ],
         "y": [
          9390.692280333718,
          11285.10284047068,
          7526.388472945602,
          7633.207905333719,
          10222.054530767748,
          6232.193956163194,
          6390.825315875772,
          5483.249786000193,
          7577.23253942419,
          5949.64086009838,
          15777.619249131945,
          6318.133349006559,
          5903.091905381944,
          6710.725296585648,
          6780.189474223573,
          5971.651798201196,
          10825.851176697532,
          6256.266688970872
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial157",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial158",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10453.686366705248,
          11066.981035397377,
          10847.576015142748
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial159",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24761.10312982253
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial160",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14639.374228395061
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial161",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11423.793191792052,
          10471.493441358025,
          40005.00226658951
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial162",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13046.315694926698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial163",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10578.755172164352,
          9661.515058352623,
          10641.963716483411
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial164",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12658.431954089507
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial165",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          11408.134102527007,
          10399.872847945602,
          8092.043270158179,
          11298.140209056714,
          9378.113444010416,
          8009.054374035494
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial166",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18968.329836998455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial167",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15330.305049189816
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial168",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13490.727207513502
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial169",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14918.35587263696
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial170",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12925.243091724536
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial171",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10920.417510609568,
          11618.078510802468
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial172",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27
         ],
         "y": [
          11658.870412567516,
          7321.4102948977625,
          41361.99990354938,
          7708.430380738811,
          8515.133831259645,
          6053.447645399306,
          13201.124722704475,
          9745.95393277392,
          6012.228714554398,
          8686.222800925925,
          5937.234094690393,
          5742.494363667052,
          5341.594108675733,
          10242.553602430555,
          5395.48227117091,
          7582.593086902006,
          5243.665801625193,
          6636.41365861304,
          6252.480911820023,
          7740.332242235725,
          9857.716435185184,
          7789.430597752701,
          5312.879747178819,
          5819.584406346451,
          9455.961431809414,
          5350.953396267361,
          5500.797845534336
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial173",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12280.263346354166
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial174",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10401.743393132716,
          10671.965723861882,
          9023.639793113425,
          12973.781732253086
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial175",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10753.090856481482,
          17809.965675636573,
          6670.659872926311,
          6407.079535590277,
          6612.375777633102,
          13324.875602816359
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial176",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10767.373058931327,
          13219.676275559414,
          54323.752507716046
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial177",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18195.431652681327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial178",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15338.729588638118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial179",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          11801.112310715664,
          9273.667070553627,
          10890.998263888889,
          7772.3984133873455,
          8339.008590133102,
          7598.834532937886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial180",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial181",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10601.682388117284,
          10484.978630160109,
          13585.824092158566
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial182",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12914.414189091434
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial183",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12380.667637201002
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial184",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10497.066225405093,
          14482.906744309414,
          20718.735146604937
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial185",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10776.401210455248,
          10285.97452498071,
          9598.988407841434,
          8400.510284047068,
          6314.415907118056,
          8206.158233265818
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial186",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12199.745937017748
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial187",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14717.122697241512
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial188",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54
         ],
         "y": [
          11387.689989631559,
          10241.409722222223,
          9318.369827835648,
          6748.177101417824,
          6001.326741536458,
          8987.991168740355,
          8786.07738353588,
          7644.480209538966,
          8311.234604070216,
          7459.357042100694,
          6770.247769579475,
          6031.655098620756,
          5729.908058449074,
          6565.23477888696,
          6315.051088686342,
          8302.088131751543,
          5976.962700737848,
          5996.882565345293,
          5218.613260151427,
          5331.792031370564,
          5362.1600025318285,
          5463.1346752025465,
          5632.707386911651,
          5415.044481819059,
          6404.926194179206,
          6262.24087336034,
          6885.921046127508,
          5153.030303578318,
          7403.03970148534,
          10131.861918885032,
          7299.870129243827,
          7075.52160192419,
          7034.817301432292,
          5178.5880443431715,
          5170.896526572145,
          5467.351677035108,
          5162.328212408372,
          5135.642150125386,
          5022.19258475598,
          5493.518907335069,
          5831.094352816358,
          5134.394308207948,
          5662.424563560957,
          4963.60376880787,
          5084.24052071277,
          5456.095070167824,
          5341.573956524884,
          5245.582332658179,
          5662.410312982253,
          5599.892746913581,
          6148.6981366946375,
          6944.92064525463,
          6507.875590760031,
          5284.1809323157795
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial189",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47
         ],
         "y": [
          11240.863968460648,
          10751.129665798611,
          8688.972620081018,
          8360.070197964891,
          6107.687873746142,
          7913.647430796682,
          6630.103952666859,
          6263.9434980227625,
          5930.211923104745,
          6135.669545114776,
          8679.459653501157,
          15923.686680169752,
          9704.334309895834,
          9294.40412808642,
          5814.183406876929,
          5835.996374059607,
          5374.74584056713,
          5511.840558087384,
          5248.140510464892,
          5309.121455439815,
          5600.939950448495,
          5379.685778959298,
          5500.8852780189045,
          5205.350230275849,
          5158.239384403935,
          5356.042423201196,
          5154.4701093508875,
          5188.313096788194,
          5527.089144483025,
          5723.337179301698,
          6255.493121865355,
          7852.533522617669,
          8595.104377652391,
          5196.8769862799,
          7081.38330078125,
          5083.122766565393,
          4965.00473210841,
          6615.264989028742,
          5186.856674382716,
          6312.513328269676,
          5440.388364438658,
          5275.1416015625,
          5116.701214072145,
          5256.894672911844,
          5757.104757426698,
          5343.6046308352625,
          5507.520320939429
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial190",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54
         ],
         "y": [
          10866.390817901234,
          9194.763852719907,
          7379.850423177083,
          5848.666220582561,
          5949.14016987365,
          5844.67736364294,
          5353.242769217785,
          6375.859809027777,
          5621.074294102044,
          5754.781904055749,
          6867.752971884645,
          5349.397693021798,
          5730.084777078511,
          5528.024344738619,
          5465.904155213156,
          5242.174964433835,
          5191.147801528742,
          5708.766288097994,
          5464.430823808835,
          5790.209288797261,
          6048.923623167439,
          6557.617742091049,
          5479.219193070023,
          5839.863513334298,
          5154.706976996527,
          5809.111300998264,
          5412.929780936535,
          5167.127510730131,
          5550.111150294174,
          5364.596462673611,
          5319.46883439429,
          5571.154688705633,
          5062.0516523196375,
          5224.214210792824,
          5235.263090157215,
          4987.273621358989,
          6038.156268084491,
          5009.44985773534,
          5272.083776403357,
          5397.293472101659,
          5989.820821879823,
          5180.06212926794,
          5246.572365089699,
          4838.967086226852,
          5191.806833526234,
          5653.149191020448,
          5185.842113353588,
          5323.569953824267,
          4869.152572820216,
          6481.38619731385,
          5088.714741271219,
          6742.57105396412,
          8103.484157986111,
          6008.500979576582
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial191",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10620.260464891975,
          11271.188856336805,
          12176.601146556714
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial192",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10802.81477261767,
          9925.116476176698,
          6874.3565357349535,
          6312.502296730324,
          7421.684784312307,
          6889.563229407793
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial193",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12635.744279272762
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial194",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
         ],
         "y": [
          10896.670187114198,
          10326.401276765046,
          8443.89406105324,
          6471.031436873071,
          6098.198130666474,
          7731.433717327353,
          10604.310136959877,
          8203.983452690973,
          7766.490517698689,
          5747.002112871335,
          5378.617717978395,
          5344.823368778935,
          5496.539318696952,
          6988.588023244599,
          7422.607735339506,
          8432.368152006173,
          5724.071029851466,
          5366.827458887924,
          5375.322380160108,
          5457.302598741319,
          5183.246413242669,
          5222.584080825617,
          5165.112871334876,
          5705.965922791281,
          6276.9244550540125,
          5351.836962287809,
          5499.596911771798,
          5619.535282841435,
          6173.2399661217205,
          5783.9057858314045,
          5764.3204029224535,
          5215.562032817323,
          5255.8869387779705
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial195",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          10210.380111882716,
          10602.14778043017,
          8051.2110279224535,
          5679.030345775463,
          6459.487446349344,
          5835.320993682484,
          6275.168734326775,
          5936.082784770448,
          6489.969515576775,
          7097.711920090664,
          6853.602906780478,
          6238.433497299383,
          5953.381525487076,
          5383.680923273534,
          7148.042368947724,
          5968.779019579475,
          6581.410276813272,
          5470.728232301311,
          5326.912917148919,
          7586.014328944831,
          5267.644483024691,
          7053.524191020448,
          7446.703709731867,
          8659.943877797068,
          6452.827341338734,
          5423.3738847897375,
          6454.079981674383,
          5806.558412905092,
          5587.25203751929,
          5779.777404031636,
          6991.9090892650465
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial196",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44
         ],
         "y": [
          11119.2442069348,
          9821.994038146218,
          8093.78891179591,
          6556.759633005401,
          8575.548056520061,
          5394.537700135031,
          6526.013599537037,
          7255.074158468364,
          5904.319932725694,
          7307.01326798804,
          6033.859537760417,
          5410.92460274402,
          5551.866153669946,
          6038.0775462962965,
          5294.688548900463,
          5645.031310281636,
          7811.521430121527,
          7195.654637466242,
          5551.049693166474,
          5633.304443359375,
          5388.722930531443,
          5391.1167233314045,
          5898.984182098766,
          5062.999996985918,
          5502.809136284723,
          5971.997775607639,
          5466.275945216049,
          5068.089415750386,
          5059.045594015239,
          5439.16845703125,
          5787.6727460696375,
          5381.8631908275465,
          5569.82266951196,
          5037.231948664159,
          5054.858326099537,
          5085.746832200039,
          5140.51306604456,
          5109.348117404514,
          5735.756293402777,
          5061.465238594715,
          5954.086989414544,
          5130.962571132331,
          5440.491232036073,
          7956.426806037809
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial197",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16670.11684992284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial198",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
         ],
         "y": [
          10205.807930652007,
          9261.807731722609,
          6663.425702883874,
          7124.827226803626,
          6975.173439308449,
          5944.955753279321,
          12140.622094425155,
          8651.429205246914,
          6243.820607880016,
          6759.001220703125,
          6289.286229263117,
          6120.874671465085,
          5585.280604986497,
          6627.431161385995,
          10726.813301745757,
          5845.344985773534,
          5979.103889371142,
          6273.195197964892,
          5314.126501012732,
          5326.674090350116,
          5415.788194444444,
          5531.949465904707,
          5244.769401644483,
          5619.054491584684,
          6172.265082465277,
          5328.815110194831,
          8161.041624469522,
          5486.330828631366,
          5304.797526041667,
          6232.577703028549,
          5535.629635657793,
          5326.51734302662,
          5275.934829523534
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial199",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11777.7685546875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial200",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10766.651288821373,
          10301.998306086034,
          8774.730293933257,
          8948.957175925925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial201",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12713.185788001543
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial202",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12174.209544994214
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial203",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10181.070023148148,
          10518.849995177468,
          12104.059178481868
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial204",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11293.076159818673,
          10589.315140335648
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial205",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16307.087432484568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial206",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10779.727551118827,
          10463.3408866223,
          10029.143602912809
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial207",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10392.311378761575,
          11929.04069613233,
          11457.562632619598
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial208",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11057.735767505786,
          10989.101689091434
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial209",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12208.622998649691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial210",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          11034.889304832175,
          10153.087944878473,
          8926.71410228588,
          6920.126169463734,
          5855.988787615741,
          7166.556899836034,
          5833.231285566165,
          6546.627411265432,
          9588.858603395061,
          7323.447705680941,
          5977.463363835841,
          6361.973979431906,
          7107.605938946759,
          6967.842378592785,
          7857.589415750386,
          6801.24307966821,
          6033.547613450039
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial211",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11728.518120659723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial212",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12671.379382474923
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial213",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20876.96229986497
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial214",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19324.918969425155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial215",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "y": [
          10804.750217013889,
          8114.6863847897375,
          6668.293800636574,
          5787.8919994212965,
          5489.277687355324,
          5521.508605203511,
          5396.346625434027,
          6453.742160373264,
          5466.309407552083,
          9136.453601224923,
          10206.51414207176,
          5514.417543764467,
          5744.283543716242,
          7192.812005690586,
          5447.583773389275,
          5536.224148220486,
          5653.3785083912035
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial216",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11899.948181905864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial217",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17733.180652006173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial218",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16774.655394000773
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial219",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16893.531008873455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial220",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial221",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11546.663495852623
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial222",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10893.641710069445,
          10620.792944637345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial223",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10445.209514853395,
          10415.236364293982,
          9385.797857590664
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial224",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12408.289725597993
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial225",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17975.633933738427
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial226",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11900.789695457175
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial227",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13741.749572000386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial228",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          34372.202883873455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial229",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22278.468400366513
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial230",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21449.304711612655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial231",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15925.188247492284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial232",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12652.328281732252
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial233",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13778.879406587577
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial234",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          132887.4436728395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial235",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13657.087179301698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial236",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27
         ],
         "y": [
          10962.913773148148,
          9298.521195023148,
          7151.890661168982,
          95594.91136188271,
          8806.923550829475,
          6130.185215326003,
          6245.492500964506,
          6067.117588372878,
          5990.36841724537,
          5952.929090711806,
          6253.805706259645,
          7428.053096064815,
          5607.892623336227,
          5391.762454185957,
          7271.7359453366125,
          6852.311650028935,
          5294.435598114391,
          7194.295690465857,
          5448.406756365741,
          5708.900197723766,
          6086.283100646219,
          5922.673686463156,
          9256.963306568286,
          9750.66431568287,
          5482.491536458333,
          5308.968472704475,
          5399.846495828511
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial237",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20419.306785300927
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial238",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11309.798671392748
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial239",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13340.484332802855
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial240",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14225.369634934414
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial241",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10427.65030623071,
          10391.552203896605,
          11368.862316743827
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial242",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12634.572663483796
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial243",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11632.270411361882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial244",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10243.531322337964,
          8943.21336082176,
          7113.747685185185,
          6373.000777633102,
          8628.006709346066,
          7327.666862581983
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial245",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12400.654724874614
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial246",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14447.498125241127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial247",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18351.01889226466
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial248",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11127.823579764661,
          11110.532407407407
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial249",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          147721.54089506174
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial250",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21667.83945794753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial251",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16944.11408902392
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial252",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19986.340386284723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial253",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18524.256474247686
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial254",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10660.82022810571,
          17523.074785397377
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial255",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20380.649679301696
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial256",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12197.95947265625
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial257",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial258",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13357.983452690973
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial259",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17598.404188368055
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial260",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12973.983856577932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial261",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12908.773154176311
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial262",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17440.990728684414
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial263",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          65669.64795524691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial264",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10690.460177951389,
          10274.518518518518,
          9289.611279899691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial265",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12610.382330246914
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial266",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14033.605324074075
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial267",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18
         ],
         "y": [
          9321.445939429012,
          7228.112889419367,
          6188.077558352624,
          5913.84033203125,
          5674.654438536844,
          5487.8808834876545,
          6875.638195650077,
          5369.706063729745,
          5712.708881896219,
          6186.771722487461,
          6761.383960865162,
          5913.002046561535,
          6275.12606095679,
          6569.930736400463,
          6150.856035397376,
          6762.315923996914,
          15885.851875964507,
          5424.368691526814
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial268",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17571.085310570987
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial269",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21112.44896556713
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial270",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18051.59184510031
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial271",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11853.957404996141
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial272",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20741.916425540123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial273",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11082.769338348766,
          11076.019302179784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial274",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26678.30765335648
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial275",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15129.716796875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial276",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10461.165159625773,
          84840.89477237655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial277",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13973.23876953125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial278",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20969.074375482254
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial279",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10466.996298707561,
          9213.793770495757,
          6547.673436294367,
          6933.224729938272,
          14053.958146460262,
          6626.395435474537
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial280",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16120.343038676698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial281",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial282",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14280.307906539352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial283",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11054.67717978395,
          10757.564766589507
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial284",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13357.417534722223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial285",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11660.195451147762
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial286",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20733.32209683642
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial287",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          41934.600067515436
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial288",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13850.464530285493
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial289",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10836.820601851852,
          13023.87279369213
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial290",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17763.381221064814
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial291",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10595.059522087191,
          10118.303976176698,
          7558.6309497974535,
          9769.316997010032,
          12365.525752314816,
          6468.611068913966
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial292",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21919.314863040123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial293",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21092.982940297068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial294",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12971.851098331405
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial295",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13467.570957513502
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial296",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10985.251579378859,
          14088.809919945988
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial297",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17285.988908179013
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial298",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12868.292926552855
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial299",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11205.314790702161,
          10527.589084201389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial300",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19950.49158468364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial301",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11122.648509837964,
          10534.864378375773
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial302",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15196.189429012345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial303",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10049.166775173611,
          10058.308629918982,
          36211.66194058642
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial304",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18499.05642361111
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial305",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial306",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14661.182520736882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial307",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19251.87053915895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial308",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22436.66096402392
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial309",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10861.624288676698,
          51528.9548128858
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial310",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14549.902373890818
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial311",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14028.769284095293
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial312",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17135.431954089505
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial313",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13519.297104070216
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial314",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18538.7596330054
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial315",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15962.206995081018
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial316",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12026.477394386575
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial317",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15700.680796682098
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial318",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10121.555519386575,
          9330.86563826196,
          13590.77899546682
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial319",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14149.717568479939
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial320",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11047.746479552468,
          11508.948459201389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial321",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13107.926365981868
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial322",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18461.968014564045
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial323",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10483.92163990162,
          9186.59009693287,
          8037.073073398919,
          11286.27830222801
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial324",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14226.901017554012
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial325",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15777.081416377316
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial326",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14600.422441647377
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial327",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24248.15128279321
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial328",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10752.047791280864,
          10331.158661265432,
          10035.84026572145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial329",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20657.960949556327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial330",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial331",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15103.815694926698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial332",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20974.825810185186
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial333",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13971.381968557098
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial334",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16531.162434895832
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial335",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10063.398744936343,
          33215.9587191358,
          8588.895435474536,
          8658.055031105325
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial336",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12771.038749035493
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial337",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11700.1708984375
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial338",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23913.27165316358
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial339",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13411.586208767361
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial340",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12632.386507764275
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial341",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12501.74462890625
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial342",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21824.83004195602
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial343",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12334.10105613426
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial344",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19264.38764708719
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial345",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22084.06253616898
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial346",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15936.569480613425
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial347",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12060.322488667052
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial348",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20696.95762201003
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial349",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11737.382734133873
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial350",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10672.020869502316,
          13686.984332802855
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial351",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14729.417088638118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial352",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18075.398341049382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial353",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11855.774926456405
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial354",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial355",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11897.817093460648
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial356",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11115.877537856868,
          9259.83831259645,
          13218.66162109375
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial357",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16259.217966338734
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial358",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21105.597198109568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial359",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22579.804808063273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial360",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18101.24575617284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial361",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14429.092556423611
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial362",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10135.302830825618,
          10513.317491319445,
          23011.310980902777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial363",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          11128.763159481095,
          9478.779345100309,
          7718.2218183352625,
          5505.412591628086,
          7237.9418704185955,
          7400.92248083044,
          8359.670940634645,
          6673.418309341242,
          5796.867672767168,
          8656.432351948302,
          6815.783474392361,
          5795.8896484375,
          6509.323682243441,
          6604.855743031443
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial364",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18534.854552469136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial365",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14825.556562258873
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial366",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17478.7373046875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial367",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          95880.38078703704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial368",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19333.229841820987
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial369",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19010.032708815586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial370",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11826.854877989968
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial371",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14115.360514322916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial372",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21773.40672019676
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial373",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12517.7520194348
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial374",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22791.460744598764
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial375",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11418.57332658179
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial376",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12617.807641300155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial377",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14620.086799527391
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial378",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial379",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11858.99846884645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial380",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21833.731143904322
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial381",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20592.58101851852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial382",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13279.672797309027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial383",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10472.443636670525,
          10096.834147135416,
          10428.753851996527
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial384",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20510.413532021605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial385",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20218.150185667437
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial386",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18103.03519241898
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial387",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14065.718418451002
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial388",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18272.833031925155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial389",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12520.676106770834
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial390",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17858.69034529321
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial391",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11591.999565972223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial392",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16910.81318721065
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial393",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16981.95721209491
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial394",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23242.663242669754
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial395",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14367.477267795139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial396",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11005.873794367284,
          9641.095100308641,
          9235.086528260032
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial397",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15174.606131847993
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial398",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20344.156659915123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial399",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20314.264636381173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial400",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12182.944088782793
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial401",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14048.342749324845
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial402",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          1141041.264660494
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial403",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16835.55239679784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial404",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11835.752791039738
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial405",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15097.237714602623
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial406",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14961.404116030093
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial407",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11688.697964891975
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial408",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10836.096100983796,
          10464.083043981482
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial409",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10657.699206693673,
          11105.6377616223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial410",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18225.994996624227
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial411",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19074.88577835648
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial412",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          11138.622082368827,
          8681.526728877316,
          12347.91544294946,
          10702.690061969523
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial413",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10783.102816358025,
          10542.213770736882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial414",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19335.24740788966
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial415",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24
         ],
         "y": [
          7948.592900028935,
          13049.904320987655,
          13204.263545283566,
          5955.836902006173,
          6170.012445143711,
          5535.440185546875,
          10266.24119285301,
          5741.330708068094,
          8018.871340904707,
          14137.759415991512,
          11520.630871431327,
          5490.792546778549,
          6101.714213806906,
          5418.104025004823,
          5636.988522376543,
          5623.328977985147,
          40970.9899691358,
          8947.993664400077,
          6025.939664110725,
          46078.60624035494,
          6870.0530840084875,
          6899.223210841049,
          6525.375783661266,
          5938.9178783275465
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial416",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14842.77048972801
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial417",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14029.83797501929
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial418",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22066.830934124227
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial419",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17960.6886091821
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial420",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12489.003562644675
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial421",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18912.065538194445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial422",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20807.89079378858
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial423",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10444.576955536266,
          12323.667812017748
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial424",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12514.703872492284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial425",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13271.553439670139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial426",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10613.652078510802,
          10342.967556423611,
          9771.44580078125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial427",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial428",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17501.062656732254
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial429",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11549.216827015818
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial430",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10604.93830777392,
          10540.995726032023
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial431",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11484.265866126543
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial432",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15742.645917727623
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial433",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16617.897822627314
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial434",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22437.89521846065
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial435",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15096.195619936343
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial436",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13629.303554205248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial437",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11606.636797116127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial438",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13273.466664255402
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial439",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21027.70681423611
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial440",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16120.614535108025
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial441",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13092.039779851466
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial442",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19711.76622781636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial443",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11989.908347800925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial444",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14170.250343605325
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial445",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14922.060329861111
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial446",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10338.067189911266,
          10961.115366994598,
          9161.392053674768
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial447",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13013.053783275464
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial448",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13186.339500144675
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial449",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21008.613437982254
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial450",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15501.120358314043
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial451",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16463.606879340277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial452",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial453",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          49502.67824074074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial454",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18630.728322723764
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial455",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19349.947072723764
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial456",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19669.40556278935
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial457",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11489.251308111498
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial458",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15975.772075135032
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial459",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19410.504171489196
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial460",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21357.35118875386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial461",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11486.293420862268
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial462",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13709.775270061727
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial463",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14297.316020447532
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial464",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16447.57073447145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial465",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24523.021207079477
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial466",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18902.927083333332
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial467",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13201.903549382716
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial468",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21140.978503568673
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial469",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13975.08856577932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial470",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10474.08406876929,
          13108.50653452932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial471",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11465.188627266589
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial472",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12007.035620418595
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial473",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14818.084062741127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial474",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15990.361508969907
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial475",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11329.756558641975
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial476",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14685.296844859182
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial477",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11777.0487618152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial478",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial479",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19417.802758487655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial480",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10215.642433449075,
          9948.873040846836,
          8958.887683256173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial481",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19102.35271990741
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial482",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15550.748167438273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial483",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11065.0185546875,
          10432.236358265818
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial484",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10559.586455922068,
          33440.157118055555
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial485",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20523.793318383487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial486",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12622.224506896218
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial487",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10662.800347222223,
          917309.1836419753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial488",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16888.527319637345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial489",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          319072.2426697531
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial490",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12266.305929301698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial491",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21407.115427276236
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial492",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12358.563693576389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial493",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22374.011742862655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial494",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17104.032455632718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial495",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17402.312656732254
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial496",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16932.26111593364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial497",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12662.290750385802
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial498",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17780.8857421875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial499",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13110.375759548611
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial500",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial501",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19875.400704089505
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial502",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          9653.574881847993,
          8331.397231867284,
          7511.772352430556,
          8145.456060715664,
          5830.473213855131,
          6291.9876543209875,
          6119.379352334105,
          10462.28971956983,
          5299.791850525656,
          20941.179060570987,
          7615.057460455247,
          6209.539683400849,
          8396.570414978782,
          5436.483115113811,
          7310.152476369599,
          5315.435507691936,
          20163.117922935955,
          15723.290641878859,
          5304.468686704283
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial503",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18072.92670958719
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial504",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21701.81428433642
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial505",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12352.32566550926
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial506",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "y": [
          10238.171447000386,
          10862.146616994598,
          6527.126519097223,
          6173.750868055556,
          6484.379843629436,
          6239.865113811728,
          14569.104184751157,
          6496.531436873071,
          98285.64863040124,
          13044.966531635802,
          6800.610339506173,
          8917.16382740162
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial507",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20331.15505642361
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial508",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11412.22784047068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial509",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10727.501121238425,
          14979.533377941743
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial510",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13924.163182388118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial511",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26239.658275462964
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial512",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18386.95920138889
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial513",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14344.651409384645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial514",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12979.352086950232
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial515",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10718.95533130787,
          10184.12843605324,
          9180.078010464891
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial516",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          10698.182484567902,
          6756.253683207948,
          6818.967698085456,
          5678.330373505016,
          6121.891104239005,
          6623.991385754244,
          6086.791488835841,
          51001.28689236111,
          6177.717767409336,
          5489.215196397569,
          7820.050552179784,
          5356.477912808642,
          5365.408136815201,
          7229.738480179398,
          5270.682764877508,
          5947.97607421875,
          5850.494942370756,
          5623.76131486304,
          12904.362883391204,
          6436.505319854359,
          7194.734417197145,
          4841.823649088542,
          4839.576259283372,
          5582.413495852624,
          4979.896978684414,
          10569.497902199075,
          4997.670193142361,
          5225.9438717689045,
          4858.324538242669,
          20913.313681520063,
          4819.421615788966,
          5217.201183931327,
          4824.625669126158,
          6468.637529538001,
          8154.82203052662,
          36239.804880401236,
          6697.247326509452,
          5297.482608748071,
          5170.958062065973,
          5742.914056471836,
          5073.426173080633
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial517",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13650.409915123457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial518",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12015.97728587963
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial519",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18297.98693094136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial520",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12226.101429880402
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial521",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11387.074339313273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial522",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15829.897774402007
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial523",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10923.128086419752,
          12748.57049937307
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial524",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10175.817087432484,
          8790.366373697916,
          10298.617308063273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial525",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15732.523172260802
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial526",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11143.326605902777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial527",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20009.818600501545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial528",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10455.583297164352,
          11883.736593364198
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial529",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13947.658160927855
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial530",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial531",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13828.635669849536
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial532",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13179.33888527199
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial533",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13764.320812837577
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial534",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12404.708875868055
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial535",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14584.893120659723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial536",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12700.975531684027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial537",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12907.519657841434
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial538",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12768.477967062114
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial539",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11842.912211853782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial540",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58
         ],
         "y": [
          11016.165286217207,
          9968.448573736498,
          6846.7231686439045,
          9266.726713204089,
          6504.1738522376545,
          6039.732849874614,
          7799.827067057292,
          42086.84553433642,
          5874.495346257716,
          5465.376076027199,
          6359.262870129244,
          8622.903784481095,
          5853.1767336998455,
          7937.908703462577,
          5539.295331790124,
          6143.584285783179,
          13083.928903838734,
          5506.335678288966,
          5392.68712926794,
          7485.121618200232,
          11547.510464891975,
          9131.618549864968,
          5461.517529899691,
          5317.892725815008,
          7791.728256413966,
          5343.875129605517,
          5310.323742525077,
          11263.7041015625,
          5421.451949508102,
          6075.007655767747,
          5744.09802698206,
          5106.37264298804,
          5242.97449182581,
          6730.015631028164,
          5069.245090060764,
          11006.75789689429,
          7090.11572265625,
          5925.45240162037,
          6000.569375120564,
          5319.215350115741,
          5036.82832694348,
          6623.504364390432,
          5316.735029055749,
          5324.064410927855,
          5350.0901933834875,
          4973.1639570071375,
          5005.782702787423,
          4956.010054976852,
          5075.446370442708,
          7149.714976369599,
          6405.938633294753,
          14114.725465374227,
          5503.162211853781,
          6221.52279851466,
          5121.129307122878,
          8504.664978780864,
          5065.899471330054,
          5554.626076027199
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial541",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10056.922393422068,
          13278.01104359568,
          7058.309588396991,
          12011.349609375,
          6822.270550009645,
          9796.726080246914
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial542",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12101.783414110725
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial543",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15990.377447434414
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial544",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17331.8719376929
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial545",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13179.328745900848
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial546",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19301.578064718364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial547",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10439.986099054784,
          10423.743688512732
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial548",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17110.930205922068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial549",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11988.886338975695
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial550",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19122.926998939045
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial551",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial552",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          87380.12991898147
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial553",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17733.24846884645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial554",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11495.957712432484
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial555",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11550.792793933257
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial556",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19142.207127700618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial557",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10436.266541280864,
          13558.891987364968
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial558",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10882.35343123071,
          10360.2705078125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial559",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11474.02195457176
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial560",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19448.70949074074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial561",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          30837.874686535495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial562",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18390.949568383487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial563",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12094.126054928627
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial564",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11055.196602527007,
          10894.429060570988
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial565",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11010.039122781636,
          10386.845528308257
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial566",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12443.415497202932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial567",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18960.43911554784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial568",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          60053.268614969136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial569",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15926.38744212963
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial570",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13986.919530044368
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial571",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          346639.62924382713
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial572",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17528.222173996914
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial573",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16964.94118923611
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial574",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial575",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          36631.69442033179
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial576",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13244.79808666088
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial577",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60
         ],
         "y": [
          10677.862425250773,
          6774.368917582948,
          9139.228021315586,
          5876.252477575232,
          8576.422315055941,
          10123.474211516204,
          9175.11686800733,
          9506.190640673225,
          7129.648913724923,
          5517.343882619599,
          10700.030629099152,
          6116.722032335069,
          8977.220329378859,
          9526.313826195988,
          5312.724422501929,
          5253.913532021605,
          5716.256823881173,
          5784.314772617669,
          7215.806339216821,
          9294.762399932484,
          8660.336817611882,
          5642.297082971643,
          5551.290002893518,
          5513.608519000772,
          5119.875575689622,
          5491.281373577353,
          11688.525854793595,
          5120.591631100501,
          6633.399793836806,
          5099.386134018133,
          8209.423279562114,
          25815.316767939814,
          7899.391185619213,
          5844.165364583333,
          5007.0810215326,
          9742.049533420139,
          5415.512478298611,
          7191.587185329861,
          5138.485613787616,
          7463.484381028164,
          5437.438853322724,
          6142.51444649402,
          5166.457748601466,
          4961.266474971065,
          13509.504279996141,
          5735.195818865741,
          4867.732156635802,
          5036.602605372299,
          5729.116997612848,
          4831.10770821277,
          5767.153534312307,
          5899.326226128473,
          9480.265872154707,
          5472.885350356867,
          4970.734278549383,
          4854.81115270544,
          5214.771041304977,
          4874.892523871527,
          4869.694061656057,
          5002.231189115548
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial578",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          10109.15811873071,
          8737.162724247684,
          8438.376000675155,
          6336.60629460841,
          5850.369041160301,
          21959.267481674382,
          9592.745822482639,
          5935.698796778549,
          6264.280755690586,
          5798.08031322338,
          13333.633608217593,
          5874.220995490934,
          7346.5342701099535,
          7753.420946662809,
          5949.681110146605,
          8036.044089988426,
          12944.879364390432,
          7428.630015432099,
          9313.17813826196
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial579",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11086.895109953704,
          13764.067654079861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial580",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13392.233217592593
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial581",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13603.195276331018
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial582",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10704.520302854939,
          10769.616566599152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial583",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12174.84784312307
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial584",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13297.778947241512
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial585",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11919.502001350309
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial586",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14064.625940393518
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial587",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13008.603057484568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial588",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21009.21607349537
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial589",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20953.04751398534
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial590",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10958.216857156636,
          12333.851110387732
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial591",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9998.66291714892,
          11166.893313560957,
          7556.117259837963,
          6943.552237051505,
          6468.013774353781,
          66425.93836805556
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial592",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18695.792088638118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial593",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12044.113419897762
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial594",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15541.039050443673
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial595",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18754.154272762345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial596",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15836.913616415895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial597",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          9817.479612750773,
          9688.475983796296,
          8197.29320384838,
          8087.146803867669
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial598",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12512.110321421682
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial599",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13840.32716652199
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial600",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16212.838638117284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial601",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9975.304000289352,
          35349.74074074074,
          7385.481559847608,
          11881.701364776234,
          6796.394898967978,
          9858.454029224536
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial602",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial603",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16795.584092881945
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial604",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15952.993007330248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial605",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          1887765.4907407407
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial606",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73
         ],
         "y": [
          8681.108579282407,
          10831.017584153164,
          136778.64052854938,
          6924.76156804591,
          5883.458053023727,
          5877.400637779707,
          5825.063946759259,
          6456.0999590084875,
          6100.457465277777,
          6117.146424093364,
          5607.467414761767,
          6937.456386236497,
          5578.451702353395,
          5553.826955536266,
          5421.373761212384,
          5506.5726484133875,
          7631.483036747685,
          5327.939359688465,
          5412.536624107832,
          5334.379747178819,
          5560.38838553723,
          9589.492163387345,
          5739.253764588156,
          5505.713270399306,
          19257.414797935955,
          5229.758258584105,
          10106.27390769676,
          6808.584297839506,
          5343.3695234133875,
          6103.503622926311,
          5250.456280743634,
          6426.148826316551,
          6096.63000036169,
          5436.516426745756,
          5185.653278115355,
          5285.000470196759,
          5643.787422839506,
          5222.694372106482,
          5153.4958737220295,
          5465.711395640432,
          6355.171739366319,
          5119.788016613619,
          5639.739734037423,
          5952.2890625,
          5784.603461371527,
          6584.7686933352625,
          6808.126757209684,
          5811.073781708141,
          5611.451174889082,
          5216.597053433642,
          5087.917393060378,
          11240.94514371142,
          5357.013400607639,
          5188.323224103009,
          8939.001350308641,
          5375.524133752893,
          5003.15165352527,
          4968.924132547261,
          4944.345073181906,
          5205.352753062307,
          11813.217327353395,
          10246.078335985725,
          5999.131172839506,
          5032.731764805169,
          4882.364929952739,
          9708.406105324075,
          6573.337348090277,
          5229.682062596451,
          12935.101460021218,
          5616.045048466435,
          5922.681381413966,
          6906.231915509259,
          5868.158896363811
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial607",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11983.244725356868
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial608",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19325.491922260804
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial609",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16450.169692804782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial610",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13145.079143759645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial611",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16535.274522569445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial612",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          11087.163966049382,
          8531.63084129051,
          11513.140667197145,
          11916.576183931327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial613",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20713.20418595679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial614",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22395.164412133487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial615",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21882.46098572531
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial616",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17175.412459008487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial617",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          10422.225308641975,
          8830.734809027777,
          7198.294777199074,
          10494.25636574074,
          6124.437159408758,
          6092.84765625,
          5680.7689043209875,
          12126.926806037809,
          7245.6954179928625,
          7006.095127435378,
          34888.13831018518,
          5968.0653965326,
          6396.42945240162,
          6365.7447193287035,
          12988.465494791666,
          5254.948875144676,
          5289.666949990355,
          9778.61090615355,
          5159.944495683835,
          6338.064001012732,
          5434.240186149691,
          6003.005292727624,
          5179.900550371335,
          5503.791766131366,
          5306.36014961902,
          7498.9249433352625,
          5110.145682629244,
          5141.892436463156,
          5280.417148919753,
          5834.693974247685,
          5087.321653766397,
          5121.213701413001,
          5624.378234109761,
          5404.01065779321,
          13167.980107060184,
          11349.356481481482,
          6356.287567515432,
          5165.696219738619,
          6223.665491174768,
          6166.518838011189,
          6391.347879292052
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial618",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14724.365210262345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial619",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17749.582127700618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial620",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10114.092990451389,
          11869.319860387732,
          10474.897738233025
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial621",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20529.982180748455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial622",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12558.005045572916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial623",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18005.800540123455
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial624",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial625",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11968.779224537036
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial626",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19212.159420814045
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial627",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9722.126519097223,
          10048.761562017748,
          6702.806520061728,
          8500.049364631559,
          12985.688331886575,
          8010.209653501158
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial628",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18305.76821711034
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial629",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19084.487823109568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial630",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11449.425552179784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial631",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11738.217375578704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial632",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11703.256594810957
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial633",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          73382.05319251544
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial634",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22853.323953510804
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial635",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          10568.942370756173,
          10105.630232445988,
          8020.708164544753,
          7584.257158444251,
          12507.525571469907
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial636",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12306.183714313273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial637",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17205.228744695218
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial638",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13510.895465615355
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial639",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          32999.302710262345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial640",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21900.748818479937
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial641",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13157.3661446277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial642",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11431.30401234568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial643",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20064.901523919754
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial644",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11493.406714168595
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial645",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15082.63160083912
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial646",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16098.844147858796
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial647",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9698.603069540895,
          10902.352394386575,
          18711.520302854937
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial648",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20834.541980131173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial649",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial650",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16501.2364607446
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial651",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21569.42628761574
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial652",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10456.225429205248,
          24638.54497010031
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial653",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16706.795874324845
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial654",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11499.092502170139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial655",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14207.394651813273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial656",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13265.16896339699
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial657",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          11005.623878761575,
          9936.697964891975,
          12057.504261911652
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial658",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12680.984091676311
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial659",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21222.574339313273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial660",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13168.883475597993
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial661",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11822.393247251157
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial662",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13628.208490065586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial663",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13037.562072000386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial664",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11132.56763599537
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial665",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11151.423098717207
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial666",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10620.015082465277,
          10547.520941840277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial667",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73
         ],
         "y": [
          10057.008698640046,
          6944.427854938272,
          9328.987244405864,
          5562.509765625,
          10853.751669801311,
          5440.761773003473,
          48242.99117476852,
          6384.471890673225,
          6159.590084876543,
          5854.450159143518,
          7000.16946674865,
          5766.494707272376,
          5412.963134765625,
          5378.107439959491,
          6421.416323061342,
          7547.669053819444,
          6563.517852406443,
          8381.397575472609,
          11092.896749614198,
          5749.439438054591,
          7207.748945071374,
          5865.294162326389,
          5351.992124204283,
          5235.984857253086,
          5189.050151306906,
          5314.778416763117,
          12128.56787109375,
          6054.9200605227625,
          14999.132052951389,
          7019.750657069831,
          5478.677773558064,
          5893.130545910494,
          5299.129590446566,
          5177.090139130016,
          5283.316427348573,
          5095.729266131366,
          5031.767761983989,
          5084.8097240306715,
          7207.126944082755,
          10239.625409915123,
          5177.350157937886,
          5092.321210696374,
          5016.258963879244,
          14899.382679880402,
          7502.729552469136,
          5020.187671802662,
          5131.794891734182,
          8803.077045958718,
          5835.076105565201,
          7149.944239486883,
          5370.53007149402,
          4915.931697892554,
          5548.935251494984,
          9513.719780815973,
          5343.4644941165125,
          6261.492633584105,
          5799.915349512924,
          10591.332826967593,
          5469.581075786073,
          6018.283480420525,
          4852.795440297068,
          5979.685561945409,
          4802.72193287037,
          5688.136387201003,
          4879.178674768518,
          10494.247691213348,
          14720.145543981482,
          5210.82467387635,
          5007.2723705150465,
          5282.277162905092,
          5810.616081331983,
          4929.336024908372,
          6055.191339940201
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial668",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12478.791937934027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial669",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18551.821192611882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial670",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          31498.943335262345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial671",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18918.496636284723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial672",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17932.85292486497
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial673",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18865.845763406636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial674",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial675",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          27461.025511188273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial676",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16709.11910445602
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial677",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17676.96603732639
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial678",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11874.05243296682
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial679",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21568.125868055555
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial680",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19683.385862750773
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial681",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12904.338179976852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial682",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10024.119152681327,
          16251.485339506173,
          8670.362630208334,
          10842.435769917052
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial683",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12982.821041907793
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial684",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19196.690694926696
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial685",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12295.20085238233
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial686",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16837.428035783178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial687",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23244.591266396605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial688",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20702.509970582563
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial689",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          11028.654031635802,
          16073.672839506173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial690",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13282.82716652199
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial691",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12954.894651813273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial692",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17639.488944347995
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial693",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16580.01580584491
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial694",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12643.380226417825
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial695",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17568.53116560571
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial696",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21162.24274209105
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial697",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          3548757.901234568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial698",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10664.154935860339,
          7840.019633728781,
          85235.38329475309,
          13841.908564814816
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial699",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20492.34490740741
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial700",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19412.861424575618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial701",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16121.36005015432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial702",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18834.140323591822
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial703",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18455.40782937886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial704",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10779.24151234568,
          13246.85907359182
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial705",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10599.55324074074,
          10428.873432677468
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial706",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11464.330879870757
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial707",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11880.774655189043
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial708",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10458.378930362655,
          9625.454427083334,
          12641.157793209877
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial709",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17422.61951437114
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial710",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10690.318721064816,
          15159.08024691358
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial711",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12700.645073784723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial712",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16448.020399305555
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial713",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10407.806182484568,
          9724.614040798611,
          15806.476743344907
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial714",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14119.418637876157
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial715",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12011.081753954475
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial716",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21629.29428288966
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial717",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15269.73797984182
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial718",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9988.00074146412,
          11203.682249469523,
          10759.753448109568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial719",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17585.15153597608
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial720",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10654.40480324074,
          14370.586474006559
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial721",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10445.889998070988,
          10408.740348910109
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial722",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial723",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10942.097270447532,
          12488.305549527391
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial724",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20608.648847415123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial725",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15465.19484230324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial726",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16692.19939959491
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial727",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17550.095401716822
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial728",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17402.498396508487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial729",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17951.06344039352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial730",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22598.03634982639
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial731",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11707.446017795139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial732",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11726.48365162037
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial733",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9037.351399739584,
          7188.2972246334875,
          7906.600338782793,
          24730.309027777777,
          7342.764051649306,
          6350.675160349151
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial734",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16156.755268614968
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial735",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14136.26153187693
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial736",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10704.010850694445,
          11300.342013888889
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial737",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12969.198453173225
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial738",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17203.356722608023
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial739",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19335.7381486304
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial740",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11611.038037712191
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial741",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11040.844280478395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial742",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14926.40894458912
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial743",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10719.367597415123,
          14159.971119068286
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial744",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18577.490644290123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial745",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial746",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24281.073772665895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial747",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19948.20413773148
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial748",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18663.52338927469
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial749",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10371.60733748071,
          9585.177167727623,
          9961.93042896412
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial750",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13938.198139708718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial751",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21846.40480324074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial752",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12910.687150366512
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial753",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11227.809389467593
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial754",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17602.540581597223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial755",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12627.195945457175
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial756",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          29529.984784915123
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial757",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17275.162133487655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial758",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15853.117476851852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial759",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11422.97371720679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial760",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14921.208984375
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial761",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21492.009186921296
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial762",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16283.996334876543
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial763",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13063.794343171296
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial764",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13436.692304446373
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial765",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          60227.27589699074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial766",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19124.592038001545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial767",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18077.96785783179
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial768",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16948.591893325618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial769",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18555.23572530864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial770",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial771",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12298.24806495949
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial772",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16204.01057339892
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial773",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12705.1737618152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial774",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17136.17051263503
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial775",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11435.184859664352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial776",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12312.248679832175
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial777",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17030.01349103009
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial778",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16847.301528742282
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial779",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21562.74117476852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial780",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14751.724537037036
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial781",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22160.965241608796
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial782",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11163.175540123457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial783",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18836.94462528935
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial784",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12446.08470775463
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial785",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10809.324242862655,
          15573.277777777777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial786",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13983.019259982639
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial787",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12245.083351417825
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial788",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10298.090627411266,
          9676.601032021605,
          10051.611219618055
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial789",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10485.120044849536,
          12056.603823061343
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial790",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12513.979251060957
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial791",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13912.3867850598
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial792",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18573.92386429398
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial793",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17882.22652633102
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial794",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial795",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9715.177746431327,
          9008.41911410108,
          10886.389491705248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial796",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12460.171097366898
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial797",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          1494662.8672839506
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial798",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10994.503134645061,
          10569.477225597993
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial799",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10322.25505160108,
          12661.285415461034
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial800",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15913.135730131173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial801",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20914.9405623071
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial802",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15061.981505594136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial803",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16341.747709297839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial804",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18568.088011188273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial805",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          33322.33798707562
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial806",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16845.459563078704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial807",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          310002.7766203704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial808",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10443.657521942516,
          9917.28175636574,
          32451.41521990741
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial809",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15823.118851273148
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial810",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17425.042402102623
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial811",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11589.069546923225
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial812",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13977.349940923998
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial813",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19007.471100983796
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial814",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10921.920042438273,
          10845.948338638118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial815",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12349.946078076775
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial816",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19096.39589361497
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial817",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13187.181544174382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial818",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16343.80706259645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial819",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial820",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15699.795934606482
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial821",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10712.096547067902,
          10765.12737509645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial822",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22481.290388695987
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial823",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15757.628689236111
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial824",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10330.316358024691,
          10881.542607060184
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial825",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14766.799744405864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial826",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14513.097005208334
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial827",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11843.54436728395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial828",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10812.09504605517,
          9987.940164448302,
          10674.218774112655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial829",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12345.935830198689
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial830",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16042.949833622684
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial831",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10695.30574845679,
          12482.559763213734
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial832",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15308.33543113426
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial833",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11139.502724729939
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial834",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10024.907190393518,
          12945.841603973766,
          12970.83839699074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial835",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13707.433262201002
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial836",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13165.739601417825
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial837",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11467.271978684414
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial838",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12399.668029031636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial839",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13083.948724440586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial840",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12015.541497878086
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial841",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18063.223198784723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial842",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial843",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17011.696168499227
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial844",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10442.869104456018,
          10533.167854214891
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial845",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17918.083887924382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial846",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18509.411615065586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial847",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13101.797085985725
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial848",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20311.04454812886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial849",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15283.427396797839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial850",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15757.073049286266
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial851",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11663.410433545525
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial852",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12416.839747299382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial853",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24145.28944830247
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial854",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16224.436897183641
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial855",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18929.77857349537
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial856",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13351.148901668595
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial857",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9902.05910011574,
          6860.435064621914,
          10494.827250916282,
          6925.426028404707,
          16327.011284722223,
          7677.468557098766
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial858",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          34334.18523341049
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial859",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10479.712203414352,
          11092.16749855324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial860",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14723.550371334877
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial861",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18761.405623070987
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial862",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          8879.948694299768,
          13055.088204089507,
          12672.382294077932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial863",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11769.798779899691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial864",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19078.176299672068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial865",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10023.758294753086,
          10186.249650366512,
          11659.58659456983
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial866",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14330.118085696373
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial867",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial868",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17022.142228491513
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial869",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          70803.27083333333
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial870",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15106.63718894676
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial871",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18000.47036554784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial872",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16484.46590470679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial873",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18786.732421875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial874",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16853.68948929398
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial875",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13155.84447337963
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial876",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11948.355987172068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial877",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12547.98363353588
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial878",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17863.81492332176
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial879",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "y": [
          10483.961793499227,
          5885.221242645641,
          12209.662555459105,
          10283.412627797068,
          6956.430441020448,
          7930.324688946759,
          7452.572199315201,
          9265.452847704475,
          13438.225362895448,
          7328.978931568287,
          7557.15707585841,
          10043.738618827161
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial880",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11540.118362991898
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial881",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10828.973837770061,
          10338.261694637345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial882",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15240.533203125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial883",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17197.814296392746
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial884",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18164.637719425155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial885",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15433.579276379243
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial886",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13771.823694299768
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial887",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13526.084912712191
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial888",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12312.523937837577
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial889",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13667.415141541282
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial890",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14941.994218991127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial891",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          35226.015866126545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial892",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial893",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          9784.527440200618,
          47972.85373263889,
          8136.24388744213,
          6540.923140914352,
          6351.353208188658,
          5945.167860243056,
          5853.226194782022,
          6505.541708863811,
          7215.325864438658,
          16763.580222800927,
          5631.820405936535,
          5819.740743754823,
          5781.343653549383,
          6076.195882161458,
          6147.992371358989,
          5373.910285855517,
          5730.451208043982,
          7428.610523365162,
          5885.064121576003,
          7958.251428674768,
          5365.796115451389,
          5884.689040195794,
          6146.17781876929,
          6554.843065803434,
          5115.749789014275,
          10871.208212770061,
          5232.377149040316,
          5369.210865162037,
          5753.390890239198,
          8248.862883391204,
          8479.036428192516,
          5713.132957175926,
          10916.966338734568,
          5187.363694179206,
          5416.5416425540125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial894",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10505.464916087964,
          15102.799346547068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial895",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15798.080054012345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial896",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16521.424503279322
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial897",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12355.973723234954
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial898",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15589.721040702161
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial899",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21874.500831886573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial900",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11823.708375530477
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial901",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13681.665081259645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial902",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12556.085425106095
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial903",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13442.997124565973
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial904",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11820.870081018518
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial905",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13246.807466483411
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial906",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10824.380220389661,
          10239.834719810957
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial907",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12074.842164592977
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial908",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18345.480902777777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial909",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13917.940942081405
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial910",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17597.572542920523
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial911",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11737.62769458912
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial912",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18646.047923900464
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial913",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19602.457091531636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial914",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13020.350941599152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial915",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13713.019121334877
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial916",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15152.805881076389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial917",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial918",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12988.79859302662
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial919",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16999.50466579861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial920",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18148.961395640432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial921",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13514.570173852238
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial922",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13953.665895061727
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial923",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17066.424792631173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial924",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10564.540569540895,
          10836.138153452932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial925",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10498.752001350309,
          10513.41652199074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial926",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11964.25830078125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial927",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22207.78362509645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial928",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11054.42798755787
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial929",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13408.373040846836
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial930",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26484.840386284723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial931",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20233.31088445216
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial932",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13520.151264708718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial933",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16148.14274691358
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial934",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27
         ],
         "y": [
          9954.370394483025,
          8280.956018518518,
          6494.789580922068,
          7304.955237871335,
          6580.197823230131,
          6122.320306471836,
          5559.828525872878,
          40811.962890625,
          6411.326822916667,
          6044.805673104745,
          8019.258192274306,
          9743.927999614198,
          5684.572117934992,
          5381.049515335648,
          5479.129897882909,
          6000.983428578318,
          5242.245439694251,
          5823.339629750193,
          6672.471197434414,
          5385.940785349151,
          5350.947139033565,
          5265.531304253473,
          9956.56534529321,
          6241.096284842785,
          6730.249686535494,
          6036.678207585841,
          5870.965678650656
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial935",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16417.73661747685
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial936",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12645.297435619214
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial937",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11936.001567322532
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial938",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16382.906708140432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial939",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial940",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11954.922827449845
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial941",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12146.124565972223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial942",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13810.536422164352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial943",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24
         ],
         "y": [
          10466.303355275848,
          7135.318281008874,
          11092.437475887345,
          6413.580692997685,
          6126.1439525462965,
          11141.726273148148,
          49323.298852237655,
          7153.737045476466,
          5683.153317298418,
          6130.543906129436,
          5839.699930073302,
          5600.456027560764,
          5611.150083188658,
          5324.111117139275,
          5713.6161868248455,
          6578.520534939236,
          6056.903986424576,
          5972.598922164352,
          5959.311879099151,
          13131.927071277007,
          7191.019874855324,
          5611.201633029514,
          5533.416618441358,
          11186.25267650463
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial944",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19216.766625675155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial945",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17391.769410686727
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial946",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15138.466097608025
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial947",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14756.307285638502
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial948",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12192.59797574267
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial949",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22811.802963445218
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial950",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11152.516360435957
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial951",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12089.839415750386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial952",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "y": [
          10088.427939332561,
          7522.518964602624,
          7278.281593605324,
          7756.162428867669,
          6449.279857494213,
          5460.892584153164,
          5842.94197892554,
          5433.742075978974,
          5524.557508680556,
          5441.7454999758875,
          6993.255841290509,
          5337.824152440201,
          9669.707483362268,
          5350.370665750386,
          6896.789406105324,
          6316.208890938465,
          7067.442286361883,
          5762.700035566165,
          5832.18227961034,
          5218.608419536073,
          5331.458881896219,
          5257.572708695023,
          5255.478108723958,
          5691.604950327932,
          7321.817015094522,
          6923.937879774306,
          6730.814459153164,
          5393.49405623071,
          6707.398781105324,
          7013.425112123842
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial953",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16648.697567033178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial954",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16967.280936535495
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial955",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14334.651415412809
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial956",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14368.66357421875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial957",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          47415.2326871142
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial958",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21693.784444926696
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial959",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22470.7391251929
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial960",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12172.351351514275
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial961",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11036.886598186727
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial962",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10866.153464988425,
          11639.527030285493
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial963",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11398.914014274691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial964",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial965",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19987.95334201389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial966",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17009.717375578704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial967",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15821.714470003859
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial968",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15665.896448206018
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial969",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11225.979335455248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial970",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21064.560655381945
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial971",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12809.28956886574
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial972",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13986.818479938273
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial973",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17744.92736062886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial974",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22127.729588638118
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial975",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14453.574230806327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial976",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11815.912374614198
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial977",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11545.488932291666
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial978",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10646.152584876543,
          10214.00235701196
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial979",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16714.164930555555
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial980",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21775.058955439814
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial981",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12859.629997347609
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial982",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12204.085865162036
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial983",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11796.541443624614
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial984",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12314.918631847993
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial985",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17677.160988136573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial986",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19223.190887827932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial987",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11268.508674527391
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial988",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial989",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18963.868356963736
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial990",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13277.761580102238
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial991",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          49063.95893614969
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial992",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17486.409155574845
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial993",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10998.689465181327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial994",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13450.872703269675
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial995",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17620.96896701389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial996",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          9164.961058063273,
          10877.173056520061,
          7697.152349778164,
          6405.566876446759,
          9882.107247058257,
          10045.94138816551
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial997",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12541.161609037423
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial998",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21545.269687982254
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial999",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10770.138888888889,
          10630.767867476852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1000",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15699.39542341821
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1001",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13288.010205680941
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1002",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11061.20490933642
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1003",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10876.537163628473,
          8969.89673755787,
          12730.37459611304
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1004",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12873.195849006559
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1005",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13998.535132137345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1006",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          1233437.1975308643
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1007",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15436.881980613425
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1008",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17021.21090133102
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1009",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20194.70642843364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1010",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10115.146604938273,
          11349.345908082561
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1011",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11414.123306086034
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1012",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11198.044596354166
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1013",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11528.773431471836
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1014",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18531.70405333719
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1015",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1016",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15181.202088155864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1017",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12517.849127121914
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1018",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13932.863829812886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1019",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19093.771677276236
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1020",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23832.866729359568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1021",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          23281.755075713736
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1022",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20194.44874855324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1023",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10154.950647424768,
          7881.702950183256,
          11037.011188271605,
          10664.627127941743
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1024",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11125.824074074075
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1025",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11443.218786168982
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1026",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14530.304066599152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1027",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37
         ],
         "y": [
          10426.572193287036,
          8948.61767578125,
          6499.333074122299,
          6014.822295765818,
          5624.025673948689,
          5949.606764805169,
          7814.052041136189,
          6717.509265287423,
          6844.895149136767,
          7716.694993007331,
          5417.750385802469,
          5546.361026716821,
          5586.811975549768,
          5725.248426649306,
          5974.706726827739,
          5685.850772810571,
          6832.302083333333,
          5351.504460841049,
          5490.396891276042,
          7117.819854359568,
          7459.116801697531,
          6595.404755015432,
          5328.133297767168,
          5371.132785373264,
          5501.049587673611,
          5849.047592351466,
          5228.082293475116,
          5398.399311583719,
          5573.858265817901,
          5470.4222577883875,
          5393.393379870756,
          9677.200183256173,
          7732.721028645833,
          5265.022750289352,
          5754.670416184414,
          7228.552053192516,
          5891.512375819831
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1028",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13010.687638647762
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1029",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10407.638635706018,
          7326.839174623842,
          7701.913025655864,
          6421.030418113426,
          7182.971408420139,
          9234.999385127316
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1030",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19264.184690875773
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1031",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20183.690224729937
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1032",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20390.268916377314
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1033",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13801.439193913966
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1034",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20119.183135609568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1035",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15755.759186921296
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1036",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1037",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11706.190417631173
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1038",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12754.09642650463
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1039",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19652.556664737655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1040",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9324.700147087191,
          9284.894302179784,
          14284.378713348766
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1041",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15966.303433641975
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1042",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12163.220715181327
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1043",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11521.641975308641
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1044",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14329.265100549768
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1045",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13207.698682243441
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1046",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11538.451563705632
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1047",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19773.719099633487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1048",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21386.110701195987
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1049",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18759.997214988427
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1050",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21806.660083912036
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1051",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21026.14151716821
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1052",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16030.218611352238
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1053",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17689.664978780864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1054",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11024.567768614968
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1055",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10824.449532214507,
          9584.844955632716,
          8669.753526475695
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1056",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11254.722692418982
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1057",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17898.361605420523
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1058",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10812.452244888118,
          10101.441134982639
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1059",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17355.633077739196
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1060",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15700.225706500773
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1061",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1062",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13943.582579812886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1063",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11857.588668258102
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1064",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18589.7850236304
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1065",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12712.216368875386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1066",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19008.713240258487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1067",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14861.088734567902
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1068",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13174.982855902777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1069",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38
         ],
         "y": [
          10463.335437162423,
          7179.941767939815,
          11378.976930217977,
          8250.591332706405,
          5693.563054591049,
          7765.198600863233,
          5442.843870563272,
          7248.779245635609,
          13389.166461709105,
          5795.090280791859,
          6385.703106915509,
          6635.065622588734,
          21578.67812017747,
          8667.478250385802,
          5909.078785083912,
          5428.328435450424,
          5740.274851104359,
          7365.067352671682,
          5291.27416087963,
          5271.601924189815,
          6594.668842833719,
          18815.339723186727,
          6919.42357494213,
          5286.765248239776,
          9108.759560667439,
          6482.0019772376545,
          21385.800166377314,
          5129.749701605902,
          5248.722342785494,
          5226.2369701244215,
          6384.943142361111,
          5158.84790943287,
          5327.797718942901,
          5139.163577232832,
          5355.861114125193,
          5288.524326654128,
          5215.272334346065,
          5148.085090543017
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1070",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12923.763274016204
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1071",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11074.93805459105
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1072",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12075.439995659723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1073",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17525.351490162036
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1074",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10226.71297501929,
          14328.736545138889
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1075",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10120.449459876543,
          10351.933232060184
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1076",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11314.149926456405
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1077",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22069.444239486882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1078",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          43320.92766203704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1079",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11898.130618248457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1080",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15003.507366415895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1081",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10689.45036410108,
          11705.232650945216
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1082",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10988.567666136189
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1083",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17762.549093364196
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1084",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          10707.615801022377,
          8912.57989125193,
          7132.472397038966,
          150785.1099537037,
          7601.339674961419
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1085",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12574.973590615355
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1086",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          174953.1986882716
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1087",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9068.679337866512,
          9475.12223910108,
          8782.948187934027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1088",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12894.652012201002
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1089",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          9989.547260802468,
          14557.148099922839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1090",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11312.92815634645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1091",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11651.063669463734
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1092",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14581.278006847993
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1093",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13308.475157937886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1094",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21214.170536747686
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1095",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10656.703721788195,
          10669.457983699845
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1096",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12198.500946421682
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1097",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12499.513141396605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1098",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16106.844099633488
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1099",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18657.902114679782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1100",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12694.248529128086
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1101",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13424.695939429012
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1102",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11807.600555796682
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1103",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1104",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17739.612111786264
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1105",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18455.24019820602
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1106",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9515.4912109375,
          13332.126205632716,
          9684.410331066743
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1107",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17503.71122685185
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1108",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12167.7334647473
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1109",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11595.098240981868
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1110",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17874.53087625386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1111",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10849.10886863426,
          13765.6757149402
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1112",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14845.03337191358
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1113",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10464.572217399691,
          10185.132939091434
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1114",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16292.908914448302
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1115",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15739.556351273148
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1116",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22090.585575810186
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1117",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          84701.97723765433
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1118",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19151.196735146605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1119",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12794.016221788195
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1120",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          24025.99099392361
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1121",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15608.907033661266
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1122",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1123",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14368.605378327546
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1124",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          94150.69791666667
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1125",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21897.17751736111
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1126",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14207.62958140432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1127",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16271.560100790895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1128",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20524.293173707563
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1129",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11145.342411747684
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1130",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17826.49159673997
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1131",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          25904.62575954861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1132",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15193.811005015432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1133",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15459.43953751929
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1134",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          8821.254641685957,
          18332.04161844136,
          10622.979600694445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1135",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12456.678819444445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1136",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11542.300853587964
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1137",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14587.691466531636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1138",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16568.52739197531
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1139",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20570.467423804013
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1140",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10550.960093557098,
          12755.863389756945
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1141",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17866.79556086034
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1142",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1143",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16380.781732253086
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1144",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10598.922538097993,
          10617.239498939043
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1145",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14165.70856240355
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1146",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15299.419825424382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1147",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17750.83156105324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1148",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14130.175009645061
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1149",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11334.170572916666
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1150",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12074.317093460648
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1151",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10926.683352623457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1152",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10994.581802179784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1153",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16103.874059606482
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1154",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10272.42943431713,
          115534.87635030864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1155",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17955.530598958332
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1156",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10148.375361689816,
          11016.90623191551
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1157",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17512.717544367282
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1158",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15759.757438753859
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1159",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11398.52473355517
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1160",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11439.168788580248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1161",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11246.760308159723
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1162",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          630199.2831790124
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1163",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17782.489498939045
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1164",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1165",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19596.001687885804
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1166",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14901.766613618827
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1167",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9459.183654031636,
          12212.805561583718,
          33603.4034529321
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1168",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11342.029345100309
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1169",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21652.507113233023
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1170",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12390.542203173225
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1171",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11798.429446373457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1172",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13349.972577883873
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1173",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16365.959888599536
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1174",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11594.448465229552
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1175",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11067.044210551698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1176",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14404.407455632716
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1177",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17844.846583236882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1178",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10715.911168981482,
          9034.065212673611,
          7835.953221450617,
          8562.072784047068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1179",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12274.289406105325
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1180",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11276.383288724923
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1181",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10479.313621238425,
          13515.901752989968
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1182",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13159.141360435957
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1183",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10658.50870466821,
          11454.47828052662
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1184",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20958.85844666281
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1185",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1186",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18133.79402970679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1187",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14415.812644675925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1188",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10634.441165123457,
          10284.09627580054
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1189",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11207.165883005402
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1190",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14605.4873046875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1191",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15242.60725308642
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1192",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21556.714180652005
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1193",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19353.991235050155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1194",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11357.797164351852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1195",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16991.86570457176
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1196",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          102434.24006558642
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1197",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21221.86700665509
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1198",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17478.379822530864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1199",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11254.842001832561
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1200",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15649.519000771605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1201",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14889.754418643905
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1202",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11755.844768759645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1203",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18703.655249324845
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1204",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14262.159722222223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1205",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16158.738920235339
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1206",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11090.040171682098
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1207",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11671.308623890818
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1208",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1209",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9884.170850212191,
          9419.434136284723,
          8757.275969328704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1210",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13799.300919897762
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1211",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10911.68465470679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1212",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          62972.59722222222
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1213",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12935.100459346066
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1214",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19715.815911940586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1215",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17231.58738425926
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1216",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11585.923207224152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1217",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16649.199520158178
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1218",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11159.21898509838
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1219",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12383.69556568287
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1220",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13107.029158227238
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1221",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16768.47345196759
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1222",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12804.243489583334
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1223",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          31188.542052469136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1224",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18921.65360966435
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1225",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          25621.605709876545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1226",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13981.164158950618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1227",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12958.435577015818
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1228",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16000.37003279321
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1229",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11996.069106867284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1230",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17775.235785590277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1231",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1232",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11330.9668631848
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1233",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13576.631202980325
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1234",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11131.627302758488
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1235",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          10585.930049189816,
          9681.185860339507,
          6991.811818817516,
          6534.631172839506,
          7883.486991222994,
          11995.957404996141
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1236",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13008.556544174382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1237",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16561.248758198304
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1238",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14449.535144193673
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1239",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          30400.243682484568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1240",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12557.953999083718
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1241",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19061.970775462964
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1242",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11764.868284625773
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1243",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14202.703872492284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1244",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11415.505811149691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1245",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18334.677975501545
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1246",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18622.999987943673
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1247",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14202.757143373843
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1248",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14963.024619020061
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1249",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13667.659342447916
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1250",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11943.091067467207
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1251",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          25318.005714699073
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1252",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14223.803668740355
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1253",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11447.341784818673
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1254",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11301.944848331405
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1255",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11295.752736786266
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1256",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12551.62932822145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1257",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1258",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11004.160951967593
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1259",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          31674.22868441358
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1260",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17600.38803288966
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1261",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12305.627531828704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1262",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11738.669023678627
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1263",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21138.44475790895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1264",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12030.301848234954
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1265",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10619.630075713734,
          10470.981662326389
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1266",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16551.306315104168
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1267",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13000.365933641975
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1268",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22099.66075906636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1269",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16893.037386670523
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1270",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17043.504400559414
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1271",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20052.314103491513
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1272",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13689.242627555941
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1273",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20485.231807002314
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1274",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15401.949652777777
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1275",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14148.052836853782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1276",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21540.0107421875
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1277",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14062.810540846836
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1278",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11158.121877411266
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1279",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17086.042426215277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1280",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16137.962052710262
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1281",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1282",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13894.444643373843
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1283",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18482.748794367282
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1284",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18442.22617669753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1285",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9701.160517939816,
          12726.005618248457,
          13977.828028549382
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1286",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12638.517379195602
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1287",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12629.369502314816
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1288",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11777.173333815586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1289",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14320.108428578318
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1290",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17603.32201244213
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1291",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11493.26212263696
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1292",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19561.65857687114
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1293",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13565.663049768518
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1294",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10168.610767505786,
          9610.116663049768,
          15709.648702739198
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1295",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12359.00944613233
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1296",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14489.309232735339
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1297",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14705.91089771412
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1298",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13750.953757957175
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1299",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15359.98492959105
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1300",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14738.857795621141
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1301",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21626.86760947145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1302",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14997.164436246141
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1303",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10949.990752797068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1304",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19065.65131896219
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1305",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1306",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12052.481523678627
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1307",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10740.324568383488,
          9735.312427662036,
          12864.932882426698
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1308",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11351.790099344136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1309",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13546.419337143132
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1310",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "y": [
          7929.10238835841,
          11169.786446277007,
          7450.391215760031,
          6114.552975501543,
          6846.75089216821,
          7146.2494212962965,
          8776.891360435957,
          8985.109688464507,
          7584.253237123842,
          6322.8354733314045,
          7922.005328896605,
          10959.935173128859
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1311",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17826.641288097995
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1312",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15244.907998167439
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1313",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10787.2139334973,
          17156.86964699074
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1314",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11562.24503279321
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1315",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22160.259741512345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1316",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15364.767047646605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1317",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70
         ],
         "y": [
          9394.328691647377,
          12606.43603515625,
          5936.36020085841,
          7676.438886477624,
          14875.024703414352,
          7089.840952932099,
          5901.675298996914,
          11314.221535011575,
          5974.579891251929,
          8460.475085599923,
          5416.225531684027,
          5403.28055977527,
          7047.531515239198,
          5302.890543619792,
          5248.848017939815,
          5343.768762659143,
          6222.8795331790125,
          5392.628607855902,
          5458.004337263696,
          5692.761658468364,
          5564.274230203511,
          5227.878861038773,
          5627.015055338542,
          5426.262035228588,
          5227.825116946374,
          8152.972812982253,
          27382.830656828704,
          5614.725851176698,
          5369.857644917052,
          6122.998486930941,
          6016.165985484182,
          5385.7917721595295,
          5119.114287953318,
          7521.0545488522375,
          5073.538495852624,
          5610.057143976659,
          5549.119215977044,
          5168.598949291088,
          9066.615831163195,
          8437.972053433641,
          28915.001519097223,
          5195.294059847608,
          5066.585150824652,
          5174.023784119406,
          5261.26424455054,
          5229.251715012539,
          5380.723765432099,
          5949.208315248842,
          5411.078794126158,
          8956.746172116127,
          5421.036455319251,
          5032.349371262539,
          4940.329312548225,
          4978.708321277006,
          5642.181709948881,
          5489.666292920525,
          6452.210150824652,
          11837.669331114968,
          5420.179295669367,
          4887.389500747492,
          6484.720413773148,
          4920.943582417052,
          5019.467447916667,
          11134.328721788195,
          5095.910924840857,
          4953.539511598186,
          11688.899456259645,
          5326.5724042727625,
          7611.660475742669,
          5472.856635199652
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1318",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14906.487678433641
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1319",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          47490.701195987655
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1320",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12213.768271363811
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1321",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11109.571138358411
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1322",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          10124.551426263502,
          8392.2255859375,
          7549.633312837577,
          6375.846435546875,
          7558.592267071759,
          5669.933654031636,
          5419.079689308449,
          9826.313506703318,
          6048.391339337384,
          5407.056321132331,
          22001.664086612655,
          9598.06202980324,
          7028.301145953897,
          5391.952690972223,
          5851.655719521605,
          5751.607777536651,
          5562.938024450232,
          7424.494399836034,
          7227.2519290123455,
          6074.7242597415125,
          5169.167127821181,
          5467.711672935957,
          7762.952094184027,
          6659.4038990162035,
          5448.435094762732,
          6178.254900896991,
          6564.033383969908,
          5670.945815851659,
          5650.51645085841,
          6708.859176070602,
          5575.80835865162
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1323",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11782.096830391589
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1324",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10481.196017795139,
          12756.263816550925
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1325",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10733.898588204089,
          15960.921826774691
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1326",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13401.823736496914
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1327",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19458.22833478009
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1328",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20390.843291859568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1329",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          33012.83646797839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1330",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13350.077425733025
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1331",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10522.494285300925,
          10684.233531057098
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1332",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          173057.82021604938
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1333",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11958.835714457948
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1334",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10505.362328800155,
          11277.38006968557
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1335",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18479.312475887345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1336",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10426.957682291666,
          15728.529031635802
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1337",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10695.067021122684,
          14243.347276475695
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1338",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10727.66259765625,
          10600.601134500386
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1339",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12724.571313175155
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1340",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15742.010223765432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1341",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11159.948296440973
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1342",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14252.746172116127
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1343",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11620.016957224152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1344",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          10125.784511236498,
          8943.179964795525,
          14490.43733121142
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1345",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15718.551239390432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1346",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19014.94145447531
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1347",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12881.852418499227
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1348",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14219.12323374807
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1349",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13095.492513020834
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1350",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15614.71573591821
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1351",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1352",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11500.299358603395
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1353",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20974.817575713736
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1354",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10509.328655478395,
          10480.618965808257
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1355",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21740.487762827932
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1356",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          10461.516818576389,
          8066.526240596065,
          7117.328106915509,
          18852.01579378858,
          15993.890492380402
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1357",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14897.78702498071
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1358",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15592.415147569445
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1359",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18611.57947530864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1360",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14604.315001687886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1361",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10645.706380208334,
          13082.753411940586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1362",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10986.903838734568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1363",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11520.66013816551
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1364",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9748.36888744213,
          8856.173599054784,
          23384.33755304784
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1365",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11069.768307532793
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1366",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13540.790129484954
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1367",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10757.679747781636,
          11216.570414978782
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1368",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10662.624379099152,
          71845.9809992284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1369",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13362.812843605325
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1370",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1371",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14929.702522183641
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1372",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10932.662073206018
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1373",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20040.344786844136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1374",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12328.093014564043
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1375",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11564.1786446277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1376",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14645.722415123457
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1377",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          9947.829499421296,
          11163.089451919368
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1378",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12262.35383511767
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1379",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11815.290171682098
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1380",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12114.757691936727
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1381",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18569.68711419753
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1382",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11913.657051745757
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1383",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10785.999336902007,
          10452.791775173611
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1384",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12890.869026089891
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1385",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19964.18627025463
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1386",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18249.13808111497
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1387",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12392.329752604166
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1388",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10543.445300443673,
          15527.855746045525
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1389",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18968.444866415895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1390",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13639.07880015432
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1391",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18950.68694540895
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1392",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16107.324809510032
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1393",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1394",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10899.391143422068
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1395",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20085.517276716822
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1396",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10945.285795235339
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1397",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26335.35496238426
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1398",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16797.68792197145
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1399",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          9459.095920138889,
          14160.072573061343,
          12716.185209297839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1400",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18565.296260127314
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1401",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13677.209110966434
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1402",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          37737.547694830246
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1403",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12924.176932629243
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1404",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16610.78023726852
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1405",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          10970.241566599152
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1406",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17575.00068721065
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1407",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          21297.019036940586
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1408",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20043.93283420139
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1409",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20814.190272955246
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1410",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10514.660011574075,
          19538.740933641977
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1411",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12631.444703655477
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1412",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11355.80982349537
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1413",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10575.827582465277,
          10936.365174093364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1414",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18688.307496624227
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1415",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15704.588095582561
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1416",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1417",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13034.339891975309
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1418",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12333.433051215277
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1419",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26918.37049093364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1420",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20683.347969714505
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1421",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          22416.165955343364
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1422",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15976.4043631848
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1423",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13144.846794222609
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1424",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17428.461142457563
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1425",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13909.031997492284
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1426",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16005.118923611111
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1427",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12939.672694830248
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1428",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11706.599494839891
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1429",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12282.273750964507
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1430",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20723.281093267746
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1431",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11851.850983796296
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1432",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16218.032166280864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1433",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "y": [
          8741.855082947532,
          25550.520109953704,
          6191.738673080633,
          6525.9173418209875,
          7240.989806375386,
          5993.824062017747,
          6096.012945481289,
          6366.639473620756,
          8020.703920717592,
          7952.250964506173,
          5838.463550708912,
          12898.814676167052,
          5560.784595630787,
          8846.18505859375,
          5802.886766975309,
          11745.062210648148,
          6436.746485580633,
          6304.258994020061,
          5735.081304856289,
          5517.866828824267,
          8922.487039448302,
          7374.515926408179,
          8545.17535927855,
          5391.056797357253,
          5415.406078197338,
          5405.856207200039,
          6453.104079258294,
          6344.458068094136,
          7256.966230227624,
          5465.167393060378,
          5242.804612147956,
          5515.824468918789,
          10204.069257571373,
          5270.463252314815,
          8520.445909288195,
          5391.92163990162,
          14094.905128761575,
          5263.517222463349,
          5308.36072229456,
          7985.324833622685,
          9043.83349609375
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1434",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12038.016173562886
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1435",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1436",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12782.957531587577
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1437",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10376.997214988425,
          22065.197627314814
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1438",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13281.616114486882
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1439",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16701.328390239196
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1440",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14642.240951726466
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1441",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20300.31840760031
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1442",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17870.60420283565
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1443",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17682.361050829477
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1444",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12784.760868778934
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1445",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11036.644422743055
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1446",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10495.362678433641,
          13414.801685474536
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1447",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16433.65658757716
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1448",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11089.970070167825
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1449",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11136.58831259645
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1450",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11281.885380497684
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1451",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          39574.75906635803
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1452",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17513.026065779322
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1453",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18172.37037037037
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1454",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13344.428982204861
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1455",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11209.353575906636
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1456",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20948.462987075618
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1457",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13143.328703703704
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1458",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14156.537085262345
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1459",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12162.39503761574
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1460",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12388.105649594907
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1461",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1462",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          19560.879255883487
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1463",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          555729.9745370371
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1464",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          8185.461413724923,
          10880.208875868055,
          8811.626603491512,
          10736.206705729166
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1465",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13397.277235243055
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1466",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15214.038628472223
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1467",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13984.170120804398
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1468",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14582.364414544752
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1469",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12484.121491608796
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1470",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16822.017783082563
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1471",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12492.98934220679
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1472",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11041.679349922839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1473",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17291.5703125
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1474",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          14557.353159963348
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1475",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13984.486129195602
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1476",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18226.6162109375
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1477",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13784.745177469136
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1478",
         "type": "scatter",
         "x": [
          1,
          2
         ],
         "y": [
          10734.310908564816,
          11058.63752652392
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1479",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1480",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18545.063994984568
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1481",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11909.202094184027
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1482",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          17861.02203896605
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1483",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12799.493302710262
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1484",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16254.171187789352
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1485",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11015.65552662037
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1486",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16265.730263792439
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1487",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          12234.262387876157
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1488",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18931.745056905864
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1489",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26806.777548707563
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1490",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          15651.755521797839
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1491",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          11434.77296730324
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1492",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13700.123667775848
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1493",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16095.06908275463
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1494",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          18115.707863136573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1495",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          13951.319673514661
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1496",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16371.326388888889
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1497",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          26811.756992669754
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1498",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          20012.028175636573
         ]
        },
        {
         "marker": {
          "maxdisplayed": 10
         },
         "mode": "lines+markers",
         "name": "Trial1499",
         "type": "scatter",
         "x": [
          1
         ],
         "y": [
          16001.91559365355
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Intermediate Values Plot"
        },
        "xaxis": {
         "title": {
          "text": "Step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Intermediate Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            12828.505365065586,
            12828.505365065586
           ],
           "values": [
            12828.505365065586
           ]
          },
          {
           "label": "activation",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "ReLU"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "dropout_rate",
           "range": [
            0.1865352470138201,
            0.1865352470138201
           ],
           "values": [
            0.1865352470138201
           ]
          },
          {
           "label": "gnn_dim",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "1024"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "hidden_dim",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "512"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "lr",
           "range": [
            -4.710047583507692,
            -4.710047583507692
           ],
           "ticktext": [
            "1.95e-05"
           ],
           "tickvals": [
            -4.710047583507692
           ],
           "values": [
            -4.710047583507692
           ]
          },
          {
           "label": "momentum",
           "range": [
            -0.08359092131611649,
            -0.08359092131611649
           ],
           "ticktext": [
            "0.825"
           ],
           "tickvals": [
            -0.08359092131611649
           ],
           "values": [
            -0.08359092131611649
           ]
          },
          {
           "label": "optimizer",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "SGD"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0
           ]
          },
          {
           "label": "weight_decay",
           "range": [
            -5.615473656735335,
            -5.615473656735335
           ],
           "ticktext": [
            "2.42e-06"
           ],
           "tickvals": [
            -5.615473656735335
           ],
           "values": [
            -5.615473656735335
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           12828.505365065586
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": true,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "GELU",
          "ReLU",
          "ReLU",
          "GELU",
          "Swish",
          "ReLU",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "GELU",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "Swish",
          "GELU",
          "GELU",
          "GELU",
          "GELU",
          "GELU",
          "GELU",
          "GELU",
          "GELU",
          "Swish",
          "Swish",
          "Swish",
          "GELU",
          "GELU",
          "Swish",
          "Swish",
          "GELU",
          "Swish",
          "GELU",
          "GELU",
          "Swish",
          "Swish",
          "GELU",
          "GELU",
          "Swish",
          "GELU",
          "Swish",
          "Swish",
          "GELU"
         ],
         "xaxis": "x",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.34789969778599206,
          0.3386970659282392,
          0.1865352470138201,
          0.33601299717314004,
          0.18059684143646632,
          0.25985474455857405,
          0.35612764458112756,
          0.28521461902471096,
          0.3128222564081033,
          0.3297342560264259,
          0.3254243160531117,
          0.36452763896294366,
          0.32998068704503075,
          0.27876939870047435,
          0.3584274447765387,
          0.34404144200017467,
          0.34484267281148634,
          0.3380344802190641,
          0.3386983578683681,
          0.33848914593289514,
          0.3409812000063129,
          0.3465303462264981,
          0.3450919219654015,
          0.35215422949179953,
          0.3524117218508306,
          0.34102979490428426,
          0.32004497572323753,
          0.3196900599921548,
          0.3202434181813916,
          0.31700788963620274,
          0.31559826290558757,
          0.29709481279179,
          0.2994125965478684,
          0.31918680128550087,
          0.3282735592940588,
          0.15561410566186373,
          0.3219525822206331,
          0.2983420488396585,
          0.3182548181466011,
          0.32602427200325795,
          0.3536014184065482,
          0.29415873851214674,
          0.3364214942279832,
          0.34170640026473564,
          0.3532681364666606,
          0.22501934635058246,
          0.30747638832015994,
          0.2356472472027058,
          0.3156806308784189,
          0.33047213169404904,
          0.3435266874531593,
          0.3101512038984424,
          0.2508482945382593,
          0.17869377686842736,
          0.32030727141327664
         ],
         "xaxis": "x2",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1024,
          256,
          1024,
          512,
          256,
          512,
          256,
          256,
          256,
          256,
          256,
          512,
          256,
          256,
          256,
          256,
          256,
          256,
          256,
          256,
          384,
          256,
          256,
          256,
          256,
          256,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          1024,
          256,
          256,
          512,
          512,
          256,
          256,
          256,
          256,
          256,
          256,
          256,
          256,
          256,
          256,
          1024,
          512,
          256,
          256,
          256,
          256
         ],
         "xaxis": "x3",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          256,
          384,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          384,
          512
         ],
         "xaxis": "x4",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.00019706110180855172,
          0.0008805083733534888,
          0.000019496309765903227,
          0.00011346972633906472,
          0.00012869301102808614,
          0.000396935242987587,
          0.0009189169772612875,
          0.0009538062531716071,
          0.0005056700478673483,
          0.0005897786395570446,
          0.0008770788250256469,
          0.0006188124850156175,
          0.0006025493886575723,
          0.0005771166905138669,
          0.0005990547500235965,
          0.0005555079210176292,
          0.0005499340402916562,
          0.0004932119011151507,
          0.00039321042774086146,
          0.0003945850812546342,
          0.0004236985648273598,
          0.00032516388931184184,
          0.00031987520208023667,
          0.0003280483367968459,
          0.0002846214809071986,
          0.00043644545151318463,
          0.0008702912440150264,
          0.0008366507177717356,
          0.0008808587742518549,
          0.000822167962658358,
          0.000908597757734247,
          0.0008234836530719138,
          0.0009937666224628348,
          0.0008748531769544928,
          0.0007630632043811693,
          0.00043604025551845693,
          0.00033921892248462885,
          0.0009019076399644156,
          0.000710957648467422,
          0.000371872705182012,
          0.0005807500950925079,
          0.00028883148927072525,
          0.00044000773544044614,
          0.0002767472118280528,
          0.0002944650323372676,
          0.00047533136982912534,
          0.0003602123566462975,
          0.00035318855638677394,
          0.00036756550873636974,
          0.0009932402556021248,
          0.000996906913932373,
          0.0002973523335303899,
          0.0003086044457037687,
          0.0002653762920438415,
          0.0009236011011224121
         ],
         "xaxis": "x5",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": [
           2
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8249147681381581
         ],
         "xaxis": "x6",
         "y": [
          12828.505365065586
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "AdamW",
          "Adam",
          "SGD",
          "Adam",
          "AdamW",
          "AdamW",
          "Adam",
          "RMSprop",
          "AdamW",
          "RMSprop",
          "AdamW",
          "Adam",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "Adam",
          "AdamW",
          "RMSprop",
          "RMSprop",
          "Adam",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "AdamW",
          "AdamW",
          "RMSprop",
          "RMSprop",
          "RMSprop",
          "RMSprop"
         ],
         "xaxis": "x7",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           6,
           8,
           12,
           16,
           57,
           64,
           66,
           81,
           82,
           83,
           134,
           135,
           138,
           143,
           145,
           149,
           150,
           152,
           155,
           156,
           172,
           188,
           189,
           190,
           194,
           195,
           196,
           198,
           210,
           215,
           236,
           267,
           363,
           415,
           502,
           516,
           540,
           577,
           617,
           667,
           879,
           893,
           934,
           943,
           952,
           1027,
           1069,
           1317,
           1322,
           1433
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.000006918777663255381,
          0.0000014250321078722525,
          0.0000024239649920149693,
          0.0000685481436715093,
          0.000023165953485163707,
          0.000013210659763817696,
          0.000002349467656920903,
          0.000024084023484740054,
          0.00001659857613372755,
          0.000010439629457863275,
          0.000010873995636900527,
          0.00000831164154954343,
          0.000010599936251987833,
          0.00001518316725621616,
          0.000009325930827977706,
          0.000009056299733554687,
          0.000009104485043537205,
          0.000013553334407880868,
          0.000001857533471319384,
          0.0000012399767027471175,
          0.0000012945012826282918,
          0.0000011123987231590512,
          0.0000010710947423292408,
          0.0000010124718992796603,
          0.0000010180786761587102,
          0.000008053774267468954,
          0.000037657807683114416,
          0.00003647131477457351,
          0.00004327603663684977,
          0.00006406461562687465,
          0.000049452302148085184,
          0.00007993942580161632,
          0.00007540947300642986,
          0.000033973619356154615,
          0.000001082295451662262,
          0.000008997255347967321,
          0.000054306513618210684,
          0.000010386234520938875,
          0.00004849503072519385,
          0.0000100623368463843,
          0.000010517333884700056,
          0.000007036298126223104,
          0.0000014446258720835799,
          0.000011981811416746035,
          0.000009844838873258651,
          0.0000010961905546072748,
          0.00000124468158429244,
          0.000007722394303366339,
          0.000004211468226295477,
          0.000008211888300046772,
          0.000009538159587544366,
          0.0000013324497345310381,
          0.000007198592945322516,
          0.000007775029978833429,
          0.000038232930216781765
         ],
         "xaxis": "x8",
         "y": [
          5197.783649209105,
          5052.430064260224,
          12828.505365065586,
          5137.008415316358,
          4895.3238691165125,
          5173.171805676119,
          5041.545129846643,
          6144.934003665124,
          5304.862024377893,
          5370.617841555749,
          5154.686996648341,
          5601.968828366126,
          5256.830708068094,
          4888.95108748071,
          4636.191819179206,
          4556.067195939429,
          5108.875099464699,
          5304.720594618056,
          5217.774314597801,
          4909.3860104407795,
          5386.708568431713,
          5208.045373987268,
          4899.03860737365,
          5036.295765817901,
          5483.249786000193,
          5243.665801625193,
          4963.60376880787,
          4965.00473210841,
          4838.967086226852,
          5165.112871334876,
          5267.644483024691,
          5037.231948664159,
          5244.769401644483,
          5833.231285566165,
          5396.346625434027,
          5294.435598114391,
          5369.706063729745,
          5505.412591628086,
          5418.104025004823,
          5299.791850525656,
          4819.421615788966,
          4956.010054976852,
          4831.10770821277,
          5087.321653766397,
          4802.72193287037,
          5885.221242645641,
          5115.749789014275,
          5242.245439694251,
          5324.111117139275,
          5218.608419536073,
          5228.082293475116,
          5129.749701605902,
          4887.389500747492,
          5169.167127821181,
          5242.804612147956
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 2400,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "ReLU",
          "GELU",
          "Swish"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          0.103125
         ],
         "title": {
          "text": "activation"
         },
         "type": "category"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.128125,
          0.23124999999999998
         ],
         "title": {
          "text": "dropout_rate"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "categoryarray": [
          256,
          384,
          512,
          1024
         ],
         "categoryorder": "array",
         "domain": [
          0.25625,
          0.359375
         ],
         "title": {
          "text": "gnn_dim"
         },
         "type": "category"
        },
        "xaxis4": {
         "anchor": "y4",
         "categoryarray": [
          256,
          384,
          512
         ],
         "categoryorder": "array",
         "domain": [
          0.38437499999999997,
          0.48749999999999993
         ],
         "title": {
          "text": "hidden_dim"
         },
         "type": "category"
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.5125,
          0.615625
         ],
         "title": {
          "text": "lr"
         },
         "type": "log"
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.640625,
          0.74375
         ],
         "title": {
          "text": "momentum"
         },
         "type": "log"
        },
        "xaxis7": {
         "anchor": "y7",
         "categoryarray": [
          "Adam",
          "AdamW",
          "SGD",
          "RMSprop"
         ],
         "categoryorder": "array",
         "domain": [
          0.76875,
          0.8718750000000001
         ],
         "title": {
          "text": "optimizer"
         },
         "type": "category"
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.8968750000000001,
          1
         ],
         "title": {
          "text": "weight_decay"
         },
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # hyperparameter search space\n",
    "    gnn_dim = trial.suggest_categorical(\"gnn_dim\", [256, 384, 512, 1024])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [256, 384, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.15, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 8e-6, 1e-3, log=True)\n",
    "    activation = trial.suggest_categorical(\"activation\", ['ReLU', 'GELU', 'Swish'])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\", \"SGD\", \"RMSprop\"])\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.8, 0.99, log=True) if optimizer_name == \"SGD\" else None\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
    "\n",
    "    # Corrected Data Splitting for Polymer Data \n",
    "    # Split the full data_list into train, validation, and test sets.\n",
    "    # Note: `data_list` should be created in a previous cell.\n",
    "    train_val_set, test_set = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "    train_set, val_set = train_test_split(train_val_set, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    valid_loader = DataLoader(val_set, batch_size=64)\n",
    "    \n",
    "    # model instantiation\n",
    "    # The rdkit_dim is dynamically taken from the pre-processed features.\n",
    "    model = HybridGNN(\n",
    "        gnn_dim=gnn_dim,\n",
    "        rdkit_dim=rdkit_features.shape[1],\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=activation\n",
    "    )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # optimizer instantiation\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer '{optimizer_name}' not supported\")\n",
    "\n",
    "    # training loop with NaN check and early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, 100):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch)\n",
    "            loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "\n",
    "            if torch.isnan(loss).any():\n",
    "                print(f\"Trial {trial.number} | Epoch {epoch:02d} | NaN loss detected so pruning trial\")\n",
    "                trial.report(float('inf'), epoch)\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch.num_graphs\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch)\n",
    "                val_loss += F.mse_loss(pred, batch.y.view(-1, 1)).item() * batch.num_graphs\n",
    "        val_loss /= len(valid_loader.dataset)\n",
    "\n",
    "        # logging, reporting, pruning, early stopping\n",
    "        print(f\"Trial {trial.number} | Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Optimizer: {optimizer_name}\")\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Trial {trial.number} - Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    study_name = \"final_2d_gnn_study_Tg_6\"\n",
    "    storage_name = f\"sqlite:///{study_name}.db\"\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "    def save_study_callback(study, trial):\n",
    "        pass\n",
    "\n",
    "    study.optimize(objective, n_trials=1500, callbacks=[save_study_callback])\n",
    "    print(study.best_params)\n",
    "    joblib.dump(study, f\"{study_name}_final.pkl\")\n",
    "    \n",
    "    # final plots\n",
    "    vis = optuna.visualization\n",
    "    fig = vis.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "    fig_params = vis.plot_param_importances(study)\n",
    "    fig_params.show()\n",
    "    fig_intermediate = vis.plot_intermediate_values(study)\n",
    "    fig_intermediate.show()\n",
    "    fig_parallel_coordinate = vis.plot_parallel_coordinate(study)\n",
    "    fig_parallel_coordinate.show()\n",
    "    fig_slice = vis.plot_slice(study)\n",
    "    fig_slice.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b2e9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gnn_dim': 256, 'hidden_dim': 512, 'dropout_rate': 0.34404144200017467, 'lr': 0.0005555079210176292, 'activation': 'Swish', 'optimizer': 'RMSprop', 'weight_decay': 9.056299733554687e-06}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad23af4",
   "metadata": {},
   "source": [
    "# Step 9: Retrain with best prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdff0035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning:\n",
      "\n",
      "'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 21075.7465 | Val Loss: 21515.0694\n",
      "Epoch 02 | Train Loss: 18412.4069 | Val Loss: 16742.9964\n",
      "Epoch 03 | Train Loss: 13482.4078 | Val Loss: 10170.9151\n",
      "Epoch 04 | Train Loss: 10762.2532 | Val Loss: 8672.9495\n",
      "Epoch 05 | Train Loss: 8752.3588 | Val Loss: 8627.0248\n",
      "Epoch 06 | Train Loss: 8989.4383 | Val Loss: 7471.9699\n",
      "Epoch 07 | Train Loss: 8687.6152 | Val Loss: 8545.6703\n",
      "Epoch 08 | Train Loss: 8494.2873 | Val Loss: 6629.4823\n",
      "Epoch 09 | Train Loss: 8199.8157 | Val Loss: 7775.6130\n",
      "Epoch 10 | Train Loss: 8492.5612 | Val Loss: 6174.4164\n",
      "Epoch 11 | Train Loss: 8841.7912 | Val Loss: 8896.0238\n",
      "Epoch 12 | Train Loss: 9961.9870 | Val Loss: 9183.1653\n",
      "Epoch 13 | Train Loss: 7850.2319 | Val Loss: 5718.5266\n",
      "Epoch 14 | Train Loss: 7588.5548 | Val Loss: 7659.2603\n",
      "Epoch 15 | Train Loss: 7269.6318 | Val Loss: 5478.8555\n",
      "Epoch 16 | Train Loss: 6827.4938 | Val Loss: 6214.1558\n",
      "Epoch 17 | Train Loss: 6833.5648 | Val Loss: 5641.3596\n",
      "Epoch 18 | Train Loss: 6821.8544 | Val Loss: 6171.5468\n",
      "Epoch 19 | Train Loss: 7436.7284 | Val Loss: 6493.2090\n",
      "Epoch 20 | Train Loss: 6704.7555 | Val Loss: 5213.5591\n",
      "Epoch 21 | Train Loss: 6486.0545 | Val Loss: 6871.7759\n",
      "Epoch 22 | Train Loss: 6879.4802 | Val Loss: 5102.1684\n",
      "Epoch 23 | Train Loss: 5992.5806 | Val Loss: 6113.3185\n",
      "Epoch 24 | Train Loss: 6684.3023 | Val Loss: 5160.4262\n",
      "Epoch 25 | Train Loss: 5870.5077 | Val Loss: 6076.3644\n",
      "Epoch 26 | Train Loss: 6925.1073 | Val Loss: 5274.2648\n",
      "Epoch 27 | Train Loss: 5791.4914 | Val Loss: 6112.2142\n",
      "Epoch 28 | Train Loss: 6352.1669 | Val Loss: 6503.4347\n",
      "Epoch 29 | Train Loss: 6267.1306 | Val Loss: 5033.7127\n",
      "Epoch 30 | Train Loss: 5265.5651 | Val Loss: 5852.9310\n",
      "Epoch 31 | Train Loss: 6335.8947 | Val Loss: 5019.3658\n",
      "Epoch 32 | Train Loss: 6143.4458 | Val Loss: 5589.3084\n",
      "Epoch 33 | Train Loss: 6331.6396 | Val Loss: 5694.1563\n",
      "Epoch 34 | Train Loss: 5544.5855 | Val Loss: 4900.6491\n",
      "Epoch 35 | Train Loss: 5962.0349 | Val Loss: 5791.3550\n",
      "Epoch 36 | Train Loss: 5640.5708 | Val Loss: 5004.3699\n",
      "Epoch 37 | Train Loss: 5542.8783 | Val Loss: 4961.1791\n",
      "Epoch 38 | Train Loss: 6128.5854 | Val Loss: 5000.2846\n",
      "Epoch 39 | Train Loss: 5863.5504 | Val Loss: 5753.8598\n",
      "Epoch 40 | Train Loss: 5301.8368 | Val Loss: 5788.5928\n",
      "Epoch 41 | Train Loss: 5672.9198 | Val Loss: 6876.7144\n",
      "Epoch 42 | Train Loss: 5731.0086 | Val Loss: 6053.4539\n",
      "Epoch 43 | Train Loss: 5869.5836 | Val Loss: 5081.3667\n",
      "Epoch 44 | Train Loss: 5616.6736 | Val Loss: 5900.0194\n",
      "Early stopping triggered at epoch 44\n",
      "\n",
      "Final Test Set Evaluation:\n",
      "        MAE       RMSE  r_squared\n",
      "0  47.41354  62.957546   0.681673\n",
      "Final Test Loss: 3963.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_16100\\639511179.py:104: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The best_params dictionary is available from your Optuna study\n",
    "best_params = study.best_params\n",
    "\n",
    "# Use the same train/val/test sets as the Optuna objective function.\n",
    "# You need to make sure `data_list` is available in this scope.\n",
    "train_val_set, test_set = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "train_set, val_set = train_test_split(train_val_set, test_size=0.25, random_state=42)\n",
    " \n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=64)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "\n",
    "# reinitialize model\n",
    "model = HybridGNN(\n",
    "    gnn_dim=best_params['gnn_dim'],\n",
    "    rdkit_dim=rdkit_features.shape[1],\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    activation=best_params['activation']\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# instantiate Optimizer based on Optuna's choice\n",
    "optimizer_name = best_params['optimizer']\n",
    "lr = best_params['lr']\n",
    "weight_decay = best_params['weight_decay']\n",
    "\n",
    "if optimizer_name == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "elif optimizer_name == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "elif optimizer_name == \"SGD\":\n",
    "    momentum = best_params['momentum']\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "elif optimizer_name == \"RMSprop\":\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "else:\n",
    "    raise ValueError(f\"Optimizer '{optimizer_name}' not supported.\")\n",
    "\n",
    "num_epochs = 100\n",
    "total_steps = num_epochs * len(train_loader)\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "# early stopping training loop w loss tracking and plotting\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            preds.append(pred.cpu())\n",
    "            targets.append(batch.y.view(-1, 1).cpu())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return avg_loss, preds, targets\n",
    "\n",
    "for epoch in range(1, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        loss = F.mse_loss(pred, batch.y.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_loss, val_preds, val_targets = evaluate(model, valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_hybridgnn.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# load best model and final evaluation on the TEST set\n",
    "model.load_state_dict(torch.load(\"best_hybridgnn.pt\"))\n",
    "model.eval()\n",
    "final_test_loss, test_preds, test_targets = evaluate(model, test_loader)\n",
    "metrics = regression_metrics(test_targets.numpy(), test_preds.numpy())\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])\n",
    "print(f\"Final Test Loss: {final_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef0f88",
   "metadata": {},
   "source": [
    "# Step 10: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9437faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting training and validation loss \n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c13e8b",
   "metadata": {},
   "source": [
    "| Model Type             | Featurization        |   MAE |  RMSE |   R² | Notes             |\n",
    "|------------------------|----------------------|-------|-------|------|-------------------|\n",
    "| Hybrid GNN (Tuned)| OGB smiles2graph + RDKit descriptors | 0.159 | 0.234 | 0.965 | Best   |\n",
    "| Hybrid GNN (Untuned) | OGB smiles2graph + RDKit descriptors | 0.223 | 0.308 | 0.939 | 2nd best|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130ba5c",
   "metadata": {},
   "source": [
    "# Step 11: Evaluate on test-dev and save the predictions to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68eba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2298/2298 [00:22<00:00, 102.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with molecule IDs saved to 'hybridgnn_testdev_predictions_with_ids.csv'\n"
     ]
    }
   ],
   "source": [
    "# map subset back to original dataset indices\n",
    "test_indices = split_idx['test-dev']\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "all_preds = []\n",
    "all_ids = [] # store original molecule indices\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader, desc=\"Predicting\")):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "\n",
    "# stack predictions\n",
    "all_preds = np.vstack(all_preds)\n",
    "\n",
    "# match predictions to original indices\n",
    "submission_df = pd.DataFrame({'mol_index': test_indices,  # original indices\n",
    "                              'prediction': all_preds.flatten()  # flatten to 1D\n",
    "                              })\n",
    "\n",
    "# sort by original molecule ID \n",
    "submission_df = submission_df.sort_values('mol_index').reset_index(drop=True)\n",
    "\n",
    "# save to CSV\n",
    "submission_df.to_csv(\"hybridgnn_testdev_predictions_with_ids.csv\", index=False)\n",
    "print(\"Predictions with molecule IDs saved to 'hybridgnn_testdev_predictions_with_ids.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f673460",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cce6e",
   "metadata": {},
   "source": [
    "## Model Performance Summary\n",
    "\n",
    "All baseline models were initially trained and evaluated on a 5,000 molecule subset of the full dataset. Below is a comparison of results across different featurization strategies and model types:\n",
    "\n",
    "### 2D Baseline Models\n",
    "\n",
    "| Model Type    | Featurization      | MAE   | RMSE  | R²    | Notes                                 |\n",
    "| ------------- | ------------------ | ----- | ----- | ----- | ------------------------------------- |\n",
    "| MLP (Tuned)   | RDKit Fingerprints | 0.426 | 0.574 | 0.798 | Strong performance across all metrics |\n",
    "| KRR (Tuned)   | RDKit Fingerprints | 0.454 | 0.593 | 0.784 | Good overall, slightly lower R²       |\n",
    "| RF (Tuned)    | RDKit Fingerprints | 0.423 | 0.583 | 0.791 | Best MAE, very competitive overall    |\n",
    "| MLP (Tuned)   | Coulomb Matrix     | 0.636 | 0.819 | 0.588 | Significantly weaker performance      |\n",
    "| MLP (Untuned) | RDKit Fingerprints | 0.467 | 0.609 | 0.772 | Solid untuned baseline                |\n",
    "| KRR (Untuned) | RDKit Fingerprints | 0.519 | 0.668 | 0.726 | Notable drop from tuned version       |\n",
    "| RF (Untuned)  | RDKit Fingerprints | 0.426 | 0.587 | 0.788 | Surprisingly close to tuned RF        |\n",
    "| MLP (Untuned) | Coulomb Matrix     | 0.663 | 0.847 | 0.559 | Consistently underperforms            |\n",
    "\n",
    "### Graph Neural Network Models (ChemML)\n",
    "\n",
    "| Model Type    | Featurization               | MAE   | RMSE  | R²    | Notes                                |\n",
    "| ------------- | --------------------------- | ----- | ----- | ----- | ------------------------------------ |\n",
    "| GNN (Tuned)   | `tensorise_molecules` Graph | 0.302 | 0.411 | 0.900 | Best results from ChemML experiments |\n",
    "| GNN (Untuned) | `tensorise_molecules` Graph | 0.400 | 0.519 | 0.841 | Strong but less optimized            |\n",
    "\n",
    "### Final Hybrid GNN Model Trained on Full Dataset (OGB-Compatible)\n",
    "\n",
    "| Model Type           | Featurization                          | MAE   | RMSE  | R²    | Notes                              |\n",
    "| -------------------- | -------------------------------------- | ----- | ----- | ----- | ---------------------------------- |\n",
    "| Hybrid GNN (Tuned)   | OGB `smiles2graph` + RDKit descriptors | 0.159 | 0.234 | 0.965 | State-of-the-art level performance |\n",
    "| Hybrid GNN (Untuned) | OGB `smiles2graph` + RDKit descriptors | 0.223 | 0.308 | 0.939 | Still very strong pre-tuning       |\n",
    "\n",
    "---\n",
    "\n",
    "## Model Error Analysis\n",
    "\n",
    "I performed qualitative evaluation by comparing predicted vs. true HOMO–LUMO gaps for both randomly selected and poorly predicted molecules. The worst performing molecules often showed rare or complex structures likely underrepresented in the training set. This highlights the importance of structural diversity and potentially more expressive 3D information to improve generalization.\n",
    "\n",
    "## Next Steps: Integrating 3D Molecular Information\n",
    "\n",
    "To push performance even further and overcome limitations of 2D graphs and hand crafted descriptors, my next step will involve:\n",
    "\n",
    "* Using **3D molecular geometries** \n",
    "* Incorporating **interatomic distances**, angles, and **spatial encoding** (SchNet, DimeNet, or SE(3)-equivariant models)\n",
    "* Comparing results against the current best MAE (\\~0.159)\n",
    "\n",
    "This direction aligns with trends in molecular property prediction where 3D aware models often outperform purely 2D approaches, especially for quantum properties like HOMO–LUMO gaps.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
