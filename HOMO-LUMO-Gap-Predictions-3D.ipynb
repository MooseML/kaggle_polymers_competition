{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034b0d50",
   "metadata": {},
   "source": [
    "\n",
    "# Hybrid GNN + 3D Distances + Transformer Attention Block + RDKit Descriptors\n",
    "\n",
    "Our 3D-aware graph neural network architecture takes as input atom features, bond types, and crucial edge distance information derived from the 3D molecular coordinates. The model begins with independent Atom and Bond Encoders to generate initial embeddings for the atoms and bonds, respectively. Notably, the Bond Encoder is augmented to directly incorporate the Euclidean distance between bonded atoms as an additional feature. These initial embeddings are then processed through two layers of Graph Isomorphism Network with Edge features (GINEConv), where the edge distance feature is explicitly utilized during message passing, allowing the model to learn relationships influenced by spatial proximity. To capture global interactions within the molecule, we employ a Self-Attention block. Following the GNN and attention layers, a CLS token pooling strategy is used to obtain a fixed-size representation of the entire molecular graph. This global graph embedding is then concatenated with a set of six 1D global molecular descriptors calculated using RDKit. Finally, the combined feature vector is fed into a multi-layer perceptron (MLP) prediction head to output the predicted HOMO-LUMO gap.\n",
    "\n",
    "The implementation of this 3D-aware GNN model involved several key steps. First, 3D molecular structures were loaded from SDF files using RDKit. Simultaneously, the 2D graph representations and the corresponding dataset splits were loaded using the PyG PCQM4Mv2 Dataset. Additionally, SMILES strings for all molecules were loaded to compute a set of six global molecular descriptors (molecular weight, number of rotatable bonds, topological polar surface area, number of hydrogen acceptors, number of hydrogen donors, and ring count) using RDKit. To enrich the atom-level information beyond the standard atomic number, a custom atom feature extractor was implemented to include features like formal charge, aromaticity, hybridization, ring membership, and the number of attached hydrogens. These extra atom features were then projected and combined with the output of the standard AtomEncoder. Crucially, a custom `create_data_object` function was developed to process each molecule: it extracts 2D graph information, retrieves 3D coordinates, calculates Euclidean distances between bonded atoms, incorporates the custom atom features, and constructs a PyG `Data` object that explicitly includes the edge distances as part of the edge attributes. These enhanced `Data` objects, now incorporating 3D information, were then chunked and saved to disk for efficient loading during training using an LMDB database. The training process utilized optimized hyperparameters identified from prior experiments, the AdamW optimizer with a cosine scheduler and warmup, mixed-precision training with gradient scaling, and early stopping based on the validation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8267785",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "# 7. model – geometry used only if present\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import random \n",
    "\n",
    "class ExtendedAtomEncoder(nn.Module):\n",
    "    def __init__(self, gnn_dim, extra_atom_dim):\n",
    "        super().__init__()\n",
    "        self.atom_encoder = AtomEncoder(emb_dim=gnn_dim)\n",
    "        self.extra_proj = nn.Linear(extra_atom_dim, gnn_dim)\n",
    "        self.output_proj = nn.Linear(gnn_dim * 2, gnn_dim)  # Combine encoded + extra info\n",
    "\n",
    "    def forward(self, x, extra_atom_features):\n",
    "        \"\"\"\n",
    "        x: [num_atoms, atom_input_dim] -> original atom input (atomic number idx)\n",
    "        extra_atom_features: [num_atoms, extra_atom_dim] -> handcrafted features\n",
    "        \"\"\"\n",
    "        atom_emb = self.atom_encoder(x)            # [num_atoms, gnn_dim]\n",
    "        extra_emb = self.extra_proj(extra_atom_features.float())  # [num_atoms, gnn_dim]\n",
    "        extra_emb = torch.nan_to_num(extra_emb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        combined = torch.cat([atom_emb, extra_emb], dim=-1)  # [num_atoms, gnn_dim*2]\n",
    "        output = self.output_proj(combined)                  # [num_atoms, gnn_dim]\n",
    "        return output\n",
    "    \n",
    "class BondEncoderWithDist(nn.Module):\n",
    "    \"\"\"\n",
    "    First three cols = OGB categorical bond features (int)\n",
    "    Remaining K cols = continuous geometry embedding (float)\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim: int, n_rbf: int = 32):\n",
    "        super().__init__()\n",
    "        from ogb.graphproppred.mol_encoder import BondEncoder\n",
    "        self.cat_enc  = BondEncoder(emb_dim)                    # (E,3)  → (E,D)\n",
    "        self.dist_mlp = nn.Sequential(                          # (E,K)  → (E,D)\n",
    "            nn.Linear(n_rbf, emb_dim), nn.SiLU(),\n",
    "            nn.Linear(emb_dim, emb_dim))\n",
    "\n",
    "    def forward(self, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        cat  = self.cat_enc(edge_attr[:, :3].long())\n",
    "        geo  = self.dist_mlp(edge_attr[:, 3:].float())\n",
    "        return cat + geo\n",
    "    \n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 8. edge & triplet up‑dates\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "class PairWiseUpdate(nn.Module):\n",
    "    \"\"\"\n",
    "    one liner edge updater e_ij ← f(e_ij , h_i , h_j)\n",
    "    keeps the size (E, D) unchanged so batching still works\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(3*dim, dim), nn.SiLU(),\n",
    "            nn.Linear(dim, dim))\n",
    "    def forward(self, e, hi, hj):        # all (E, D)\n",
    "        return self.f(torch.cat([e, hi, hj], -1))\n",
    "\n",
    "from torch_scatter import scatter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TripletBlock(nn.Module):\n",
    "    def __init__(self, dim, num_samples=4):\n",
    "        super().__init__()\n",
    "        self.angle_mlp = nn.Sequential(\n",
    "            nn.Linear(1, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def forward(self, pos, edge_index, e):  # pos: (N,3), edge_index: (2,E), e: (E,D)\n",
    "        device = pos.device\n",
    "        src, dst = edge_index[0], edge_index[1]\n",
    "        num_nodes = pos.size(0)\n",
    "\n",
    "        # Build adjacency list\n",
    "        adj = [[] for _ in range(num_nodes)]\n",
    "        for i, j in zip(src.tolist(), dst.tolist()):\n",
    "            adj[i].append(j)\n",
    "\n",
    "        # Sample k for each edge (i, j)\n",
    "        new_i, new_j, new_k, group_idx = [], [], [], []\n",
    "        for idx, (i, j) in enumerate(zip(src.tolist(), dst.tolist())):\n",
    "            neighbors = [k for k in adj[i] if k != j]\n",
    "            if len(neighbors) == 0:\n",
    "                continue\n",
    "            ks = random.sample(neighbors, min(self.num_samples, len(neighbors)))\n",
    "            for k in ks:\n",
    "                new_i.append(i)\n",
    "                new_j.append(j)\n",
    "                new_k.append(k)\n",
    "                group_idx.append(idx)  # for aggregation\n",
    "\n",
    "        if len(new_i) == 0:\n",
    "            return e  # no triplets found\n",
    "\n",
    "        i = torch.tensor(new_i, device=device)\n",
    "        j = torch.tensor(new_j, device=device)\n",
    "        k = torch.tensor(new_k, device=device)\n",
    "        group_idx = torch.tensor(group_idx, device=device)\n",
    "\n",
    "        v1 = pos[i] - pos[j]\n",
    "        v2 = pos[i] - pos[k]\n",
    "        cos = (v1 * v2).sum(-1, keepdim=True) / (\n",
    "            v1.norm(dim=-1, keepdim=True) * v2.norm(dim=-1, keepdim=True) + 1e-9)\n",
    "        ang = torch.acos(torch.clamp(cos, -1 + 1e-6, 1 - 1e-6))  # (T, 1)\n",
    "        gate = self.angle_mlp(ang)  # (T, D)\n",
    "\n",
    "        # Aggregate angle gates over original edges\n",
    "        angle_update = scatter(gate, group_idx, dim=0, dim_size=e.size(0), reduce='mean')\n",
    "        return e + angle_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fcc218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDB contains 0 graphs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# ── DataLoaders (multiprocessing safe) ────────────────────────────────\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m---> 26\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLMDBDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLMDB_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[0;32m     27\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(LMDBDataset(valid_ids, LMDB_PATH), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# quick smoke test\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:87\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_batch \u001b[38;5;241m=\u001b[39m follow_batch\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_keys \u001b[38;5;241m=\u001b[39m exclude_keys\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCollater\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\utils\\data\\sampler.py:144\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "import lmdb, random, torch\n",
    "from graphdata_lmdb import LMDBDataset          \n",
    "import os\n",
    "\n",
    "# ── create the loader first ───────────────────────────────────\n",
    "DATA_ROOT = r\"C:/Users/mattg/Downloads/HOMO-LUMO/data\"\n",
    "LMDB_PATH = os.path.join(DATA_ROOT, \"processed_chunks\", \"pcqm4m_train3d_dist.lmdb\")\n",
    "RAND_SEED  = 0\n",
    "\n",
    "# ── fetch every key once (fast – ~1 s for 3.3 M graphs) ────────────────\n",
    "with lmdb.open(LMDB_PATH, readonly=True, lock=False, readahead=False) as env:\n",
    "    with env.begin(buffers=True) as txn:\n",
    "        all_ids = [int(k) for k, _ in txn.cursor()]\n",
    "print(f\"LMDB contains {len(all_ids):,} graphs\")\n",
    "\n",
    "# ── train/val split (10 %) ─────────────────────────────────────────────\n",
    "random.seed(RAND_SEED)\n",
    "val_k    = int(0.10 * len(all_ids))\n",
    "valid_ids = random.sample(all_ids, k=val_k)\n",
    "valid_ids_set = set(valid_ids)  # Convert to a set for faster lookups\n",
    "train_ids = [i for i in all_ids if i not in valid_ids_set]\n",
    "\n",
    "# ── DataLoaders (multiprocessing safe) ────────────────────────────────\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(LMDBDataset(train_ids, LMDB_PATH), batch_size=128, shuffle=True) \n",
    "valid_loader = DataLoader(LMDBDataset(valid_ids, LMDB_PATH), batch_size=128, shuffle=False) \n",
    "\n",
    "# quick smoke test\n",
    "batch = next(iter(train_loader))\n",
    "print(\"dist shape:\", batch.dist[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1a67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "\n",
    "CKPT_DIR = Path(\"checkpoints\")         \n",
    "CKPT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_ckpt(tag, epoch, model, optimizer, scheduler, scaler, best_val, patience_ctr, train_hist, val_hist, keep_last=2, folder=\"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Save `ckpt_{epoch:03d}.pt` and keep only the *latest* `keep_last`\n",
    "    files with the given tag (e.g. tag = \"runA\").\n",
    "    \"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    fname = f\"{folder}/{tag}_e{epoch:03d}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\"   : epoch,\n",
    "        \"model\"   : model.state_dict(),\n",
    "        \"optim\"   : optimizer.state_dict(),\n",
    "        \"sched\"   : scheduler.state_dict(),\n",
    "        \"scaler\"  : scaler.state_dict(),\n",
    "        \"best_val\": best_val,\n",
    "        \"patience\": patience_ctr,\n",
    "        \"train_hist\": train_hist,\n",
    "        \"val_hist\": val_hist,\n",
    "    }, fname)\n",
    "\n",
    "    # ── garbage-collect older ckpts ─────────────────────────────\n",
    "    ckpts = sorted(Path(folder).glob(f\"{tag}_e*.pt\"),\n",
    "                   key=lambda p: int(re.search(r\"e(\\d+)\", p.stem).group(1)))\n",
    "    for p in ckpts[:-keep_last]:\n",
    "        p.unlink(missing_ok=True)\n",
    "\n",
    "def load_ckpt(path, model, optimizer, scheduler, scaler, map_location=\"cpu\"):\n",
    "    ckpt = torch.load(path, map_location=map_location)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optim\"])\n",
    "    scheduler.load_state_dict(ckpt[\"sched\"])\n",
    "    scaler.load_state_dict(ckpt[\"scaler\"])\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151ee96",
   "metadata": {},
   "source": [
    "What if you later need 3-D for the public test split?\n",
    "\n",
    "Exactly the same idea:\n",
    "---\n",
    "test_ids   = split[\"test-dev\"]          # or test-challenge\n",
    "\n",
    "test_3d    = [(i, None) for i in test_ids]     # no SDF available\n",
    "\n",
    "env = lmdb.open(\"pcqm4m_test3d.lmdb\", map_size=...)\n",
    "\n",
    "txn = env.begin(write=True)\n",
    "\n",
    "for idx, _ in tqdm.tqdm(test_3d):\n",
    "\n",
    "    smiles = smiles_ds[idx][0]\n",
    "\n",
    "    mol    = make_conformer(smiles)           # ETKDG\n",
    "\n",
    "    txn.put(str(idx).encode(), dump(pack(build_data(idx, mol))))\n",
    "    \n",
    "txn.commit(); env.close()\n",
    "---\n",
    "You can concatenate that LMDB with the existing one (or keep two separate databases and query the right one, up to you) – since the keys are the same indices everything stays consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8982e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "# 12. TransformerEncoderLayerWithBias\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ── helpers for robust training ─────────────────────────────────────────\n",
    "def has_nan(t: torch.Tensor) -> bool:\n",
    "    \"\"\"True ⇢ tensor contains NaN or ±Inf (works on fp16/fp32).\"\"\"\n",
    "    return torch.isfinite(t).logical_not().any().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def clip_grad_and_nan(parameters, max_norm: float = 5.0, eps: float = 1e-6):\n",
    "    \"\"\"\n",
    "    • set grad-NaNs / Infs → 0  \n",
    "    • global-norm clip (like torch.clip_grad_norm_)  \n",
    "    \"\"\"\n",
    "    total_norm = torch.zeros(1, device=next(iter(parameters)).device)\n",
    "    for p in parameters:\n",
    "        if p.grad is None:            # skip leafs w/o grad\n",
    "            continue\n",
    "        # 1) kill NaN & Inf in this parameter’s grad\n",
    "        bad_mask = torch.isfinite(p.grad).logical_not()\n",
    "        if bad_mask.any():\n",
    "            p.grad[bad_mask] = 0.0\n",
    "        # 2) accumulate L2-norm² for global clip\n",
    "        total_norm.add_(p.grad.norm(2).pow(2))\n",
    "    total_norm = total_norm.sqrt()\n",
    "    clip_coef  = max_norm / (total_norm + eps)\n",
    "    if clip_coef < 1.0:\n",
    "        for p in parameters:\n",
    "            if p.grad is not None:\n",
    "                p.grad.mul_(clip_coef)\n",
    "\n",
    "def safe_optimizer_step(scaler, optimizer, model, max_norm: float = 5.0):\n",
    "    \"\"\"\n",
    "    Replacement for the usual unscale → clip → step → update block.\n",
    "    \"\"\"\n",
    "    scaler.unscale_(optimizer)                     # grads now fp32\n",
    "    clip_grad_and_nan(model.parameters(), max_norm)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "class TransformerEncoderLayerWithBias(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1,\n",
    "                 dim_feedforward=2048, activation=\"ReLU\", batch_first=True):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first)\n",
    "        self.d_model = d_model\n",
    "        self.linear1  = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        self.linear2  = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1    = nn.LayerNorm(d_model)\n",
    "        self.norm2    = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"ReLU\" else F.gelu\n",
    "        self.nhead = nhead # keep for external checks\n",
    "\n",
    "    def forward(self, src, src_key_padding_mask=None, attn_bias=None):\n",
    "        B, L, _ = src.size()\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # build attention mask\n",
    "        # expected shape:  (B · nhead,  L,  L)\n",
    "        # ------------------------------------------------------------------\n",
    "        if attn_bias is not None:\n",
    "            assert attn_bias.shape == (B, self.nhead, L, L), f\"attn_bias must be (B,H,L,L), got {attn_bias.shape}\"\n",
    "            attn_mask = attn_bias.view(B * self.nhead, L, L)\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        # MultiheadAttention already projects & splits into heads internally\n",
    "        attn_output, _ = self.self_attn(src, src, src, attn_mask=attn_mask, key_padding_mask=src_key_padding_mask) # attn_output: (B, L, D)\n",
    "        src = self.norm1(src + self.dropout1(attn_output))\n",
    "        ff  = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = self.norm2(src + self.dropout2(ff))\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f069c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "# 14. final model  \n",
    "# ════════════════════════════════════════════════════════════════\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "# Custom Transformer encoder wrapper that accepts attn_bias\n",
    "class CustomTransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(encoder_layer.d_model)\n",
    "\n",
    "    def forward(self, src, mask, attn_bias=None):\n",
    "        for mod in self.layers:\n",
    "            src = mod(src, src_key_padding_mask=mask, attn_bias=attn_bias)\n",
    "        return self.norm(src)\n",
    "\n",
    "\n",
    "class GNN_Transformer_Hybrid(nn.Module):\n",
    "    def __init__(self, gnn_dim, rdkit_dim, hidden_dim, extra_atom_dim, num_transformer_layers=2, num_heads=8, dropout_rate=0.2, activation='GELU'):\n",
    "        super().__init__()\n",
    "        act_map = {'ReLU': nn.ReLU(), 'ELU': nn.ELU(), 'LeakyReLU': nn.LeakyReLU(), 'PReLU': nn.PReLU(), 'GELU': nn.GELU(), 'Swish': nn.SiLU()}\n",
    "        act_fn = act_map[activation]\n",
    "        self.gnn_dim = gnn_dim\n",
    "        self.rdkit_dim = rdkit_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads  \n",
    "\n",
    "        # Atom and bond encoders\n",
    "        self.atom_encoder = ExtendedAtomEncoder(gnn_dim, extra_atom_dim)\n",
    "        self.bond_encoder = BondEncoderWithDist(gnn_dim, n_rbf=32)\n",
    "        # in __init__\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, gnn_dim))\n",
    "        nn.init.normal_(self.cls_token, std=0.02)\n",
    "        \n",
    "        # message passing\n",
    "        self.conv1 = GINEConv(nn.Sequential(nn.Linear(gnn_dim, gnn_dim), act_fn, nn.Linear(gnn_dim, gnn_dim)))\n",
    "        self.edge_upd1 = PairWiseUpdate(gnn_dim)\n",
    "        self.conv2 = GINEConv(nn.Sequential(nn.Linear(gnn_dim, gnn_dim), act_fn, nn.Linear(gnn_dim, gnn_dim)))\n",
    "        self.edge_upd2 = PairWiseUpdate(gnn_dim)\n",
    "        self.triplet   = TripletBlock(gnn_dim)\n",
    "\n",
    "        # Custom Transformer encoder\n",
    "        encoder_layer = TransformerEncoderLayerWithBias(d_model=gnn_dim,\n",
    "                                                        nhead=num_heads,\n",
    "                                                        batch_first=True,\n",
    "                                                        dim_feedforward=gnn_dim * 4,\n",
    "                                                        dropout=dropout_rate)\n",
    "        self.transformer = CustomTransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "\n",
    "        # Final prediction head\n",
    "        self.mlp = nn.Sequential(nn.Linear(gnn_dim + rdkit_dim, hidden_dim), act_fn,\n",
    "                                 nn.Dropout(dropout_rate),\n",
    "                                 nn.Linear(hidden_dim, hidden_dim // 2), act_fn,\n",
    "                                 nn.Dropout(dropout_rate),\n",
    "                                 nn.Linear(hidden_dim // 2, 1))\n",
    "    \n",
    "    def forward(self, data):\n",
    "\n",
    "        # 1) encoders \n",
    "        x = self.atom_encoder(data.x, data.extra_atom_feats)\n",
    "        if has_nan(x):\n",
    "            raise RuntimeError(\"NaN after atom_encoder\")\n",
    "\n",
    "        e   = self.bond_encoder(data.edge_attr)\n",
    "        src, dst = data.edge_index\n",
    "\n",
    "        for conv, upd in [(self.conv1, self.edge_upd1),\n",
    "                        (self.conv2, self.edge_upd2)]:\n",
    "            x = conv(x, data.edge_index, e)\n",
    "            e = upd(e, x[src], x[dst])\n",
    "            if data.has_xyz.any():\n",
    "                e = self.triplet(data.pos, data.edge_index, e)\n",
    "        if has_nan(x):\n",
    "            raise RuntimeError(\"NaN after GINE\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # 2) pack graphs (+CLS)\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        B, parts, sizes = int(data.batch.max()) + 1, [], []\n",
    "        for i in range(B):\n",
    "            idx = (data.batch == i).nonzero(as_tuple=True)[0]\n",
    "            xi  = x[idx]\n",
    "            parts.append(torch.cat([xi, self.cls_token], 0))\n",
    "            sizes.append(xi.size(0) + 1)\n",
    "\n",
    "        all_feat = torch.cat(parts, 0)\n",
    "        batch    = torch.repeat_interleave(\n",
    "                        torch.arange(B, device=x.device),\n",
    "                        torch.tensor(sizes, device=x.device))\n",
    "        pad, mask = to_dense_batch(all_feat, batch)          # (B,L,D)\n",
    "        max_nodes = pad.size(1)\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # 3) attention-bias   (fp32,   B × H × L × L)\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        bias_stack = []\n",
    "        dist_iter  = iter(data.dist)                         # (MAX_NODES, MAX_NODES)\n",
    "\n",
    "        for i in range(B):\n",
    "            dist = next(dist_iter).to(x.device)              # uint8 → device\n",
    "            n    = sizes[i] - 1                              # real atoms  (–CLS)\n",
    "\n",
    "            # safety-net ① — empty graph (rare, but possible with data errors)\n",
    "            if n == 0:\n",
    "                bias_stack.append(torch.zeros(max_nodes, max_nodes,\n",
    "                                            dtype=torch.float32,\n",
    "                                            device=x.device))\n",
    "                continue\n",
    "\n",
    "            # crop and negate distances, then CLAMP\n",
    "            local = -dist[:n, :n].float()                    # 0 on diag, –d elsewhere\n",
    "            tmp   = torch.zeros(max_nodes, max_nodes,\n",
    "                                dtype=torch.float32,\n",
    "                                device=x.device)\n",
    "            tmp[:n, :n] = local.clamp(min=-5.0, max=0.0)     # safety-net ②\n",
    "            bias_stack.append(tmp)\n",
    "\n",
    "        attn_bias = torch.stack(bias_stack, 0)               # (B,L,L)\n",
    "        attn_bias = attn_bias.unsqueeze(1)                   # (B,1,L,L)\n",
    "        attn_bias = attn_bias.repeat(1, self.num_heads, 1, 1)# (B,H,L,L)\n",
    "\n",
    "        if has_nan(attn_bias):\n",
    "            raise RuntimeError(\"NaN in attention-bias\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # 4) Transformer  (fp32 everywhere → no dtype warning)\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        pad_fp32      = pad.float()                   # (B,L,D)  fp32 -- safer numerics\n",
    "        valid_mask    = mask                          # (B,L)    bool   True==real node\n",
    "        key_padding   = (~valid_mask).float()         # (B,L)    fp32   1==PAD, 0==keep\n",
    "\n",
    "        # forward through the stacked encoder layers\n",
    "        pad_out = self.transformer(pad_fp32,           # src\n",
    "                                key_padding,        # src_key_padding_mask (fp32)\n",
    "                                attn_bias)          # attn_bias (fp32, B×H×L×L)\n",
    "\n",
    "        # last-resort sanitiser – replace any NaNs/Infs that still slip through\n",
    "        if has_nan(pad_out):\n",
    "            pad_out = torch.nan_to_num(pad_out, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # CLS token is always the last *real* position in each sequence\n",
    "        cls_idx  = valid_mask.sum(1) - 1              # (B,)\n",
    "        cls_out  = pad_out[torch.arange(B, device=x.device), cls_idx]\n",
    "\n",
    "        out = torch.cat([cls_out, data.rdkit_feats.float()], dim=1)\n",
    "        return self.mlp(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244a6dd",
   "metadata": {},
   "source": [
    "# preprocessing function\n",
    "\n",
    "1. Load each molecule from the dataset\n",
    "\n",
    "2. Extract 3D coordinates (optional, later for distance edges)\n",
    "\n",
    "3. Extract atom features (formal charge, aromaticity, etc.)\n",
    "\n",
    "4. Return a fully enhanced torch_geometric.data.Data object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aef2fe4",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "LMDB (Lightning Memory-Mapped Database) is a highly efficient, ordered key-value store that leverages memory mapping for exceptional read performance. Instead of traditional disk I/O, LMDB directly maps the database file into the virtual address space of your process, eliminating the overhead of system calls and data copying. This memory-mapped approach allows for zero-copy reads, making data access feel as fast as accessing in-memory data while retaining disk-based persistence and data safety. Keys within an LMDB database are always lexicographically sorted, which can be advantageous for range queries. It supports multiple concurrent readers without blocking and a single, consistent writer (MVCC), making it robust for various applications requiring fast and reliable data access with a small footprint.\n",
    "\n",
    "To employ LMDB for efficient handling of 3D molecular graph data, the process involves a distinct writing and reading phase. Initially, pre-processed PyTorch Geometric (Data) objects, representing individual molecules, are loaded from chunk files (.pt files). Each Data object, containing graph features like node features (x), edge indices (edge_index), edge attributes (edge_attr), and 3D coordinates (pos), is converted into a lean Python dictionary using the pack function. This step also includes downcasting the numerical data types of the tensors to reduce memory usage. Subsequently, this dictionary is serialized using Python's pickle library and then compressed with gzip via the gz_pickle function, yielding a compact byte string. This compressed representation of each molecular graph is then stored in an LMDB database (pcqm4_3d.lmdb) using a unique integer identifier (gidx) as the key.\n",
    "\n",
    "For accessing this data during model training or evaluation, a custom PyTorch Dataset class, LeanLMDBDataset, is created. This dataset takes a list of indices and the path to the LMDB database. When a specific molecular graph is requested by the DataLoader (through the __getitem__ method using an index), the LeanLMDBDataset opens a read-only transaction with the LMDB environment. It then retrieves the corresponding compressed byte string using the provided index as the key. The gz_unpickle function decompresses and deserializes this byte string back into the lean dictionary. Finally, the dict_to_data function reconstructs the PyTorch Geometric Data object from this dictionary, ensuring the tensors are converted back to the appropriate PyTorch tensors. This on-demand retrieval mechanism avoids loading the entire dataset into memory, enabling the processing of large molecular datasets one graph at a time or in mini-batches managed by the DataLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ccd1c",
   "metadata": {},
   "source": [
    "Right now your graph edges have only:\n",
    "\n",
    "Bond types (edge_attr)\n",
    "\n",
    "But we want to add distance information to edge_attr, so your GNN knows how far apart two atoms are in 3D space.\n",
    "\n",
    "This massively improves model accuracy for tasks like HOMO-LUMO gap prediction!\n",
    "\n",
    "Step | Action\n",
    "1 | For each molecule, extract 3D coordinates from the SDF\n",
    "2 | For each bond (edge), calculate the 3D distance between the two atoms\n",
    "3 | Concatenate or add this distance as a new dimension in edge_attr\n",
    "4 | Train model with this upgraded information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a22a08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, device, criterion=F.mse_loss):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.history = []\n",
    "\n",
    "    def range_test(self, train_loader, start_lr=1e-7, end_lr=1.0, num_iter=100):\n",
    "        self.model.train()\n",
    "        lr_lambda = lambda x: np.exp(x * np.log(end_lr / start_lr) / num_iter)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "        losses = []\n",
    "        lrs = []\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        iter_loader = iter(train_loader)\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            try:\n",
    "                batch = next(iter_loader)\n",
    "            except StopIteration:\n",
    "                iter_loader = iter(train_loader)\n",
    "                batch = next(iter_loader)\n",
    "\n",
    "            batch = batch.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            output = self.model(batch)\n",
    "            loss = self.criterion(output, batch.y.view(-1, 1))\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "            if has_nan(loss) or torch.isinf(loss):\n",
    "                print(f\"NaN at iter {i}, LR={lr:.2e}\")\n",
    "                break\n",
    "            losses.append(loss.item())\n",
    "            lrs.append(lr)\n",
    "\n",
    "            # Stop if loss explodes\n",
    "            if loss.item() > 100 * best_loss:\n",
    "                break\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "\n",
    "        self.history = (lrs, losses)\n",
    "\n",
    "    def plot(self, skip_start=1, skip_end=1):\n",
    "        lrs, losses = self.history\n",
    "        lrs = lrs[skip_start:-skip_end]\n",
    "        losses = losses[skip_start:-skip_end]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel(\"Learning Rate (log scale)\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"LR Range Test\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Clone and reinit model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GNN_Transformer_Hybrid(gnn_dim=512,\n",
    "                               rdkit_dim=6,\n",
    "                               hidden_dim=256,\n",
    "                               extra_atom_dim=5,\n",
    "                               dropout_rate=0.2,\n",
    "                               activation='GELU').to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-7, weight_decay=2e-5)\n",
    "# run LR range test\n",
    "lr_finder = LRFinder(model, optimizer, device)\n",
    "lr_finder.range_test(train_loader, start_lr=1e-7, end_lr=1.0, num_iter=1000)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12eabf",
   "metadata": {},
   "source": [
    "### How to read the LR‑range plot\n",
    "\n",
    "* **Flat / noisy region (10⁻⁷ → ≈ 3 × 10⁻⁶)**\n",
    "  Network is barely learning, loss hovers 35 – 50.\n",
    "* **Steep descent (≈ 3 × 10⁻⁶ → 3 × 10⁻⁵)**\n",
    "  Loss drops rapidly from ≈ 40 to < 10.\n",
    "  *The “knee” is typically the best maximum LR.*\n",
    "* **Bottom plateau (≈ 3 × 10⁻⁵ → 8 × 10⁻⁵)**\n",
    "  Loss stabilises between 2 and 5.\n",
    "* **Up‑slope / noise (< 1 × 10⁻⁴)**\n",
    "  Curve flattens again; past this point risk of divergence increases.\n",
    "\n",
    "### Recommended hyper‑parameters\n",
    "\n",
    "| Region              | LR (log-10)     | Observation                               | Take-away for **One-Cycle**                                          |\n",
    "| ------------------- | --------------- | ----------------------------------------- | -------------------------------------------------------------------- |\n",
    "| **plateau / noisy** | 1 e-7 → 5 e-6   | loss is flat ≈ 25-30                      | LR is still too small – good candidate for *initial* LR              |\n",
    "| **smooth fall**     | 5 e-6 → 3 e-4   | loss drops steadily to the global minimum | choose **max\\_lr** anywhere in the ‘floor’ just *before* bumps start |\n",
    "| **first bumps**     | 5 e-4 → 5 e-3   | small oscillations but still usable       | upper safety limit                                                   |\n",
    "| **divergence**      | > 2 e-2 – 1 e-1 | loss spikes → NaNs soon                   | keep well below this                                                 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a72c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train   1.261 | val   0.237 | lr 3.53e-06\n",
      "Epoch 002 | train   0.441 | val   0.197 | lr 4.51e-06\n",
      "Epoch 003 | train   0.322 | val   0.130 | lr 6.12e-06\n",
      "Epoch 004 | train   0.248 | val   0.108 | lr 8.34e-06\n",
      "Epoch 005 | train   0.201 | val   0.092 | lr 1.11e-05\n",
      "Epoch 006 | train   0.171 | val   0.081 | lr 1.44e-05\n",
      "Epoch 007 | train   0.152 | val   0.069 | lr 1.82e-05\n",
      "Epoch 008 | train   0.138 | val   0.065 | lr 2.24e-05\n",
      "Epoch 009 | train   0.127 | val   0.058 | lr 2.69e-05\n",
      "Epoch 010 | train   0.118 | val   0.053 | lr 3.17e-05\n",
      "Epoch 011 | train   0.109 | val   0.052 | lr 3.66e-05\n",
      "Epoch 012 | train   0.101 | val   0.050 | lr 4.16e-05\n",
      "Epoch 013 | train   0.094 | val   0.047 | lr 4.66e-05\n",
      "Epoch 014 | train   0.087 | val   0.045 | lr 5.15e-05\n",
      "Epoch 015 | train   0.080 | val   0.044 | lr 5.63e-05\n",
      "Epoch 016 | train   0.073 | val   0.043 | lr 6.08e-05\n",
      "Epoch 017 | train   0.068 | val   0.043 | lr 6.50e-05\n",
      "Epoch 018 | train   0.062 | val   0.044 | lr 6.88e-05\n",
      "Epoch 019 | train   0.057 | val   0.038 | lr 7.21e-05\n",
      "Epoch 020 | train   0.053 | val   0.040 | lr 7.49e-05\n",
      "Epoch 021 | train   0.049 | val   0.040 | lr 7.71e-05\n",
      "Epoch 022 | train   0.046 | val   0.037 | lr 7.87e-05\n",
      "Epoch 023 | train   0.044 | val   0.037 | lr 7.97e-05\n",
      "Epoch 024 | train   0.042 | val   0.035 | lr 8.00e-05\n",
      "Epoch 025 | train   0.040 | val   0.036 | lr 7.99e-05\n",
      "Epoch 026 | train   0.039 | val   0.037 | lr 7.97e-05\n",
      "Epoch 027 | train   0.038 | val   0.036 | lr 7.94e-05\n",
      "Epoch 028 | train   0.037 | val   0.035 | lr 7.90e-05\n",
      "Epoch 029 | train   0.036 | val   0.033 | lr 7.84e-05\n",
      "Epoch 030 | train   0.035 | val   0.033 | lr 7.78e-05\n",
      "Epoch 031 | train   0.034 | val   0.032 | lr 7.70e-05\n",
      "Epoch 032 | train   0.033 | val   0.032 | lr 7.60e-05\n",
      "Epoch 033 | train   0.032 | val   0.031 | lr 7.50e-05\n",
      "Epoch 034 | train   0.032 | val   0.033 | lr 7.39e-05\n",
      "Epoch 035 | train   0.031 | val   0.031 | lr 7.26e-05\n",
      "Epoch 036 | train   0.030 | val   0.031 | lr 7.13e-05\n",
      "Epoch 037 | train   0.030 | val   0.032 | lr 6.98e-05\n",
      "Epoch 038 | train   0.029 | val   0.030 | lr 6.83e-05\n",
      "Epoch 039 | train   0.028 | val   0.031 | lr 6.67e-05\n",
      "Epoch 040 | train   0.028 | val   0.030 | lr 6.49e-05\n",
      "Epoch 041 | train   0.027 | val   0.030 | lr 6.31e-05\n",
      "Epoch 042 | train   0.027 | val   0.030 | lr 6.13e-05\n",
      "Epoch 043 | train   0.026 | val   0.030 | lr 5.93e-05\n",
      "Epoch 044 | train   0.026 | val   0.031 | lr 5.74e-05\n",
      "Epoch 045 | train   0.025 | val   0.030 | lr 5.53e-05\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m     pred  \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[0;32m     93\u001b[0m     loss  \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(pred, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccum_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 95\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m running  \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs \u001b[38;5;241m*\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccum_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     97\u001b[0m n_graphs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "# 0. imports / reproducibility\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "import os, torch, torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch import amp                            \n",
    "from chemml.utils import regression_metrics        \n",
    "torch.manual_seed(0)\n",
    "os.environ[\"TORCHSDP_FORCE_DISABLE\"] = \"1\"  # disable SDP kernel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 1. hyper‑parameters (from LR‑range)\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "cfg = dict(gnn_dim = 512,\n",
    "           hidden_dim = 256,\n",
    "           extra_atom_dim = 5,\n",
    "           rdkit_dim = 6,\n",
    "           dropout = 0.2142,\n",
    "           act = \"GELU\",\n",
    "           # optimiser / schedule\n",
    "           max_lr = 8e-5, # ⅓ of valley bottom\n",
    "           div_factor = 25, # init_lr 3.2e-6\n",
    "           final_div_factor = 5_000, # min_lr 1.6e-8\n",
    "           pct_start = 0.30,\n",
    "           weight_decay = 2e-5,\n",
    "           num_epochs = 80,\n",
    "           # misc\n",
    "           accum_steps = 1,\n",
    "           clip_norm = 2.0,\n",
    "           patience = 10)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 2. model, optimiser, scheduler\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "model = GNN_Transformer_Hybrid(gnn_dim = cfg[\"gnn_dim\"],\n",
    "                               rdkit_dim = cfg[\"rdkit_dim\"],\n",
    "                               hidden_dim = cfg[\"hidden_dim\"],\n",
    "                               extra_atom_dim = cfg[\"extra_atom_dim\"],\n",
    "                               dropout_rate = cfg[\"dropout\"],\n",
    "                               activation = cfg[\"act\"]).to(device)\n",
    "\n",
    "init_lr  = cfg[\"max_lr\"] / cfg[\"div_factor\"]\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_lr, weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "scheduler = OneCycleLR(optimizer,\n",
    "                       max_lr = cfg[\"max_lr\"],\n",
    "                       epochs = cfg[\"num_epochs\"],\n",
    "                       steps_per_epoch = len(train_loader),\n",
    "                       pct_start = cfg[\"pct_start\"],\n",
    "                       anneal_strategy = \"cos\",\n",
    "                       div_factor = cfg[\"div_factor\"],\n",
    "                       final_div_factor = cfg[\"final_div_factor\"])\n",
    "\n",
    "scaler = amp.GradScaler(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 3. evaluation helper\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "@torch.no_grad()\n",
    "def evaluate(net, loader):\n",
    "    net.eval()\n",
    "    tot_loss, preds, targets = 0.0, [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        out   = net(batch)\n",
    "        loss  = F.mse_loss(out, batch.y.view(-1, 1))\n",
    "        tot_loss += loss.item() * batch.num_graphs\n",
    "        preds.append(out.cpu())\n",
    "        targets.append(batch.y.view(-1, 1).cpu())\n",
    "    preds   = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return tot_loss / len(loader.dataset), preds, targets\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 4. training loop\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "train_history, val_history = [], []\n",
    "\n",
    "best_val, patience_ctr = float(\"inf\"), 0\n",
    "\n",
    "for epoch in range(1, cfg[\"num_epochs\"] + 1):\n",
    "    model.train()\n",
    "    running, n_graphs = 0.0, 0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, batch in enumerate(train_loader, 1):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "            pred  = model(batch)\n",
    "            loss  = F.mse_loss(pred, batch.y.view(-1, 1)) / cfg[\"accum_steps\"]\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        running  += loss.item() * batch.num_graphs * cfg[\"accum_steps\"]\n",
    "        n_graphs += batch.num_graphs\n",
    "\n",
    "        if step % cfg[\"accum_steps\"] == 0 or step == len(train_loader):\n",
    "            # scaler.unscale_(optimizer)\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), cfg[\"clip_norm\"])\n",
    "            # scaler.step(optimizer)   # update weights\n",
    "            # scaler.update()\n",
    "            safe_optimizer_step(scaler, optimizer, model, max_norm=cfg[\"clip_norm\"])\n",
    "            scheduler.step()  # update LR *after* optimizer\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "    train_loss = running / n_graphs\n",
    "    val_loss, _, _ = evaluate(model, valid_loader)\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    val_history.append(val_loss)\n",
    "\n",
    "    lr_now = scheduler.get_last_lr()[0]\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train {train_loss:7.3f} \"\n",
    "          f\"| val {val_loss:7.3f} | lr {lr_now:.2e}\")\n",
    "    \n",
    "    save_ckpt(\"runA\", epoch, model, optimizer, scheduler, scaler, best_val, patience_ctr, train_history, val_history, keep_last=2)\n",
    "    \n",
    "    # early stopping\n",
    "    if val_loss < best_val:\n",
    "        best_val, patience_ctr = val_loss, 0\n",
    "        torch.save(model.state_dict(), \"best_gnn_transformer_hybrid.pt\")\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= cfg[\"patience\"]:\n",
    "            print(f\"Early stop at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 5. final evaluation\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\"))\n",
    "final_val_loss, preds, targets = evaluate(model, valid_loader)\n",
    "metrics = regression_metrics(targets.numpy(), preds.numpy())\n",
    "\n",
    "print(\"\\n Final validation:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])\n",
    "print(f\"Final MSE loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c68b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from epoch 46  (best_val=0.0295)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_28936\\2670409266.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "import os, torch, torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch import amp                            \n",
    "from chemml.utils import regression_metrics \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 1. hyper‑parameters (from LR‑range)\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "cfg = dict(gnn_dim = 512,\n",
    "           hidden_dim = 256,\n",
    "           extra_atom_dim = 5,\n",
    "           rdkit_dim = 6,\n",
    "           dropout = 0.2142,\n",
    "           act = \"GELU\",\n",
    "           # optimiser / schedule\n",
    "           max_lr = 8e-5, # ⅓ of valley bottom\n",
    "           div_factor = 25, # init_lr 3.2e-6\n",
    "           final_div_factor = 5_000, # min_lr 1.6e-8\n",
    "           pct_start = 0.30,\n",
    "           weight_decay = 2e-5,\n",
    "           num_epochs = 80,\n",
    "           # misc\n",
    "           accum_steps = 1,\n",
    "           clip_norm = 2.0,\n",
    "           patience = 10)\n",
    "\n",
    "model = GNN_Transformer_Hybrid(gnn_dim = cfg[\"gnn_dim\"],\n",
    "                               rdkit_dim = cfg[\"rdkit_dim\"],\n",
    "                               hidden_dim = cfg[\"hidden_dim\"],\n",
    "                               extra_atom_dim = cfg[\"extra_atom_dim\"],\n",
    "                               dropout_rate = cfg[\"dropout\"],\n",
    "                               activation = cfg[\"act\"]).to(device)\n",
    "\n",
    "init_lr  = cfg[\"max_lr\"] / cfg[\"div_factor\"]\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_lr, weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "scheduler = OneCycleLR(optimizer,\n",
    "                       max_lr = cfg[\"max_lr\"],\n",
    "                       epochs = cfg[\"num_epochs\"],\n",
    "                       steps_per_epoch = len(train_loader),\n",
    "                       pct_start = cfg[\"pct_start\"],\n",
    "                       anneal_strategy = \"cos\",\n",
    "                       div_factor = cfg[\"div_factor\"],\n",
    "                       final_div_factor = cfg[\"final_div_factor\"])\n",
    "\n",
    "scaler = amp.GradScaler(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ckpt = load_ckpt(\"C:/Users/mattg/Downloads/HOMO-LUMO/checkpoints/runA_e045.pt\", model, optimizer,\n",
    "                 scheduler, scaler, map_location=device)\n",
    "\n",
    "start_epoch  = ckpt[\"epoch\"] + 1      # resume with the next epoch\n",
    "best_val     = ckpt[\"best_val\"]\n",
    "patience_ctr = ckpt[\"patience\"]\n",
    "\n",
    "# histories were stored inside the ckpt – restore them\n",
    "train_history   = ckpt[\"train_hist\"]\n",
    "val_history     = ckpt[\"val_hist\"]\n",
    "\n",
    "\n",
    "print(f\"Resuming from epoch {start_epoch}  (best_val={best_val:.4f})\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(net, loader):\n",
    "    net.eval()\n",
    "    tot_loss, preds, targets = 0.0, [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        out   = net(batch)\n",
    "        loss  = F.mse_loss(out, batch.y.view(-1, 1))\n",
    "        tot_loss += loss.item() * batch.num_graphs\n",
    "        preds.append(out.cpu())\n",
    "        targets.append(batch.y.view(-1, 1).cpu())\n",
    "    preds   = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return tot_loss / len(loader.dataset), preds, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ce8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 | train   0.025 | val   0.030 | lr 5.32e-05\n",
      "Epoch 047 | train   0.024 | val   0.030 | lr 5.11e-05\n",
      "Epoch 048 | train   0.024 | val   0.031 | lr 4.89e-05\n",
      "Epoch 049 | train   0.023 | val   0.030 | lr 4.67e-05\n",
      "Epoch 050 | train   0.023 | val   0.028 | lr 4.45e-05\n",
      "Epoch 051 | train   0.022 | val   0.029 | lr 4.22e-05\n",
      "Epoch 052 | train   0.022 | val   0.029 | lr 4.00e-05\n",
      "Epoch 053 | train   0.021 | val   0.028 | lr 3.78e-05\n",
      "Epoch 054 | train   0.021 | val   0.028 | lr 3.55e-05\n",
      "Epoch 055 | train   0.020 | val   0.028 | lr 3.33e-05\n",
      "Epoch 056 | train   0.020 | val   0.029 | lr 3.11e-05\n",
      "Epoch 057 | train   0.020 | val   0.028 | lr 2.89e-05\n",
      "Epoch 058 | train   0.019 | val   0.028 | lr 2.68e-05\n",
      "Epoch 059 | train   0.019 | val   0.027 | lr 2.47e-05\n",
      "Epoch 060 | train   0.019 | val   0.027 | lr 2.26e-05\n",
      "Epoch 061 | train   0.018 | val   0.028 | lr 2.07e-05\n",
      "Epoch 062 | train   0.018 | val   0.028 | lr 1.87e-05\n",
      "Epoch 063 | train   0.018 | val   0.027 | lr 1.69e-05\n",
      "Epoch 064 | train   0.017 | val   0.027 | lr 1.51e-05\n",
      "Epoch 065 | train   0.017 | val   0.027 | lr 1.33e-05\n",
      "Epoch 066 | train   0.017 | val   0.027 | lr 1.17e-05\n",
      "Epoch 067 | train   0.017 | val   0.027 | lr 1.02e-05\n",
      "Epoch 068 | train   0.016 | val   0.027 | lr 8.73e-06\n",
      "Epoch 069 | train   0.016 | val   0.027 | lr 7.38e-06\n",
      "Epoch 070 | train   0.016 | val   0.027 | lr 6.13e-06\n",
      "Epoch 071 | train   0.016 | val   0.027 | lr 4.99e-06\n",
      "Epoch 072 | train   0.016 | val   0.027 | lr 3.96e-06\n",
      "Epoch 073 | train   0.016 | val   0.027 | lr 3.05e-06\n",
      "Epoch 074 | train   0.016 | val   0.027 | lr 2.25e-06\n",
      "Epoch 075 | train   0.015 | val   0.027 | lr 1.56e-06\n",
      "Epoch 076 | train   0.015 | val   0.027 | lr 1.00e-06\n",
      "Epoch 077 | train   0.015 | val   0.027 | lr 5.66e-07\n",
      "Epoch 078 | train   0.015 | val   0.027 | lr 2.52e-07\n",
      "Epoch 079 | train   0.015 | val   0.027 | lr 6.36e-08\n",
      "Epoch 080 | train   0.015 | val   0.027 | lr 6.40e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_28936\\1122252468.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final validation:\n",
      "        MAE      RMSE  r_squared\n",
      "0  0.098801  0.164139   0.980119\n",
      "Final MSE loss: 0.0269\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2) training loop  (identical to the original one)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "for epoch in range(start_epoch, cfg[\"num_epochs\"] + 1):\n",
    "    model.train()\n",
    "    running, n_graphs = 0.0, 0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, batch in enumerate(train_loader, 1):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "            pred  = model(batch)\n",
    "            loss  = F.mse_loss(pred, batch.y.view(-1, 1)) / cfg[\"accum_steps\"]\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        running  += loss.item() * batch.num_graphs * cfg[\"accum_steps\"]\n",
    "        n_graphs += batch.num_graphs\n",
    "\n",
    "        if step % cfg[\"accum_steps\"] == 0 or step == len(train_loader):\n",
    "            safe_optimizer_step(scaler, optimizer, model,\n",
    "                                max_norm=cfg[\"clip_norm\"])  # ← includes scaler.step()\n",
    "            scheduler.step()                                 # ← LR AFTER weights\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    train_loss = running / n_graphs\n",
    "    val_loss, _, _ = evaluate(model, valid_loader)\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    val_history.append(val_loss)\n",
    "\n",
    "    lr_now = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {epoch:03d} | train {train_loss:7.3f} \"\n",
    "          f\"| val {val_loss:7.3f} | lr {lr_now:.2e}\")\n",
    "\n",
    "    save_ckpt(\"runA\", epoch, model, optimizer, scheduler, scaler,\n",
    "              best_val, patience_ctr, train_history, val_history, keep_last=2)\n",
    "\n",
    "    # ─ early-stopping bookkeeping\n",
    "    if val_loss < best_val:\n",
    "        best_val, patience_ctr = val_loss, 0\n",
    "        torch.save(model.state_dict(), \"best_gnn_transformer_hybrid.pt\")\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= cfg[\"patience\"]:\n",
    "            print(f\"Early stop at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# 5. final evaluation\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\"))\n",
    "final_val_loss, preds, targets = evaluate(model, valid_loader)\n",
    "metrics = regression_metrics(targets.numpy(), preds.numpy())\n",
    "\n",
    "print(\"\\n Final validation:\")\n",
    "print(metrics[['MAE', 'RMSE', 'r_squared']])\n",
    "print(f\"Final MSE loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded0bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(train_history, label=\"train\")\n",
    "plt.plot(val_history,   label=\"val\")\n",
    "plt.xlabel(\"epoch\");  plt.ylabel(\"Log(MSE loss)\");  plt.yscale(\"log\")\n",
    "plt.title(\"loss curves\");  plt.legend();  plt.grid(True);  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070cb8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\" baseProfile=\"full\" xml:space=\"preserve\" width=\"750px\" height=\"500px\" viewBox=\"0 0 750 500\">\n",
       "<!-- END OF HEADER -->\n",
       "<rect style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"750.0\" height=\"500.0\" x=\"0.0\" y=\"0.0\"> </rect>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 109.6,106.5 L 99.2,106.4 L 99.3,104.5 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.5px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 99.2,106.4 L 89.1,102.5 L 88.8,106.4 Z\" style=\"fill:#FF0000;fill-rule:evenodd;fill-opacity:1;stroke:#FF0000;stroke-width:0.5px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 99.2,106.4 L 99.3,104.5 L 89.1,102.5 Z\" style=\"fill:#FF0000;fill-rule:evenodd;fill-opacity:1;stroke:#FF0000;stroke-width:0.5px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 109.6,106.5 L 120.2,130.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 120.2,130.0 L 115.4,138.3 L 113.8,137.2 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.5px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 115.4,138.3 L 107.4,144.4 L 110.6,146.7 Z\" style=\"fill:#FF0000;fill-rule:evenodd;fill-opacity:1;stroke:#FF0000;stroke-width:0.5px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 115.4,138.3 L 113.8,137.2 L 107.4,144.4 Z\" style=\"fill:#FF0000;fill-rule:evenodd;fill-opacity:1;stroke:#FF0000;stroke-width:0.5px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"bond-3 atom-2 atom-4\" d=\"M 120.2,130.0 L 145.9,132.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 145.9,132.6 L 158.5,109.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 158.5,109.9 L 147.7,109.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 147.7,109.9 L 136.9,110.0\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 131.2,105.5 L 127.9,95.5\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 127.9,95.5 L 124.6,85.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 124.6,85.5 L 145.4,70.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 145.4,70.2 L 153.8,76.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 153.8,76.2 L 162.2,82.3\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-7 atom-1\" d=\"M 124.6,85.5 L 109.6,106.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-9 atom-5\" d=\"M 164.9,89.9 L 161.7,99.9\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-9 atom-5\" d=\"M 161.7,99.9 L 158.5,109.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-5 atom-10\" d=\"M 161.1,112.7 L 160.5,113.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-5 atom-10\" d=\"M 163.7,115.6 L 162.5,116.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-5 atom-10\" d=\"M 166.3,118.4 L 164.4,119.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-5 atom-10\" d=\"M 168.9,121.3 L 166.4,123.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-5 atom-10\" d=\"M 171.5,124.2 L 168.3,126.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-7 atom-11\" d=\"M 121.2,84.8 L 121.4,84.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-7 atom-11\" d=\"M 117.7,84.0 L 118.1,82.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-7 atom-11\" d=\"M 114.3,83.2 L 114.9,81.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-7 atom-11\" d=\"M 110.9,82.5 L 111.7,80.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-7 atom-11\" d=\"M 107.4,81.7 L 108.4,78.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-7 atom-11\" d=\"M 104.0,81.0 L 105.2,77.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 110.1,107.7 L 109.6,106.5 L 110.3,105.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 119.7,128.8 L 120.2,130.0 L 121.5,130.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 144.6,132.4 L 145.9,132.6 L 146.5,131.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 144.4,71.0 L 145.4,70.2 L 145.8,70.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 73.3 100.3 L 74.3 100.3 L 74.3 103.4 L 78.0 103.4 L 78.0 100.3 L 79.0 100.3 L 79.0 107.6 L 78.0 107.6 L 78.0 104.2 L 74.3 104.2 L 74.3 107.6 L 73.3 107.6 L 73.3 100.3 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-0\" d=\"M 80.5 103.9 Q 80.5 102.2, 81.4 101.2 Q 82.3 100.2, 83.9 100.2 Q 85.5 100.2, 86.4 101.2 Q 87.2 102.2, 87.2 103.9 Q 87.2 105.7, 86.4 106.7 Q 85.5 107.7, 83.9 107.7 Q 82.3 107.7, 81.4 106.7 Q 80.5 105.7, 80.5 103.9 M 83.9 106.9 Q 85.0 106.9, 85.6 106.2 Q 86.2 105.4, 86.2 103.9 Q 86.2 102.5, 85.6 101.8 Q 85.0 101.1, 83.9 101.1 Q 82.8 101.1, 82.2 101.8 Q 81.6 102.5, 81.6 103.9 Q 81.6 105.4, 82.2 106.2 Q 82.8 106.9, 83.9 106.9 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-3\" d=\"M 94.6 147.4 L 95.6 147.4 L 95.6 150.5 L 99.3 150.5 L 99.3 147.4 L 100.3 147.4 L 100.3 154.7 L 99.3 154.7 L 99.3 151.3 L 95.6 151.3 L 95.6 154.7 L 94.6 154.7 L 94.6 147.4 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-3\" d=\"M 101.8 151.0 Q 101.8 149.2, 102.7 148.3 Q 103.5 147.3, 105.1 147.3 Q 106.8 147.3, 107.6 148.3 Q 108.5 149.2, 108.5 151.0 Q 108.5 152.8, 107.6 153.8 Q 106.7 154.8, 105.1 154.8 Q 103.5 154.8, 102.7 153.8 Q 101.8 152.8, 101.8 151.0 M 105.1 153.9 Q 106.3 153.9, 106.9 153.2 Q 107.5 152.5, 107.5 151.0 Q 107.5 149.6, 106.9 148.8 Q 106.3 148.1, 105.1 148.1 Q 104.0 148.1, 103.4 148.8 Q 102.8 149.5, 102.8 151.0 Q 102.8 152.5, 103.4 153.2 Q 104.0 153.9, 105.1 153.9 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-6\" d=\"M 129.4 110.0 Q 129.4 108.3, 130.2 107.3 Q 131.1 106.3, 132.7 106.3 Q 134.4 106.3, 135.2 107.3 Q 136.1 108.3, 136.1 110.0 Q 136.1 111.8, 135.2 112.8 Q 134.3 113.8, 132.7 113.8 Q 131.1 113.8, 130.2 112.8 Q 129.4 111.8, 129.4 110.0 M 132.7 113.0 Q 133.8 113.0, 134.4 112.3 Q 135.1 111.5, 135.1 110.0 Q 135.1 108.6, 134.4 107.9 Q 133.8 107.1, 132.7 107.1 Q 131.6 107.1, 131.0 107.9 Q 130.4 108.6, 130.4 110.0 Q 130.4 111.5, 131.0 112.3 Q 131.6 113.0, 132.7 113.0 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-9\" d=\"M 163.0 85.3 Q 163.0 83.5, 163.9 82.6 Q 164.8 81.6, 166.4 81.6 Q 168.0 81.6, 168.9 82.6 Q 169.7 83.5, 169.7 85.3 Q 169.7 87.1, 168.9 88.1 Q 168.0 89.1, 166.4 89.1 Q 164.8 89.1, 163.9 88.1 Q 163.0 87.1, 163.0 85.3 M 166.4 88.3 Q 167.5 88.3, 168.1 87.5 Q 168.7 86.8, 168.7 85.3 Q 168.7 83.9, 168.1 83.1 Q 167.5 82.4, 166.4 82.4 Q 165.3 82.4, 164.7 83.1 Q 164.1 83.9, 164.1 85.3 Q 164.1 86.8, 164.7 87.5 Q 165.3 88.3, 166.4 88.3 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-10\" d=\"M 171.0 127.0 L 172.0 127.0 L 172.0 130.1 L 175.7 130.1 L 175.7 127.0 L 176.7 127.0 L 176.7 134.3 L 175.7 134.3 L 175.7 130.9 L 172.0 130.9 L 172.0 134.3 L 171.0 134.3 L 171.0 127.0 \" fill=\"#000000\"/>\n",
       "<path class=\"atom-11\" d=\"M 97.2 74.0 L 98.2 74.0 L 98.2 77.1 L 101.9 77.1 L 101.9 74.0 L 102.9 74.0 L 102.9 81.3 L 101.9 81.3 L 101.9 78.0 L 98.2 78.0 L 98.2 81.3 L 97.2 81.3 L 97.2 74.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 23.5 230.6 L 20.0 230.6 L 20.0 229.3 L 28.4 229.3 L 28.4 230.6 L 25.0 230.6 L 25.0 240.7 L 23.5 240.7 L 23.5 230.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 30.1 232.4 L 30.3 233.6 Q 31.1 232.3, 32.5 232.3 Q 33.0 232.3, 33.6 232.5 L 33.4 233.8 Q 32.7 233.6, 32.3 233.6 Q 31.6 233.6, 31.2 233.9 Q 30.7 234.2, 30.4 234.8 L 30.4 240.7 L 28.9 240.7 L 28.9 232.4 L 30.1 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 41.3 232.4 L 41.3 240.7 L 40.1 240.7 L 39.9 239.5 Q 38.9 240.8, 37.1 240.8 Q 35.7 240.8, 35.0 240.1 Q 34.3 239.3, 34.3 237.9 L 34.3 232.4 L 35.8 232.4 L 35.8 237.8 Q 35.8 238.7, 36.2 239.2 Q 36.6 239.6, 37.4 239.6 Q 38.2 239.6, 38.8 239.3 Q 39.4 238.9, 39.8 238.3 L 39.8 232.4 L 41.3 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 43.2 236.5 Q 43.2 234.5, 44.2 233.4 Q 45.2 232.3, 47.0 232.3 Q 48.8 232.3, 49.6 233.4 Q 50.4 234.5, 50.4 236.5 L 50.4 236.7 L 44.7 236.7 Q 44.7 238.1, 45.3 238.9 Q 46.0 239.6, 47.1 239.6 Q 47.8 239.6, 48.4 239.5 Q 49.0 239.3, 49.7 239.0 L 50.1 240.0 Q 49.3 240.4, 48.6 240.6 Q 47.8 240.8, 47.1 240.8 Q 45.2 240.8, 44.2 239.7 Q 43.2 238.6, 43.2 236.5 M 47.0 233.5 Q 46.1 233.5, 45.5 234.0 Q 44.9 234.6, 44.8 235.6 L 48.9 235.6 Q 48.7 234.5, 48.3 234.0 Q 47.8 233.5, 47.0 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 51.6 238.8 L 53.2 238.8 L 53.2 240.4 L 51.6 240.4 L 51.6 238.8 M 51.6 233.3 L 53.2 233.3 L 53.2 234.9 L 51.6 234.9 L 51.6 233.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 66.6 230.6 L 60.7 230.6 L 60.7 229.3 L 68.2 229.3 L 68.2 230.5 L 63.7 240.7 L 62.1 240.7 L 66.6 230.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 69.2 239.1 L 70.8 239.1 L 70.8 240.7 L 69.2 240.7 L 69.2 239.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 78.1 234.7 Q 79.2 235.1, 79.8 235.8 Q 80.4 236.4, 80.4 237.6 Q 80.4 238.5, 79.9 239.3 Q 79.4 240.0, 78.5 240.4 Q 77.6 240.8, 76.4 240.8 Q 74.5 240.8, 73.4 240.0 Q 72.4 239.1, 72.4 237.6 Q 72.4 236.6, 72.8 235.9 Q 73.3 235.2, 74.3 234.7 Q 73.6 234.3, 73.2 233.7 Q 72.8 233.1, 72.8 232.1 Q 72.8 230.8, 73.7 230.0 Q 74.7 229.2, 76.4 229.2 Q 78.0 229.2, 79.0 230.0 Q 79.9 230.8, 79.9 232.1 Q 79.9 232.9, 79.5 233.6 Q 79.0 234.2, 78.1 234.7 M 76.4 230.4 Q 75.4 230.4, 74.9 230.9 Q 74.4 231.3, 74.4 232.1 Q 74.4 232.7, 74.7 233.1 Q 75.1 233.5, 75.6 233.7 Q 76.1 233.9, 77.1 234.3 Q 77.7 233.8, 78.0 233.3 Q 78.3 232.8, 78.3 232.1 Q 78.3 231.3, 77.8 230.9 Q 77.3 230.4, 76.4 230.4 M 76.4 239.6 Q 77.5 239.6, 78.1 239.1 Q 78.8 238.5, 78.8 237.5 Q 78.8 236.9, 78.4 236.6 Q 78.1 236.2, 77.6 235.9 Q 77.1 235.7, 76.2 235.4 L 75.5 235.2 Q 74.7 235.7, 74.3 236.2 Q 74.0 236.8, 74.0 237.5 Q 74.0 238.5, 74.6 239.1 Q 75.3 239.6, 76.4 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 85.7 229.2 Q 87.7 229.2, 88.7 230.6 Q 89.7 231.9, 89.7 234.7 Q 89.7 237.7, 88.5 239.2 Q 87.2 240.8, 84.8 240.8 Q 84.1 240.8, 83.5 240.6 Q 82.9 240.5, 82.3 240.1 L 82.9 239.1 Q 83.8 239.5, 84.8 239.5 Q 86.4 239.5, 87.2 238.5 Q 88.0 237.4, 88.1 235.3 Q 87.5 235.8, 86.8 236.1 Q 86.1 236.4, 85.3 236.4 Q 84.3 236.4, 83.5 236.0 Q 82.7 235.5, 82.3 234.8 Q 81.9 234.0, 81.9 233.0 Q 81.9 231.9, 82.3 231.0 Q 82.8 230.2, 83.7 229.7 Q 84.6 229.2, 85.7 229.2 M 83.5 233.0 Q 83.5 234.0, 84.0 234.6 Q 84.6 235.1, 85.6 235.1 Q 86.3 235.1, 86.9 234.9 Q 87.6 234.6, 88.1 234.1 Q 88.0 232.2, 87.5 231.4 Q 86.9 230.5, 85.7 230.5 Q 85.1 230.5, 84.5 230.8 Q 84.0 231.2, 83.8 231.7 Q 83.5 232.3, 83.5 233.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 98.7 236.8 L 100.0 236.8 L 100.0 238.1 L 98.7 238.1 L 98.7 240.7 L 97.2 240.7 L 97.2 238.1 L 91.3 238.1 L 91.3 237.0 L 96.3 229.3 L 98.7 229.3 L 98.7 236.8 M 93.2 236.8 L 97.2 236.8 L 97.2 230.4 L 93.2 236.8 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 107.2 228.3 L 108.5 228.3 L 108.5 243.8 L 107.2 243.8 L 107.2 228.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 119.6 229.3 Q 121.5 229.3, 122.5 230.2 Q 123.5 231.1, 123.5 232.7 Q 123.5 234.2, 122.5 235.1 Q 121.5 236.0, 119.6 236.0 L 117.8 236.0 L 117.8 240.7 L 116.2 240.7 L 116.2 229.3 L 119.6 229.3 M 119.6 234.7 Q 120.7 234.7, 121.3 234.2 Q 121.9 233.7, 121.9 232.7 Q 121.9 231.7, 121.3 231.1 Q 120.7 230.6, 119.6 230.6 L 117.8 230.6 L 117.8 234.7 L 119.6 234.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 125.9 232.4 L 126.1 233.6 Q 127.0 232.3, 128.4 232.3 Q 128.8 232.3, 129.5 232.5 L 129.2 233.8 Q 128.5 233.6, 128.1 233.6 Q 127.5 233.6, 127.0 233.9 Q 126.6 234.2, 126.2 234.8 L 126.2 240.7 L 124.7 240.7 L 124.7 232.4 L 125.9 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 130.2 236.5 Q 130.2 234.5, 131.2 233.4 Q 132.2 232.3, 134.1 232.3 Q 135.9 232.3, 136.7 233.4 Q 137.5 234.5, 137.5 236.5 L 137.5 236.7 L 131.7 236.7 Q 131.8 238.1, 132.4 238.9 Q 133.0 239.6, 134.2 239.6 Q 134.8 239.6, 135.4 239.5 Q 136.0 239.3, 136.7 239.0 L 137.2 240.0 Q 136.3 240.4, 135.6 240.6 Q 134.9 240.8, 134.1 240.8 Q 132.3 240.8, 131.2 239.7 Q 130.2 238.6, 130.2 236.5 M 134.1 233.5 Q 133.1 233.5, 132.5 234.0 Q 132.0 234.6, 131.8 235.6 L 135.9 235.6 Q 135.8 234.5, 135.3 234.0 Q 134.9 233.5, 134.1 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 146.1 228.5 L 146.1 240.6 L 144.9 240.6 L 144.6 239.6 Q 143.7 240.8, 142.2 240.8 Q 140.5 240.8, 139.5 239.7 Q 138.6 238.7, 138.6 236.7 Q 138.6 234.6, 139.7 233.5 Q 140.9 232.3, 142.8 232.3 Q 143.7 232.3, 144.6 232.5 L 144.6 228.5 L 146.1 228.5 M 142.3 239.6 Q 143.1 239.6, 143.7 239.2 Q 144.3 238.7, 144.6 237.9 L 144.6 233.7 Q 143.8 233.5, 142.8 233.5 Q 141.6 233.5, 140.9 234.3 Q 140.1 235.2, 140.1 236.7 Q 140.1 238.1, 140.7 238.9 Q 141.3 239.6, 142.3 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 147.9 229.3 L 149.3 229.3 L 149.3 230.7 L 147.9 230.7 L 147.9 229.3 M 147.9 232.4 L 149.3 232.4 L 149.3 240.7 L 147.9 240.7 L 147.9 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 151.2 236.5 Q 151.2 234.6, 152.2 233.4 Q 153.2 232.3, 155.2 232.3 Q 157.0 232.3, 158.0 233.7 L 157.0 234.4 Q 156.6 233.9, 156.2 233.7 Q 155.7 233.5, 155.2 233.5 Q 154.0 233.5, 153.4 234.3 Q 152.8 235.0, 152.8 236.5 Q 152.8 238.1, 153.4 238.8 Q 154.1 239.6, 155.3 239.6 Q 155.9 239.6, 156.4 239.5 Q 156.9 239.3, 157.4 239.0 L 157.8 240.1 Q 156.7 240.8, 155.1 240.8 Q 153.2 240.8, 152.2 239.6 Q 151.2 238.5, 151.2 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 158.9 233.6 L 158.9 232.4 L 160.5 232.4 L 160.7 230.0 L 161.8 230.0 L 161.8 232.4 L 164.4 232.4 L 164.4 233.6 L 161.8 233.6 L 161.8 238.1 Q 161.8 239.6, 163.0 239.6 Q 163.5 239.6, 164.2 239.3 L 164.5 240.4 Q 163.6 240.8, 162.8 240.8 Q 161.7 240.8, 161.0 240.1 Q 160.3 239.5, 160.3 238.2 L 160.3 233.6 L 158.9 233.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 165.4 236.5 Q 165.4 234.5, 166.4 233.4 Q 167.4 232.3, 169.2 232.3 Q 171.1 232.3, 171.9 233.4 Q 172.7 234.5, 172.7 236.5 L 172.7 236.7 L 166.9 236.7 Q 167.0 238.1, 167.6 238.9 Q 168.2 239.6, 169.4 239.6 Q 170.0 239.6, 170.6 239.5 Q 171.2 239.3, 171.9 239.0 L 172.4 240.0 Q 171.5 240.4, 170.8 240.6 Q 170.1 240.8, 169.3 240.8 Q 167.4 240.8, 166.4 239.7 Q 165.4 238.6, 165.4 236.5 M 169.2 233.5 Q 168.3 233.5, 167.7 234.0 Q 167.2 234.6, 167.0 235.6 L 171.1 235.6 Q 171.0 234.5, 170.5 234.0 Q 170.1 233.5, 169.2 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 181.3 228.5 L 181.3 240.6 L 180.0 240.6 L 179.8 239.6 Q 178.9 240.8, 177.4 240.8 Q 175.7 240.8, 174.7 239.7 Q 173.8 238.7, 173.8 236.7 Q 173.8 234.6, 174.9 233.5 Q 176.0 232.3, 178.0 232.3 Q 178.9 232.3, 179.8 232.5 L 179.8 228.5 L 181.3 228.5 M 177.5 239.6 Q 178.3 239.6, 178.9 239.2 Q 179.5 238.7, 179.8 237.9 L 179.8 233.7 Q 178.9 233.5, 178.0 233.5 Q 176.8 233.5, 176.0 234.3 Q 175.3 235.2, 175.3 236.7 Q 175.3 238.1, 175.9 238.9 Q 176.5 239.6, 177.5 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 183.1 238.8 L 184.7 238.8 L 184.7 240.4 L 183.1 240.4 L 183.1 238.8 M 183.1 233.3 L 184.7 233.3 L 184.7 234.9 L 183.1 234.9 L 183.1 233.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 198.0 234.7 Q 199.0 235.1, 199.6 235.8 Q 200.2 236.4, 200.2 237.6 Q 200.2 238.5, 199.7 239.3 Q 199.2 240.0, 198.3 240.4 Q 197.4 240.8, 196.3 240.8 Q 194.4 240.8, 193.3 240.0 Q 192.2 239.1, 192.2 237.6 Q 192.2 236.6, 192.7 235.9 Q 193.2 235.2, 194.2 234.7 Q 193.4 234.3, 193.0 233.7 Q 192.6 233.1, 192.6 232.1 Q 192.6 230.8, 193.6 230.0 Q 194.6 229.2, 196.2 229.2 Q 197.9 229.2, 198.8 230.0 Q 199.8 230.8, 199.8 232.1 Q 199.8 232.9, 199.3 233.6 Q 198.9 234.2, 198.0 234.7 M 196.2 230.4 Q 195.3 230.4, 194.7 230.9 Q 194.2 231.3, 194.2 232.1 Q 194.2 232.7, 194.6 233.1 Q 194.9 233.5, 195.4 233.7 Q 195.9 233.9, 196.9 234.3 Q 197.6 233.8, 197.9 233.3 Q 198.2 232.8, 198.2 232.1 Q 198.2 231.3, 197.7 230.9 Q 197.2 230.4, 196.2 230.4 M 196.3 239.6 Q 197.3 239.6, 198.0 239.1 Q 198.6 238.5, 198.6 237.5 Q 198.6 236.9, 198.3 236.6 Q 197.9 236.2, 197.4 235.9 Q 196.9 235.7, 196.0 235.4 L 195.3 235.2 Q 194.5 235.7, 194.2 236.2 Q 193.8 236.8, 193.8 237.5 Q 193.8 238.5, 194.5 239.1 Q 195.2 239.6, 196.3 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 201.7 239.1 L 203.3 239.1 L 203.3 240.7 L 201.7 240.7 L 201.7 239.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 209.3 233.6 Q 210.3 233.6, 211.1 234.0 Q 211.9 234.5, 212.3 235.2 Q 212.7 236.0, 212.7 237.0 Q 212.7 238.1, 212.2 239.0 Q 211.8 239.8, 210.9 240.3 Q 210.0 240.8, 208.9 240.8 Q 206.9 240.8, 205.9 239.4 Q 204.9 238.1, 204.9 235.3 Q 204.9 232.3, 206.1 230.8 Q 207.4 229.2, 209.8 229.2 Q 210.5 229.2, 211.1 229.4 Q 211.7 229.5, 212.3 229.9 L 211.7 230.9 Q 210.8 230.5, 209.8 230.5 Q 208.2 230.5, 207.4 231.5 Q 206.6 232.6, 206.5 234.7 Q 207.1 234.2, 207.8 233.9 Q 208.5 233.6, 209.3 233.6 M 208.9 239.5 Q 209.5 239.5, 210.0 239.2 Q 210.6 238.8, 210.8 238.3 Q 211.1 237.7, 211.1 237.0 Q 211.1 236.0, 210.6 235.4 Q 210.0 234.9, 209.0 234.9 Q 208.3 234.9, 207.6 235.2 Q 207.0 235.4, 206.5 235.9 Q 206.6 237.8, 207.1 238.6 Q 207.7 239.5, 208.9 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 214.7 239.4 L 217.2 239.4 L 217.2 230.9 L 214.5 231.8 L 214.1 230.8 L 217.6 229.3 L 218.7 229.5 L 218.7 239.4 L 221.0 239.4 L 221.0 240.7 L 214.7 240.7 L 214.7 239.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 226.6 233.6 Q 227.6 233.6, 228.3 234.0 Q 229.1 234.5, 229.6 235.2 Q 230.0 236.0, 230.0 237.0 Q 230.0 238.1, 229.5 239.0 Q 229.0 239.8, 228.2 240.3 Q 227.3 240.8, 226.2 240.8 Q 224.2 240.8, 223.1 239.4 Q 222.1 238.1, 222.1 235.3 Q 222.1 232.3, 223.4 230.8 Q 224.6 229.2, 227.1 229.2 Q 227.8 229.2, 228.4 229.4 Q 229.0 229.5, 229.5 229.9 L 228.9 230.9 Q 228.1 230.5, 227.1 230.5 Q 225.5 230.5, 224.7 231.5 Q 223.8 232.6, 223.8 234.7 Q 224.3 234.2, 225.0 233.9 Q 225.8 233.6, 226.6 233.6 M 226.2 239.5 Q 226.8 239.5, 227.3 239.2 Q 227.8 238.8, 228.1 238.3 Q 228.4 237.7, 228.4 237.0 Q 228.4 236.0, 227.8 235.4 Q 227.3 234.9, 226.3 234.9 Q 225.6 234.9, 224.9 235.2 Q 224.2 235.4, 223.8 235.9 Q 223.8 237.8, 224.4 238.6 Q 225.0 239.5, 226.2 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 274.6,161.9 L 279.7,153.0\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 279.7,153.0 L 284.8,144.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 284.8,144.1 L 310.7,144.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 310.7,144.1 L 323.6,121.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 323.6,121.8 L 349.4,121.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 349.4,121.8 L 362.3,99.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 362.3,99.4 L 349.4,77.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 364.5,95.5 L 353.8,77.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 349.4,77.1 L 362.3,54.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 362.3,54.7 L 388.1,54.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 364.5,58.6 L 385.9,58.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 388.1,54.7 L 401.0,77.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 401.0,77.1 L 388.1,99.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 396.5,77.1 L 385.9,95.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-10 atom-11\" d=\"M 388.1,99.4 L 401.0,121.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-11 atom-12\" d=\"M 401.0,121.8 L 426.8,121.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-12 atom-13\" d=\"M 426.8,121.8 L 439.7,144.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-13 atom-14\" d=\"M 439.7,144.1 L 465.5,144.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-14 atom-15\" d=\"M 465.5,144.1 L 470.7,153.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-14 atom-15\" d=\"M 470.7,153.0 L 475.8,161.9\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-10 atom-5\" d=\"M 388.1,99.4 L 362.3,99.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 284.6,144.6 L 284.8,144.1 L 286.1,144.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 309.4,144.1 L 310.7,144.1 L 311.3,143.0\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 322.9,122.9 L 323.6,121.8 L 324.8,121.8\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 348.1,121.8 L 349.4,121.8 L 350.0,120.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 350.0,78.2 L 349.4,77.1 L 350.0,75.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 361.6,55.8 L 362.3,54.7 L 363.6,54.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 386.8,54.7 L 388.1,54.7 L 388.7,55.8\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 400.3,75.9 L 401.0,77.1 L 400.3,78.2\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 400.3,120.7 L 401.0,121.8 L 402.3,121.8\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 425.5,121.8 L 426.8,121.8 L 427.4,122.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 439.1,143.0 L 439.7,144.1 L 441.0,144.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 464.2,144.1 L 465.5,144.1 L 465.8,144.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 261.4 162.9 L 262.4 162.9 L 262.4 166.0 L 266.1 166.0 L 266.1 162.9 L 267.1 162.9 L 267.1 170.2 L 266.1 170.2 L 266.1 166.8 L 262.4 166.8 L 262.4 170.2 L 261.4 170.2 L 261.4 162.9 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-0\" d=\"M 268.6 166.5 Q 268.6 164.7, 269.4 163.8 Q 270.3 162.8, 271.9 162.8 Q 273.6 162.8, 274.4 163.8 Q 275.3 164.7, 275.3 166.5 Q 275.3 168.3, 274.4 169.3 Q 273.5 170.3, 271.9 170.3 Q 270.3 170.3, 269.4 169.3 Q 268.6 168.3, 268.6 166.5 M 271.9 169.5 Q 273.1 169.5, 273.7 168.7 Q 274.3 168.0, 274.3 166.5 Q 274.3 165.1, 273.7 164.3 Q 273.1 163.6, 271.9 163.6 Q 270.8 163.6, 270.2 164.3 Q 269.6 165.1, 269.6 166.5 Q 269.6 168.0, 270.2 168.7 Q 270.8 169.5, 271.9 169.5 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-15\" d=\"M 475.1 166.5 Q 475.1 164.7, 475.9 163.8 Q 476.8 162.8, 478.4 162.8 Q 480.0 162.8, 480.9 163.8 Q 481.8 164.7, 481.8 166.5 Q 481.8 168.3, 480.9 169.3 Q 480.0 170.3, 478.4 170.3 Q 476.8 170.3, 475.9 169.3 Q 475.1 168.3, 475.1 166.5 M 478.4 169.5 Q 479.5 169.5, 480.1 168.7 Q 480.7 168.0, 480.7 166.5 Q 480.7 165.1, 480.1 164.3 Q 479.5 163.6, 478.4 163.6 Q 477.3 163.6, 476.7 164.3 Q 476.1 165.1, 476.1 166.5 Q 476.1 168.0, 476.7 168.7 Q 477.3 169.5, 478.4 169.5 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-15\" d=\"M 482.9 162.9 L 483.9 162.9 L 483.9 166.0 L 487.6 166.0 L 487.6 162.9 L 488.6 162.9 L 488.6 170.2 L 487.6 170.2 L 487.6 166.8 L 483.9 166.8 L 483.9 170.2 L 482.9 170.2 L 482.9 162.9 \" fill=\"#FF0000\"/>\n",
       "<path class=\"legend\" d=\"M 273.5 230.6 L 270.0 230.6 L 270.0 229.3 L 278.3 229.3 L 278.3 230.6 L 275.0 230.6 L 275.0 240.7 L 273.5 240.7 L 273.5 230.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 280.1 232.4 L 280.2 233.6 Q 281.1 232.3, 282.5 232.3 Q 283.0 232.3, 283.6 232.5 L 283.3 233.8 Q 282.6 233.6, 282.3 233.6 Q 281.6 233.6, 281.1 233.9 Q 280.7 234.2, 280.4 234.8 L 280.4 240.7 L 278.8 240.7 L 278.8 232.4 L 280.1 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 291.3 232.4 L 291.3 240.7 L 290.1 240.7 L 289.9 239.5 Q 288.8 240.8, 287.1 240.8 Q 285.7 240.8, 285.0 240.1 Q 284.3 239.3, 284.3 237.9 L 284.3 232.4 L 285.8 232.4 L 285.8 237.8 Q 285.8 238.7, 286.2 239.2 Q 286.6 239.6, 287.4 239.6 Q 288.2 239.6, 288.8 239.3 Q 289.4 238.9, 289.8 238.3 L 289.8 232.4 L 291.3 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 293.1 236.5 Q 293.1 234.5, 294.1 233.4 Q 295.1 232.3, 297.0 232.3 Q 298.8 232.3, 299.6 233.4 Q 300.4 234.5, 300.4 236.5 L 300.4 236.7 L 294.7 236.7 Q 294.7 238.1, 295.3 238.9 Q 295.9 239.6, 297.1 239.6 Q 297.8 239.6, 298.3 239.5 Q 298.9 239.3, 299.7 239.0 L 300.1 240.0 Q 299.3 240.4, 298.5 240.6 Q 297.8 240.8, 297.0 240.8 Q 295.2 240.8, 294.2 239.7 Q 293.1 238.6, 293.1 236.5 M 297.0 233.5 Q 296.0 233.5, 295.5 234.0 Q 294.9 234.6, 294.7 235.6 L 298.8 235.6 Q 298.7 234.5, 298.3 234.0 Q 297.8 233.5, 297.0 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 301.5 238.8 L 303.1 238.8 L 303.1 240.4 L 301.5 240.4 L 301.5 238.8 M 301.5 233.3 L 303.1 233.3 L 303.1 234.9 L 301.5 234.9 L 301.5 233.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 315.1 233.6 Q 316.1 233.6, 316.9 234.0 Q 317.7 234.5, 318.1 235.2 Q 318.5 236.0, 318.5 237.0 Q 318.5 238.1, 318.0 239.0 Q 317.6 239.8, 316.7 240.3 Q 315.8 240.8, 314.7 240.8 Q 312.7 240.8, 311.7 239.4 Q 310.7 238.1, 310.7 235.3 Q 310.7 232.3, 311.9 230.8 Q 313.2 229.2, 315.6 229.2 Q 316.3 229.2, 316.9 229.4 Q 317.5 229.5, 318.1 229.9 L 317.5 230.9 Q 316.6 230.5, 315.6 230.5 Q 314.0 230.5, 313.2 231.5 Q 312.4 232.6, 312.3 234.7 Q 312.9 234.2, 313.6 233.9 Q 314.3 233.6, 315.1 233.6 M 314.7 239.5 Q 315.3 239.5, 315.8 239.2 Q 316.4 238.8, 316.6 238.3 Q 316.9 237.7, 316.9 237.0 Q 316.9 236.0, 316.4 235.4 Q 315.8 234.9, 314.8 234.9 Q 314.1 234.9, 313.4 235.2 Q 312.8 235.4, 312.3 235.9 Q 312.4 237.8, 312.9 238.6 Q 313.5 239.5, 314.7 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 319.9 239.1 L 321.5 239.1 L 321.5 240.7 L 319.9 240.7 L 319.9 239.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 323.1 231.5 Q 323.5 230.4, 324.5 229.8 Q 325.5 229.2, 326.9 229.2 Q 328.6 229.2, 329.5 230.1 Q 330.5 231.1, 330.5 232.7 Q 330.5 234.4, 329.3 236.0 Q 328.0 237.5, 325.5 239.4 L 330.7 239.4 L 330.7 240.7 L 323.1 240.7 L 323.1 239.6 Q 325.2 238.1, 326.4 237.0 Q 327.7 235.8, 328.3 234.8 Q 328.9 233.8, 328.9 232.8 Q 328.9 231.7, 328.4 231.1 Q 327.8 230.5, 326.9 230.5 Q 326.0 230.5, 325.4 230.9 Q 324.7 231.2, 324.3 232.0 L 323.1 231.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 337.9 234.7 Q 339.0 235.1, 339.6 235.8 Q 340.2 236.4, 340.2 237.6 Q 340.2 238.5, 339.7 239.3 Q 339.2 240.0, 338.3 240.4 Q 337.4 240.8, 336.2 240.8 Q 334.3 240.8, 333.3 240.0 Q 332.2 239.1, 332.2 237.6 Q 332.2 236.6, 332.6 235.9 Q 333.1 235.2, 334.1 234.7 Q 333.4 234.3, 333.0 233.7 Q 332.6 233.1, 332.6 232.1 Q 332.6 230.8, 333.5 230.0 Q 334.5 229.2, 336.2 229.2 Q 337.8 229.2, 338.8 230.0 Q 339.8 230.8, 339.8 232.1 Q 339.8 232.9, 339.3 233.6 Q 338.8 234.2, 337.9 234.7 M 336.2 230.4 Q 335.2 230.4, 334.7 230.9 Q 334.2 231.3, 334.2 232.1 Q 334.2 232.7, 334.5 233.1 Q 334.9 233.5, 335.4 233.7 Q 335.9 233.9, 336.9 234.3 Q 337.6 233.8, 337.8 233.3 Q 338.2 232.8, 338.2 232.1 Q 338.2 231.3, 337.6 230.9 Q 337.1 230.4, 336.2 230.4 M 336.2 239.6 Q 337.3 239.6, 337.9 239.1 Q 338.6 238.5, 338.6 237.5 Q 338.6 236.9, 338.2 236.6 Q 337.9 236.2, 337.4 235.9 Q 336.9 235.7, 336.0 235.4 L 335.3 235.2 Q 334.5 235.7, 334.1 236.2 Q 333.8 236.8, 333.8 237.5 Q 333.8 238.5, 334.4 239.1 Q 335.1 239.6, 336.2 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 345.5 229.2 Q 347.5 229.2, 348.5 230.6 Q 349.5 231.9, 349.5 234.7 Q 349.5 237.7, 348.3 239.2 Q 347.0 240.8, 344.6 240.8 Q 343.9 240.8, 343.3 240.6 Q 342.7 240.5, 342.1 240.1 L 342.8 239.1 Q 343.6 239.5, 344.6 239.5 Q 346.2 239.5, 347.0 238.5 Q 347.8 237.4, 347.9 235.3 Q 347.3 235.8, 346.6 236.1 Q 345.9 236.4, 345.1 236.4 Q 344.1 236.4, 343.3 236.0 Q 342.5 235.5, 342.1 234.8 Q 341.7 234.0, 341.7 233.0 Q 341.7 231.9, 342.2 231.0 Q 342.7 230.2, 343.5 229.7 Q 344.4 229.2, 345.5 229.2 M 343.3 233.0 Q 343.3 234.0, 343.8 234.6 Q 344.4 235.1, 345.4 235.1 Q 346.1 235.1, 346.8 234.9 Q 347.4 234.6, 347.9 234.1 Q 347.9 232.2, 347.3 231.4 Q 346.7 230.5, 345.5 230.5 Q 344.9 230.5, 344.4 230.8 Q 343.9 231.2, 343.6 231.7 Q 343.3 232.3, 343.3 233.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 357.0 228.3 L 358.3 228.3 L 358.3 243.8 L 357.0 243.8 L 357.0 228.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 369.4 229.3 Q 371.3 229.3, 372.3 230.2 Q 373.3 231.1, 373.3 232.7 Q 373.3 234.2, 372.3 235.1 Q 371.3 236.0, 369.4 236.0 L 367.6 236.0 L 367.6 240.7 L 366.0 240.7 L 366.0 229.3 L 369.4 229.3 M 369.4 234.7 Q 370.5 234.7, 371.1 234.2 Q 371.7 233.7, 371.7 232.7 Q 371.7 231.7, 371.1 231.1 Q 370.5 230.6, 369.4 230.6 L 367.6 230.6 L 367.6 234.7 L 369.4 234.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 375.7 232.4 L 375.9 233.6 Q 376.8 232.3, 378.2 232.3 Q 378.6 232.3, 379.2 232.5 L 379.0 233.8 Q 378.3 233.6, 377.9 233.6 Q 377.3 233.6, 376.8 233.9 Q 376.4 234.2, 376.0 234.8 L 376.0 240.7 L 374.5 240.7 L 374.5 232.4 L 375.7 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 380.0 236.5 Q 380.0 234.5, 381.0 233.4 Q 382.0 232.3, 383.8 232.3 Q 385.7 232.3, 386.5 233.4 Q 387.3 234.5, 387.3 236.5 L 387.3 236.7 L 381.5 236.7 Q 381.6 238.1, 382.2 238.9 Q 382.8 239.6, 384.0 239.6 Q 384.6 239.6, 385.2 239.5 Q 385.8 239.3, 386.5 239.0 L 387.0 240.0 Q 386.1 240.4, 385.4 240.6 Q 384.7 240.8, 383.9 240.8 Q 382.0 240.8, 381.0 239.7 Q 380.0 238.6, 380.0 236.5 M 383.8 233.5 Q 382.9 233.5, 382.3 234.0 Q 381.8 234.6, 381.6 235.6 L 385.7 235.6 Q 385.6 234.5, 385.1 234.0 Q 384.7 233.5, 383.8 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 395.9 228.5 L 395.9 240.6 L 394.6 240.6 L 394.4 239.6 Q 393.5 240.8, 392.0 240.8 Q 390.3 240.8, 389.3 239.7 Q 388.4 238.7, 388.4 236.7 Q 388.4 234.6, 389.5 233.5 Q 390.6 232.3, 392.6 232.3 Q 393.5 232.3, 394.4 232.5 L 394.4 228.5 L 395.9 228.5 M 392.1 239.6 Q 392.9 239.6, 393.5 239.2 Q 394.1 238.7, 394.4 237.9 L 394.4 233.7 Q 393.5 233.5, 392.6 233.5 Q 391.4 233.5, 390.6 234.3 Q 389.9 235.2, 389.9 236.7 Q 389.9 238.1, 390.5 238.9 Q 391.1 239.6, 392.1 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 397.6 229.3 L 399.1 229.3 L 399.1 230.7 L 397.6 230.7 L 397.6 229.3 M 397.6 232.4 L 399.1 232.4 L 399.1 240.7 L 397.6 240.7 L 397.6 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 401.0 236.5 Q 401.0 234.6, 402.0 233.4 Q 403.0 232.3, 404.9 232.3 Q 406.8 232.3, 407.8 233.7 L 406.8 234.4 Q 406.4 233.9, 405.9 233.7 Q 405.5 233.5, 404.9 233.5 Q 403.8 233.5, 403.2 234.3 Q 402.5 235.0, 402.5 236.5 Q 402.5 238.1, 403.2 238.8 Q 403.8 239.6, 405.0 239.6 Q 405.7 239.6, 406.2 239.5 Q 406.6 239.3, 407.2 239.0 L 407.6 240.1 Q 406.4 240.8, 404.9 240.8 Q 403.0 240.8, 402.0 239.6 Q 401.0 238.5, 401.0 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 408.7 233.6 L 408.7 232.4 L 410.2 232.4 L 410.5 230.0 L 411.6 230.0 L 411.6 232.4 L 414.1 232.4 L 414.1 233.6 L 411.6 233.6 L 411.6 238.1 Q 411.6 239.6, 412.8 239.6 Q 413.3 239.6, 414.0 239.3 L 414.3 240.4 Q 413.4 240.8, 412.6 240.8 Q 411.5 240.8, 410.8 240.1 Q 410.1 239.5, 410.1 238.2 L 410.1 233.6 L 408.7 233.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 415.2 236.5 Q 415.2 234.5, 416.2 233.4 Q 417.2 232.3, 419.0 232.3 Q 420.8 232.3, 421.6 233.4 Q 422.5 234.5, 422.5 236.5 L 422.5 236.7 L 416.7 236.7 Q 416.7 238.1, 417.4 238.9 Q 418.0 239.6, 419.2 239.6 Q 419.8 239.6, 420.4 239.5 Q 421.0 239.3, 421.7 239.0 L 422.1 240.0 Q 421.3 240.4, 420.6 240.6 Q 419.8 240.8, 419.1 240.8 Q 417.2 240.8, 416.2 239.7 Q 415.2 238.6, 415.2 236.5 M 419.0 233.5 Q 418.1 233.5, 417.5 234.0 Q 416.9 234.6, 416.8 235.6 L 420.9 235.6 Q 420.8 234.5, 420.3 234.0 Q 419.9 233.5, 419.0 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 431.0 228.5 L 431.0 240.6 L 429.8 240.6 L 429.6 239.6 Q 428.7 240.8, 427.2 240.8 Q 425.5 240.8, 424.5 239.7 Q 423.6 238.7, 423.6 236.7 Q 423.6 234.6, 424.7 233.5 Q 425.8 232.3, 427.8 232.3 Q 428.6 232.3, 429.5 232.5 L 429.5 228.5 L 431.0 228.5 M 427.3 239.6 Q 428.1 239.6, 428.7 239.2 Q 429.3 238.7, 429.5 237.9 L 429.5 233.7 Q 428.7 233.5, 427.8 233.5 Q 426.5 233.5, 425.8 234.3 Q 425.1 235.2, 425.1 236.7 Q 425.1 238.1, 425.7 238.9 Q 426.2 239.6, 427.3 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 432.8 238.8 L 434.4 238.8 L 434.4 240.4 L 432.8 240.4 L 432.8 238.8 M 432.8 233.3 L 434.4 233.3 L 434.4 234.9 L 432.8 234.9 L 432.8 233.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 446.4 233.6 Q 447.4 233.6, 448.2 234.0 Q 449.0 234.5, 449.4 235.2 Q 449.8 236.0, 449.8 237.0 Q 449.8 238.1, 449.3 239.0 Q 448.9 239.8, 448.0 240.3 Q 447.1 240.8, 446.0 240.8 Q 444.0 240.8, 443.0 239.4 Q 442.0 238.1, 442.0 235.3 Q 442.0 232.3, 443.2 230.8 Q 444.5 229.2, 446.9 229.2 Q 447.6 229.2, 448.2 229.4 Q 448.8 229.5, 449.4 229.9 L 448.8 230.9 Q 447.9 230.5, 446.9 230.5 Q 445.3 230.5, 444.5 231.5 Q 443.7 232.6, 443.6 234.7 Q 444.2 234.2, 444.9 233.9 Q 445.6 233.6, 446.4 233.6 M 446.0 239.5 Q 446.7 239.5, 447.1 239.2 Q 447.7 238.8, 447.9 238.3 Q 448.2 237.7, 448.2 237.0 Q 448.2 236.0, 447.7 235.4 Q 447.1 234.9, 446.1 234.9 Q 445.4 234.9, 444.7 235.2 Q 444.1 235.4, 443.6 235.9 Q 443.7 237.8, 444.3 238.6 Q 444.8 239.5, 446.0 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 451.2 239.1 L 452.8 239.1 L 452.8 240.7 L 451.2 240.7 L 451.2 239.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 459.8 234.7 Q 460.9 235.0, 461.4 235.7 Q 462.0 236.4, 462.0 237.6 Q 462.0 238.5, 461.5 239.3 Q 461.0 240.0, 460.1 240.4 Q 459.3 240.8, 458.1 240.8 Q 456.9 240.8, 456.0 240.4 Q 455.1 240.0, 454.4 239.1 L 455.3 238.2 Q 456.0 239.0, 456.6 239.3 Q 457.2 239.5, 458.1 239.5 Q 459.1 239.5, 459.8 239.0 Q 460.4 238.4, 460.4 237.5 Q 460.4 236.4, 459.7 235.9 Q 459.1 235.4, 457.7 235.4 L 456.9 235.4 L 456.9 234.2 L 457.6 234.2 Q 458.8 234.2, 459.5 233.7 Q 460.1 233.1, 460.1 232.1 Q 460.1 231.4, 459.6 230.9 Q 459.1 230.5, 458.1 230.5 Q 457.2 230.5, 456.6 230.8 Q 456.0 231.2, 455.6 232.0 L 454.5 231.4 Q 454.9 230.5, 455.8 229.8 Q 456.8 229.2, 458.1 229.2 Q 459.8 229.2, 460.8 230.0 Q 461.7 230.8, 461.7 232.1 Q 461.7 233.0, 461.3 233.7 Q 460.8 234.3, 459.8 234.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 467.6 233.6 Q 468.5 233.6, 469.4 234.0 Q 470.2 234.4, 470.6 235.2 Q 471.1 236.0, 471.1 237.1 Q 471.1 238.2, 470.5 239.1 Q 470.0 239.9, 469.0 240.4 Q 468.1 240.8, 467.1 240.8 Q 466.0 240.8, 465.1 240.4 Q 464.1 240.0, 463.4 239.3 L 464.4 238.3 Q 464.9 238.9, 465.6 239.2 Q 466.4 239.5, 467.1 239.5 Q 468.1 239.5, 468.8 238.9 Q 469.5 238.2, 469.5 237.1 Q 469.5 235.9, 468.8 235.4 Q 468.1 234.8, 467.0 234.8 Q 466.0 234.8, 464.9 235.2 L 464.0 234.8 L 464.6 229.3 L 470.4 229.3 L 470.2 230.6 L 465.9 230.6 L 465.6 234.0 Q 466.6 233.6, 467.6 233.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 472.4 231.5 Q 472.8 230.4, 473.8 229.8 Q 474.8 229.2, 476.2 229.2 Q 477.9 229.2, 478.9 230.1 Q 479.8 231.1, 479.8 232.7 Q 479.8 234.4, 478.6 236.0 Q 477.3 237.5, 474.8 239.4 L 480.0 239.4 L 480.0 240.7 L 472.4 240.7 L 472.4 239.6 Q 474.5 238.1, 475.7 237.0 Q 477.0 235.8, 477.6 234.8 Q 478.2 233.8, 478.2 232.8 Q 478.2 231.7, 477.7 231.1 Q 477.1 230.5, 476.2 230.5 Q 475.3 230.5, 474.7 230.9 Q 474.1 231.2, 473.6 232.0 L 472.4 231.5 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 664.7,118.3 L 658.8,110.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 658.8,110.2 L 652.8,102.0\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 645.9,98.6 L 628.6,104.3\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 625.0,109.9 L 625.0,120.6\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 625.0,120.6 L 625.0,131.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 625.0,131.3 L 649.5,139.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-3 atom-5\" d=\"M 625.0,131.3 L 600.5,139.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-3 atom-5\" d=\"M 621.1,128.4 L 601.9,134.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 600.5,139.2 L 585.3,118.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 585.3,118.3 L 600.5,97.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 590.1,118.3 L 601.9,102.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-4 atom-0\" d=\"M 649.5,139.2 L 664.7,118.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-7 atom-2\" d=\"M 600.5,97.5 L 610.9,100.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-7 atom-2\" d=\"M 610.9,100.9 L 621.4,104.3\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 664.4,117.9 L 664.7,118.3 L 664.0,119.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 648.3,138.8 L 649.5,139.2 L 650.3,138.2\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 601.7,138.8 L 600.5,139.2 L 599.7,138.2\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 586.0,119.4 L 585.3,118.3 L 586.0,117.3\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 599.7,98.5 L 600.5,97.5 L 601.0,97.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-1\" d=\"M 647.9 93.8 L 650.3 97.7 Q 650.6 98.1, 650.9 98.8 Q 651.3 99.4, 651.3 99.5 L 651.3 93.8 L 652.3 93.8 L 652.3 101.1 L 651.3 101.1 L 648.7 96.9 Q 648.4 96.4, 648.1 95.8 Q 647.8 95.3, 647.7 95.1 L 647.7 101.1 L 646.8 101.1 L 646.8 93.8 L 647.9 93.8 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-1\" d=\"M 646.7 85.8 L 647.7 85.8 L 647.7 88.9 L 651.4 88.9 L 651.4 85.8 L 652.4 85.8 L 652.4 93.1 L 651.4 93.1 L 651.4 89.7 L 647.7 89.7 L 647.7 93.1 L 646.7 93.1 L 646.7 85.8 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-2\" d=\"M 623.4 101.8 L 625.8 105.7 Q 626.0 106.0, 626.4 106.7 Q 626.8 107.4, 626.8 107.5 L 626.8 101.8 L 627.8 101.8 L 627.8 109.1 L 626.8 109.1 L 624.2 104.9 Q 623.9 104.4, 623.6 103.8 Q 623.3 103.2, 623.2 103.1 L 623.2 109.1 L 622.2 109.1 L 622.2 101.8 L 623.4 101.8 \" fill=\"#0000FF\"/>\n",
       "<path class=\"legend\" d=\"M 523.3 230.6 L 519.8 230.6 L 519.8 229.3 L 528.1 229.3 L 528.1 230.6 L 524.8 230.6 L 524.8 240.7 L 523.3 240.7 L 523.3 230.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 529.9 232.4 L 530.0 233.6 Q 530.9 232.3, 532.3 232.3 Q 532.8 232.3, 533.4 232.5 L 533.1 233.8 Q 532.4 233.6, 532.1 233.6 Q 531.4 233.6, 530.9 233.9 Q 530.5 234.2, 530.2 234.8 L 530.2 240.7 L 528.7 240.7 L 528.7 232.4 L 529.9 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 541.1 232.4 L 541.1 240.7 L 539.9 240.7 L 539.7 239.5 Q 538.6 240.8, 536.9 240.8 Q 535.5 240.8, 534.8 240.1 Q 534.1 239.3, 534.1 237.9 L 534.1 232.4 L 535.6 232.4 L 535.6 237.8 Q 535.6 238.7, 536.0 239.2 Q 536.4 239.6, 537.2 239.6 Q 538.0 239.6, 538.6 239.3 Q 539.2 238.9, 539.6 238.3 L 539.6 232.4 L 541.1 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 542.9 236.5 Q 542.9 234.5, 543.9 233.4 Q 545.0 232.3, 546.8 232.3 Q 548.6 232.3, 549.4 233.4 Q 550.2 234.5, 550.2 236.5 L 550.2 236.7 L 544.5 236.7 Q 544.5 238.1, 545.1 238.9 Q 545.8 239.6, 546.9 239.6 Q 547.6 239.6, 548.2 239.5 Q 548.7 239.3, 549.5 239.0 L 549.9 240.0 Q 549.1 240.4, 548.3 240.6 Q 547.6 240.8, 546.8 240.8 Q 545.0 240.8, 544.0 239.7 Q 542.9 238.6, 542.9 236.5 M 546.8 233.5 Q 545.9 233.5, 545.3 234.0 Q 544.7 234.6, 544.5 235.6 L 548.6 235.6 Q 548.5 234.5, 548.1 234.0 Q 547.6 233.5, 546.8 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 551.3 238.8 L 552.9 238.8 L 552.9 240.4 L 551.3 240.4 L 551.3 238.8 M 551.3 233.3 L 552.9 233.3 L 552.9 234.9 L 551.3 234.9 L 551.3 233.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 564.9 233.6 Q 565.9 233.6, 566.7 234.0 Q 567.5 234.5, 567.9 235.2 Q 568.4 236.0, 568.4 237.0 Q 568.4 238.1, 567.9 239.0 Q 567.4 239.8, 566.5 240.3 Q 565.6 240.8, 564.5 240.8 Q 562.5 240.8, 561.5 239.4 Q 560.5 238.1, 560.5 235.3 Q 560.5 232.3, 561.7 230.8 Q 563.0 229.2, 565.4 229.2 Q 566.1 229.2, 566.7 229.4 Q 567.3 229.5, 567.9 229.9 L 567.3 230.9 Q 566.4 230.5, 565.4 230.5 Q 563.8 230.5, 563.0 231.5 Q 562.2 232.6, 562.1 234.7 Q 562.7 234.2, 563.4 233.9 Q 564.1 233.6, 564.9 233.6 M 564.6 239.5 Q 565.2 239.5, 565.7 239.2 Q 566.2 238.8, 566.5 238.3 Q 566.8 237.7, 566.8 237.0 Q 566.8 236.0, 566.2 235.4 Q 565.6 234.9, 564.6 234.9 Q 564.0 234.9, 563.3 235.2 Q 562.6 235.4, 562.1 235.9 Q 562.2 237.8, 562.8 238.6 Q 563.4 239.5, 564.6 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 569.7 239.1 L 571.3 239.1 L 571.3 240.7 L 569.7 240.7 L 569.7 239.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 577.3 233.6 Q 578.3 233.6, 579.1 234.0 Q 579.9 234.5, 580.3 235.2 Q 580.7 236.0, 580.7 237.0 Q 580.7 238.1, 580.3 239.0 Q 579.8 239.8, 578.9 240.3 Q 578.0 240.8, 576.9 240.8 Q 574.9 240.8, 573.9 239.4 Q 572.9 238.1, 572.9 235.3 Q 572.9 232.3, 574.1 230.8 Q 575.4 229.2, 577.8 229.2 Q 578.5 229.2, 579.1 229.4 Q 579.7 229.5, 580.3 229.9 L 579.7 230.9 Q 578.8 230.5, 577.8 230.5 Q 576.2 230.5, 575.4 231.5 Q 574.6 232.6, 574.5 234.7 Q 575.1 234.2, 575.8 233.9 Q 576.5 233.6, 577.3 233.6 M 577.0 239.5 Q 577.6 239.5, 578.1 239.2 Q 578.6 238.8, 578.9 238.3 Q 579.1 237.7, 579.1 237.0 Q 579.1 236.0, 578.6 235.4 Q 578.0 234.9, 577.0 234.9 Q 576.3 234.9, 575.7 235.2 Q 575.0 235.4, 574.5 235.9 Q 574.6 237.8, 575.2 238.6 Q 575.8 239.5, 577.0 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 589.5 236.8 L 590.9 236.8 L 590.9 238.1 L 589.5 238.1 L 589.5 240.7 L 588.0 240.7 L 588.0 238.1 L 582.1 238.1 L 582.1 237.0 L 587.1 229.3 L 589.5 229.3 L 589.5 236.8 M 584.0 236.8 L 588.0 236.8 L 588.0 230.4 L 584.0 236.8 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 597.9 234.7 Q 599.0 235.1, 599.6 235.8 Q 600.2 236.4, 600.2 237.6 Q 600.2 238.5, 599.7 239.3 Q 599.2 240.0, 598.3 240.4 Q 597.4 240.8, 596.2 240.8 Q 594.3 240.8, 593.2 240.0 Q 592.2 239.1, 592.2 237.6 Q 592.2 236.6, 592.6 235.9 Q 593.1 235.2, 594.1 234.7 Q 593.4 234.3, 593.0 233.7 Q 592.6 233.1, 592.6 232.1 Q 592.6 230.8, 593.5 230.0 Q 594.5 229.2, 596.2 229.2 Q 597.8 229.2, 598.8 230.0 Q 599.7 230.8, 599.7 232.1 Q 599.7 232.9, 599.3 233.6 Q 598.8 234.2, 597.9 234.7 M 596.2 230.4 Q 595.2 230.4, 594.7 230.9 Q 594.2 231.3, 594.2 232.1 Q 594.2 232.7, 594.5 233.1 Q 594.9 233.5, 595.4 233.7 Q 595.9 233.9, 596.9 234.3 Q 597.5 233.8, 597.8 233.3 Q 598.1 232.8, 598.1 232.1 Q 598.1 231.3, 597.6 230.9 Q 597.1 230.4, 596.2 230.4 M 596.2 239.6 Q 597.3 239.6, 597.9 239.1 Q 598.6 238.5, 598.6 237.5 Q 598.6 236.9, 598.2 236.6 Q 597.9 236.2, 597.4 235.9 Q 596.9 235.7, 596.0 235.4 L 595.3 235.2 Q 594.5 235.7, 594.1 236.2 Q 593.8 236.8, 593.8 237.5 Q 593.8 238.5, 594.4 239.1 Q 595.1 239.6, 596.2 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 607.5 228.3 L 608.9 228.3 L 608.9 243.8 L 607.5 243.8 L 607.5 228.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 619.9 229.3 Q 621.9 229.3, 622.8 230.2 Q 623.8 231.1, 623.8 232.7 Q 623.8 234.2, 622.8 235.1 Q 621.8 236.0, 619.9 236.0 L 618.1 236.0 L 618.1 240.7 L 616.6 240.7 L 616.6 229.3 L 619.9 229.3 M 619.9 234.7 Q 621.0 234.7, 621.6 234.2 Q 622.2 233.7, 622.2 232.7 Q 622.2 231.7, 621.6 231.1 Q 621.0 230.6, 619.9 230.6 L 618.1 230.6 L 618.1 234.7 L 619.9 234.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 626.3 232.4 L 626.5 233.6 Q 627.3 232.3, 628.7 232.3 Q 629.2 232.3, 629.8 232.5 L 629.6 233.8 Q 628.9 233.6, 628.5 233.6 Q 627.8 233.6, 627.4 233.9 Q 626.9 234.2, 626.6 234.8 L 626.6 240.7 L 625.1 240.7 L 625.1 232.4 L 626.3 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 630.5 236.5 Q 630.5 234.5, 631.6 233.4 Q 632.6 232.3, 634.4 232.3 Q 636.2 232.3, 637.0 233.4 Q 637.8 234.5, 637.8 236.5 L 637.8 236.7 L 632.1 236.7 Q 632.1 238.1, 632.7 238.9 Q 633.4 239.6, 634.5 239.6 Q 635.2 239.6, 635.8 239.5 Q 636.4 239.3, 637.1 239.0 L 637.5 240.0 Q 636.7 240.4, 636.0 240.6 Q 635.2 240.8, 634.5 240.8 Q 632.6 240.8, 631.6 239.7 Q 630.5 238.6, 630.5 236.5 M 634.4 233.5 Q 633.5 233.5, 632.9 234.0 Q 632.3 234.6, 632.1 235.6 L 636.2 235.6 Q 636.1 234.5, 635.7 234.0 Q 635.2 233.5, 634.4 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 646.4 228.5 L 646.4 240.6 L 645.2 240.6 L 645.0 239.6 Q 644.1 240.8, 642.6 240.8 Q 640.9 240.8, 639.9 239.7 Q 638.9 238.7, 638.9 236.7 Q 638.9 234.6, 640.1 233.5 Q 641.2 232.3, 643.2 232.3 Q 644.0 232.3, 644.9 232.5 L 644.9 228.5 L 646.4 228.5 M 642.7 239.6 Q 643.5 239.6, 644.1 239.2 Q 644.7 238.7, 644.9 237.9 L 644.9 233.7 Q 644.1 233.5, 643.2 233.5 Q 641.9 233.5, 641.2 234.3 Q 640.5 235.2, 640.5 236.7 Q 640.5 238.1, 641.0 238.9 Q 641.6 239.6, 642.7 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 648.2 229.3 L 649.7 229.3 L 649.7 230.7 L 648.2 230.7 L 648.2 229.3 M 648.2 232.4 L 649.7 232.4 L 649.7 240.7 L 648.2 240.7 L 648.2 232.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 651.6 236.5 Q 651.6 234.6, 652.6 233.4 Q 653.6 232.3, 655.5 232.3 Q 657.4 232.3, 658.4 233.7 L 657.3 234.4 Q 657.0 233.9, 656.5 233.7 Q 656.1 233.5, 655.5 233.5 Q 654.4 233.5, 653.7 234.3 Q 653.1 235.0, 653.1 236.5 Q 653.1 238.1, 653.7 238.8 Q 654.4 239.6, 655.6 239.6 Q 656.3 239.6, 656.7 239.5 Q 657.2 239.3, 657.8 239.0 L 658.2 240.1 Q 657.0 240.8, 655.5 240.8 Q 653.6 240.8, 652.6 239.6 Q 651.6 238.5, 651.6 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 659.3 233.6 L 659.3 232.4 L 660.8 232.4 L 661.1 230.0 L 662.2 230.0 L 662.2 232.4 L 664.7 232.4 L 664.7 233.6 L 662.2 233.6 L 662.2 238.1 Q 662.2 239.6, 663.4 239.6 Q 663.9 239.6, 664.6 239.3 L 664.8 240.4 Q 664.0 240.8, 663.1 240.8 Q 662.1 240.8, 661.4 240.1 Q 660.7 239.5, 660.7 238.2 L 660.7 233.6 L 659.3 233.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 665.7 236.5 Q 665.7 234.5, 666.8 233.4 Q 667.8 232.3, 669.6 232.3 Q 671.4 232.3, 672.2 233.4 Q 673.0 234.5, 673.0 236.5 L 673.0 236.7 L 667.3 236.7 Q 667.3 238.1, 667.9 238.9 Q 668.6 239.6, 669.7 239.6 Q 670.4 239.6, 671.0 239.5 Q 671.6 239.3, 672.3 239.0 L 672.7 240.0 Q 671.9 240.4, 671.2 240.6 Q 670.4 240.8, 669.7 240.8 Q 667.8 240.8, 666.8 239.7 Q 665.7 238.6, 665.7 236.5 M 669.6 233.5 Q 668.7 233.5, 668.1 234.0 Q 667.5 234.6, 667.3 235.6 L 671.4 235.6 Q 671.3 234.5, 670.9 234.0 Q 670.4 233.5, 669.6 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 681.6 228.5 L 681.6 240.6 L 680.4 240.6 L 680.2 239.6 Q 679.3 240.8, 677.8 240.8 Q 676.0 240.8, 675.1 239.7 Q 674.1 238.7, 674.1 236.7 Q 674.1 234.6, 675.3 233.5 Q 676.4 232.3, 678.4 232.3 Q 679.2 232.3, 680.1 232.5 L 680.1 228.5 L 681.6 228.5 M 677.9 239.6 Q 678.7 239.6, 679.3 239.2 Q 679.9 238.7, 680.1 237.9 L 680.1 233.7 Q 679.3 233.5, 678.4 233.5 Q 677.1 233.5, 676.4 234.3 Q 675.7 235.2, 675.7 236.7 Q 675.7 238.1, 676.2 238.9 Q 676.8 239.6, 677.9 239.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 683.4 238.8 L 685.0 238.8 L 685.0 240.4 L 683.4 240.4 L 683.4 238.8 M 683.4 233.3 L 685.0 233.3 L 685.0 234.9 L 683.4 234.9 L 683.4 233.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 697.0 233.6 Q 698.0 233.6, 698.8 234.0 Q 699.6 234.5, 700.0 235.2 Q 700.4 236.0, 700.4 237.0 Q 700.4 238.1, 699.9 239.0 Q 699.4 239.8, 698.6 240.3 Q 697.7 240.8, 696.6 240.8 Q 694.6 240.8, 693.6 239.4 Q 692.6 238.1, 692.6 235.3 Q 692.6 232.3, 693.8 230.8 Q 695.1 229.2, 697.5 229.2 Q 698.2 229.2, 698.8 229.4 Q 699.4 229.5, 700.0 229.9 L 699.3 230.9 Q 698.5 230.5, 697.5 230.5 Q 695.9 230.5, 695.1 231.5 Q 694.3 232.6, 694.2 234.7 Q 694.8 234.2, 695.5 233.9 Q 696.2 233.6, 697.0 233.6 M 696.6 239.5 Q 697.2 239.5, 697.7 239.2 Q 698.2 238.8, 698.5 238.3 Q 698.8 237.7, 698.8 237.0 Q 698.8 236.0, 698.3 235.4 Q 697.7 234.9, 696.7 234.9 Q 696.0 234.9, 695.3 235.2 Q 694.7 235.4, 694.2 235.9 Q 694.2 237.8, 694.8 238.6 Q 695.4 239.5, 696.6 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 701.8 239.1 L 703.4 239.1 L 703.4 240.7 L 701.8 240.7 L 701.8 239.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 709.1 233.6 Q 710.1 233.6, 710.9 234.0 Q 711.7 234.4, 712.2 235.2 Q 712.6 236.0, 712.6 237.1 Q 712.6 238.2, 712.1 239.1 Q 711.5 239.9, 710.6 240.4 Q 709.6 240.8, 708.6 240.8 Q 707.5 240.8, 706.6 240.4 Q 705.6 240.0, 705.0 239.3 L 705.9 238.3 Q 706.5 238.9, 707.2 239.2 Q 707.9 239.5, 708.6 239.5 Q 709.6 239.5, 710.3 238.9 Q 711.0 238.2, 711.0 237.1 Q 711.0 235.9, 710.3 235.4 Q 709.6 234.8, 708.5 234.8 Q 707.5 234.8, 706.4 235.2 L 705.6 234.8 L 706.1 229.3 L 711.9 229.3 L 711.8 230.6 L 707.4 230.6 L 707.1 234.0 Q 708.1 233.6, 709.1 233.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 714.5 239.4 L 717.0 239.4 L 717.0 230.9 L 714.3 231.8 L 713.9 230.8 L 717.4 229.3 L 718.5 229.5 L 718.5 239.4 L 720.7 239.4 L 720.7 240.7 L 714.5 240.7 L 714.5 239.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 726.1 240.8 Q 724.0 240.8, 722.9 239.3 Q 721.9 237.7, 721.9 235.0 Q 721.9 232.2, 722.9 230.7 Q 724.0 229.2, 726.1 229.2 Q 728.2 229.2, 729.2 230.7 Q 730.2 232.2, 730.2 235.0 Q 730.2 237.7, 729.2 239.3 Q 728.1 240.8, 726.1 240.8 M 726.1 239.5 Q 727.3 239.5, 728.0 238.4 Q 728.6 237.2, 728.6 235.0 Q 728.6 232.8, 728.0 231.6 Q 727.3 230.5, 726.1 230.5 Q 724.9 230.5, 724.2 231.6 Q 723.5 232.8, 723.5 235.0 Q 723.5 237.2, 724.2 238.4 Q 724.9 239.5, 726.1 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 178.8,381.3 L 178.8,355.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 178.8,355.4 L 154.2,347.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 154.2,347.5 L 139.1,368.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 139.1,368.3 L 154.2,389.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-5 atom-3\" d=\"M 116.9,368.7 L 116.9,368.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-5 atom-3\" d=\"M 120.6,369.0 L 120.6,367.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-5 atom-3\" d=\"M 124.3,369.3 L 124.3,367.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-5 atom-3\" d=\"M 128.0,369.6 L 128.0,367.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-5 atom-3\" d=\"M 131.7,370.0 L 131.7,366.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-5 atom-3\" d=\"M 135.4,370.3 L 135.4,366.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 113.3,368.3 L 98.1,389.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 98.1,389.2 L 87.4,385.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 87.4,385.8 L 76.7,382.3\" style=\"fill:none;fill-rule:evenodd;stroke:#CCCC00;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 73.5,376.8 L 73.5,366.1\" style=\"fill:none;fill-rule:evenodd;stroke:#CCCC00;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 73.5,366.1 L 73.5,355.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 73.5,355.4 L 84.0,352.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 84.0,352.0 L 94.5,348.6\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-4 atom-0\" d=\"M 154.2,389.2 L 178.8,381.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-9 atom-5\" d=\"M 101.4,352.0 L 107.3,360.2\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-9 atom-5\" d=\"M 107.3,360.2 L 113.3,368.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 178.8,380.0 L 178.8,381.3 L 177.6,381.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 178.8,356.7 L 178.8,355.4 L 177.6,355.0\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 155.5,347.9 L 154.2,347.5 L 153.5,348.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 139.8,367.3 L 139.1,368.3 L 139.8,369.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 153.5,388.2 L 154.2,389.2 L 155.5,388.8\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 112.5,369.4 L 113.3,368.3 L 113.0,367.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 98.9,388.2 L 98.1,389.2 L 97.6,389.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 73.5,356.0 L 73.5,355.4 L 74.1,355.3\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-7\" d=\"M 71.5 383.8 Q 71.6 383.8, 71.9 383.9 Q 72.2 384.1, 72.6 384.2 Q 73.0 384.3, 73.4 384.3 Q 74.1 384.3, 74.5 383.9 Q 74.9 383.6, 74.9 383.0 Q 74.9 382.6, 74.7 382.3 Q 74.5 382.1, 74.2 382.0 Q 73.8 381.8, 73.3 381.7 Q 72.7 381.5, 72.3 381.3 Q 71.9 381.1, 71.6 380.7 Q 71.4 380.3, 71.4 379.7 Q 71.4 378.7, 72.0 378.2 Q 72.6 377.6, 73.8 377.6 Q 74.7 377.6, 75.7 378.0 L 75.4 378.8 Q 74.5 378.4, 73.9 378.4 Q 73.2 378.4, 72.8 378.7 Q 72.4 379.0, 72.4 379.5 Q 72.4 379.9, 72.6 380.2 Q 72.8 380.4, 73.1 380.5 Q 73.4 380.7, 73.9 380.8 Q 74.5 381.0, 74.9 381.2 Q 75.3 381.4, 75.6 381.9 Q 75.9 382.3, 75.9 383.0 Q 75.9 384.0, 75.2 384.6 Q 74.5 385.1, 73.4 385.1 Q 72.8 385.1, 72.3 384.9 Q 71.8 384.8, 71.2 384.6 L 71.5 383.8 \" fill=\"#CCCC00\"/>\n",
       "<path class=\"atom-9\" d=\"M 96.5 343.8 L 98.9 347.7 Q 99.1 348.1, 99.5 348.8 Q 99.9 349.4, 99.9 349.5 L 99.9 343.8 L 100.9 343.8 L 100.9 351.1 L 99.9 351.1 L 97.3 346.9 Q 97.0 346.4, 96.7 345.8 Q 96.4 345.3, 96.3 345.1 L 96.3 351.1 L 95.3 351.1 L 95.3 343.8 L 96.5 343.8 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-9\" d=\"M 95.2 335.8 L 96.2 335.8 L 96.2 338.9 L 100.0 338.9 L 100.0 335.8 L 101.0 335.8 L 101.0 343.1 L 100.0 343.1 L 100.0 339.7 L 96.2 339.7 L 96.2 343.1 L 95.2 343.1 L 95.2 335.8 \" fill=\"#0000FF\"/>\n",
       "<path class=\"legend\" d=\"M 24.0 480.6 L 20.5 480.6 L 20.5 479.3 L 28.8 479.3 L 28.8 480.6 L 25.5 480.6 L 25.5 490.7 L 24.0 490.7 L 24.0 480.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 30.6 482.4 L 30.7 483.6 Q 31.6 482.3, 33.0 482.3 Q 33.5 482.3, 34.1 482.5 L 33.8 483.8 Q 33.1 483.6, 32.8 483.6 Q 32.1 483.6, 31.6 483.9 Q 31.2 484.2, 30.9 484.8 L 30.9 490.7 L 29.4 490.7 L 29.4 482.4 L 30.6 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 41.8 482.4 L 41.8 490.7 L 40.6 490.7 L 40.4 489.5 Q 39.3 490.8, 37.6 490.8 Q 36.2 490.8, 35.5 490.1 Q 34.8 489.3, 34.8 487.9 L 34.8 482.4 L 36.3 482.4 L 36.3 487.8 Q 36.3 488.7, 36.7 489.2 Q 37.1 489.6, 37.9 489.6 Q 38.7 489.6, 39.3 489.3 Q 39.9 488.9, 40.3 488.3 L 40.3 482.4 L 41.8 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 43.6 486.5 Q 43.6 484.5, 44.6 483.4 Q 45.6 482.3, 47.5 482.3 Q 49.3 482.3, 50.1 483.4 Q 50.9 484.5, 50.9 486.5 L 50.9 486.7 L 45.2 486.7 Q 45.2 488.1, 45.8 488.9 Q 46.4 489.6, 47.6 489.6 Q 48.3 489.6, 48.8 489.5 Q 49.4 489.3, 50.2 489.0 L 50.6 490.0 Q 49.8 490.4, 49.0 490.6 Q 48.3 490.8, 47.5 490.8 Q 45.7 490.8, 44.7 489.7 Q 43.6 488.6, 43.6 486.5 M 47.5 483.5 Q 46.5 483.5, 46.0 484.0 Q 45.4 484.6, 45.2 485.6 L 49.3 485.6 Q 49.2 484.5, 48.8 484.0 Q 48.3 483.5, 47.5 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 52.0 488.8 L 53.6 488.8 L 53.6 490.4 L 52.0 490.4 L 52.0 488.8 M 52.0 483.3 L 53.6 483.3 L 53.6 484.9 L 52.0 484.9 L 52.0 483.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 65.6 483.6 Q 66.6 483.6, 67.4 484.0 Q 68.2 484.5, 68.6 485.2 Q 69.0 486.0, 69.0 487.0 Q 69.0 488.1, 68.5 489.0 Q 68.0 489.8, 67.2 490.3 Q 66.3 490.8, 65.2 490.8 Q 63.2 490.8, 62.2 489.4 Q 61.2 488.1, 61.2 485.3 Q 61.2 482.3, 62.4 480.8 Q 63.7 479.2, 66.1 479.2 Q 66.8 479.2, 67.4 479.4 Q 68.0 479.5, 68.6 479.9 L 68.0 480.9 Q 67.1 480.5, 66.1 480.5 Q 64.5 480.5, 63.7 481.5 Q 62.9 482.6, 62.8 484.7 Q 63.4 484.2, 64.1 483.9 Q 64.8 483.6, 65.6 483.6 M 65.2 489.5 Q 65.8 489.5, 66.3 489.2 Q 66.8 488.8, 67.1 488.3 Q 67.4 487.7, 67.4 487.0 Q 67.4 486.0, 66.9 485.4 Q 66.3 484.9, 65.3 484.9 Q 64.6 484.9, 63.9 485.2 Q 63.3 485.4, 62.8 485.9 Q 62.8 487.8, 63.4 488.6 Q 64.0 489.5, 65.2 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 70.4 489.1 L 72.0 489.1 L 72.0 490.7 L 70.4 490.7 L 70.4 489.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 78.0 483.6 Q 79.0 483.6, 79.8 484.0 Q 80.6 484.5, 81.0 485.2 Q 81.4 486.0, 81.4 487.0 Q 81.4 488.1, 80.9 489.0 Q 80.4 489.8, 79.6 490.3 Q 78.7 490.8, 77.6 490.8 Q 75.6 490.8, 74.6 489.4 Q 73.6 488.1, 73.6 485.3 Q 73.6 482.3, 74.8 480.8 Q 76.1 479.2, 78.5 479.2 Q 79.2 479.2, 79.8 479.4 Q 80.4 479.5, 81.0 479.9 L 80.3 480.9 Q 79.5 480.5, 78.5 480.5 Q 76.9 480.5, 76.1 481.5 Q 75.3 482.6, 75.2 484.7 Q 75.8 484.2, 76.5 483.9 Q 77.2 483.6, 78.0 483.6 M 77.6 489.5 Q 78.2 489.5, 78.7 489.2 Q 79.2 488.8, 79.5 488.3 Q 79.8 487.7, 79.8 487.0 Q 79.8 486.0, 79.3 485.4 Q 78.7 484.9, 77.7 484.9 Q 77.0 484.9, 76.3 485.2 Q 75.7 485.4, 75.2 485.9 Q 75.2 487.8, 75.8 488.6 Q 76.4 489.5, 77.6 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 83.4 489.4 L 85.9 489.4 L 85.9 480.9 L 83.2 481.8 L 82.8 480.8 L 86.3 479.3 L 87.4 479.5 L 87.4 489.4 L 89.6 489.4 L 89.6 490.7 L 83.4 490.7 L 83.4 489.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 90.8 481.5 Q 91.3 480.4, 92.3 479.8 Q 93.2 479.2, 94.6 479.2 Q 96.3 479.2, 97.3 480.1 Q 98.3 481.1, 98.3 482.7 Q 98.3 484.4, 97.0 486.0 Q 95.8 487.5, 93.2 489.4 L 98.4 489.4 L 98.4 490.7 L 90.8 490.7 L 90.8 489.6 Q 92.9 488.1, 94.2 487.0 Q 95.4 485.8, 96.0 484.8 Q 96.7 483.8, 96.7 482.8 Q 96.7 481.7, 96.1 481.1 Q 95.6 480.5, 94.6 480.5 Q 93.7 480.5, 93.1 480.9 Q 92.5 481.2, 92.1 482.0 L 90.8 481.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 105.7 478.3 L 107.1 478.3 L 107.1 493.8 L 105.7 493.8 L 105.7 478.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 118.1 479.3 Q 120.1 479.3, 121.1 480.2 Q 122.0 481.1, 122.0 482.7 Q 122.0 484.2, 121.0 485.1 Q 120.0 486.0, 118.1 486.0 L 116.3 486.0 L 116.3 490.7 L 114.8 490.7 L 114.8 479.3 L 118.1 479.3 M 118.1 484.7 Q 119.2 484.7, 119.8 484.2 Q 120.4 483.7, 120.4 482.7 Q 120.4 481.7, 119.8 481.1 Q 119.3 480.6, 118.1 480.6 L 116.3 480.6 L 116.3 484.7 L 118.1 484.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 124.5 482.4 L 124.7 483.6 Q 125.5 482.3, 127.0 482.3 Q 127.4 482.3, 128.0 482.5 L 127.8 483.8 Q 127.1 483.6, 126.7 483.6 Q 126.0 483.6, 125.6 483.9 Q 125.1 484.2, 124.8 484.8 L 124.8 490.7 L 123.3 490.7 L 123.3 482.4 L 124.5 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 128.8 486.5 Q 128.8 484.5, 129.8 483.4 Q 130.8 482.3, 132.6 482.3 Q 134.4 482.3, 135.2 483.4 Q 136.0 484.5, 136.0 486.5 L 136.0 486.7 L 130.3 486.7 Q 130.3 488.1, 130.9 488.9 Q 131.6 489.6, 132.7 489.6 Q 133.4 489.6, 134.0 489.5 Q 134.6 489.3, 135.3 489.0 L 135.7 490.0 Q 134.9 490.4, 134.2 490.6 Q 133.4 490.8, 132.7 490.8 Q 130.8 490.8, 129.8 489.7 Q 128.8 488.6, 128.8 486.5 M 132.6 483.5 Q 131.7 483.5, 131.1 484.0 Q 130.5 484.6, 130.4 485.6 L 134.5 485.6 Q 134.3 484.5, 133.9 484.0 Q 133.4 483.5, 132.6 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 144.6 478.5 L 144.6 490.6 L 143.4 490.6 L 143.2 489.6 Q 142.3 490.8, 140.8 490.8 Q 139.1 490.8, 138.1 489.7 Q 137.2 488.7, 137.2 486.7 Q 137.2 484.6, 138.3 483.5 Q 139.4 482.3, 141.4 482.3 Q 142.2 482.3, 143.1 482.5 L 143.1 478.5 L 144.6 478.5 M 140.9 489.6 Q 141.7 489.6, 142.3 489.2 Q 142.9 488.7, 143.1 487.9 L 143.1 483.7 Q 142.3 483.5, 141.4 483.5 Q 140.1 483.5, 139.4 484.3 Q 138.7 485.2, 138.7 486.7 Q 138.7 488.1, 139.2 488.9 Q 139.8 489.6, 140.9 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 146.4 479.3 L 147.9 479.3 L 147.9 480.7 L 146.4 480.7 L 146.4 479.3 M 146.4 482.4 L 147.9 482.4 L 147.9 490.7 L 146.4 490.7 L 146.4 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 149.8 486.5 Q 149.8 484.6, 150.8 483.4 Q 151.7 482.3, 153.7 482.3 Q 155.6 482.3, 156.5 483.7 L 155.5 484.4 Q 155.2 483.9, 154.7 483.7 Q 154.3 483.5, 153.7 483.5 Q 152.6 483.5, 151.9 484.3 Q 151.3 485.0, 151.3 486.5 Q 151.3 488.1, 151.9 488.8 Q 152.6 489.6, 153.8 489.6 Q 154.5 489.6, 154.9 489.5 Q 155.4 489.3, 156.0 489.0 L 156.4 490.1 Q 155.2 490.8, 153.7 490.8 Q 151.7 490.8, 150.8 489.6 Q 149.8 488.5, 149.8 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 157.4 483.6 L 157.4 482.4 L 159.0 482.4 L 159.3 480.0 L 160.4 480.0 L 160.4 482.4 L 162.9 482.4 L 162.9 483.6 L 160.4 483.6 L 160.4 488.1 Q 160.4 489.6, 161.6 489.6 Q 162.1 489.6, 162.8 489.3 L 163.0 490.4 Q 162.1 490.8, 161.3 490.8 Q 160.2 490.8, 159.6 490.1 Q 158.9 489.5, 158.9 488.2 L 158.9 483.6 L 157.4 483.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 163.9 486.5 Q 163.9 484.5, 164.9 483.4 Q 165.9 482.3, 167.8 482.3 Q 169.6 482.3, 170.4 483.4 Q 171.2 484.5, 171.2 486.5 L 171.2 486.7 L 165.5 486.7 Q 165.5 488.1, 166.1 488.9 Q 166.7 489.6, 167.9 489.6 Q 168.6 489.6, 169.1 489.5 Q 169.7 489.3, 170.5 489.0 L 170.9 490.0 Q 170.1 490.4, 169.3 490.6 Q 168.6 490.8, 167.8 490.8 Q 166.0 490.8, 165.0 489.7 Q 163.9 488.6, 163.9 486.5 M 167.8 483.5 Q 166.8 483.5, 166.3 484.0 Q 165.7 484.6, 165.5 485.6 L 169.6 485.6 Q 169.5 484.5, 169.1 484.0 Q 168.6 483.5, 167.8 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 179.8 478.5 L 179.8 490.6 L 178.6 490.6 L 178.4 489.6 Q 177.5 490.8, 175.9 490.8 Q 174.2 490.8, 173.3 489.7 Q 172.3 488.7, 172.3 486.7 Q 172.3 484.6, 173.4 483.5 Q 174.6 482.3, 176.5 482.3 Q 177.4 482.3, 178.3 482.5 L 178.3 478.5 L 179.8 478.5 M 176.0 489.6 Q 176.9 489.6, 177.5 489.2 Q 178.1 488.7, 178.3 487.9 L 178.3 483.7 Q 177.5 483.5, 176.6 483.5 Q 175.3 483.5, 174.6 484.3 Q 173.9 485.2, 173.9 486.7 Q 173.9 488.1, 174.4 488.9 Q 175.0 489.6, 176.0 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 181.6 488.8 L 183.2 488.8 L 183.2 490.4 L 181.6 490.4 L 181.6 488.8 M 181.6 483.3 L 183.2 483.3 L 183.2 484.9 L 181.6 484.9 L 181.6 483.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 195.2 483.6 Q 196.2 483.6, 196.9 484.0 Q 197.7 484.5, 198.2 485.2 Q 198.6 486.0, 198.6 487.0 Q 198.6 488.1, 198.1 489.0 Q 197.6 489.8, 196.7 490.3 Q 195.9 490.8, 194.8 490.8 Q 192.8 490.8, 191.7 489.4 Q 190.7 488.1, 190.7 485.3 Q 190.7 482.3, 192.0 480.8 Q 193.2 479.2, 195.7 479.2 Q 196.4 479.2, 197.0 479.4 Q 197.6 479.5, 198.1 479.9 L 197.5 480.9 Q 196.7 480.5, 195.7 480.5 Q 194.1 480.5, 193.3 481.5 Q 192.4 482.6, 192.3 484.7 Q 192.9 484.2, 193.6 483.9 Q 194.4 483.6, 195.2 483.6 M 194.8 489.5 Q 195.4 489.5, 195.9 489.2 Q 196.4 488.8, 196.7 488.3 Q 197.0 487.7, 197.0 487.0 Q 197.0 486.0, 196.4 485.4 Q 195.9 484.9, 194.9 484.9 Q 194.2 484.9, 193.5 485.2 Q 192.8 485.4, 192.3 485.9 Q 192.4 487.8, 193.0 488.6 Q 193.6 489.5, 194.8 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 200.0 489.1 L 201.6 489.1 L 201.6 490.7 L 200.0 490.7 L 200.0 489.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 207.2 483.6 Q 208.2 483.6, 209.0 484.0 Q 209.9 484.4, 210.3 485.2 Q 210.8 486.0, 210.8 487.1 Q 210.8 488.2, 210.2 489.1 Q 209.6 489.9, 208.7 490.4 Q 207.8 490.8, 206.7 490.8 Q 205.7 490.8, 204.7 490.4 Q 203.8 490.0, 203.1 489.3 L 204.1 488.3 Q 204.6 488.9, 205.3 489.2 Q 206.0 489.5, 206.8 489.5 Q 207.8 489.5, 208.5 488.9 Q 209.2 488.2, 209.2 487.1 Q 209.2 485.9, 208.5 485.4 Q 207.8 484.8, 206.7 484.8 Q 205.7 484.8, 204.6 485.2 L 203.7 484.8 L 204.3 479.3 L 210.1 479.3 L 209.9 480.6 L 205.6 480.6 L 205.2 484.0 Q 206.2 483.6, 207.2 483.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 215.9 479.2 Q 217.9 479.2, 218.9 480.6 Q 219.9 481.9, 219.9 484.7 Q 219.9 487.7, 218.6 489.2 Q 217.4 490.8, 215.0 490.8 Q 214.3 490.8, 213.7 490.6 Q 213.1 490.5, 212.5 490.1 L 213.1 489.1 Q 214.0 489.5, 215.0 489.5 Q 216.6 489.5, 217.4 488.5 Q 218.2 487.4, 218.3 485.3 Q 217.7 485.8, 217.0 486.1 Q 216.3 486.4, 215.5 486.4 Q 214.5 486.4, 213.7 486.0 Q 212.9 485.5, 212.5 484.8 Q 212.1 484.0, 212.1 483.0 Q 212.1 481.9, 212.5 481.0 Q 213.0 480.2, 213.9 479.7 Q 214.8 479.2, 215.9 479.2 M 213.7 483.0 Q 213.7 484.0, 214.2 484.6 Q 214.8 485.1, 215.8 485.1 Q 216.5 485.1, 217.1 484.9 Q 217.8 484.6, 218.3 484.1 Q 218.2 482.2, 217.6 481.4 Q 217.0 480.5, 215.8 480.5 Q 215.2 480.5, 214.7 480.8 Q 214.2 481.2, 213.9 481.7 Q 213.7 482.3, 213.7 483.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 227.3 484.7 Q 228.3 485.1, 228.9 485.8 Q 229.5 486.4, 229.5 487.6 Q 229.5 488.5, 229.0 489.3 Q 228.5 490.0, 227.6 490.4 Q 226.7 490.8, 225.6 490.8 Q 223.7 490.8, 222.6 490.0 Q 221.5 489.1, 221.5 487.6 Q 221.5 486.6, 222.0 485.9 Q 222.5 485.2, 223.5 484.7 Q 222.7 484.3, 222.3 483.7 Q 221.9 483.1, 221.9 482.1 Q 221.9 480.8, 222.9 480.0 Q 223.9 479.2, 225.5 479.2 Q 227.2 479.2, 228.1 480.0 Q 229.1 480.8, 229.1 482.1 Q 229.1 482.9, 228.6 483.6 Q 228.2 484.2, 227.3 484.7 M 225.5 480.4 Q 224.6 480.4, 224.0 480.9 Q 223.5 481.3, 223.5 482.1 Q 223.5 482.7, 223.9 483.1 Q 224.2 483.5, 224.7 483.7 Q 225.2 483.9, 226.2 484.3 Q 226.9 483.8, 227.2 483.3 Q 227.5 482.8, 227.5 482.1 Q 227.5 481.3, 227.0 480.9 Q 226.5 480.4, 225.5 480.4 M 225.6 489.6 Q 226.6 489.6, 227.3 489.1 Q 227.9 488.5, 227.9 487.5 Q 227.9 486.9, 227.6 486.6 Q 227.2 486.2, 226.7 485.9 Q 226.2 485.7, 225.3 485.4 L 224.6 485.2 Q 223.8 485.7, 223.5 486.2 Q 223.1 486.8, 223.1 487.5 Q 223.1 488.5, 223.8 489.1 Q 224.5 489.6, 225.6 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 426.6,364.3 L 400.8,364.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 400.8,364.3 L 395.7,373.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 395.7,373.3 L 390.5,382.2\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 396.3,364.3 L 391.7,372.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 391.7,372.3 L 387.2,380.3\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 384.3,386.7 L 373.2,386.7\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 373.2,386.7 L 362.1,386.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 362.1,386.7 L 349.2,409.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-3 atom-5\" d=\"M 362.1,386.7 L 349.2,364.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-3 atom-5\" d=\"M 364.3,382.8 L 353.7,364.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 349.2,364.3 L 354.3,355.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 354.3,355.4 L 359.5,346.5\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 370.3,342.0 L 379.1,342.0\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 379.1,342.0 L 387.9,342.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 370.3,345.9 L 378.0,345.9\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 378.0,345.9 L 385.7,345.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-6 atom-8\" d=\"M 359.5,337.5 L 355.7,330.9\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-6 atom-8\" d=\"M 355.7,330.9 L 351.9,324.3\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-5 atom-9\" d=\"M 349.2,364.3 L 323.4,364.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-7 atom-1\" d=\"M 387.9,342.0 L 400.8,364.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 387.5,342.0 L 387.9,342.0 L 388.6,343.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-2\" d=\"M 386.3 383.0 L 388.7 386.9 Q 388.9 387.3, 389.3 388.0 Q 389.7 388.7, 389.7 388.7 L 389.7 383.0 L 390.7 383.0 L 390.7 390.4 L 389.7 390.4 L 387.1 386.1 Q 386.8 385.6, 386.5 385.1 Q 386.2 384.5, 386.1 384.3 L 386.1 390.4 L 385.1 390.4 L 385.1 383.0 L 386.3 383.0 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-6\" d=\"M 360.5 338.3 L 362.9 342.2 Q 363.1 342.6, 363.5 343.3 Q 363.9 344.0, 363.9 344.0 L 363.9 338.3 L 364.9 338.3 L 364.9 345.7 L 363.9 345.7 L 361.3 341.4 Q 361.0 340.9, 360.7 340.4 Q 360.4 339.8, 360.3 339.6 L 360.3 345.7 L 359.3 345.7 L 359.3 338.3 L 360.5 338.3 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-6\" d=\"M 366.2 339.7 L 367.5 339.7 L 367.5 338.3 L 368.1 338.3 L 368.1 339.7 L 369.4 339.7 L 369.4 340.1 L 368.1 340.1 L 368.1 341.5 L 367.5 341.5 L 367.5 340.1 L 366.2 340.1 L 366.2 339.7 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-8\" d=\"M 345.8 319.7 Q 345.8 317.9, 346.7 316.9 Q 347.6 315.9, 349.2 315.9 Q 350.8 315.9, 351.7 316.9 Q 352.5 317.9, 352.5 319.7 Q 352.5 321.4, 351.7 322.5 Q 350.8 323.5, 349.2 323.5 Q 347.6 323.5, 346.7 322.5 Q 345.8 321.4, 345.8 319.7 M 349.2 322.6 Q 350.3 322.6, 350.9 321.9 Q 351.5 321.1, 351.5 319.7 Q 351.5 318.2, 350.9 317.5 Q 350.3 316.8, 349.2 316.8 Q 348.1 316.8, 347.5 317.5 Q 346.9 318.2, 346.9 319.7 Q 346.9 321.1, 347.5 321.9 Q 348.1 322.6, 349.2 322.6 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-8\" d=\"M 353.6 317.1 L 356.1 317.1 L 356.1 317.7 L 353.6 317.7 L 353.6 317.1 \" fill=\"#FF0000\"/>\n",
       "<path class=\"legend\" d=\"M 271.8 480.6 L 268.3 480.6 L 268.3 479.3 L 276.7 479.3 L 276.7 480.6 L 273.4 480.6 L 273.4 490.7 L 271.8 490.7 L 271.8 480.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 278.4 482.4 L 278.6 483.6 Q 279.5 482.3, 280.9 482.3 Q 281.3 482.3, 281.9 482.5 L 281.7 483.8 Q 281.0 483.6, 280.6 483.6 Q 279.9 483.6, 279.5 483.9 Q 279.1 484.2, 278.7 484.8 L 278.7 490.7 L 277.2 490.7 L 277.2 482.4 L 278.4 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 289.7 482.4 L 289.7 490.7 L 288.4 490.7 L 288.3 489.5 Q 287.2 490.8, 285.5 490.8 Q 284.1 490.8, 283.4 490.1 Q 282.7 489.3, 282.7 487.9 L 282.7 482.4 L 284.2 482.4 L 284.2 487.8 Q 284.2 488.7, 284.5 489.2 Q 284.9 489.6, 285.8 489.6 Q 286.5 489.6, 287.1 489.3 Q 287.8 488.9, 288.2 488.3 L 288.2 482.4 L 289.7 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 291.5 486.5 Q 291.5 484.5, 292.5 483.4 Q 293.5 482.3, 295.4 482.3 Q 297.2 482.3, 298.0 483.4 Q 298.8 484.5, 298.8 486.5 L 298.8 486.7 L 293.0 486.7 Q 293.1 488.1, 293.7 488.9 Q 294.3 489.6, 295.5 489.6 Q 296.1 489.6, 296.7 489.5 Q 297.3 489.3, 298.0 489.0 L 298.5 490.0 Q 297.6 490.4, 296.9 490.6 Q 296.2 490.8, 295.4 490.8 Q 293.5 490.8, 292.5 489.7 Q 291.5 488.6, 291.5 486.5 M 295.4 483.5 Q 294.4 483.5, 293.8 484.0 Q 293.3 484.6, 293.1 485.6 L 297.2 485.6 Q 297.1 484.5, 296.6 484.0 Q 296.2 483.5, 295.4 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 299.9 488.8 L 301.5 488.8 L 301.5 490.4 L 299.9 490.4 L 299.9 488.8 M 299.9 483.3 L 301.5 483.3 L 301.5 484.9 L 299.9 484.9 L 299.9 483.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 316.4 486.8 L 317.8 486.8 L 317.8 488.1 L 316.4 488.1 L 316.4 490.7 L 314.9 490.7 L 314.9 488.1 L 309.1 488.1 L 309.1 487.0 L 314.0 479.3 L 316.4 479.3 L 316.4 486.8 M 310.9 486.8 L 314.9 486.8 L 314.9 480.4 L 310.9 486.8 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 319.1 489.1 L 320.7 489.1 L 320.7 490.7 L 319.1 490.7 L 319.1 489.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 328.0 484.7 Q 329.1 485.1, 329.7 485.8 Q 330.3 486.4, 330.3 487.6 Q 330.3 488.5, 329.8 489.3 Q 329.3 490.0, 328.4 490.4 Q 327.5 490.8, 326.3 490.8 Q 324.4 490.8, 323.4 490.0 Q 322.3 489.1, 322.3 487.6 Q 322.3 486.6, 322.8 485.9 Q 323.2 485.2, 324.2 484.7 Q 323.5 484.3, 323.1 483.7 Q 322.7 483.1, 322.7 482.1 Q 322.7 480.8, 323.6 480.0 Q 324.6 479.2, 326.3 479.2 Q 327.9 479.2, 328.9 480.0 Q 329.9 480.8, 329.9 482.1 Q 329.9 482.9, 329.4 483.6 Q 328.9 484.2, 328.0 484.7 M 326.3 480.4 Q 325.3 480.4, 324.8 480.9 Q 324.3 481.3, 324.3 482.1 Q 324.3 482.7, 324.6 483.1 Q 325.0 483.5, 325.5 483.7 Q 326.0 483.9, 327.0 484.3 Q 327.7 483.8, 328.0 483.3 Q 328.3 482.8, 328.3 482.1 Q 328.3 481.3, 327.7 480.9 Q 327.2 480.4, 326.3 480.4 M 326.3 489.6 Q 327.4 489.6, 328.0 489.1 Q 328.7 488.5, 328.7 487.5 Q 328.7 486.9, 328.3 486.6 Q 328.0 486.2, 327.5 485.9 Q 327.0 485.7, 326.1 485.4 L 325.4 485.2 Q 324.6 485.7, 324.2 486.2 Q 323.9 486.8, 323.9 487.5 Q 323.9 488.5, 324.5 489.1 Q 325.2 489.6, 326.3 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 337.7 480.6 L 331.8 480.6 L 331.8 479.3 L 339.3 479.3 L 339.3 480.5 L 334.7 490.7 L 333.2 490.7 L 337.7 480.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 347.7 486.8 L 349.0 486.8 L 349.0 488.1 L 347.7 488.1 L 347.7 490.7 L 346.2 490.7 L 346.2 488.1 L 340.3 488.1 L 340.3 487.0 L 345.3 479.3 L 347.7 479.3 L 347.7 486.8 M 342.2 486.8 L 346.2 486.8 L 346.2 480.4 L 342.2 486.8 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 356.2 478.3 L 357.5 478.3 L 357.5 493.8 L 356.2 493.8 L 356.2 478.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 368.6 479.3 Q 370.5 479.3, 371.5 480.2 Q 372.5 481.1, 372.5 482.7 Q 372.5 484.2, 371.5 485.1 Q 370.5 486.0, 368.6 486.0 L 366.8 486.0 L 366.8 490.7 L 365.3 490.7 L 365.3 479.3 L 368.6 479.3 M 368.6 484.7 Q 369.7 484.7, 370.3 484.2 Q 370.9 483.7, 370.9 482.7 Q 370.9 481.7, 370.3 481.1 Q 369.7 480.6, 368.6 480.6 L 366.8 480.6 L 366.8 484.7 L 368.6 484.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 375.0 482.4 L 375.2 483.6 Q 376.0 482.3, 377.4 482.3 Q 377.9 482.3, 378.5 482.5 L 378.2 483.8 Q 377.6 483.6, 377.2 483.6 Q 376.5 483.6, 376.1 483.9 Q 375.6 484.2, 375.3 484.8 L 375.3 490.7 L 373.8 490.7 L 373.8 482.4 L 375.0 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 379.3 486.5 Q 379.3 484.5, 380.3 483.4 Q 381.3 482.3, 383.1 482.3 Q 384.9 482.3, 385.7 483.4 Q 386.5 484.5, 386.5 486.5 L 386.5 486.7 L 380.8 486.7 Q 380.8 488.1, 381.4 488.9 Q 382.1 489.6, 383.2 489.6 Q 383.9 489.6, 384.5 489.5 Q 385.1 489.3, 385.8 489.0 L 386.2 490.0 Q 385.4 490.4, 384.7 490.6 Q 383.9 490.8, 383.2 490.8 Q 381.3 490.8, 380.3 489.7 Q 379.3 488.6, 379.3 486.5 M 383.1 483.5 Q 382.2 483.5, 381.6 484.0 Q 381.0 484.6, 380.9 485.6 L 384.9 485.6 Q 384.8 484.5, 384.4 484.0 Q 383.9 483.5, 383.1 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 395.1 478.5 L 395.1 490.6 L 393.9 490.6 L 393.7 489.6 Q 392.8 490.8, 391.3 490.8 Q 389.6 490.8, 388.6 489.7 Q 387.7 488.7, 387.7 486.7 Q 387.7 484.6, 388.8 483.5 Q 389.9 482.3, 391.9 482.3 Q 392.7 482.3, 393.6 482.5 L 393.6 478.5 L 395.1 478.5 M 391.4 489.6 Q 392.2 489.6, 392.8 489.2 Q 393.4 488.7, 393.6 487.9 L 393.6 483.7 Q 392.8 483.5, 391.9 483.5 Q 390.6 483.5, 389.9 484.3 Q 389.2 485.2, 389.2 486.7 Q 389.2 488.1, 389.8 488.9 Q 390.3 489.6, 391.4 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 396.9 479.3 L 398.4 479.3 L 398.4 480.7 L 396.9 480.7 L 396.9 479.3 M 396.9 482.4 L 398.4 482.4 L 398.4 490.7 L 396.9 490.7 L 396.9 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 400.3 486.5 Q 400.3 484.6, 401.3 483.4 Q 402.3 482.3, 404.2 482.3 Q 406.1 482.3, 407.1 483.7 L 406.1 484.4 Q 405.7 483.9, 405.2 483.7 Q 404.8 483.5, 404.2 483.5 Q 403.1 483.5, 402.5 484.3 Q 401.8 485.0, 401.8 486.5 Q 401.8 488.1, 402.5 488.8 Q 403.1 489.6, 404.3 489.6 Q 405.0 489.6, 405.5 489.5 Q 405.9 489.3, 406.5 489.0 L 406.9 490.1 Q 405.7 490.8, 404.2 490.8 Q 402.3 490.8, 401.3 489.6 Q 400.3 488.5, 400.3 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 408.0 483.6 L 408.0 482.4 L 409.6 482.4 L 409.8 480.0 L 410.9 480.0 L 410.9 482.4 L 413.4 482.4 L 413.4 483.6 L 410.9 483.6 L 410.9 488.1 Q 410.9 489.6, 412.1 489.6 Q 412.6 489.6, 413.3 489.3 L 413.6 490.4 Q 412.7 490.8, 411.9 490.8 Q 410.8 490.8, 410.1 490.1 Q 409.4 489.5, 409.4 488.2 L 409.4 483.6 L 408.0 483.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 414.5 486.5 Q 414.5 484.5, 415.5 483.4 Q 416.5 482.3, 418.4 482.3 Q 420.2 482.3, 421.0 483.4 Q 421.8 484.5, 421.8 486.5 L 421.8 486.7 L 416.0 486.7 Q 416.1 488.1, 416.7 488.9 Q 417.3 489.6, 418.5 489.6 Q 419.1 489.6, 419.7 489.5 Q 420.3 489.3, 421.0 489.0 L 421.5 490.0 Q 420.6 490.4, 419.9 490.6 Q 419.2 490.8, 418.4 490.8 Q 416.5 490.8, 415.5 489.7 Q 414.5 488.6, 414.5 486.5 M 418.4 483.5 Q 417.4 483.5, 416.8 484.0 Q 416.3 484.6, 416.1 485.6 L 420.2 485.6 Q 420.1 484.5, 419.6 484.0 Q 419.2 483.5, 418.4 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 430.4 478.5 L 430.4 490.6 L 429.2 490.6 L 429.0 489.6 Q 428.0 490.8, 426.5 490.8 Q 424.8 490.8, 423.8 489.7 Q 422.9 488.7, 422.9 486.7 Q 422.9 484.6, 424.0 483.5 Q 425.2 482.3, 427.1 482.3 Q 428.0 482.3, 428.9 482.5 L 428.9 478.5 L 430.4 478.5 M 426.6 489.6 Q 427.4 489.6, 428.0 489.2 Q 428.6 488.7, 428.9 487.9 L 428.9 483.7 Q 428.1 483.5, 427.1 483.5 Q 425.9 483.5, 425.2 484.3 Q 424.4 485.2, 424.4 486.7 Q 424.4 488.1, 425.0 488.9 Q 425.6 489.6, 426.6 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 432.2 488.8 L 433.8 488.8 L 433.8 490.4 L 432.2 490.4 L 432.2 488.8 M 432.2 483.3 L 433.8 483.3 L 433.8 484.9 L 432.2 484.9 L 432.2 483.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 448.7 486.8 L 450.1 486.8 L 450.1 488.1 L 448.7 488.1 L 448.7 490.7 L 447.2 490.7 L 447.2 488.1 L 441.4 488.1 L 441.4 487.0 L 446.3 479.3 L 448.7 479.3 L 448.7 486.8 M 443.2 486.8 L 447.2 486.8 L 447.2 480.4 L 443.2 486.8 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 451.4 489.1 L 453.0 489.1 L 453.0 490.7 L 451.4 490.7 L 451.4 489.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 458.3 479.2 Q 460.4 479.2, 461.4 480.6 Q 462.4 481.9, 462.4 484.7 Q 462.4 487.7, 461.1 489.2 Q 459.9 490.8, 457.5 490.8 Q 456.8 490.8, 456.2 490.6 Q 455.6 490.5, 455.0 490.1 L 455.6 489.1 Q 456.4 489.5, 457.5 489.5 Q 459.1 489.5, 459.9 488.5 Q 460.7 487.4, 460.8 485.3 Q 460.2 485.8, 459.5 486.1 Q 458.7 486.4, 458.0 486.4 Q 457.0 486.4, 456.2 486.0 Q 455.4 485.5, 455.0 484.8 Q 454.5 484.0, 454.5 483.0 Q 454.5 481.9, 455.0 481.0 Q 455.5 480.2, 456.4 479.7 Q 457.2 479.2, 458.3 479.2 M 456.1 483.0 Q 456.1 484.0, 456.7 484.6 Q 457.3 485.1, 458.3 485.1 Q 458.9 485.1, 459.6 484.9 Q 460.3 484.6, 460.8 484.1 Q 460.7 482.2, 460.1 481.4 Q 459.5 480.5, 458.3 480.5 Q 457.7 480.5, 457.2 480.8 Q 456.7 481.2, 456.4 481.7 Q 456.1 482.3, 456.1 483.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 468.1 483.6 Q 469.1 483.6, 469.9 484.0 Q 470.7 484.4, 471.2 485.2 Q 471.7 486.0, 471.7 487.1 Q 471.7 488.2, 471.1 489.1 Q 470.5 489.9, 469.6 490.4 Q 468.7 490.8, 467.6 490.8 Q 466.6 490.8, 465.6 490.4 Q 464.7 490.0, 464.0 489.3 L 465.0 488.3 Q 465.5 488.9, 466.2 489.2 Q 466.9 489.5, 467.7 489.5 Q 468.7 489.5, 469.4 488.9 Q 470.1 488.2, 470.1 487.1 Q 470.1 485.9, 469.4 485.4 Q 468.7 484.8, 467.6 484.8 Q 466.6 484.8, 465.5 485.2 L 464.6 484.8 L 465.1 479.3 L 471.0 479.3 L 470.8 480.6 L 466.5 480.6 L 466.1 484.0 Q 467.1 483.6, 468.1 483.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 480.3 486.8 L 481.7 486.8 L 481.7 488.1 L 480.3 488.1 L 480.3 490.7 L 478.8 490.7 L 478.8 488.1 L 473.0 488.1 L 473.0 487.0 L 477.9 479.3 L 480.3 479.3 L 480.3 486.8 M 474.8 486.8 L 478.8 486.8 L 478.8 480.4 L 474.8 486.8 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 531.9,336.7 L 557.6,335.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 557.6,335.3 L 563.2,343.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 563.2,343.9 L 568.7,352.4\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 575.9,356.7 L 586.7,356.2\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 586.7,356.2 L 597.5,355.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 598.7,357.5 L 603.6,347.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 603.6,347.8 L 608.5,338.1\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 595.2,355.7 L 600.2,346.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 600.2,346.0 L 605.1,336.4\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-3 atom-5\" d=\"M 597.5,355.6 L 611.5,377.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 611.5,377.2 L 633.2,363.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 633.2,363.2 L 656.2,374.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 656.2,374.9 L 665.2,369.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 665.2,369.0 L 674.2,363.2\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 681.4,362.2 L 698.3,368.7\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 705.5,365.6 L 711.8,357.8\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 711.8,357.8 L 718.1,350.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 702.5,363.2 L 707.9,356.5\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 707.9,356.5 L 713.4,349.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-10 atom-11\" d=\"M 718.1,350.0 L 704.1,328.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-11 atom-12\" d=\"M 704.1,328.4 L 679.2,335.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-11 atom-12\" d=\"M 702.4,332.8 L 682.9,338.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-12 atom-13\" d=\"M 679.2,335.1 L 659.1,318.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 656.6,378.6 L 656.1,378.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 657.1,382.2 L 656.0,382.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 657.6,385.9 L 655.9,386.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 658.0,389.6 L 655.8,389.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 658.5,393.2 L 655.8,393.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 659.0,396.9 L 655.7,397.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-7 atom-14\" d=\"M 659.5,400.6 L 655.6,400.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-5 atom-15\" d=\"M 611.5,377.2 L 617.1,385.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-5 atom-15\" d=\"M 617.1,385.8 L 622.7,394.4\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 608.6,379.5 L 608.3,379.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 605.6,381.7 L 605.0,380.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 602.7,384.0 L 601.8,382.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 599.8,386.2 L 598.6,384.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 596.8,388.4 L 595.3,386.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 593.9,390.7 L 592.1,387.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-5 atom-16\" d=\"M 590.9,392.9 L 588.8,389.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16 atom-12 atom-8\" d=\"M 679.2,335.1 L 678.6,345.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16 atom-12 atom-8\" d=\"M 678.6,345.7 L 678.0,356.3\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 556.3,335.4 L 557.6,335.3 L 557.9,335.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 596.9,355.6 L 597.5,355.6 L 598.2,356.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 632.1,363.9 L 633.2,363.2 L 634.3,363.8\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 655.0,374.3 L 656.2,374.9 L 656.6,374.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 717.8,350.4 L 718.1,350.0 L 717.4,348.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 704.8,329.4 L 704.1,328.4 L 702.8,328.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-2\" d=\"M 568.3 357.0 Q 568.3 355.2, 569.2 354.2 Q 570.1 353.3, 571.7 353.3 Q 573.3 353.3, 574.2 354.2 Q 575.0 355.2, 575.0 357.0 Q 575.0 358.7, 574.2 359.8 Q 573.3 360.8, 571.7 360.8 Q 570.1 360.8, 569.2 359.8 Q 568.3 358.8, 568.3 357.0 M 571.7 359.9 Q 572.8 359.9, 573.4 359.2 Q 574.0 358.4, 574.0 357.0 Q 574.0 355.5, 573.4 354.8 Q 572.8 354.1, 571.7 354.1 Q 570.6 354.1, 570.0 354.8 Q 569.4 355.5, 569.4 357.0 Q 569.4 358.4, 570.0 359.2 Q 570.6 359.9, 571.7 359.9 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-4\" d=\"M 605.8 332.6 Q 605.8 330.9, 606.7 329.9 Q 607.6 328.9, 609.2 328.9 Q 610.8 328.9, 611.7 329.9 Q 612.5 330.9, 612.5 332.6 Q 612.5 334.4, 611.7 335.4 Q 610.8 336.4, 609.2 336.4 Q 607.6 336.4, 606.7 335.4 Q 605.8 334.4, 605.8 332.6 M 609.2 335.6 Q 610.3 335.6, 610.9 334.8 Q 611.5 334.1, 611.5 332.6 Q 611.5 331.2, 610.9 330.5 Q 610.3 329.7, 609.2 329.7 Q 608.1 329.7, 607.5 330.4 Q 606.9 331.2, 606.9 332.6 Q 606.9 334.1, 607.5 334.8 Q 608.1 335.6, 609.2 335.6 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-8\" d=\"M 676.2 357.2 L 678.6 361.0 Q 678.8 361.4, 679.2 362.1 Q 679.6 362.8, 679.6 362.8 L 679.6 357.2 L 680.6 357.2 L 680.6 364.5 L 679.6 364.5 L 677.0 360.2 Q 676.7 359.8, 676.4 359.2 Q 676.1 358.6, 676.0 358.4 L 676.0 364.5 L 675.0 364.5 L 675.0 357.2 L 676.2 357.2 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-9\" d=\"M 700.3 366.4 L 702.7 370.3 Q 702.9 370.7, 703.3 371.4 Q 703.7 372.1, 703.7 372.1 L 703.7 366.4 L 704.7 366.4 L 704.7 373.7 L 703.7 373.7 L 701.1 369.5 Q 700.8 369.0, 700.5 368.4 Q 700.2 367.9, 700.1 367.7 L 700.1 373.7 L 699.1 373.7 L 699.1 366.4 L 700.3 366.4 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-15\" d=\"M 624.0 395.2 L 626.4 399.1 Q 626.6 399.5, 627.0 400.2 Q 627.4 400.9, 627.4 400.9 L 627.4 395.2 L 628.4 395.2 L 628.4 402.5 L 627.4 402.5 L 624.8 398.3 Q 624.5 397.8, 624.2 397.2 Q 623.9 396.7, 623.8 396.5 L 623.8 402.5 L 622.8 402.5 L 622.8 395.2 L 624.0 395.2 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-15\" d=\"M 629.8 395.2 L 630.7 395.2 L 630.7 398.3 L 634.5 398.3 L 634.5 395.2 L 635.5 395.2 L 635.5 402.5 L 634.5 402.5 L 634.5 399.2 L 630.7 399.2 L 630.7 402.5 L 629.8 402.5 L 629.8 395.2 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-15\" d=\"M 636.9 402.3 Q 637.1 401.8, 637.5 401.6 Q 637.9 401.3, 638.5 401.3 Q 639.2 401.3, 639.7 401.7 Q 640.1 402.1, 640.1 402.8 Q 640.1 403.5, 639.5 404.2 Q 639.0 404.9, 637.9 405.6 L 640.1 405.6 L 640.1 406.2 L 636.9 406.2 L 636.9 405.7 Q 637.8 405.1, 638.3 404.6 Q 638.9 404.1, 639.1 403.7 Q 639.4 403.3, 639.4 402.8 Q 639.4 402.4, 639.1 402.1 Q 638.9 401.9, 638.5 401.9 Q 638.1 401.9, 637.9 402.0 Q 637.6 402.2, 637.4 402.5 L 636.9 402.3 \" fill=\"#0000FF\"/>\n",
       "<path class=\"legend\" d=\"M 523.0 480.6 L 519.5 480.6 L 519.5 479.3 L 527.8 479.3 L 527.8 480.6 L 524.5 480.6 L 524.5 490.7 L 523.0 490.7 L 523.0 480.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 529.6 482.4 L 529.7 483.6 Q 530.6 482.3, 532.0 482.3 Q 532.5 482.3, 533.1 482.5 L 532.8 483.8 Q 532.1 483.6, 531.8 483.6 Q 531.1 483.6, 530.6 483.9 Q 530.2 484.2, 529.8 484.8 L 529.8 490.7 L 528.3 490.7 L 528.3 482.4 L 529.6 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 540.8 482.4 L 540.8 490.7 L 539.6 490.7 L 539.4 489.5 Q 538.3 490.8, 536.6 490.8 Q 535.2 490.8, 534.5 490.1 Q 533.8 489.3, 533.8 487.9 L 533.8 482.4 L 535.3 482.4 L 535.3 487.8 Q 535.3 488.7, 535.7 489.2 Q 536.1 489.6, 536.9 489.6 Q 537.7 489.6, 538.3 489.3 Q 538.9 488.9, 539.3 488.3 L 539.3 482.4 L 540.8 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 542.6 486.5 Q 542.6 484.5, 543.6 483.4 Q 544.6 482.3, 546.5 482.3 Q 548.3 482.3, 549.1 483.4 Q 549.9 484.5, 549.9 486.5 L 549.9 486.7 L 544.2 486.7 Q 544.2 488.1, 544.8 488.9 Q 545.4 489.6, 546.6 489.6 Q 547.3 489.6, 547.8 489.5 Q 548.4 489.3, 549.2 489.0 L 549.6 490.0 Q 548.8 490.4, 548.0 490.6 Q 547.3 490.8, 546.5 490.8 Q 544.7 490.8, 543.7 489.7 Q 542.6 488.6, 542.6 486.5 M 546.5 483.5 Q 545.5 483.5, 545.0 484.0 Q 544.4 484.6, 544.2 485.6 L 548.3 485.6 Q 548.2 484.5, 547.8 484.0 Q 547.3 483.5, 546.5 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 551.0 488.8 L 552.6 488.8 L 552.6 490.4 L 551.0 490.4 L 551.0 488.8 M 551.0 483.3 L 552.6 483.3 L 552.6 484.9 L 551.0 484.9 L 551.0 483.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 564.6 483.6 Q 565.6 483.6, 566.4 484.0 Q 567.2 484.5, 567.6 485.2 Q 568.0 486.0, 568.0 487.0 Q 568.0 488.1, 567.5 489.0 Q 567.1 489.8, 566.2 490.3 Q 565.3 490.8, 564.2 490.8 Q 562.2 490.8, 561.2 489.4 Q 560.2 488.1, 560.2 485.3 Q 560.2 482.3, 561.4 480.8 Q 562.7 479.2, 565.1 479.2 Q 565.8 479.2, 566.4 479.4 Q 567.0 479.5, 567.6 479.9 L 567.0 480.9 Q 566.1 480.5, 565.1 480.5 Q 563.5 480.5, 562.7 481.5 Q 561.9 482.6, 561.8 484.7 Q 562.4 484.2, 563.1 483.9 Q 563.8 483.6, 564.6 483.6 M 564.2 489.5 Q 564.9 489.5, 565.4 489.2 Q 565.9 488.8, 566.2 488.3 Q 566.4 487.7, 566.4 487.0 Q 566.4 486.0, 565.9 485.4 Q 565.3 484.9, 564.3 484.9 Q 563.6 484.9, 563.0 485.2 Q 562.3 485.4, 561.8 485.9 Q 561.9 487.8, 562.5 488.6 Q 563.0 489.5, 564.2 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 569.4 489.1 L 571.0 489.1 L 571.0 490.7 L 569.4 490.7 L 569.4 489.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 578.0 484.7 Q 579.1 485.0, 579.7 485.7 Q 580.2 486.4, 580.2 487.6 Q 580.2 488.5, 579.7 489.3 Q 579.2 490.0, 578.4 490.4 Q 577.5 490.8, 576.3 490.8 Q 575.1 490.8, 574.2 490.4 Q 573.3 490.0, 572.6 489.1 L 573.5 488.2 Q 574.2 489.0, 574.8 489.3 Q 575.4 489.5, 576.3 489.5 Q 577.3 489.5, 578.0 489.0 Q 578.6 488.4, 578.6 487.5 Q 578.6 486.4, 577.9 485.9 Q 577.3 485.4, 575.9 485.4 L 575.1 485.4 L 575.1 484.2 L 575.8 484.2 Q 577.0 484.2, 577.7 483.7 Q 578.4 483.1, 578.4 482.1 Q 578.4 481.4, 577.8 480.9 Q 577.3 480.5, 576.3 480.5 Q 575.4 480.5, 574.8 480.8 Q 574.2 481.2, 573.8 482.0 L 572.7 481.4 Q 573.1 480.5, 574.0 479.8 Q 575.0 479.2, 576.3 479.2 Q 578.0 479.2, 579.0 480.0 Q 580.0 480.8, 580.0 482.1 Q 580.0 483.0, 579.5 483.7 Q 579.0 484.3, 578.0 484.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 587.4 484.7 Q 588.5 485.1, 589.1 485.8 Q 589.6 486.4, 589.6 487.6 Q 589.6 488.5, 589.2 489.3 Q 588.7 490.0, 587.8 490.4 Q 586.9 490.8, 585.7 490.8 Q 583.8 490.8, 582.7 490.0 Q 581.6 489.1, 581.6 487.6 Q 581.6 486.6, 582.1 485.9 Q 582.6 485.2, 583.6 484.7 Q 582.9 484.3, 582.5 483.7 Q 582.1 483.1, 582.1 482.1 Q 582.1 480.8, 583.0 480.0 Q 584.0 479.2, 585.6 479.2 Q 587.3 479.2, 588.3 480.0 Q 589.2 480.8, 589.2 482.1 Q 589.2 482.9, 588.8 483.6 Q 588.3 484.2, 587.4 484.7 M 585.6 480.4 Q 584.7 480.4, 584.2 480.9 Q 583.7 481.3, 583.7 482.1 Q 583.7 482.7, 584.0 483.1 Q 584.4 483.5, 584.9 483.7 Q 585.4 483.9, 586.4 484.3 Q 587.0 483.8, 587.3 483.3 Q 587.6 482.8, 587.6 482.1 Q 587.6 481.3, 587.1 480.9 Q 586.6 480.4, 585.6 480.4 M 585.7 489.6 Q 586.8 489.6, 587.4 489.1 Q 588.1 488.5, 588.1 487.5 Q 588.1 486.9, 587.7 486.6 Q 587.4 486.2, 586.9 485.9 Q 586.4 485.7, 585.5 485.4 L 584.8 485.2 Q 584.0 485.7, 583.6 486.2 Q 583.2 486.8, 583.2 487.5 Q 583.2 488.5, 583.9 489.1 Q 584.6 489.6, 585.7 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 595.0 479.2 Q 597.0 479.2, 598.0 480.6 Q 599.0 481.9, 599.0 484.7 Q 599.0 487.7, 597.8 489.2 Q 596.5 490.8, 594.1 490.8 Q 593.4 490.8, 592.8 490.6 Q 592.2 490.5, 591.6 490.1 L 592.2 489.1 Q 593.1 489.5, 594.1 489.5 Q 595.7 489.5, 596.5 488.5 Q 597.3 487.4, 597.4 485.3 Q 596.8 485.8, 596.1 486.1 Q 595.4 486.4, 594.6 486.4 Q 593.6 486.4, 592.8 486.0 Q 592.0 485.5, 591.6 484.8 Q 591.2 484.0, 591.2 483.0 Q 591.2 481.9, 591.6 481.0 Q 592.1 480.2, 593.0 479.7 Q 593.9 479.2, 595.0 479.2 M 592.8 483.0 Q 592.8 484.0, 593.3 484.6 Q 593.9 485.1, 594.9 485.1 Q 595.6 485.1, 596.2 484.9 Q 596.9 484.6, 597.4 484.1 Q 597.3 482.2, 596.8 481.4 Q 596.2 480.5, 595.0 480.5 Q 594.4 480.5, 593.8 480.8 Q 593.3 481.2, 593.1 481.7 Q 592.8 482.3, 592.8 483.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 606.5 478.3 L 607.8 478.3 L 607.8 493.8 L 606.5 493.8 L 606.5 478.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 618.9 479.3 Q 620.8 479.3, 621.8 480.2 Q 622.8 481.1, 622.8 482.7 Q 622.8 484.2, 621.8 485.1 Q 620.8 486.0, 618.9 486.0 L 617.1 486.0 L 617.1 490.7 L 615.5 490.7 L 615.5 479.3 L 618.9 479.3 M 618.9 484.7 Q 620.0 484.7, 620.6 484.2 Q 621.2 483.7, 621.2 482.7 Q 621.2 481.7, 620.6 481.1 Q 620.0 480.6, 618.9 480.6 L 617.1 480.6 L 617.1 484.7 L 618.9 484.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 625.2 482.4 L 625.4 483.6 Q 626.3 482.3, 627.7 482.3 Q 628.1 482.3, 628.7 482.5 L 628.5 483.8 Q 627.8 483.6, 627.4 483.6 Q 626.8 483.6, 626.3 483.9 Q 625.9 484.2, 625.5 484.8 L 625.5 490.7 L 624.0 490.7 L 624.0 482.4 L 625.2 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 629.5 486.5 Q 629.5 484.5, 630.5 483.4 Q 631.5 482.3, 633.3 482.3 Q 635.2 482.3, 636.0 483.4 Q 636.8 484.5, 636.8 486.5 L 636.8 486.7 L 631.0 486.7 Q 631.1 488.1, 631.7 488.9 Q 632.3 489.6, 633.5 489.6 Q 634.1 489.6, 634.7 489.5 Q 635.3 489.3, 636.0 489.0 L 636.5 490.0 Q 635.6 490.4, 634.9 490.6 Q 634.2 490.8, 633.4 490.8 Q 631.5 490.8, 630.5 489.7 Q 629.5 488.6, 629.5 486.5 M 633.3 483.5 Q 632.4 483.5, 631.8 484.0 Q 631.3 484.6, 631.1 485.6 L 635.2 485.6 Q 635.1 484.5, 634.6 484.0 Q 634.2 483.5, 633.3 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 645.4 478.5 L 645.4 490.6 L 644.1 490.6 L 643.9 489.6 Q 643.0 490.8, 641.5 490.8 Q 639.8 490.8, 638.8 489.7 Q 637.9 488.7, 637.9 486.7 Q 637.9 484.6, 639.0 483.5 Q 640.1 482.3, 642.1 482.3 Q 643.0 482.3, 643.9 482.5 L 643.9 478.5 L 645.4 478.5 M 641.6 489.6 Q 642.4 489.6, 643.0 489.2 Q 643.6 488.7, 643.9 487.9 L 643.9 483.7 Q 643.0 483.5, 642.1 483.5 Q 640.9 483.5, 640.1 484.3 Q 639.4 485.2, 639.4 486.7 Q 639.4 488.1, 640.0 488.9 Q 640.6 489.6, 641.6 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 647.2 479.3 L 648.6 479.3 L 648.6 480.7 L 647.2 480.7 L 647.2 479.3 M 647.2 482.4 L 648.6 482.4 L 648.6 490.7 L 647.2 490.7 L 647.2 482.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 650.5 486.5 Q 650.5 484.6, 651.5 483.4 Q 652.5 482.3, 654.4 482.3 Q 656.3 482.3, 657.3 483.7 L 656.3 484.4 Q 655.9 483.9, 655.5 483.7 Q 655.0 483.5, 654.4 483.5 Q 653.3 483.5, 652.7 484.3 Q 652.0 485.0, 652.0 486.5 Q 652.0 488.1, 652.7 488.8 Q 653.3 489.6, 654.5 489.6 Q 655.2 489.6, 655.7 489.5 Q 656.1 489.3, 656.7 489.0 L 657.1 490.1 Q 656.0 490.8, 654.4 490.8 Q 652.5 490.8, 651.5 489.6 Q 650.5 488.5, 650.5 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 658.2 483.6 L 658.2 482.4 L 659.8 482.4 L 660.0 480.0 L 661.1 480.0 L 661.1 482.4 L 663.6 482.4 L 663.6 483.6 L 661.1 483.6 L 661.1 488.1 Q 661.1 489.6, 662.3 489.6 Q 662.8 489.6, 663.5 489.3 L 663.8 490.4 Q 662.9 490.8, 662.1 490.8 Q 661.0 490.8, 660.3 490.1 Q 659.6 489.5, 659.6 488.2 L 659.6 483.6 L 658.2 483.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 664.7 486.5 Q 664.7 484.5, 665.7 483.4 Q 666.7 482.3, 668.5 482.3 Q 670.3 482.3, 671.1 483.4 Q 672.0 484.5, 672.0 486.5 L 672.0 486.7 L 666.2 486.7 Q 666.3 488.1, 666.9 488.9 Q 667.5 489.6, 668.7 489.6 Q 669.3 489.6, 669.9 489.5 Q 670.5 489.3, 671.2 489.0 L 671.6 490.0 Q 670.8 490.4, 670.1 490.6 Q 669.4 490.8, 668.6 490.8 Q 666.7 490.8, 665.7 489.7 Q 664.7 488.6, 664.7 486.5 M 668.5 483.5 Q 667.6 483.5, 667.0 484.0 Q 666.5 484.6, 666.3 485.6 L 670.4 485.6 Q 670.3 484.5, 669.8 484.0 Q 669.4 483.5, 668.5 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 680.6 478.5 L 680.6 490.6 L 679.3 490.6 L 679.1 489.6 Q 678.2 490.8, 676.7 490.8 Q 675.0 490.8, 674.0 489.7 Q 673.1 488.7, 673.1 486.7 Q 673.1 484.6, 674.2 483.5 Q 675.3 482.3, 677.3 482.3 Q 678.2 482.3, 679.1 482.5 L 679.1 478.5 L 680.6 478.5 M 676.8 489.6 Q 677.6 489.6, 678.2 489.2 Q 678.8 488.7, 679.1 487.9 L 679.1 483.7 Q 678.2 483.5, 677.3 483.5 Q 676.1 483.5, 675.3 484.3 Q 674.6 485.2, 674.6 486.7 Q 674.6 488.1, 675.2 488.9 Q 675.8 489.6, 676.8 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 682.3 488.8 L 683.9 488.8 L 683.9 490.4 L 682.3 490.4 L 682.3 488.8 M 682.3 483.3 L 683.9 483.3 L 683.9 484.9 L 682.3 484.9 L 682.3 483.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 695.9 483.6 Q 696.9 483.6, 697.7 484.0 Q 698.5 484.5, 698.9 485.2 Q 699.4 486.0, 699.4 487.0 Q 699.4 488.1, 698.9 489.0 Q 698.4 489.8, 697.5 490.3 Q 696.7 490.8, 695.5 490.8 Q 693.5 490.8, 692.5 489.4 Q 691.5 488.1, 691.5 485.3 Q 691.5 482.3, 692.7 480.8 Q 694.0 479.2, 696.4 479.2 Q 697.1 479.2, 697.7 479.4 Q 698.3 479.5, 698.9 479.9 L 698.3 480.9 Q 697.5 480.5, 696.4 480.5 Q 694.8 480.5, 694.0 481.5 Q 693.2 482.6, 693.1 484.7 Q 693.7 484.2, 694.4 483.9 Q 695.1 483.6, 695.9 483.6 M 695.6 489.5 Q 696.2 489.5, 696.7 489.2 Q 697.2 488.8, 697.5 488.3 Q 697.8 487.7, 697.8 487.0 Q 697.8 486.0, 697.2 485.4 Q 696.6 484.9, 695.6 484.9 Q 695.0 484.9, 694.3 485.2 Q 693.6 485.4, 693.1 485.9 Q 693.2 487.8, 693.8 488.6 Q 694.4 489.5, 695.6 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 700.7 489.1 L 702.3 489.1 L 702.3 490.7 L 700.7 490.7 L 700.7 489.1 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 703.9 481.5 Q 704.3 480.4, 705.3 479.8 Q 706.3 479.2, 707.7 479.2 Q 709.4 479.2, 710.4 480.1 Q 711.3 481.1, 711.3 482.7 Q 711.3 484.4, 710.1 486.0 Q 708.9 487.5, 706.3 489.4 L 711.5 489.4 L 711.5 490.7 L 703.9 490.7 L 703.9 489.6 Q 706.0 488.1, 707.3 487.0 Q 708.5 485.8, 709.1 484.8 Q 709.7 483.8, 709.7 482.8 Q 709.7 481.7, 709.2 481.1 Q 708.7 480.5, 707.7 480.5 Q 706.8 480.5, 706.2 480.9 Q 705.6 481.2, 705.1 482.0 L 703.9 481.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 718.8 484.7 Q 719.8 485.1, 720.4 485.8 Q 721.0 486.4, 721.0 487.6 Q 721.0 488.5, 720.5 489.3 Q 720.0 490.0, 719.1 490.4 Q 718.2 490.8, 717.1 490.8 Q 715.2 490.8, 714.1 490.0 Q 713.0 489.1, 713.0 487.6 Q 713.0 486.6, 713.5 485.9 Q 714.0 485.2, 715.0 484.7 Q 714.2 484.3, 713.8 483.7 Q 713.4 483.1, 713.4 482.1 Q 713.4 480.8, 714.4 480.0 Q 715.4 479.2, 717.0 479.2 Q 718.6 479.2, 719.6 480.0 Q 720.6 480.8, 720.6 482.1 Q 720.6 482.9, 720.1 483.6 Q 719.7 484.2, 718.8 484.7 M 717.0 480.4 Q 716.1 480.4, 715.5 480.9 Q 715.0 481.3, 715.0 482.1 Q 715.0 482.7, 715.4 483.1 Q 715.7 483.5, 716.2 483.7 Q 716.7 483.9, 717.7 484.3 Q 718.4 483.8, 718.7 483.3 Q 719.0 482.8, 719.0 482.1 Q 719.0 481.3, 718.5 480.9 Q 717.9 480.4, 717.0 480.4 M 717.1 489.6 Q 718.1 489.6, 718.8 489.1 Q 719.4 488.5, 719.4 487.5 Q 719.4 486.9, 719.1 486.6 Q 718.7 486.2, 718.2 485.9 Q 717.7 485.7, 716.8 485.4 L 716.1 485.2 Q 715.3 485.7, 715.0 486.2 Q 714.6 486.8, 714.6 487.5 Q 714.6 488.5, 715.3 489.1 Q 715.9 489.6, 717.1 489.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 728.3 484.7 Q 729.3 485.1, 729.9 485.8 Q 730.5 486.4, 730.5 487.6 Q 730.5 488.5, 730.0 489.3 Q 729.5 490.0, 728.6 490.4 Q 727.8 490.8, 726.6 490.8 Q 724.7 490.8, 723.6 490.0 Q 722.5 489.1, 722.5 487.6 Q 722.5 486.6, 723.0 485.9 Q 723.5 485.2, 724.5 484.7 Q 723.7 484.3, 723.3 483.7 Q 722.9 483.1, 722.9 482.1 Q 722.9 480.8, 723.9 480.0 Q 724.9 479.2, 726.5 479.2 Q 728.2 479.2, 729.1 480.0 Q 730.1 480.8, 730.1 482.1 Q 730.1 482.9, 729.6 483.6 Q 729.2 484.2, 728.3 484.7 M 726.5 480.4 Q 725.6 480.4, 725.0 480.9 Q 724.5 481.3, 724.5 482.1 Q 724.5 482.7, 724.9 483.1 Q 725.2 483.5, 725.7 483.7 Q 726.2 483.9, 727.2 484.3 Q 727.9 483.8, 728.2 483.3 Q 728.5 482.8, 728.5 482.1 Q 728.5 481.3, 728.0 480.9 Q 727.5 480.4, 726.5 480.4 M 726.6 489.6 Q 727.6 489.6, 728.3 489.1 Q 728.9 488.5, 728.9 487.5 Q 728.9 486.9, 728.6 486.6 Q 728.2 486.2, 727.7 485.9 Q 727.2 485.7, 726.3 485.4 L 725.6 485.2 Q 724.8 485.7, 724.5 486.2 Q 724.1 486.8, 724.1 487.5 Q 724.1 488.5, 724.8 489.1 Q 725.5 489.6, 726.6 489.6 \" fill=\"#000000\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, torch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from ogb.lsc import PCQM4Mv2Dataset          \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:          \n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        out   = model(batch)\n",
    "        all_preds.append(out.cpu())\n",
    "        all_targets.append(batch.y.view(-1,1).cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy().flatten()   \n",
    "all_targets = torch.cat(all_targets).numpy().flatten()\n",
    "\n",
    "# load SMILES for the same indices\n",
    "smiles_ds = PCQM4Mv2Dataset(root=\"C:/Users/mattg/Downloads/HOMO-LUMO/data/pcqm4mv2\", only_smiles=True)\n",
    "\n",
    "assert max(valid_ids) < len(smiles_ds), \"idx out of range - check dataset root\"\n",
    "\n",
    "valid_smiles = [smiles_ds[i] for i in valid_ids]       # list of (smiles, y)\n",
    "\n",
    "k = 6\n",
    "r_idx = random.sample(range(len(valid_ids)), k=k)\n",
    "\n",
    "smiles = [ valid_smiles[i][0] for i in r_idx]\n",
    "y_true = [ valid_smiles[i][1] for i in r_idx]\n",
    "y_pred = [ all_preds[i] for i in r_idx]\n",
    "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "legends = [f\"True: {t:.3f} | Predicted: {p:.3f}\" for t, p in zip(y_true, y_pred)]\n",
    "img = Draw.MolsToGridImage(mols, molsPerRow=3, subImgSize=(250, 250), legends=legends, useSVG=True)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "474b2489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\" baseProfile=\"full\" xml:space=\"preserve\" width=\"750px\" height=\"500px\" viewBox=\"0 0 750 500\">\n",
       "<!-- END OF HEADER -->\n",
       "<rect style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"750.0\" height=\"500.0\" x=\"0.0\" y=\"0.0\"> </rect>\n",
       "<path class=\"atom-0\" d=\"M 109.0 117.9 L 110.1 117.9 L 110.1 121.3 L 114.2 121.3 L 114.2 117.9 L 115.3 117.9 L 115.3 125.9 L 114.2 125.9 L 114.2 122.2 L 110.1 122.2 L 110.1 125.9 L 109.0 125.9 L 109.0 117.9 \" fill=\"#000000\"/>\n",
       "<path class=\"atom-0\" d=\"M 116.9 123.0 Q 116.9 121.6, 117.6 120.8 Q 118.3 120.0, 119.6 120.0 Q 120.9 120.0, 121.5 120.8 Q 122.0 121.5, 122.0 123.0 L 122.0 123.2 L 118.0 123.2 Q 118.0 124.1, 118.4 124.7 Q 118.9 125.2, 119.7 125.2 Q 120.1 125.2, 120.6 125.1 Q 121.0 125.0, 121.5 124.8 L 121.8 125.5 Q 121.2 125.8, 120.7 125.9 Q 120.2 126.0, 119.6 126.0 Q 118.3 126.0, 117.6 125.2 Q 116.9 124.4, 116.9 123.0 M 119.6 120.8 Q 118.9 120.8, 118.5 121.2 Q 118.1 121.6, 118.0 122.4 L 120.9 122.4 Q 120.8 121.6, 120.5 121.2 Q 120.2 120.8, 119.6 120.8 \" fill=\"#000000\"/>\n",
       "<path class=\"atom-1\" d=\"M 128.0 117.9 L 129.1 117.9 L 129.1 121.3 L 133.2 121.3 L 133.2 117.9 L 134.3 117.9 L 134.3 125.9 L 133.2 125.9 L 133.2 122.2 L 129.1 122.2 L 129.1 125.9 L 128.0 125.9 L 128.0 117.9 \" fill=\"#000000\"/>\n",
       "<path class=\"atom-1\" d=\"M 135.8 123.0 Q 135.8 121.6, 136.5 120.8 Q 137.2 120.0, 138.5 120.0 Q 139.8 120.0, 140.4 120.8 Q 141.0 121.5, 141.0 123.0 L 141.0 123.2 L 136.9 123.2 Q 136.9 124.1, 137.4 124.7 Q 137.8 125.2, 138.6 125.2 Q 139.1 125.2, 139.5 125.1 Q 139.9 125.0, 140.4 124.8 L 140.7 125.5 Q 140.2 125.8, 139.6 125.9 Q 139.1 126.0, 138.6 126.0 Q 137.3 126.0, 136.5 125.2 Q 135.8 124.4, 135.8 123.0 M 138.5 120.8 Q 137.9 120.8, 137.5 121.2 Q 137.1 121.6, 136.9 122.4 L 139.8 122.4 Q 139.8 121.6, 139.4 121.2 Q 139.1 120.8, 138.5 120.8 \" fill=\"#000000\"/>\n",
       "<path class=\"atom-2\" d=\"M 109.0 99.0 L 110.1 99.0 L 110.1 102.4 L 114.2 102.4 L 114.2 99.0 L 115.3 99.0 L 115.3 107.0 L 114.2 107.0 L 114.2 103.3 L 110.1 103.3 L 110.1 107.0 L 109.0 107.0 L 109.0 99.0 \" fill=\"#000000\"/>\n",
       "<path class=\"atom-2\" d=\"M 116.9 104.1 Q 116.9 102.6, 117.6 101.9 Q 118.3 101.1, 119.6 101.1 Q 120.9 101.1, 121.5 101.8 Q 122.0 102.6, 122.0 104.0 L 122.0 104.2 L 118.0 104.2 Q 118.0 105.2, 118.4 105.7 Q 118.9 106.3, 119.7 106.3 Q 120.1 106.3, 120.6 106.2 Q 121.0 106.0, 121.5 105.8 L 121.8 106.5 Q 121.2 106.8, 120.7 107.0 Q 120.2 107.1, 119.6 107.1 Q 118.3 107.1, 117.6 106.3 Q 116.9 105.5, 116.9 104.1 M 119.6 101.9 Q 118.9 101.9, 118.5 102.3 Q 118.1 102.7, 118.0 103.4 L 120.9 103.4 Q 120.8 102.6, 120.5 102.3 Q 120.2 101.9, 119.6 101.9 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 18.8 233.5 L 15.3 233.5 L 15.3 232.3 L 23.6 232.3 L 23.6 233.5 L 20.3 233.5 L 20.3 243.6 L 18.8 243.6 L 18.8 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 25.4 235.4 L 25.6 236.5 Q 26.4 235.2, 27.9 235.2 Q 28.3 235.2, 28.9 235.4 L 28.7 236.7 Q 28.0 236.6, 27.6 236.6 Q 26.9 236.6, 26.5 236.8 Q 26.0 237.1, 25.7 237.7 L 25.7 243.6 L 24.2 243.6 L 24.2 235.4 L 25.4 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 36.7 235.4 L 36.7 243.6 L 35.5 243.6 L 35.3 242.5 Q 34.2 243.7, 32.5 243.7 Q 31.1 243.7, 30.4 243.0 Q 29.7 242.2, 29.7 240.8 L 29.7 235.4 L 31.2 235.4 L 31.2 240.7 Q 31.2 241.7, 31.6 242.1 Q 32.0 242.6, 32.8 242.6 Q 33.5 242.6, 34.2 242.2 Q 34.8 241.9, 35.2 241.3 L 35.2 235.4 L 36.7 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 38.6 239.5 Q 38.6 237.4, 39.6 236.3 Q 40.6 235.2, 42.4 235.2 Q 44.2 235.2, 45.0 236.3 Q 45.8 237.4, 45.8 239.4 L 45.8 239.7 L 40.1 239.7 Q 40.1 241.1, 40.8 241.8 Q 41.4 242.5, 42.5 242.5 Q 43.2 242.5, 43.8 242.4 Q 44.4 242.2, 45.1 241.9 L 45.5 242.9 Q 44.7 243.3, 44.0 243.5 Q 43.2 243.7, 42.5 243.7 Q 40.6 243.7, 39.6 242.6 Q 38.6 241.5, 38.6 239.5 M 42.4 236.4 Q 41.5 236.4, 40.9 236.9 Q 40.3 237.5, 40.2 238.6 L 44.3 238.6 Q 44.1 237.4, 43.7 236.9 Q 43.3 236.4, 42.4 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 47.0 241.7 L 48.6 241.7 L 48.6 243.3 L 47.0 243.3 L 47.0 241.7 M 47.0 236.2 L 48.6 236.2 L 48.6 237.8 L 47.0 237.8 L 47.0 236.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 63.6 239.7 L 65.0 239.7 L 65.0 241.0 L 63.6 241.0 L 63.6 243.6 L 62.1 243.6 L 62.1 241.0 L 56.3 241.0 L 56.3 240.0 L 61.2 232.3 L 63.6 232.3 L 63.6 239.7 M 58.1 239.7 L 62.1 239.7 L 62.1 233.3 L 58.1 239.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 70.7 236.5 Q 71.7 236.5, 72.5 236.9 Q 73.3 237.4, 73.7 238.2 Q 74.2 239.0, 74.2 239.9 Q 74.2 241.0, 73.7 241.9 Q 73.2 242.8, 72.3 243.2 Q 71.5 243.7, 70.4 243.7 Q 68.3 243.7, 67.3 242.4 Q 66.3 241.0, 66.3 238.3 Q 66.3 235.3, 67.6 233.7 Q 68.8 232.1, 71.2 232.1 Q 71.9 232.1, 72.5 232.3 Q 73.1 232.5, 73.7 232.8 L 73.1 233.9 Q 72.3 233.4, 71.3 233.4 Q 69.7 233.4, 68.8 234.5 Q 68.0 235.5, 67.9 237.6 Q 68.5 237.1, 69.2 236.8 Q 70.0 236.5, 70.7 236.5 M 70.4 242.4 Q 71.0 242.4, 71.5 242.1 Q 72.0 241.8, 72.3 241.2 Q 72.6 240.6, 72.6 240.0 Q 72.6 239.0, 72.0 238.4 Q 71.4 237.8, 70.5 237.8 Q 69.8 237.8, 69.1 238.1 Q 68.4 238.4, 67.9 238.8 Q 68.0 240.7, 68.6 241.6 Q 69.2 242.4, 70.4 242.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 75.6 242.0 L 77.2 242.0 L 77.2 243.6 L 75.6 243.6 L 75.6 242.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 84.2 237.6 Q 85.3 237.9, 85.9 238.7 Q 86.4 239.4, 86.4 240.5 Q 86.4 241.4, 85.9 242.2 Q 85.5 242.9, 84.6 243.3 Q 83.7 243.8, 82.5 243.8 Q 81.3 243.8, 80.4 243.3 Q 79.5 242.9, 78.8 242.0 L 79.7 241.1 Q 80.4 241.9, 81.0 242.2 Q 81.6 242.5, 82.5 242.5 Q 83.6 242.5, 84.2 241.9 Q 84.8 241.4, 84.8 240.5 Q 84.8 239.3, 84.2 238.8 Q 83.5 238.3, 82.1 238.3 L 81.3 238.3 L 81.3 237.1 L 82.0 237.1 Q 83.3 237.1, 83.9 236.6 Q 84.6 236.0, 84.6 235.0 Q 84.6 234.3, 84.0 233.9 Q 83.5 233.4, 82.6 233.4 Q 81.6 233.4, 81.0 233.8 Q 80.4 234.1, 80.0 234.9 L 78.9 234.3 Q 79.3 233.4, 80.3 232.8 Q 81.2 232.1, 82.6 232.1 Q 84.2 232.1, 85.2 232.9 Q 86.2 233.7, 86.2 235.0 Q 86.2 235.9, 85.7 236.6 Q 85.2 237.3, 84.2 237.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 93.7 237.6 Q 94.7 238.0, 95.3 238.7 Q 95.9 239.4, 95.9 240.5 Q 95.9 241.4, 95.4 242.2 Q 94.9 242.9, 94.0 243.3 Q 93.1 243.8, 92.0 243.8 Q 90.1 243.8, 89.0 242.9 Q 87.9 242.0, 87.9 240.5 Q 87.9 239.6, 88.4 238.9 Q 88.9 238.2, 89.9 237.6 Q 89.1 237.2, 88.7 236.6 Q 88.3 236.0, 88.3 235.0 Q 88.3 233.7, 89.3 232.9 Q 90.3 232.1, 91.9 232.1 Q 93.6 232.1, 94.5 232.9 Q 95.5 233.7, 95.5 235.0 Q 95.5 235.9, 95.0 236.5 Q 94.6 237.1, 93.7 237.6 M 91.9 233.3 Q 91.0 233.3, 90.4 233.8 Q 89.9 234.2, 89.9 235.0 Q 89.9 235.6, 90.3 236.0 Q 90.6 236.4, 91.1 236.6 Q 91.6 236.9, 92.6 237.2 Q 93.3 236.7, 93.6 236.2 Q 93.9 235.7, 93.9 235.0 Q 93.9 234.2, 93.4 233.8 Q 92.9 233.3, 91.9 233.3 M 92.0 242.6 Q 93.0 242.6, 93.7 242.0 Q 94.3 241.4, 94.3 240.5 Q 94.3 239.9, 94.0 239.5 Q 93.6 239.1, 93.1 238.9 Q 92.6 238.6, 91.7 238.4 L 91.0 238.1 Q 90.2 238.6, 89.9 239.2 Q 89.5 239.7, 89.5 240.5 Q 89.5 241.4, 90.2 242.0 Q 90.9 242.6, 92.0 242.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 97.5 234.4 Q 97.9 233.3, 98.9 232.7 Q 99.9 232.1, 101.3 232.1 Q 103.0 232.1, 104.0 233.1 Q 104.9 234.0, 104.9 235.6 Q 104.9 237.3, 103.7 238.9 Q 102.4 240.5, 99.9 242.3 L 105.1 242.3 L 105.1 243.6 L 97.5 243.6 L 97.5 242.5 Q 99.6 241.0, 100.8 239.9 Q 102.1 238.8, 102.7 237.8 Q 103.3 236.8, 103.3 235.7 Q 103.3 234.6, 102.8 234.0 Q 102.2 233.4, 101.3 233.4 Q 100.4 233.4, 99.8 233.8 Q 99.2 234.2, 98.7 235.0 L 97.5 234.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 115.9 232.3 Q 117.8 232.3, 118.8 233.1 Q 119.7 234.0, 119.7 235.6 Q 119.7 237.2, 118.7 238.1 Q 117.7 238.9, 115.9 238.9 L 114.0 238.9 L 114.0 243.6 L 112.5 243.6 L 112.5 232.3 L 115.9 232.3 M 115.9 237.7 Q 117.0 237.7, 117.6 237.1 Q 118.1 236.6, 118.1 235.6 Q 118.1 234.6, 117.6 234.1 Q 117.0 233.5, 115.9 233.5 L 114.0 233.5 L 114.0 237.7 L 115.9 237.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 122.3 235.4 L 122.4 236.5 Q 123.3 235.2, 124.7 235.2 Q 125.2 235.2, 125.8 235.4 L 125.5 236.7 Q 124.8 236.6, 124.5 236.6 Q 123.8 236.6, 123.3 236.8 Q 122.9 237.1, 122.6 237.7 L 122.6 243.6 L 121.1 243.6 L 121.1 235.4 L 122.3 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 126.6 239.5 Q 126.6 237.4, 127.6 236.3 Q 128.6 235.2, 130.4 235.2 Q 132.2 235.2, 133.0 236.3 Q 133.8 237.4, 133.8 239.4 L 133.8 239.7 L 128.1 239.7 Q 128.1 241.1, 128.8 241.8 Q 129.4 242.5, 130.6 242.5 Q 131.2 242.5, 131.8 242.4 Q 132.4 242.2, 133.1 241.9 L 133.5 242.9 Q 132.7 243.3, 132.0 243.5 Q 131.2 243.7, 130.5 243.7 Q 128.6 243.7, 127.6 242.6 Q 126.6 241.5, 126.6 239.5 M 130.4 236.4 Q 129.5 236.4, 128.9 236.9 Q 128.3 237.5, 128.2 238.6 L 132.3 238.6 Q 132.2 237.4, 131.7 236.9 Q 131.3 236.4, 130.4 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 142.5 231.4 L 142.5 243.6 L 141.3 243.6 L 141.1 242.6 Q 140.1 243.7, 138.6 243.7 Q 136.9 243.7, 136.0 242.7 Q 135.0 241.6, 135.0 239.6 Q 135.0 237.5, 136.1 236.4 Q 137.3 235.2, 139.2 235.2 Q 140.1 235.2, 141.0 235.4 L 141.0 231.4 L 142.5 231.4 M 138.7 242.5 Q 139.6 242.5, 140.1 242.1 Q 140.8 241.6, 141.0 240.8 L 141.0 236.6 Q 140.2 236.4, 139.3 236.4 Q 138.0 236.4, 137.3 237.3 Q 136.5 238.1, 136.5 239.6 Q 136.5 241.0, 137.1 241.8 Q 137.7 242.5, 138.7 242.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 144.3 232.3 L 145.8 232.3 L 145.8 233.7 L 144.3 233.7 L 144.3 232.3 M 144.3 235.4 L 145.8 235.4 L 145.8 243.6 L 144.3 243.6 L 144.3 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 147.7 239.5 Q 147.7 237.5, 148.7 236.4 Q 149.7 235.2, 151.7 235.2 Q 153.5 235.2, 154.5 236.6 L 153.5 237.3 Q 153.1 236.9, 152.7 236.6 Q 152.2 236.4, 151.7 236.4 Q 150.5 236.4, 149.9 237.2 Q 149.3 238.0, 149.3 239.5 Q 149.3 241.0, 149.9 241.8 Q 150.6 242.5, 151.8 242.5 Q 152.4 242.5, 152.9 242.4 Q 153.4 242.2, 153.9 242.0 L 154.3 243.0 Q 153.2 243.7, 151.6 243.7 Q 149.7 243.7, 148.7 242.6 Q 147.7 241.4, 147.7 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 155.4 236.5 L 155.4 235.4 L 157.0 235.4 L 157.3 233.0 L 158.4 233.0 L 158.4 235.4 L 160.9 235.4 L 160.9 236.5 L 158.4 236.5 L 158.4 241.1 Q 158.4 242.5, 159.6 242.5 Q 160.1 242.5, 160.8 242.3 L 161.0 243.3 Q 160.2 243.7, 159.3 243.7 Q 158.2 243.7, 157.6 243.0 Q 156.9 242.4, 156.9 241.1 L 156.9 236.5 L 155.4 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 162.0 239.5 Q 162.0 237.4, 163.0 236.3 Q 164.0 235.2, 165.8 235.2 Q 167.6 235.2, 168.4 236.3 Q 169.3 237.4, 169.3 239.4 L 169.3 239.7 L 163.5 239.7 Q 163.6 241.1, 164.2 241.8 Q 164.8 242.5, 166.0 242.5 Q 166.6 242.5, 167.2 242.4 Q 167.8 242.2, 168.5 241.9 L 168.9 242.9 Q 168.1 243.3, 167.4 243.5 Q 166.7 243.7, 165.9 243.7 Q 164.0 243.7, 163.0 242.6 Q 162.0 241.5, 162.0 239.5 M 165.8 236.4 Q 164.9 236.4, 164.3 236.9 Q 163.8 237.5, 163.6 238.6 L 167.7 238.6 Q 167.6 237.4, 167.1 236.9 Q 166.7 236.4, 165.8 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 177.9 231.4 L 177.9 243.6 L 176.7 243.6 L 176.5 242.6 Q 175.6 243.7, 174.0 243.7 Q 172.3 243.7, 171.4 242.7 Q 170.4 241.6, 170.4 239.6 Q 170.4 237.5, 171.5 236.4 Q 172.7 235.2, 174.7 235.2 Q 175.5 235.2, 176.4 235.4 L 176.4 231.4 L 177.9 231.4 M 174.1 242.5 Q 175.0 242.5, 175.6 242.1 Q 176.2 241.6, 176.4 240.8 L 176.4 236.6 Q 175.6 236.4, 174.7 236.4 Q 173.4 236.4, 172.7 237.3 Q 172.0 238.1, 172.0 239.6 Q 172.0 241.0, 172.5 241.8 Q 173.1 242.5, 174.1 242.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 179.7 241.7 L 181.3 241.7 L 181.3 243.3 L 179.7 243.3 L 179.7 241.7 M 179.7 236.2 L 181.3 236.2 L 181.3 237.8 L 179.7 237.8 L 179.7 236.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 189.6 242.3 L 192.1 242.3 L 192.1 233.8 L 189.3 234.7 L 189.0 233.8 L 192.5 232.2 L 193.6 232.4 L 193.6 242.3 L 195.8 242.3 L 195.8 243.6 L 189.6 243.6 L 189.6 242.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 202.5 237.6 Q 203.6 237.9, 204.1 238.7 Q 204.7 239.4, 204.7 240.5 Q 204.7 241.4, 204.2 242.2 Q 203.7 242.9, 202.8 243.3 Q 201.9 243.8, 200.8 243.8 Q 199.6 243.8, 198.7 243.3 Q 197.8 242.9, 197.0 242.0 L 198.0 241.1 Q 198.7 241.9, 199.2 242.2 Q 199.8 242.5, 200.8 242.5 Q 201.8 242.5, 202.4 241.9 Q 203.1 241.4, 203.1 240.5 Q 203.1 239.3, 202.4 238.8 Q 201.8 238.3, 200.4 238.3 L 199.6 238.3 L 199.6 237.1 L 200.3 237.1 Q 201.5 237.1, 202.2 236.6 Q 202.8 236.0, 202.8 235.0 Q 202.8 234.3, 202.3 233.9 Q 201.7 233.4, 200.8 233.4 Q 199.9 233.4, 199.3 233.8 Q 198.7 234.1, 198.2 234.9 L 197.1 234.3 Q 197.5 233.4, 198.5 232.8 Q 199.5 232.1, 200.8 232.1 Q 202.5 232.1, 203.4 232.9 Q 204.4 233.7, 204.4 235.0 Q 204.4 235.9, 203.9 236.6 Q 203.4 237.3, 202.5 237.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 206.2 242.0 L 207.8 242.0 L 207.8 243.6 L 206.2 243.6 L 206.2 242.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 215.3 233.5 L 209.4 233.5 L 209.4 232.3 L 216.9 232.3 L 216.9 233.4 L 212.3 243.6 L 210.8 243.6 L 215.3 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 223.8 233.5 L 217.9 233.5 L 217.9 232.3 L 225.4 232.3 L 225.4 233.4 L 220.8 243.6 L 219.3 243.6 L 223.8 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 230.6 243.7 Q 228.5 243.7, 227.5 242.2 Q 226.4 240.6, 226.4 237.9 Q 226.4 235.2, 227.5 233.7 Q 228.5 232.1, 230.6 232.1 Q 232.7 232.1, 233.7 233.7 Q 234.7 235.2, 234.7 237.9 Q 234.7 240.6, 233.7 242.2 Q 232.7 243.7, 230.6 243.7 M 230.6 242.4 Q 231.8 242.4, 232.5 241.3 Q 233.1 240.2, 233.1 237.9 Q 233.1 235.7, 232.5 234.6 Q 231.8 233.4, 230.6 233.4 Q 229.4 233.4, 228.7 234.6 Q 228.0 235.7, 228.0 237.9 Q 228.0 240.2, 228.7 241.3 Q 229.4 242.4, 230.6 242.4 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 265.2,134.6 L 290.6,121.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 290.6,121.8 L 314.3,137.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 314.3,137.4 L 325.0,132.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 325.0,132.0 L 335.7,126.6\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 340.0,119.6 L 340.6,107.9\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 340.6,107.9 L 341.3,96.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 341.1,98.7 L 352.0,93.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 352.0,93.2 L 363.0,87.7\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 339.2,94.9 L 350.1,89.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 350.1,89.4 L 361.0,83.8\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-4 atom-6\" d=\"M 341.3,96.2 L 317.5,80.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-3 atom-7\" d=\"M 343.7,127.2 L 353.6,133.7\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-3 atom-7\" d=\"M 353.6,133.7 L 363.4,140.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 363.4,140.1 L 388.8,127.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 388.8,127.3 L 412.6,142.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 434.6,131.4 L 434.9,132.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 431.3,132.7 L 431.9,133.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 428.0,134.1 L 428.8,135.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 424.7,135.4 L 425.8,137.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 421.4,136.7 L 422.8,139.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 418.1,138.1 L 419.7,141.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-10 atom-9\" d=\"M 414.8,139.4 L 416.7,143.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-10 atom-11\" d=\"M 437.9,130.1 L 439.5,101.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-11 atom-12\" d=\"M 439.5,101.7 L 464.9,88.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-12 atom-13\" d=\"M 464.9,88.9 L 488.6,104.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-13 atom-14\" d=\"M 488.6,104.5 L 487.0,132.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-13 atom-14\" d=\"M 484.2,106.7 L 482.9,130.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-14 atom-15\" d=\"M 487.0,132.9 L 461.7,145.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-15 atom-10\" d=\"M 461.7,145.7 L 437.9,130.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 289.3,122.4 L 290.6,121.8 L 291.7,122.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 313.1,136.6 L 314.3,137.4 L 314.9,137.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 341.2,96.8 L 341.3,96.2 L 340.1,95.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 362.9,139.8 L 363.4,140.1 L 364.7,139.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 387.5,128.0 L 388.8,127.3 L 390.0,128.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 438.0,128.7 L 437.9,130.1 L 439.1,130.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 439.4,103.2 L 439.5,101.7 L 440.8,101.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 463.6,89.6 L 464.9,88.9 L 466.1,89.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 487.4,103.7 L 488.6,104.5 L 488.6,105.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 487.1,131.4 L 487.0,132.9 L 485.8,133.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 463.0,145.0 L 461.7,145.7 L 460.5,144.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-3\" d=\"M 337.9 120.5 L 340.5 124.8 Q 340.8 125.2, 341.2 126.0 Q 341.6 126.8, 341.7 126.8 L 341.7 120.5 L 342.7 120.5 L 342.7 128.6 L 341.6 128.6 L 338.8 123.9 Q 338.5 123.4, 338.1 122.8 Q 337.8 122.1, 337.7 121.9 L 337.7 128.6 L 336.6 128.6 L 336.6 120.5 L 337.9 120.5 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-5\" d=\"M 362.9 83.4 Q 362.9 81.5, 363.9 80.4 Q 364.8 79.3, 366.6 79.3 Q 368.4 79.3, 369.4 80.4 Q 370.3 81.5, 370.3 83.4 Q 370.3 85.4, 369.4 86.5 Q 368.4 87.6, 366.6 87.6 Q 364.9 87.6, 363.9 86.5 Q 362.9 85.4, 362.9 83.4 M 366.6 86.7 Q 367.9 86.7, 368.5 85.9 Q 369.2 85.0, 369.2 83.4 Q 369.2 81.9, 368.5 81.1 Q 367.9 80.3, 366.6 80.3 Q 365.4 80.3, 364.7 81.0 Q 364.1 81.8, 364.1 83.4 Q 364.1 85.1, 364.7 85.9 Q 365.4 86.7, 366.6 86.7 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-0\" d=\"M 262.4,134.6 L 262.4,134.7 L 262.3,134.7 L 262.3,134.8 L 262.3,134.8 L 262.3,134.8 L 262.3,134.9 L 262.3,134.9 L 262.2,135.0 L 262.2,135.0 L 262.2,135.0 L 262.1,135.1 L 262.1,135.1 L 262.0,135.1 L 262.0,135.1 L 261.9,135.2 L 261.9,135.2 L 261.9,135.2 L 261.8,135.2 L 261.8,135.2 L 261.7,135.2 L 261.7,135.2 L 261.6,135.1 L 261.6,135.1 L 261.5,135.1 L 261.5,135.1 L 261.4,135.1 L 261.4,135.0 L 261.4,135.0 L 261.3,135.0 L 261.3,134.9 L 261.3,134.9 L 261.3,134.8 L 261.2,134.8 L 261.2,134.7 L 261.2,134.7 L 261.2,134.6 L 261.2,134.6 L 261.2,134.5 L 261.2,134.5 L 261.2,134.4 L 261.3,134.4 L 261.3,134.4 L 261.3,134.3 L 261.3,134.3 L 261.4,134.2 L 261.4,134.2 L 261.4,134.2 L 261.5,134.1 L 261.5,134.1 L 261.6,134.1 L 261.6,134.1 L 261.7,134.1 L 261.7,134.0 L 261.8,134.0 L 261.8,134.0 L 261.9,134.0 L 261.9,134.1 L 261.9,134.1 L 262.0,134.1 L 262.0,134.1 L 262.1,134.1 L 262.1,134.1 L 262.2,134.2 L 262.2,134.2 L 262.2,134.2 L 262.3,134.3 L 262.3,134.3 L 262.3,134.4 L 262.3,134.4 L 262.3,134.5 L 262.3,134.5 L 262.4,134.6 L 262.4,134.6 L 261.8,134.6 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-8\" d=\"M 389.4,124.8 L 389.4,124.8 L 389.4,124.9 L 389.3,124.9 L 389.3,125.0 L 389.3,125.0 L 389.3,125.1 L 389.3,125.1 L 389.2,125.1 L 389.2,125.2 L 389.2,125.2 L 389.1,125.2 L 389.1,125.3 L 389.0,125.3 L 389.0,125.3 L 389.0,125.3 L 388.9,125.3 L 388.9,125.3 L 388.8,125.3 L 388.8,125.3 L 388.7,125.3 L 388.7,125.3 L 388.6,125.3 L 388.6,125.3 L 388.5,125.3 L 388.5,125.3 L 388.4,125.2 L 388.4,125.2 L 388.4,125.2 L 388.3,125.1 L 388.3,125.1 L 388.3,125.0 L 388.3,125.0 L 388.3,124.9 L 388.2,124.9 L 388.2,124.8 L 388.2,124.8 L 388.2,124.8 L 388.2,124.7 L 388.2,124.7 L 388.3,124.6 L 388.3,124.6 L 388.3,124.5 L 388.3,124.5 L 388.3,124.4 L 388.4,124.4 L 388.4,124.4 L 388.4,124.3 L 388.5,124.3 L 388.5,124.3 L 388.6,124.3 L 388.6,124.2 L 388.7,124.2 L 388.7,124.2 L 388.8,124.2 L 388.8,124.2 L 388.9,124.2 L 388.9,124.2 L 389.0,124.2 L 389.0,124.2 L 389.0,124.3 L 389.1,124.3 L 389.1,124.3 L 389.2,124.3 L 389.2,124.4 L 389.2,124.4 L 389.3,124.5 L 389.3,124.5 L 389.3,124.5 L 389.3,124.6 L 389.3,124.6 L 389.4,124.7 L 389.4,124.7 L 389.4,124.8 L 388.8,124.8 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"legend\" d=\"M 277.9 233.6 L 274.4 233.6 L 274.4 232.3 L 282.8 232.3 L 282.8 233.6 L 279.5 233.6 L 279.5 243.6 L 277.9 243.6 L 277.9 233.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 284.5 235.4 L 284.7 236.5 Q 285.6 235.2, 287.0 235.2 Q 287.4 235.2, 288.0 235.4 L 287.8 236.7 Q 287.1 236.6, 286.7 236.6 Q 286.0 236.6, 285.6 236.9 Q 285.2 237.1, 284.8 237.7 L 284.8 243.6 L 283.3 243.6 L 283.3 235.4 L 284.5 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 295.8 235.4 L 295.8 243.6 L 294.6 243.6 L 294.4 242.5 Q 293.3 243.8, 291.6 243.8 Q 290.2 243.8, 289.5 243.0 Q 288.8 242.3, 288.8 240.8 L 288.8 235.4 L 290.3 235.4 L 290.3 240.7 Q 290.3 241.7, 290.7 242.1 Q 291.1 242.6, 291.9 242.6 Q 292.6 242.6, 293.3 242.2 Q 293.9 241.9, 294.3 241.3 L 294.3 235.4 L 295.8 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 297.6 239.5 Q 297.6 237.5, 298.7 236.4 Q 299.7 235.2, 301.5 235.2 Q 303.3 235.2, 304.1 236.3 Q 304.9 237.4, 304.9 239.4 L 304.9 239.7 L 299.2 239.7 Q 299.2 241.1, 299.8 241.8 Q 300.5 242.6, 301.6 242.6 Q 302.3 242.6, 302.9 242.4 Q 303.5 242.2, 304.2 241.9 L 304.6 243.0 Q 303.8 243.4, 303.1 243.6 Q 302.3 243.7, 301.6 243.7 Q 299.7 243.7, 298.7 242.6 Q 297.6 241.5, 297.6 239.5 M 301.5 236.4 Q 300.6 236.4, 300.0 237.0 Q 299.4 237.5, 299.2 238.6 L 303.3 238.6 Q 303.2 237.5, 302.8 237.0 Q 302.3 236.4, 301.5 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 306.1 241.7 L 307.7 241.7 L 307.7 243.3 L 306.1 243.3 L 306.1 241.7 M 306.1 236.2 L 307.7 236.2 L 307.7 237.8 L 306.1 237.8 L 306.1 236.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 319.4 236.5 Q 320.4 236.5, 321.2 237.0 Q 322.0 237.4, 322.5 238.2 Q 322.9 239.0, 322.9 240.0 Q 322.9 241.2, 322.4 242.0 Q 321.8 242.9, 320.9 243.3 Q 320.0 243.7, 318.9 243.7 Q 317.9 243.7, 316.9 243.4 Q 315.9 243.0, 315.3 242.2 L 316.2 241.2 Q 316.8 241.8, 317.5 242.1 Q 318.2 242.4, 318.9 242.4 Q 320.0 242.4, 320.6 241.8 Q 321.3 241.2, 321.3 240.1 Q 321.3 238.9, 320.6 238.3 Q 320.0 237.7, 318.9 237.7 Q 317.9 237.7, 316.8 238.2 L 315.9 237.7 L 316.4 232.3 L 322.2 232.3 L 322.1 233.6 L 317.7 233.6 L 317.4 236.9 Q 318.4 236.5, 319.4 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 324.3 242.0 L 325.9 242.0 L 325.9 243.6 L 324.3 243.6 L 324.3 242.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 331.2 232.2 Q 333.3 232.2, 334.3 233.5 Q 335.3 234.9, 335.3 237.6 Q 335.3 240.6, 334.0 242.2 Q 332.8 243.7, 330.4 243.7 Q 329.7 243.7, 329.0 243.6 Q 328.5 243.4, 327.9 243.1 L 328.5 242.0 Q 329.3 242.5, 330.3 242.5 Q 331.9 242.5, 332.8 241.4 Q 333.6 240.4, 333.7 238.3 Q 333.1 238.8, 332.4 239.1 Q 331.6 239.4, 330.9 239.4 Q 329.9 239.4, 329.1 238.9 Q 328.3 238.5, 327.9 237.7 Q 327.4 236.9, 327.4 235.9 Q 327.4 234.8, 327.9 234.0 Q 328.4 233.1, 329.3 232.6 Q 330.1 232.2, 331.2 232.2 M 329.0 235.9 Q 329.0 236.9, 329.6 237.5 Q 330.2 238.1, 331.1 238.1 Q 331.8 238.1, 332.5 237.8 Q 333.2 237.5, 333.7 237.0 Q 333.6 235.2, 333.0 234.3 Q 332.4 233.5, 331.2 233.5 Q 330.6 233.5, 330.1 233.8 Q 329.6 234.1, 329.3 234.7 Q 329.0 235.2, 329.0 235.9 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 336.9 234.4 Q 337.4 233.4, 338.4 232.8 Q 339.3 232.2, 340.7 232.2 Q 342.4 232.2, 343.4 233.1 Q 344.4 234.0, 344.4 235.7 Q 344.4 237.3, 343.1 238.9 Q 341.9 240.5, 339.3 242.3 L 344.5 242.3 L 344.5 243.6 L 336.9 243.6 L 336.9 242.5 Q 339.0 241.0, 340.3 239.9 Q 341.5 238.8, 342.1 237.8 Q 342.8 236.8, 342.8 235.7 Q 342.8 234.6, 342.2 234.0 Q 341.7 233.4, 340.7 233.4 Q 339.8 233.4, 339.2 233.8 Q 338.6 234.2, 338.2 235.0 L 336.9 234.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 353.4 239.7 L 354.8 239.7 L 354.8 241.0 L 353.4 241.0 L 353.4 243.6 L 351.9 243.6 L 351.9 241.0 L 346.0 241.0 L 346.0 240.0 L 351.0 232.3 L 353.4 232.3 L 353.4 239.7 M 347.9 239.7 L 351.9 239.7 L 351.9 233.3 L 347.9 239.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 365.3 232.3 Q 367.2 232.3, 368.2 233.2 Q 369.2 234.0, 369.2 235.6 Q 369.2 237.2, 368.2 238.1 Q 367.2 239.0, 365.3 239.0 L 363.5 239.0 L 363.5 243.6 L 362.0 243.6 L 362.0 232.3 L 365.3 232.3 M 365.3 237.7 Q 366.4 237.7, 367.0 237.1 Q 367.6 236.6, 367.6 235.6 Q 367.6 234.6, 367.0 234.1 Q 366.4 233.6, 365.3 233.6 L 363.5 233.6 L 363.5 237.7 L 365.3 237.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 371.7 235.4 L 371.9 236.5 Q 372.7 235.2, 374.1 235.2 Q 374.6 235.2, 375.2 235.4 L 375.0 236.7 Q 374.3 236.6, 373.9 236.6 Q 373.2 236.6, 372.8 236.9 Q 372.3 237.1, 372.0 237.7 L 372.0 243.6 L 370.5 243.6 L 370.5 235.4 L 371.7 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 376.0 239.5 Q 376.0 237.5, 377.0 236.4 Q 378.0 235.2, 379.8 235.2 Q 381.6 235.2, 382.4 236.3 Q 383.3 237.4, 383.3 239.4 L 383.3 239.7 L 377.5 239.7 Q 377.6 241.1, 378.2 241.8 Q 378.8 242.6, 380.0 242.6 Q 380.6 242.6, 381.2 242.4 Q 381.8 242.2, 382.5 241.9 L 382.9 243.0 Q 382.1 243.4, 381.4 243.6 Q 380.7 243.7, 379.9 243.7 Q 378.0 243.7, 377.0 242.6 Q 376.0 241.5, 376.0 239.5 M 379.8 236.4 Q 378.9 236.4, 378.3 237.0 Q 377.8 237.5, 377.6 238.6 L 381.7 238.6 Q 381.6 237.5, 381.1 237.0 Q 380.7 236.4, 379.8 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 391.9 231.5 L 391.9 243.6 L 390.7 243.6 L 390.5 242.6 Q 389.5 243.7, 388.0 243.7 Q 386.3 243.7, 385.4 242.7 Q 384.4 241.6, 384.4 239.6 Q 384.4 237.6, 385.5 236.4 Q 386.7 235.2, 388.6 235.2 Q 389.5 235.2, 390.4 235.5 L 390.4 231.5 L 391.9 231.5 M 388.1 242.6 Q 389.0 242.6, 389.5 242.1 Q 390.2 241.6, 390.4 240.8 L 390.4 236.7 Q 389.6 236.4, 388.7 236.4 Q 387.4 236.4, 386.7 237.3 Q 385.9 238.1, 385.9 239.6 Q 385.9 241.0, 386.5 241.8 Q 387.1 242.6, 388.1 242.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 393.7 232.3 L 395.2 232.3 L 395.2 233.7 L 393.7 233.7 L 393.7 232.3 M 393.7 235.4 L 395.2 235.4 L 395.2 243.6 L 393.7 243.6 L 393.7 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 397.1 239.5 Q 397.1 237.5, 398.1 236.4 Q 399.1 235.2, 401.0 235.2 Q 402.9 235.2, 403.9 236.6 L 402.9 237.4 Q 402.5 236.9, 402.0 236.7 Q 401.6 236.4, 401.0 236.4 Q 399.9 236.4, 399.2 237.2 Q 398.6 238.0, 398.6 239.5 Q 398.6 241.0, 399.3 241.8 Q 399.9 242.6, 401.1 242.6 Q 401.8 242.6, 402.3 242.4 Q 402.7 242.2, 403.3 242.0 L 403.7 243.0 Q 402.5 243.7, 401.0 243.7 Q 399.1 243.7, 398.1 242.6 Q 397.1 241.5, 397.1 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 404.8 236.5 L 404.8 235.4 L 406.4 235.4 L 406.6 233.0 L 407.7 233.0 L 407.7 235.4 L 410.3 235.4 L 410.3 236.5 L 407.7 236.5 L 407.7 241.1 Q 407.7 242.5, 408.9 242.5 Q 409.4 242.5, 410.1 242.3 L 410.4 243.3 Q 409.5 243.7, 408.7 243.7 Q 407.6 243.7, 406.9 243.1 Q 406.2 242.4, 406.2 241.2 L 406.2 236.5 L 404.8 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 411.3 239.5 Q 411.3 237.5, 412.3 236.4 Q 413.3 235.2, 415.2 235.2 Q 417.0 235.2, 417.8 236.3 Q 418.6 237.4, 418.6 239.4 L 418.6 239.7 L 412.9 239.7 Q 412.9 241.1, 413.5 241.8 Q 414.1 242.6, 415.3 242.6 Q 415.9 242.6, 416.5 242.4 Q 417.1 242.2, 417.8 241.9 L 418.3 243.0 Q 417.5 243.4, 416.7 243.6 Q 416.0 243.7, 415.2 243.7 Q 413.4 243.7, 412.3 242.6 Q 411.3 241.5, 411.3 239.5 M 415.2 236.4 Q 414.2 236.4, 413.7 237.0 Q 413.1 237.5, 412.9 238.6 L 417.0 238.6 Q 416.9 237.5, 416.5 237.0 Q 416.0 236.4, 415.2 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 427.2 231.5 L 427.2 243.6 L 426.0 243.6 L 425.8 242.6 Q 424.9 243.7, 423.4 243.7 Q 421.6 243.7, 420.7 242.7 Q 419.7 241.6, 419.7 239.6 Q 419.7 237.6, 420.9 236.4 Q 422.0 235.2, 424.0 235.2 Q 424.8 235.2, 425.7 235.5 L 425.7 231.5 L 427.2 231.5 M 423.5 242.6 Q 424.3 242.6, 424.9 242.1 Q 425.5 241.6, 425.7 240.8 L 425.7 236.7 Q 424.9 236.4, 424.0 236.4 Q 422.7 236.4, 422.0 237.3 Q 421.3 238.1, 421.3 239.6 Q 421.3 241.0, 421.8 241.8 Q 422.4 242.6, 423.5 242.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 429.0 241.7 L 430.6 241.7 L 430.6 243.3 L 429.0 243.3 L 429.0 241.7 M 429.0 236.2 L 430.6 236.2 L 430.6 237.8 L 429.0 237.8 L 429.0 236.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 438.9 242.3 L 441.4 242.3 L 441.4 233.9 L 438.6 234.7 L 438.2 233.8 L 441.7 232.2 L 442.9 232.4 L 442.9 242.3 L 445.1 242.3 L 445.1 243.6 L 438.9 243.6 L 438.9 242.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 446.3 242.0 L 447.9 242.0 L 447.9 243.6 L 446.3 243.6 L 446.3 242.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 449.5 234.4 Q 449.9 233.4, 450.9 232.8 Q 451.9 232.2, 453.3 232.2 Q 455.0 232.2, 455.9 233.1 Q 456.9 234.0, 456.9 235.7 Q 456.9 237.3, 455.7 238.9 Q 454.4 240.5, 451.9 242.3 L 457.1 242.3 L 457.1 243.6 L 449.5 243.6 L 449.5 242.5 Q 451.6 241.0, 452.8 239.9 Q 454.1 238.8, 454.7 237.8 Q 455.3 236.8, 455.3 235.7 Q 455.3 234.6, 454.8 234.0 Q 454.2 233.4, 453.3 233.4 Q 452.4 233.4, 451.8 233.8 Q 451.1 234.2, 450.7 235.0 L 449.5 234.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 458.6 234.4 Q 459.0 233.4, 460.0 232.8 Q 461.0 232.2, 462.4 232.2 Q 464.1 232.2, 465.1 233.1 Q 466.0 234.0, 466.0 235.7 Q 466.0 237.3, 464.8 238.9 Q 463.6 240.5, 461.0 242.3 L 466.2 242.3 L 466.2 243.6 L 458.6 243.6 L 458.6 242.5 Q 460.7 241.0, 462.0 239.9 Q 463.2 238.8, 463.8 237.8 Q 464.4 236.8, 464.4 235.7 Q 464.4 234.6, 463.9 234.0 Q 463.4 233.4, 462.4 233.4 Q 461.5 233.4, 460.9 233.8 Q 460.3 234.2, 459.8 235.0 L 458.6 234.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 471.5 232.2 Q 473.6 232.2, 474.6 233.5 Q 475.6 234.9, 475.6 237.6 Q 475.6 240.6, 474.3 242.2 Q 473.1 243.7, 470.7 243.7 Q 470.0 243.7, 469.3 243.6 Q 468.8 243.4, 468.2 243.1 L 468.8 242.0 Q 469.6 242.5, 470.6 242.5 Q 472.2 242.5, 473.1 241.4 Q 473.9 240.4, 474.0 238.3 Q 473.4 238.8, 472.7 239.1 Q 471.9 239.4, 471.2 239.4 Q 470.2 239.4, 469.4 238.9 Q 468.6 238.5, 468.2 237.7 Q 467.7 236.9, 467.7 235.9 Q 467.7 234.8, 468.2 234.0 Q 468.7 233.1, 469.6 232.6 Q 470.4 232.2, 471.5 232.2 M 469.3 235.9 Q 469.3 236.9, 469.9 237.5 Q 470.4 238.1, 471.4 238.1 Q 472.1 238.1, 472.8 237.8 Q 473.5 237.5, 474.0 237.0 Q 473.9 235.2, 473.3 234.3 Q 472.7 233.5, 471.5 233.5 Q 470.9 233.5, 470.4 233.8 Q 469.9 234.1, 469.6 234.7 Q 469.3 235.2, 469.3 235.9 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 640.8,112.2 L 640.8,112.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 644.4,112.0 L 644.4,113.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 647.9,111.7 L 647.9,113.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 651.5,111.4 L 651.5,113.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 655.0,111.2 L 655.0,113.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 658.6,110.9 L 658.6,114.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 662.1,110.6 L 662.1,114.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-0 atom-1 atom-0\" d=\"M 665.7,110.4 L 665.7,114.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 637.3,112.5 L 623.1,137.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 623.1,137.1 L 610.9,137.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 610.9,137.1 L 598.7,137.1\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 591.8,132.1 L 586.1,122.3\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 586.1,122.3 L 580.5,112.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 580.5,112.5 L 594.7,87.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 594.7,87.9 L 606.9,87.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 606.9,87.9 L 619.1,87.9\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-1\" d=\"M 625.9,92.9 L 631.6,102.7\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-1\" d=\"M 631.6,102.7 L 637.3,112.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 636.6,113.7 L 637.3,112.5 L 637.0,112.0\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 623.8,135.9 L 623.1,137.1 L 622.5,137.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 580.8,113.0 L 580.5,112.5 L 581.2,111.3\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 594.0,89.1 L 594.7,87.9 L 595.3,87.9\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-3\" d=\"M 583.7 133.1 L 584.8 133.1 L 584.8 136.5 L 589.0 136.5 L 589.0 133.1 L 590.0 133.1 L 590.0 141.1 L 589.0 141.1 L 589.0 137.4 L 584.8 137.4 L 584.8 141.1 L 583.7 141.1 L 583.7 133.1 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-3\" d=\"M 592.9 133.1 L 595.5 137.3 Q 595.8 137.8, 596.2 138.5 Q 596.6 139.3, 596.7 139.3 L 596.7 133.1 L 597.7 133.1 L 597.7 141.1 L 596.6 141.1 L 593.8 136.5 Q 593.5 135.9, 593.1 135.3 Q 592.8 134.7, 592.7 134.5 L 592.7 141.1 L 591.6 141.1 L 591.6 133.1 L 592.9 133.1 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-6\" d=\"M 621.3 83.9 L 623.9 88.1 Q 624.2 88.6, 624.6 89.3 Q 625.0 90.1, 625.1 90.1 L 625.1 83.9 L 626.1 83.9 L 626.1 91.9 L 625.0 91.9 L 622.2 87.3 Q 621.9 86.7, 621.5 86.1 Q 621.2 85.5, 621.1 85.3 L 621.1 91.9 L 620.0 91.9 L 620.0 83.9 L 621.3 83.9 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-6\" d=\"M 627.7 83.9 L 628.8 83.9 L 628.8 87.3 L 632.9 87.3 L 632.9 83.9 L 634.0 83.9 L 634.0 91.9 L 632.9 91.9 L 632.9 88.2 L 628.8 88.2 L 628.8 91.9 L 627.7 91.9 L 627.7 83.9 \" fill=\"#0000FF\"/>\n",
       "<path class=\"atom-0\" d=\"M 669.7,113.6 L 669.7,113.7 L 669.7,113.7 L 669.6,113.8 L 669.6,113.8 L 669.6,113.9 L 669.6,113.9 L 669.6,114.0 L 669.5,114.0 L 669.5,114.0 L 669.5,114.1 L 669.4,114.1 L 669.4,114.1 L 669.3,114.1 L 669.3,114.2 L 669.3,114.2 L 669.2,114.2 L 669.2,114.2 L 669.1,114.2 L 669.1,114.2 L 669.0,114.2 L 669.0,114.2 L 668.9,114.2 L 668.9,114.2 L 668.8,114.1 L 668.8,114.1 L 668.7,114.1 L 668.7,114.1 L 668.7,114.0 L 668.6,114.0 L 668.6,113.9 L 668.6,113.9 L 668.6,113.9 L 668.6,113.8 L 668.5,113.8 L 668.5,113.7 L 668.5,113.7 L 668.5,113.6 L 668.5,113.6 L 668.5,113.5 L 668.6,113.5 L 668.6,113.4 L 668.6,113.4 L 668.6,113.3 L 668.6,113.3 L 668.7,113.3 L 668.7,113.2 L 668.7,113.2 L 668.8,113.2 L 668.8,113.1 L 668.9,113.1 L 668.9,113.1 L 669.0,113.1 L 669.0,113.1 L 669.1,113.1 L 669.1,113.1 L 669.2,113.1 L 669.2,113.1 L 669.3,113.1 L 669.3,113.1 L 669.3,113.1 L 669.4,113.1 L 669.4,113.2 L 669.5,113.2 L 669.5,113.2 L 669.5,113.3 L 669.6,113.3 L 669.6,113.4 L 669.6,113.4 L 669.6,113.4 L 669.6,113.5 L 669.7,113.5 L 669.7,113.6 L 669.7,113.6 L 669.1,113.6 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 669.7,111.4 L 669.7,111.4 L 669.7,111.5 L 669.6,111.5 L 669.6,111.6 L 669.6,111.6 L 669.6,111.6 L 669.6,111.7 L 669.5,111.7 L 669.5,111.8 L 669.5,111.8 L 669.4,111.8 L 669.4,111.9 L 669.3,111.9 L 669.3,111.9 L 669.3,111.9 L 669.2,111.9 L 669.2,111.9 L 669.1,111.9 L 669.1,111.9 L 669.0,111.9 L 669.0,111.9 L 668.9,111.9 L 668.9,111.9 L 668.8,111.9 L 668.8,111.8 L 668.7,111.8 L 668.7,111.8 L 668.7,111.7 L 668.6,111.7 L 668.6,111.7 L 668.6,111.6 L 668.6,111.6 L 668.6,111.5 L 668.5,111.5 L 668.5,111.4 L 668.5,111.4 L 668.5,111.3 L 668.5,111.3 L 668.5,111.2 L 668.6,111.2 L 668.6,111.1 L 668.6,111.1 L 668.6,111.1 L 668.6,111.0 L 668.7,111.0 L 668.7,110.9 L 668.7,110.9 L 668.8,110.9 L 668.8,110.9 L 668.9,110.8 L 668.9,110.8 L 669.0,110.8 L 669.0,110.8 L 669.1,110.8 L 669.1,110.8 L 669.2,110.8 L 669.2,110.8 L 669.3,110.8 L 669.3,110.8 L 669.3,110.9 L 669.4,110.9 L 669.4,110.9 L 669.5,110.9 L 669.5,111.0 L 669.5,111.0 L 669.6,111.0 L 669.6,111.1 L 669.6,111.1 L 669.6,111.2 L 669.6,111.2 L 669.7,111.3 L 669.7,111.3 L 669.7,111.4 L 669.1,111.4 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"legend\" d=\"M 529.3 233.5 L 525.8 233.5 L 525.8 232.3 L 534.2 232.3 L 534.2 233.5 L 530.8 233.5 L 530.8 243.6 L 529.3 243.6 L 529.3 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 535.9 235.4 L 536.1 236.5 Q 536.9 235.2, 538.4 235.2 Q 538.8 235.2, 539.4 235.4 L 539.2 236.7 Q 538.5 236.6, 538.1 236.6 Q 537.4 236.6, 537.0 236.8 Q 536.5 237.1, 536.2 237.7 L 536.2 243.6 L 534.7 243.6 L 534.7 235.4 L 535.9 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 547.2 235.4 L 547.2 243.6 L 545.9 243.6 L 545.8 242.5 Q 544.7 243.7, 543.0 243.7 Q 541.6 243.7, 540.9 243.0 Q 540.2 242.2, 540.2 240.8 L 540.2 235.4 L 541.7 235.4 L 541.7 240.7 Q 541.7 241.7, 542.1 242.1 Q 542.4 242.6, 543.3 242.6 Q 544.0 242.6, 544.6 242.2 Q 545.3 241.9, 545.7 241.3 L 545.7 235.4 L 547.2 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 549.0 239.5 Q 549.0 237.4, 550.0 236.3 Q 551.0 235.2, 552.9 235.2 Q 554.7 235.2, 555.5 236.3 Q 556.3 237.4, 556.3 239.4 L 556.3 239.7 L 550.6 239.7 Q 550.6 241.1, 551.2 241.8 Q 551.8 242.5, 553.0 242.5 Q 553.6 242.5, 554.2 242.4 Q 554.8 242.2, 555.6 241.9 L 556.0 242.9 Q 555.2 243.3, 554.4 243.5 Q 553.7 243.7, 552.9 243.7 Q 551.1 243.7, 550.0 242.6 Q 549.0 241.5, 549.0 239.5 M 552.9 236.4 Q 551.9 236.4, 551.4 236.9 Q 550.8 237.5, 550.6 238.6 L 554.7 238.6 Q 554.6 237.4, 554.2 236.9 Q 553.7 236.4, 552.9 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 557.4 241.7 L 559.0 241.7 L 559.0 243.3 L 557.4 243.3 L 557.4 241.7 M 557.4 236.2 L 559.0 236.2 L 559.0 237.8 L 557.4 237.8 L 557.4 236.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 572.1 237.6 Q 573.2 237.9, 573.7 238.7 Q 574.3 239.4, 574.3 240.5 Q 574.3 241.4, 573.8 242.2 Q 573.3 242.9, 572.4 243.3 Q 571.5 243.8, 570.4 243.8 Q 569.2 243.8, 568.3 243.3 Q 567.4 242.9, 566.6 242.0 L 567.6 241.1 Q 568.3 241.9, 568.9 242.2 Q 569.4 242.5, 570.4 242.5 Q 571.4 242.5, 572.0 241.9 Q 572.7 241.4, 572.7 240.5 Q 572.7 239.3, 572.0 238.8 Q 571.4 238.3, 570.0 238.3 L 569.2 238.3 L 569.2 237.1 L 569.9 237.1 Q 571.1 237.1, 571.8 236.6 Q 572.4 236.0, 572.4 235.0 Q 572.4 234.3, 571.9 233.9 Q 571.3 233.4, 570.4 233.4 Q 569.5 233.4, 568.9 233.8 Q 568.3 234.1, 567.8 234.9 L 566.7 234.3 Q 567.1 233.4, 568.1 232.8 Q 569.1 232.1, 570.4 232.1 Q 572.1 232.1, 573.0 232.9 Q 574.0 233.7, 574.0 235.0 Q 574.0 235.9, 573.5 236.6 Q 573.0 237.3, 572.1 237.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 575.7 242.0 L 577.3 242.0 L 577.3 243.6 L 575.7 243.6 L 575.7 242.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 584.4 237.6 Q 585.5 237.9, 586.0 238.7 Q 586.5 239.4, 586.5 240.5 Q 586.5 241.4, 586.0 242.2 Q 585.6 242.9, 584.7 243.3 Q 583.8 243.8, 582.7 243.8 Q 581.4 243.8, 580.5 243.3 Q 579.6 242.9, 578.9 242.0 L 579.8 241.1 Q 580.5 241.9, 581.1 242.2 Q 581.7 242.5, 582.7 242.5 Q 583.7 242.5, 584.3 241.9 Q 584.9 241.4, 584.9 240.5 Q 584.9 239.3, 584.3 238.8 Q 583.6 238.3, 582.2 238.3 L 581.4 238.3 L 581.4 237.1 L 582.1 237.1 Q 583.4 237.1, 584.0 236.6 Q 584.7 236.0, 584.7 235.0 Q 584.7 234.3, 584.1 233.9 Q 583.6 233.4, 582.7 233.4 Q 581.7 233.4, 581.1 233.8 Q 580.6 234.1, 580.1 234.9 L 579.0 234.3 Q 579.4 233.4, 580.4 232.8 Q 581.3 232.1, 582.7 232.1 Q 584.3 232.1, 585.3 232.9 Q 586.3 233.7, 586.3 235.0 Q 586.3 235.9, 585.8 236.6 Q 585.3 237.3, 584.4 237.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 593.9 233.5 L 588.0 233.5 L 588.0 232.3 L 595.5 232.3 L 595.5 233.4 L 590.9 243.6 L 589.4 243.6 L 593.9 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 597.1 242.3 L 599.6 242.3 L 599.6 233.8 L 596.9 234.7 L 596.5 233.8 L 600.0 232.2 L 601.1 232.4 L 601.1 242.3 L 603.4 242.3 L 603.4 243.6 L 597.1 243.6 L 597.1 242.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 613.8 232.3 Q 615.7 232.3, 616.7 233.1 Q 617.7 234.0, 617.7 235.6 Q 617.7 237.2, 616.7 238.1 Q 615.7 238.9, 613.8 238.9 L 612.0 238.9 L 612.0 243.6 L 610.4 243.6 L 610.4 232.3 L 613.8 232.3 M 613.8 237.7 Q 614.9 237.7, 615.5 237.1 Q 616.1 236.6, 616.1 235.6 Q 616.1 234.6, 615.5 234.1 Q 614.9 233.5, 613.8 233.5 L 612.0 233.5 L 612.0 237.7 L 613.8 237.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 620.2 235.4 L 620.3 236.5 Q 621.2 235.2, 622.6 235.2 Q 623.1 235.2, 623.7 235.4 L 623.4 236.7 Q 622.7 236.6, 622.4 236.6 Q 621.7 236.6, 621.2 236.8 Q 620.8 237.1, 620.4 237.7 L 620.4 243.6 L 618.9 243.6 L 618.9 235.4 L 620.2 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 624.4 239.5 Q 624.4 237.4, 625.4 236.3 Q 626.5 235.2, 628.3 235.2 Q 630.1 235.2, 630.9 236.3 Q 631.7 237.4, 631.7 239.4 L 631.7 239.7 L 626.0 239.7 Q 626.0 241.1, 626.6 241.8 Q 627.3 242.5, 628.4 242.5 Q 629.1 242.5, 629.7 242.4 Q 630.2 242.2, 631.0 241.9 L 631.4 242.9 Q 630.6 243.3, 629.8 243.5 Q 629.1 243.7, 628.3 243.7 Q 626.5 243.7, 625.5 242.6 Q 624.4 241.5, 624.4 239.5 M 628.3 236.4 Q 627.3 236.4, 626.8 236.9 Q 626.2 237.5, 626.0 238.6 L 630.1 238.6 Q 630.0 237.4, 629.6 236.9 Q 629.1 236.4, 628.3 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 640.3 231.4 L 640.3 243.6 L 639.1 243.6 L 638.9 242.6 Q 638.0 243.7, 636.5 243.7 Q 634.8 243.7, 633.8 242.7 Q 632.9 241.6, 632.9 239.6 Q 632.9 237.5, 634.0 236.4 Q 635.1 235.2, 637.1 235.2 Q 637.9 235.2, 638.8 235.4 L 638.8 231.4 L 640.3 231.4 M 636.6 242.5 Q 637.4 242.5, 638.0 242.1 Q 638.6 241.6, 638.8 240.8 L 638.8 236.6 Q 638.0 236.4, 637.1 236.4 Q 635.8 236.4, 635.1 237.3 Q 634.4 238.1, 634.4 239.6 Q 634.4 241.0, 635.0 241.8 Q 635.5 242.5, 636.6 242.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 642.1 232.3 L 643.6 232.3 L 643.6 233.7 L 642.1 233.7 L 642.1 232.3 M 642.1 235.4 L 643.6 235.4 L 643.6 243.6 L 642.1 243.6 L 642.1 235.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 645.5 239.5 Q 645.5 237.5, 646.5 236.4 Q 647.5 235.2, 649.5 235.2 Q 651.3 235.2, 652.3 236.6 L 651.3 237.3 Q 650.9 236.9, 650.5 236.6 Q 650.0 236.4, 649.5 236.4 Q 648.3 236.4, 647.7 237.2 Q 647.1 238.0, 647.1 239.5 Q 647.1 241.0, 647.7 241.8 Q 648.4 242.5, 649.6 242.5 Q 650.2 242.5, 650.7 242.4 Q 651.2 242.2, 651.7 242.0 L 652.1 243.0 Q 651.0 243.7, 649.4 243.7 Q 647.5 243.7, 646.5 242.6 Q 645.5 241.4, 645.5 239.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 653.2 236.5 L 653.2 235.4 L 654.8 235.4 L 655.1 233.0 L 656.2 233.0 L 656.2 235.4 L 658.7 235.4 L 658.7 236.5 L 656.2 236.5 L 656.2 241.1 Q 656.2 242.5, 657.4 242.5 Q 657.9 242.5, 658.6 242.3 L 658.8 243.3 Q 657.9 243.7, 657.1 243.7 Q 656.0 243.7, 655.3 243.0 Q 654.7 242.4, 654.7 241.1 L 654.7 236.5 L 653.2 236.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 659.7 239.5 Q 659.7 237.4, 660.8 236.3 Q 661.8 235.2, 663.6 235.2 Q 665.4 235.2, 666.2 236.3 Q 667.0 237.4, 667.0 239.4 L 667.0 239.7 L 661.3 239.7 Q 661.3 241.1, 661.9 241.8 Q 662.6 242.5, 663.7 242.5 Q 664.4 242.5, 665.0 242.4 Q 665.6 242.2, 666.3 241.9 L 666.7 242.9 Q 665.9 243.3, 665.2 243.5 Q 664.4 243.7, 663.6 243.7 Q 661.8 243.7, 660.8 242.6 Q 659.7 241.5, 659.7 239.5 M 663.6 236.4 Q 662.7 236.4, 662.1 236.9 Q 661.5 237.5, 661.3 238.6 L 665.4 238.6 Q 665.3 237.4, 664.9 236.9 Q 664.4 236.4, 663.6 236.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 675.6 231.4 L 675.6 243.6 L 674.4 243.6 L 674.2 242.6 Q 673.3 243.7, 671.8 243.7 Q 670.1 243.7, 669.1 242.7 Q 668.2 241.6, 668.2 239.6 Q 668.2 237.5, 669.3 236.4 Q 670.4 235.2, 672.4 235.2 Q 673.2 235.2, 674.1 235.4 L 674.1 231.4 L 675.6 231.4 M 671.9 242.5 Q 672.7 242.5, 673.3 242.1 Q 673.9 241.6, 674.1 240.8 L 674.1 236.6 Q 673.3 236.4, 672.4 236.4 Q 671.1 236.4, 670.4 237.3 Q 669.7 238.1, 669.7 239.6 Q 669.7 241.0, 670.3 241.8 Q 670.8 242.5, 671.9 242.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 677.5 241.7 L 679.1 241.7 L 679.1 243.3 L 677.5 243.3 L 677.5 241.7 M 677.5 236.2 L 679.1 236.2 L 679.1 237.8 L 677.5 237.8 L 677.5 236.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 692.6 233.5 L 686.7 233.5 L 686.7 232.3 L 694.2 232.3 L 694.2 233.4 L 689.6 243.6 L 688.1 243.6 L 692.6 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 695.2 242.0 L 696.8 242.0 L 696.8 243.6 L 695.2 243.6 L 695.2 242.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 704.3 233.5 L 698.3 233.5 L 698.3 232.3 L 705.9 232.3 L 705.9 233.4 L 701.3 243.6 L 699.8 243.6 L 704.3 233.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 710.7 232.1 Q 712.7 232.1, 713.7 233.5 Q 714.7 234.9, 714.7 237.6 Q 714.7 240.6, 713.5 242.2 Q 712.2 243.7, 709.8 243.7 Q 709.1 243.7, 708.5 243.6 Q 707.9 243.4, 707.3 243.1 L 707.9 242.0 Q 708.8 242.4, 709.8 242.4 Q 711.4 242.4, 712.2 241.4 Q 713.0 240.4, 713.1 238.2 Q 712.5 238.8, 711.8 239.1 Q 711.1 239.3, 710.3 239.3 Q 709.3 239.3, 708.5 238.9 Q 707.7 238.5, 707.3 237.7 Q 706.9 236.9, 706.9 235.9 Q 706.9 234.8, 707.3 234.0 Q 707.8 233.1, 708.7 232.6 Q 709.6 232.1, 710.7 232.1 M 708.5 235.9 Q 708.5 236.9, 709.0 237.5 Q 709.6 238.1, 710.6 238.1 Q 711.3 238.1, 711.9 237.8 Q 712.6 237.5, 713.1 237.0 Q 713.0 235.1, 712.4 234.3 Q 711.9 233.4, 710.7 233.4 Q 710.0 233.4, 709.5 233.8 Q 709.0 234.1, 708.7 234.6 Q 708.5 235.2, 708.5 235.9 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 720.8 236.5 Q 721.8 236.5, 722.5 236.9 Q 723.3 237.4, 723.8 238.2 Q 724.2 239.0, 724.2 239.9 Q 724.2 241.0, 723.7 241.9 Q 723.2 242.8, 722.4 243.2 Q 721.5 243.7, 720.4 243.7 Q 718.4 243.7, 717.3 242.4 Q 716.3 241.0, 716.3 238.3 Q 716.3 235.3, 717.6 233.7 Q 718.9 232.1, 721.3 232.1 Q 722.0 232.1, 722.6 232.3 Q 723.2 232.5, 723.7 232.8 L 723.1 233.9 Q 722.3 233.4, 721.3 233.4 Q 719.7 233.4, 718.9 234.5 Q 718.1 235.5, 718.0 237.6 Q 718.5 237.1, 719.3 236.8 Q 720.0 236.5, 720.8 236.5 M 720.4 242.4 Q 721.0 242.4, 721.5 242.1 Q 722.0 241.8, 722.3 241.2 Q 722.6 240.6, 722.6 240.0 Q 722.6 239.0, 722.0 238.4 Q 721.5 237.8, 720.5 237.8 Q 719.8 237.8, 719.1 238.1 Q 718.4 238.4, 718.0 238.8 Q 718.0 240.7, 718.6 241.6 Q 719.2 242.4, 720.4 242.4 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 135.4,362.5 L 110.8,348.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 110.8,348.3 L 110.8,376.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-0\" d=\"M 110.8,376.7 L 135.4,362.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 134.2,361.8 L 135.4,362.5 L 134.2,363.2\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 112.0,349.0 L 110.8,348.3 L 110.8,349.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 110.8,375.3 L 110.8,376.7 L 112.0,376.0\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 139.4,363.6 L 139.4,363.7 L 139.4,363.7 L 139.3,363.8 L 139.3,363.8 L 139.3,363.9 L 139.3,363.9 L 139.3,364.0 L 139.2,364.0 L 139.2,364.0 L 139.2,364.1 L 139.1,364.1 L 139.1,364.1 L 139.0,364.1 L 139.0,364.2 L 138.9,364.2 L 138.9,364.2 L 138.9,364.2 L 138.8,364.2 L 138.8,364.2 L 138.7,364.2 L 138.7,364.2 L 138.6,364.2 L 138.6,364.2 L 138.5,364.1 L 138.5,364.1 L 138.4,364.1 L 138.4,364.1 L 138.4,364.0 L 138.3,364.0 L 138.3,363.9 L 138.3,363.9 L 138.3,363.9 L 138.2,363.8 L 138.2,363.8 L 138.2,363.7 L 138.2,363.7 L 138.2,363.6 L 138.2,363.6 L 138.2,363.5 L 138.2,363.5 L 138.3,363.4 L 138.3,363.4 L 138.3,363.3 L 138.3,363.3 L 138.4,363.3 L 138.4,363.2 L 138.4,363.2 L 138.5,363.2 L 138.5,363.1 L 138.6,363.1 L 138.6,363.1 L 138.7,363.1 L 138.7,363.1 L 138.8,363.1 L 138.8,363.1 L 138.9,363.1 L 138.9,363.1 L 138.9,363.1 L 139.0,363.1 L 139.0,363.1 L 139.1,363.1 L 139.1,363.2 L 139.2,363.2 L 139.2,363.2 L 139.2,363.3 L 139.3,363.3 L 139.3,363.4 L 139.3,363.4 L 139.3,363.4 L 139.3,363.5 L 139.4,363.5 L 139.4,363.6 L 139.4,363.6 L 138.8,363.6 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 139.4,361.4 L 139.4,361.4 L 139.4,361.5 L 139.3,361.5 L 139.3,361.6 L 139.3,361.6 L 139.3,361.6 L 139.3,361.7 L 139.2,361.7 L 139.2,361.8 L 139.2,361.8 L 139.1,361.8 L 139.1,361.9 L 139.0,361.9 L 139.0,361.9 L 138.9,361.9 L 138.9,361.9 L 138.9,361.9 L 138.8,361.9 L 138.8,361.9 L 138.7,361.9 L 138.7,361.9 L 138.6,361.9 L 138.6,361.9 L 138.5,361.9 L 138.5,361.8 L 138.4,361.8 L 138.4,361.8 L 138.4,361.7 L 138.3,361.7 L 138.3,361.7 L 138.3,361.6 L 138.3,361.6 L 138.2,361.5 L 138.2,361.5 L 138.2,361.4 L 138.2,361.4 L 138.2,361.3 L 138.2,361.3 L 138.2,361.2 L 138.2,361.2 L 138.3,361.1 L 138.3,361.1 L 138.3,361.1 L 138.3,361.0 L 138.4,361.0 L 138.4,360.9 L 138.4,360.9 L 138.5,360.9 L 138.5,360.9 L 138.6,360.8 L 138.6,360.8 L 138.7,360.8 L 138.7,360.8 L 138.8,360.8 L 138.8,360.8 L 138.9,360.8 L 138.9,360.8 L 138.9,360.8 L 139.0,360.8 L 139.0,360.9 L 139.1,360.9 L 139.1,360.9 L 139.2,360.9 L 139.2,361.0 L 139.2,361.0 L 139.3,361.0 L 139.3,361.1 L 139.3,361.1 L 139.3,361.2 L 139.3,361.2 L 139.4,361.3 L 139.4,361.3 L 139.4,361.4 L 138.8,361.4 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"legend\" d=\"M 27.0 483.5 L 23.5 483.5 L 23.5 482.3 L 31.9 482.3 L 31.9 483.5 L 28.6 483.5 L 28.6 493.6 L 27.0 493.6 L 27.0 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 33.6 485.4 L 33.8 486.5 Q 34.7 485.2, 36.1 485.2 Q 36.5 485.2, 37.1 485.4 L 36.9 486.7 Q 36.2 486.6, 35.8 486.6 Q 35.2 486.6, 34.7 486.8 Q 34.3 487.1, 33.9 487.7 L 33.9 493.6 L 32.4 493.6 L 32.4 485.4 L 33.6 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 44.9 485.4 L 44.9 493.6 L 43.7 493.6 L 43.5 492.5 Q 42.4 493.7, 40.7 493.7 Q 39.3 493.7, 38.6 493.0 Q 37.9 492.2, 37.9 490.8 L 37.9 485.4 L 39.4 485.4 L 39.4 490.7 Q 39.4 491.7, 39.8 492.1 Q 40.2 492.6, 41.0 492.6 Q 41.8 492.6, 42.4 492.2 Q 43.0 491.9, 43.4 491.3 L 43.4 485.4 L 44.9 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 46.8 489.5 Q 46.8 487.4, 47.8 486.3 Q 48.8 485.2, 50.6 485.2 Q 52.4 485.2, 53.2 486.3 Q 54.1 487.4, 54.1 489.4 L 54.1 489.7 L 48.3 489.7 Q 48.3 491.1, 49.0 491.8 Q 49.6 492.5, 50.8 492.5 Q 51.4 492.5, 52.0 492.4 Q 52.6 492.2, 53.3 491.9 L 53.7 492.9 Q 52.9 493.4, 52.2 493.5 Q 51.5 493.7, 50.7 493.7 Q 48.8 493.7, 47.8 492.6 Q 46.8 491.5, 46.8 489.5 M 50.6 486.4 Q 49.7 486.4, 49.1 487.0 Q 48.6 487.5, 48.4 488.6 L 52.5 488.6 Q 52.4 487.4, 51.9 486.9 Q 51.5 486.4, 50.6 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 55.2 491.7 L 56.8 491.7 L 56.8 493.3 L 55.2 493.3 L 55.2 491.7 M 55.2 486.2 L 56.8 486.2 L 56.8 487.8 L 55.2 487.8 L 55.2 486.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 70.2 487.6 Q 71.2 488.0, 71.8 488.7 Q 72.4 489.4, 72.4 490.5 Q 72.4 491.4, 71.9 492.2 Q 71.4 492.9, 70.5 493.4 Q 69.7 493.8, 68.5 493.8 Q 66.6 493.8, 65.5 492.9 Q 64.4 492.0, 64.4 490.5 Q 64.4 489.6, 64.9 488.9 Q 65.4 488.2, 66.4 487.6 Q 65.6 487.2, 65.2 486.6 Q 64.8 486.0, 64.8 485.0 Q 64.8 483.7, 65.8 482.9 Q 66.8 482.1, 68.4 482.1 Q 70.1 482.1, 71.0 482.9 Q 72.0 483.7, 72.0 485.0 Q 72.0 485.9, 71.6 486.5 Q 71.1 487.1, 70.2 487.6 M 68.4 483.3 Q 67.5 483.3, 67.0 483.8 Q 66.4 484.2, 66.4 485.0 Q 66.4 485.6, 66.8 486.0 Q 67.2 486.4, 67.6 486.6 Q 68.2 486.9, 69.1 487.2 Q 69.8 486.7, 70.1 486.2 Q 70.4 485.7, 70.4 485.0 Q 70.4 484.2, 69.9 483.8 Q 69.4 483.3, 68.4 483.3 M 68.5 492.6 Q 69.6 492.6, 70.2 492.0 Q 70.8 491.4, 70.8 490.5 Q 70.8 489.9, 70.5 489.5 Q 70.2 489.1, 69.6 488.9 Q 69.2 488.6, 68.3 488.4 L 67.5 488.1 Q 66.7 488.6, 66.4 489.2 Q 66.0 489.7, 66.0 490.5 Q 66.0 491.4, 66.7 492.0 Q 67.4 492.6, 68.5 492.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 74.0 492.0 L 75.6 492.0 L 75.6 493.6 L 74.0 493.6 L 74.0 492.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 81.3 493.7 Q 79.2 493.7, 78.2 492.2 Q 77.2 490.6, 77.2 487.9 Q 77.2 485.2, 78.2 483.7 Q 79.2 482.1, 81.3 482.1 Q 83.4 482.1, 84.4 483.7 Q 85.5 485.2, 85.5 487.9 Q 85.5 490.6, 84.4 492.2 Q 83.4 493.7, 81.3 493.7 M 81.3 492.4 Q 82.5 492.4, 83.2 491.3 Q 83.9 490.2, 83.9 487.9 Q 83.9 485.7, 83.2 484.6 Q 82.5 483.4, 81.3 483.4 Q 80.1 483.4, 79.4 484.6 Q 78.8 485.7, 78.8 487.9 Q 78.8 490.2, 79.4 491.3 Q 80.1 492.4, 81.3 492.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 91.2 486.5 Q 92.1 486.5, 93.0 486.9 Q 93.8 487.4, 94.2 488.2 Q 94.7 488.9, 94.7 490.0 Q 94.7 491.2, 94.1 492.0 Q 93.6 492.9, 92.6 493.3 Q 91.7 493.7, 90.7 493.7 Q 89.6 493.7, 88.7 493.3 Q 87.7 493.0, 87.0 492.2 L 88.0 491.2 Q 88.5 491.8, 89.3 492.1 Q 90.0 492.4, 90.7 492.4 Q 91.7 492.4, 92.4 491.8 Q 93.1 491.2, 93.1 490.0 Q 93.1 488.8, 92.4 488.3 Q 91.7 487.7, 90.6 487.7 Q 89.6 487.7, 88.5 488.1 L 87.6 487.7 L 88.2 482.3 L 94.0 482.3 L 93.8 483.5 L 89.5 483.5 L 89.2 486.9 Q 90.2 486.5, 91.2 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 100.1 486.5 Q 101.1 486.5, 101.9 486.9 Q 102.8 487.4, 103.2 488.2 Q 103.7 488.9, 103.7 490.0 Q 103.7 491.2, 103.1 492.0 Q 102.5 492.9, 101.6 493.3 Q 100.7 493.7, 99.6 493.7 Q 98.6 493.7, 97.6 493.3 Q 96.7 493.0, 96.0 492.2 L 97.0 491.2 Q 97.5 491.8, 98.2 492.1 Q 98.9 492.4, 99.7 492.4 Q 100.7 492.4, 101.4 491.8 Q 102.1 491.2, 102.1 490.0 Q 102.1 488.8, 101.4 488.3 Q 100.7 487.7, 99.6 487.7 Q 98.6 487.7, 97.5 488.1 L 96.6 487.7 L 97.2 482.3 L 103.0 482.3 L 102.8 483.5 L 98.5 483.5 L 98.1 486.9 Q 99.1 486.5, 100.1 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 114.2 482.3 Q 116.2 482.3, 117.1 483.1 Q 118.1 484.0, 118.1 485.6 Q 118.1 487.2, 117.1 488.1 Q 116.1 488.9, 114.2 488.9 L 112.4 488.9 L 112.4 493.6 L 110.9 493.6 L 110.9 482.3 L 114.2 482.3 M 114.2 487.7 Q 115.3 487.7, 115.9 487.1 Q 116.5 486.6, 116.5 485.6 Q 116.5 484.6, 115.9 484.1 Q 115.3 483.5, 114.2 483.5 L 112.4 483.5 L 112.4 487.7 L 114.2 487.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 120.6 485.4 L 120.8 486.5 Q 121.7 485.2, 123.1 485.2 Q 123.5 485.2, 124.1 485.4 L 123.9 486.7 Q 123.2 486.6, 122.8 486.6 Q 122.1 486.6, 121.7 486.8 Q 121.3 487.1, 120.9 487.7 L 120.9 493.6 L 119.4 493.6 L 119.4 485.4 L 120.6 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 124.9 489.5 Q 124.9 487.4, 125.9 486.3 Q 126.9 485.2, 128.8 485.2 Q 130.6 485.2, 131.4 486.3 Q 132.2 487.4, 132.2 489.4 L 132.2 489.7 L 126.4 489.7 Q 126.5 491.1, 127.1 491.8 Q 127.7 492.5, 128.9 492.5 Q 129.5 492.5, 130.1 492.4 Q 130.7 492.2, 131.4 491.9 L 131.9 492.9 Q 131.1 493.4, 130.3 493.5 Q 129.6 493.7, 128.8 493.7 Q 127.0 493.7, 125.9 492.6 Q 124.9 491.5, 124.9 489.5 M 128.8 486.4 Q 127.8 486.4, 127.2 487.0 Q 126.7 487.5, 126.5 488.6 L 130.6 488.6 Q 130.5 487.4, 130.0 486.9 Q 129.6 486.4, 128.8 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 140.8 481.4 L 140.8 493.6 L 139.6 493.6 L 139.4 492.6 Q 138.5 493.7, 137.0 493.7 Q 135.2 493.7, 134.3 492.7 Q 133.3 491.6, 133.3 489.6 Q 133.3 487.5, 134.5 486.4 Q 135.6 485.2, 137.6 485.2 Q 138.4 485.2, 139.3 485.4 L 139.3 481.4 L 140.8 481.4 M 137.1 492.5 Q 137.9 492.5, 138.5 492.1 Q 139.1 491.6, 139.3 490.8 L 139.3 486.6 Q 138.5 486.4, 137.6 486.4 Q 136.3 486.4, 135.6 487.3 Q 134.9 488.1, 134.9 489.6 Q 134.9 491.0, 135.4 491.8 Q 136.0 492.5, 137.1 492.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 142.6 482.3 L 144.1 482.3 L 144.1 483.7 L 142.6 483.7 L 142.6 482.3 M 142.6 485.4 L 144.1 485.4 L 144.1 493.6 L 142.6 493.6 L 142.6 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 146.0 489.5 Q 146.0 487.5, 147.0 486.4 Q 148.0 485.2, 150.0 485.2 Q 151.8 485.2, 152.8 486.6 L 151.8 487.3 Q 151.4 486.9, 151.0 486.6 Q 150.5 486.4, 150.0 486.4 Q 148.8 486.4, 148.2 487.2 Q 147.6 488.0, 147.6 489.5 Q 147.6 491.0, 148.2 491.8 Q 148.9 492.5, 150.1 492.5 Q 150.7 492.5, 151.2 492.4 Q 151.7 492.2, 152.2 492.0 L 152.7 493.0 Q 151.5 493.7, 149.9 493.7 Q 148.0 493.7, 147.0 492.6 Q 146.0 491.4, 146.0 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 153.7 486.5 L 153.7 485.4 L 155.3 485.4 L 155.6 483.0 L 156.7 483.0 L 156.7 485.4 L 159.2 485.4 L 159.2 486.5 L 156.7 486.5 L 156.7 491.1 Q 156.7 492.5, 157.9 492.5 Q 158.4 492.5, 159.1 492.3 L 159.3 493.3 Q 158.4 493.7, 157.6 493.7 Q 156.5 493.7, 155.9 493.0 Q 155.2 492.4, 155.2 491.1 L 155.2 486.5 L 153.7 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 160.3 489.5 Q 160.3 487.4, 161.3 486.3 Q 162.3 485.2, 164.1 485.2 Q 165.9 485.2, 166.7 486.3 Q 167.5 487.4, 167.5 489.4 L 167.5 489.7 L 161.8 489.7 Q 161.8 491.1, 162.5 491.8 Q 163.1 492.5, 164.3 492.5 Q 164.9 492.5, 165.5 492.4 Q 166.1 492.2, 166.8 491.9 L 167.2 492.9 Q 166.4 493.4, 165.7 493.5 Q 164.9 493.7, 164.2 493.7 Q 162.3 493.7, 161.3 492.6 Q 160.3 491.5, 160.3 489.5 M 164.1 486.4 Q 163.2 486.4, 162.6 487.0 Q 162.0 487.5, 161.9 488.6 L 166.0 488.6 Q 165.9 487.4, 165.4 486.9 Q 165.0 486.4, 164.1 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 176.2 481.4 L 176.2 493.6 L 175.0 493.6 L 174.8 492.6 Q 173.8 493.7, 172.3 493.7 Q 170.6 493.7, 169.6 492.7 Q 168.7 491.6, 168.7 489.6 Q 168.7 487.5, 169.8 486.4 Q 171.0 485.2, 172.9 485.2 Q 173.8 485.2, 174.7 485.4 L 174.7 481.4 L 176.2 481.4 M 172.4 492.5 Q 173.2 492.5, 173.8 492.1 Q 174.4 491.6, 174.7 490.8 L 174.7 486.6 Q 173.9 486.4, 172.9 486.4 Q 171.7 486.4, 171.0 487.3 Q 170.2 488.1, 170.2 489.6 Q 170.2 491.0, 170.8 491.8 Q 171.4 492.5, 172.4 492.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 178.0 491.7 L 179.6 491.7 L 179.6 493.3 L 178.0 493.3 L 178.0 491.7 M 178.0 486.2 L 179.6 486.2 L 179.6 487.8 L 178.0 487.8 L 178.0 486.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 192.7 487.6 Q 193.8 487.9, 194.3 488.7 Q 194.8 489.4, 194.8 490.5 Q 194.8 491.4, 194.4 492.2 Q 193.9 492.9, 193.0 493.4 Q 192.1 493.8, 191.0 493.8 Q 189.7 493.8, 188.8 493.3 Q 187.9 492.9, 187.2 492.0 L 188.1 491.1 Q 188.8 491.9, 189.4 492.2 Q 190.0 492.5, 191.0 492.5 Q 192.0 492.5, 192.6 491.9 Q 193.2 491.4, 193.2 490.5 Q 193.2 489.3, 192.6 488.8 Q 191.9 488.3, 190.5 488.3 L 189.7 488.3 L 189.7 487.1 L 190.5 487.1 Q 191.7 487.1, 192.3 486.6 Q 193.0 486.0, 193.0 485.0 Q 193.0 484.3, 192.5 483.9 Q 191.9 483.4, 191.0 483.4 Q 190.0 483.4, 189.4 483.8 Q 188.9 484.1, 188.4 484.9 L 187.3 484.3 Q 187.7 483.4, 188.7 482.8 Q 189.6 482.1, 191.0 482.1 Q 192.6 482.1, 193.6 482.9 Q 194.6 483.7, 194.6 485.0 Q 194.6 485.9, 194.1 486.6 Q 193.6 487.3, 192.7 487.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 196.3 492.0 L 197.9 492.0 L 197.9 493.6 L 196.3 493.6 L 196.3 492.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 203.9 486.5 Q 204.9 486.5, 205.7 487.0 Q 206.5 487.4, 206.9 488.2 Q 207.4 489.0, 207.4 489.9 Q 207.4 491.0, 206.9 491.9 Q 206.4 492.8, 205.5 493.2 Q 204.7 493.7, 203.6 493.7 Q 201.5 493.7, 200.5 492.4 Q 199.5 491.0, 199.5 488.3 Q 199.5 485.3, 200.8 483.7 Q 202.0 482.1, 204.4 482.1 Q 205.1 482.1, 205.7 482.3 Q 206.3 482.5, 206.9 482.8 L 206.3 483.9 Q 205.5 483.4, 204.5 483.4 Q 202.9 483.4, 202.0 484.5 Q 201.2 485.5, 201.1 487.6 Q 201.7 487.1, 202.4 486.8 Q 203.2 486.5, 203.9 486.5 M 203.6 492.4 Q 204.2 492.4, 204.7 492.1 Q 205.2 491.8, 205.5 491.2 Q 205.8 490.6, 205.8 490.0 Q 205.8 489.0, 205.2 488.4 Q 204.6 487.8, 203.7 487.8 Q 203.0 487.8, 202.3 488.1 Q 201.6 488.4, 201.1 488.8 Q 201.2 490.7, 201.8 491.6 Q 202.4 492.4, 203.6 492.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 216.2 489.7 L 217.5 489.7 L 217.5 491.0 L 216.2 491.0 L 216.2 493.6 L 214.6 493.6 L 214.6 491.0 L 208.8 491.0 L 208.8 490.0 L 213.8 482.3 L 216.2 482.3 L 216.2 489.7 M 210.6 489.7 L 214.6 489.7 L 214.6 483.3 L 210.6 489.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 218.9 484.4 Q 219.3 483.3, 220.3 482.7 Q 221.3 482.1, 222.6 482.1 Q 224.4 482.1, 225.3 483.1 Q 226.3 484.0, 226.3 485.6 Q 226.3 487.3, 225.0 488.9 Q 223.8 490.5, 221.2 492.3 L 226.5 492.3 L 226.5 493.6 L 218.8 493.6 L 218.8 492.5 Q 221.0 491.0, 222.2 489.9 Q 223.5 488.8, 224.1 487.8 Q 224.7 486.8, 224.7 485.7 Q 224.7 484.6, 224.1 484.0 Q 223.6 483.4, 222.6 483.4 Q 221.7 483.4, 221.1 483.8 Q 220.5 484.2, 220.1 485.0 L 218.9 484.4 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 436.1,356.8 L 412.4,372.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 412.4,372.4 L 387.0,359.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 387.0,359.6 L 363.2,375.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 363.2,375.3 L 337.9,362.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 337.9,362.5 L 326.8,357.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 326.8,357.0 L 315.8,351.4\" style=\"fill:none;fill-rule:evenodd;stroke:#33CCCC;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-4 atom-6\" d=\"M 337.9,362.5 L 332.7,372.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-4 atom-6\" d=\"M 332.7,372.7 L 327.6,382.9\" style=\"fill:none;fill-rule:evenodd;stroke:#33CCCC;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-4 atom-7\" d=\"M 337.9,362.5 L 343.0,352.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-4 atom-7\" d=\"M 343.0,352.3 L 348.1,342.1\" style=\"fill:none;fill-rule:evenodd;stroke:#33CCCC;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 413.5,371.6 L 412.4,372.4 L 411.1,371.8\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 388.2,360.3 L 387.0,359.6 L 385.8,360.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 364.4,374.5 L 363.2,375.3 L 362.0,374.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-5\" d=\"M 310.1 345.7 L 314.9 345.7 L 314.9 346.6 L 311.2 346.6 L 311.2 349.1 L 314.5 349.1 L 314.5 350.0 L 311.2 350.0 L 311.2 353.8 L 310.1 353.8 L 310.1 345.7 \" fill=\"#33CCCC\"/>\n",
       "<path class=\"atom-6\" d=\"M 322.7 383.9 L 327.5 383.9 L 327.5 384.8 L 323.8 384.8 L 323.8 387.2 L 327.1 387.2 L 327.1 388.2 L 323.8 388.2 L 323.8 391.9 L 322.7 391.9 L 322.7 383.9 \" fill=\"#33CCCC\"/>\n",
       "<path class=\"atom-7\" d=\"M 348.2 333.1 L 353.0 333.1 L 353.0 334.0 L 349.3 334.0 L 349.3 336.5 L 352.6 336.5 L 352.6 337.4 L 349.3 337.4 L 349.3 341.1 L 348.2 341.1 L 348.2 333.1 \" fill=\"#33CCCC\"/>\n",
       "<path class=\"atom-0\" d=\"M 440.1,357.9 L 440.1,358.0 L 440.1,358.0 L 440.0,358.1 L 440.0,358.1 L 440.0,358.2 L 440.0,358.2 L 440.0,358.3 L 439.9,358.3 L 439.9,358.3 L 439.9,358.4 L 439.8,358.4 L 439.8,358.4 L 439.7,358.4 L 439.7,358.5 L 439.7,358.5 L 439.6,358.5 L 439.6,358.5 L 439.5,358.5 L 439.5,358.5 L 439.4,358.5 L 439.4,358.5 L 439.3,358.5 L 439.3,358.5 L 439.2,358.4 L 439.2,358.4 L 439.1,358.4 L 439.1,358.3 L 439.1,358.3 L 439.0,358.3 L 439.0,358.2 L 439.0,358.2 L 439.0,358.1 L 439.0,358.1 L 438.9,358.1 L 438.9,358.0 L 438.9,358.0 L 438.9,357.9 L 438.9,357.9 L 438.9,357.8 L 439.0,357.8 L 439.0,357.7 L 439.0,357.7 L 439.0,357.6 L 439.0,357.6 L 439.1,357.6 L 439.1,357.5 L 439.1,357.5 L 439.2,357.5 L 439.2,357.4 L 439.3,357.4 L 439.3,357.4 L 439.4,357.4 L 439.4,357.4 L 439.5,357.4 L 439.5,357.4 L 439.6,357.4 L 439.6,357.4 L 439.7,357.4 L 439.7,357.4 L 439.7,357.4 L 439.8,357.4 L 439.8,357.5 L 439.9,357.5 L 439.9,357.5 L 439.9,357.6 L 440.0,357.6 L 440.0,357.7 L 440.0,357.7 L 440.0,357.7 L 440.0,357.8 L 440.1,357.8 L 440.1,357.9 L 440.1,357.9 L 439.5,357.9 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 440.1,355.7 L 440.1,355.7 L 440.1,355.8 L 440.0,355.8 L 440.0,355.9 L 440.0,355.9 L 440.0,355.9 L 440.0,356.0 L 439.9,356.0 L 439.9,356.1 L 439.9,356.1 L 439.8,356.1 L 439.8,356.1 L 439.7,356.2 L 439.7,356.2 L 439.7,356.2 L 439.6,356.2 L 439.6,356.2 L 439.5,356.2 L 439.5,356.2 L 439.4,356.2 L 439.4,356.2 L 439.3,356.2 L 439.3,356.2 L 439.2,356.2 L 439.2,356.1 L 439.1,356.1 L 439.1,356.1 L 439.1,356.0 L 439.0,356.0 L 439.0,356.0 L 439.0,355.9 L 439.0,355.9 L 439.0,355.8 L 438.9,355.8 L 438.9,355.7 L 438.9,355.7 L 438.9,355.6 L 438.9,355.6 L 438.9,355.5 L 439.0,355.5 L 439.0,355.4 L 439.0,355.4 L 439.0,355.4 L 439.0,355.3 L 439.1,355.3 L 439.1,355.2 L 439.1,355.2 L 439.2,355.2 L 439.2,355.2 L 439.3,355.1 L 439.3,355.1 L 439.4,355.1 L 439.4,355.1 L 439.5,355.1 L 439.5,355.1 L 439.6,355.1 L 439.6,355.1 L 439.7,355.1 L 439.7,355.1 L 439.7,355.1 L 439.8,355.2 L 439.8,355.2 L 439.9,355.2 L 439.9,355.3 L 439.9,355.3 L 440.0,355.3 L 440.0,355.4 L 440.0,355.4 L 440.0,355.5 L 440.0,355.5 L 440.1,355.6 L 440.1,355.6 L 440.1,355.7 L 439.5,355.7 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"legend\" d=\"M 277.6 483.5 L 274.1 483.5 L 274.1 482.3 L 282.4 482.3 L 282.4 483.5 L 279.1 483.5 L 279.1 493.6 L 277.6 493.6 L 277.6 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 284.2 485.4 L 284.4 486.5 Q 285.2 485.2, 286.7 485.2 Q 287.1 485.2, 287.7 485.4 L 287.5 486.7 Q 286.8 486.6, 286.4 486.6 Q 285.7 486.6, 285.3 486.8 Q 284.8 487.1, 284.5 487.7 L 284.5 493.6 L 283.0 493.6 L 283.0 485.4 L 284.2 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 295.5 485.4 L 295.5 493.6 L 294.3 493.6 L 294.1 492.5 Q 293.0 493.7, 291.3 493.7 Q 289.9 493.7, 289.2 493.0 Q 288.5 492.2, 288.5 490.8 L 288.5 485.4 L 290.0 485.4 L 290.0 490.7 Q 290.0 491.7, 290.4 492.1 Q 290.7 492.6, 291.6 492.6 Q 292.3 492.6, 293.0 492.2 Q 293.6 491.9, 294.0 491.3 L 294.0 485.4 L 295.5 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 297.3 489.5 Q 297.3 487.4, 298.3 486.3 Q 299.4 485.2, 301.2 485.2 Q 303.0 485.2, 303.8 486.3 Q 304.6 487.4, 304.6 489.4 L 304.6 489.7 L 298.9 489.7 Q 298.9 491.1, 299.5 491.8 Q 300.2 492.5, 301.3 492.5 Q 302.0 492.5, 302.6 492.4 Q 303.1 492.2, 303.9 491.9 L 304.3 492.9 Q 303.5 493.4, 302.7 493.5 Q 302.0 493.7, 301.2 493.7 Q 299.4 493.7, 298.4 492.6 Q 297.3 491.5, 297.3 489.5 M 301.2 486.4 Q 300.2 486.4, 299.7 487.0 Q 299.1 487.5, 298.9 488.6 L 303.0 488.6 Q 302.9 487.4, 302.5 486.9 Q 302.0 486.4, 301.2 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 305.8 491.7 L 307.4 491.7 L 307.4 493.3 L 305.8 493.3 L 305.8 491.7 M 305.8 486.2 L 307.4 486.2 L 307.4 487.8 L 305.8 487.8 L 305.8 486.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 320.8 487.6 Q 321.8 488.0, 322.4 488.7 Q 323.0 489.4, 323.0 490.5 Q 323.0 491.4, 322.5 492.2 Q 322.0 492.9, 321.1 493.4 Q 320.2 493.8, 319.0 493.8 Q 317.2 493.8, 316.1 492.9 Q 315.0 492.0, 315.0 490.5 Q 315.0 489.6, 315.5 488.9 Q 315.9 488.2, 316.9 487.6 Q 316.2 487.2, 315.8 486.6 Q 315.4 486.0, 315.4 485.0 Q 315.4 483.7, 316.4 482.9 Q 317.3 482.1, 319.0 482.1 Q 320.6 482.1, 321.6 482.9 Q 322.6 483.7, 322.6 485.0 Q 322.6 485.9, 322.1 486.5 Q 321.7 487.1, 320.8 487.6 M 319.0 483.3 Q 318.0 483.3, 317.5 483.8 Q 317.0 484.2, 317.0 485.0 Q 317.0 485.6, 317.3 486.0 Q 317.7 486.4, 318.2 486.6 Q 318.7 486.9, 319.7 487.2 Q 320.4 486.7, 320.7 486.2 Q 321.0 485.7, 321.0 485.0 Q 321.0 484.2, 320.4 483.8 Q 319.9 483.3, 319.0 483.3 M 319.0 492.6 Q 320.1 492.6, 320.7 492.0 Q 321.4 491.4, 321.4 490.5 Q 321.4 489.9, 321.0 489.5 Q 320.7 489.1, 320.2 488.9 Q 319.7 488.6, 318.8 488.4 L 318.1 488.1 Q 317.3 488.6, 316.9 489.2 Q 316.6 489.7, 316.6 490.5 Q 316.6 491.4, 317.3 492.0 Q 317.9 492.6, 319.0 492.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 324.5 492.0 L 326.1 492.0 L 326.1 493.6 L 324.5 493.6 L 324.5 492.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 333.1 487.6 Q 334.3 487.9, 334.8 488.7 Q 335.3 489.4, 335.3 490.5 Q 335.3 491.4, 334.8 492.2 Q 334.4 492.9, 333.5 493.4 Q 332.6 493.8, 331.5 493.8 Q 330.2 493.8, 329.3 493.3 Q 328.4 492.9, 327.7 492.0 L 328.6 491.1 Q 329.3 491.9, 329.9 492.2 Q 330.5 492.5, 331.5 492.5 Q 332.5 492.5, 333.1 491.9 Q 333.7 491.4, 333.7 490.5 Q 333.7 489.3, 333.1 488.8 Q 332.4 488.3, 331.0 488.3 L 330.2 488.3 L 330.2 487.1 L 330.9 487.1 Q 332.2 487.1, 332.8 486.6 Q 333.5 486.0, 333.5 485.0 Q 333.5 484.3, 332.9 483.9 Q 332.4 483.4, 331.5 483.4 Q 330.5 483.4, 329.9 483.8 Q 329.4 484.1, 328.9 484.9 L 327.8 484.3 Q 328.2 483.4, 329.2 482.8 Q 330.1 482.1, 331.5 482.1 Q 333.1 482.1, 334.1 482.9 Q 335.1 483.7, 335.1 485.0 Q 335.1 485.9, 334.6 486.6 Q 334.1 487.3, 333.1 487.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 344.2 489.7 L 345.5 489.7 L 345.5 491.0 L 344.2 491.0 L 344.2 493.6 L 342.7 493.6 L 342.7 491.0 L 336.8 491.0 L 336.8 490.0 L 341.8 482.3 L 344.2 482.3 L 344.2 489.7 M 338.7 489.7 L 342.7 489.7 L 342.7 483.3 L 338.7 489.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 351.3 486.5 Q 352.3 486.5, 353.1 487.0 Q 353.8 487.4, 354.3 488.2 Q 354.7 489.0, 354.7 489.9 Q 354.7 491.0, 354.2 491.9 Q 353.7 492.8, 352.9 493.2 Q 352.0 493.7, 350.9 493.7 Q 348.9 493.7, 347.9 492.4 Q 346.9 491.0, 346.9 488.3 Q 346.9 485.3, 348.1 483.7 Q 349.4 482.1, 351.8 482.1 Q 352.5 482.1, 353.1 482.3 Q 353.7 482.5, 354.3 482.8 L 353.6 483.9 Q 352.8 483.4, 351.8 483.4 Q 350.2 483.4, 349.4 484.5 Q 348.6 485.5, 348.5 487.6 Q 349.0 487.1, 349.8 486.8 Q 350.5 486.5, 351.3 486.5 M 350.9 492.4 Q 351.5 492.4, 352.0 492.1 Q 352.5 491.8, 352.8 491.2 Q 353.1 490.6, 353.1 490.0 Q 353.1 489.0, 352.6 488.4 Q 352.0 487.8, 351.0 487.8 Q 350.3 487.8, 349.6 488.1 Q 349.0 488.4, 348.5 488.8 Q 348.5 490.7, 349.1 491.6 Q 349.7 492.4, 350.9 492.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 365.4 482.3 Q 367.3 482.3, 368.3 483.1 Q 369.2 484.0, 369.2 485.6 Q 369.2 487.2, 368.2 488.1 Q 367.2 488.9, 365.4 488.9 L 363.5 488.9 L 363.5 493.6 L 362.0 493.6 L 362.0 482.3 L 365.4 482.3 M 365.4 487.7 Q 366.5 487.7, 367.0 487.1 Q 367.6 486.6, 367.6 485.6 Q 367.6 484.6, 367.0 484.1 Q 366.5 483.5, 365.4 483.5 L 363.5 483.5 L 363.5 487.7 L 365.4 487.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 371.7 485.4 L 371.9 486.5 Q 372.8 485.2, 374.2 485.2 Q 374.6 485.2, 375.3 485.4 L 375.0 486.7 Q 374.3 486.6, 373.9 486.6 Q 373.3 486.6, 372.8 486.8 Q 372.4 487.1, 372.0 487.7 L 372.0 493.6 L 370.5 493.6 L 370.5 485.4 L 371.7 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 376.0 489.5 Q 376.0 487.4, 377.0 486.3 Q 378.0 485.2, 379.9 485.2 Q 381.7 485.2, 382.5 486.3 Q 383.3 487.4, 383.3 489.4 L 383.3 489.7 L 377.6 489.7 Q 377.6 491.1, 378.2 491.8 Q 378.8 492.5, 380.0 492.5 Q 380.7 492.5, 381.2 492.4 Q 381.8 492.2, 382.6 491.9 L 383.0 492.9 Q 382.2 493.4, 381.4 493.5 Q 380.7 493.7, 379.9 493.7 Q 378.1 493.7, 377.1 492.6 Q 376.0 491.5, 376.0 489.5 M 379.9 486.4 Q 378.9 486.4, 378.4 487.0 Q 377.8 487.5, 377.6 488.6 L 381.7 488.6 Q 381.6 487.4, 381.2 486.9 Q 380.7 486.4, 379.9 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 391.9 481.4 L 391.9 493.6 L 390.7 493.6 L 390.5 492.6 Q 389.6 493.7, 388.1 493.7 Q 386.4 493.7, 385.4 492.7 Q 384.5 491.6, 384.5 489.6 Q 384.5 487.5, 385.6 486.4 Q 386.7 485.2, 388.7 485.2 Q 389.5 485.2, 390.4 485.4 L 390.4 481.4 L 391.9 481.4 M 388.2 492.5 Q 389.0 492.5, 389.6 492.1 Q 390.2 491.6, 390.4 490.8 L 390.4 486.6 Q 389.6 486.4, 388.7 486.4 Q 387.4 486.4, 386.7 487.3 Q 386.0 488.1, 386.0 489.6 Q 386.0 491.0, 386.6 491.8 Q 387.1 492.5, 388.2 492.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 393.8 482.3 L 395.2 482.3 L 395.2 483.7 L 393.8 483.7 L 393.8 482.3 M 393.8 485.4 L 395.2 485.4 L 395.2 493.6 L 393.8 493.6 L 393.8 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 397.1 489.5 Q 397.1 487.5, 398.1 486.4 Q 399.1 485.2, 401.1 485.2 Q 403.0 485.2, 403.9 486.6 L 402.9 487.3 Q 402.5 486.9, 402.1 486.6 Q 401.7 486.4, 401.1 486.4 Q 399.9 486.4, 399.3 487.2 Q 398.7 488.0, 398.7 489.5 Q 398.7 491.0, 399.3 491.8 Q 400.0 492.5, 401.2 492.5 Q 401.8 492.5, 402.3 492.4 Q 402.8 492.2, 403.4 492.0 L 403.8 493.0 Q 402.6 493.7, 401.1 493.7 Q 399.1 493.7, 398.1 492.6 Q 397.1 491.4, 397.1 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 404.9 486.5 L 404.9 485.4 L 406.4 485.4 L 406.7 483.0 L 407.8 483.0 L 407.8 485.4 L 410.3 485.4 L 410.3 486.5 L 407.8 486.5 L 407.8 491.1 Q 407.8 492.5, 409.0 492.5 Q 409.5 492.5, 410.2 492.3 L 410.4 493.3 Q 409.6 493.7, 408.7 493.7 Q 407.7 493.7, 407.0 493.0 Q 406.3 492.4, 406.3 491.1 L 406.3 486.5 L 404.9 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 411.4 489.5 Q 411.4 487.4, 412.4 486.3 Q 413.4 485.2, 415.2 485.2 Q 417.0 485.2, 417.8 486.3 Q 418.7 487.4, 418.7 489.4 L 418.7 489.7 L 412.9 489.7 Q 412.9 491.1, 413.6 491.8 Q 414.2 492.5, 415.4 492.5 Q 416.0 492.5, 416.6 492.4 Q 417.2 492.2, 417.9 491.9 L 418.3 492.9 Q 417.5 493.4, 416.8 493.5 Q 416.1 493.7, 415.3 493.7 Q 413.4 493.7, 412.4 492.6 Q 411.4 491.5, 411.4 489.5 M 415.2 486.4 Q 414.3 486.4, 413.7 487.0 Q 413.2 487.5, 413.0 488.6 L 417.1 488.6 Q 417.0 487.4, 416.5 486.9 Q 416.1 486.4, 415.2 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 427.3 481.4 L 427.3 493.6 L 426.1 493.6 L 425.9 492.6 Q 424.9 493.7, 423.4 493.7 Q 421.7 493.7, 420.8 492.7 Q 419.8 491.6, 419.8 489.6 Q 419.8 487.5, 420.9 486.4 Q 422.1 485.2, 424.0 485.2 Q 424.9 485.2, 425.8 485.4 L 425.8 481.4 L 427.3 481.4 M 423.5 492.5 Q 424.4 492.5, 424.9 492.1 Q 425.6 491.6, 425.8 490.8 L 425.8 486.6 Q 425.0 486.4, 424.0 486.4 Q 422.8 486.4, 422.1 487.3 Q 421.3 488.1, 421.3 489.6 Q 421.3 491.0, 421.9 491.8 Q 422.5 492.5, 423.5 492.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 429.1 491.7 L 430.7 491.7 L 430.7 493.3 L 429.1 493.3 L 429.1 491.7 M 429.1 486.2 L 430.7 486.2 L 430.7 487.8 L 429.1 487.8 L 429.1 486.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 445.7 489.7 L 447.0 489.7 L 447.0 491.0 L 445.7 491.0 L 445.7 493.6 L 444.2 493.6 L 444.2 491.0 L 438.3 491.0 L 438.3 490.0 L 443.3 482.3 L 445.7 482.3 L 445.7 489.7 M 440.2 489.7 L 444.2 489.7 L 444.2 483.3 L 440.2 489.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 448.4 492.0 L 450.0 492.0 L 450.0 493.6 L 448.4 493.6 L 448.4 492.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 452.2 492.3 L 454.6 492.3 L 454.6 483.8 L 451.9 484.7 L 451.5 483.8 L 455.0 482.2 L 456.1 482.4 L 456.1 492.3 L 458.4 492.3 L 458.4 493.6 L 452.2 493.6 L 452.2 492.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 463.4 482.1 Q 465.4 482.1, 466.4 483.5 Q 467.4 484.9, 467.4 487.6 Q 467.4 490.6, 466.2 492.2 Q 464.9 493.7, 462.5 493.7 Q 461.8 493.7, 461.2 493.6 Q 460.6 493.4, 460.0 493.1 L 460.7 492.0 Q 461.5 492.4, 462.5 492.4 Q 464.1 492.4, 464.9 491.4 Q 465.7 490.4, 465.8 488.2 Q 465.3 488.8, 464.5 489.1 Q 463.8 489.3, 463.0 489.3 Q 462.0 489.3, 461.2 488.9 Q 460.5 488.5, 460.0 487.7 Q 459.6 486.9, 459.6 485.9 Q 459.6 484.8, 460.1 484.0 Q 460.6 483.1, 461.4 482.6 Q 462.3 482.1, 463.4 482.1 M 461.2 485.9 Q 461.2 486.9, 461.7 487.5 Q 462.3 488.1, 463.3 488.1 Q 464.0 488.1, 464.7 487.8 Q 465.3 487.5, 465.8 487.0 Q 465.8 485.1, 465.2 484.3 Q 464.6 483.4, 463.4 483.4 Q 462.8 483.4, 462.3 483.8 Q 461.8 484.1, 461.5 484.6 Q 461.2 485.2, 461.2 485.9 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 469.7 492.3 L 472.2 492.3 L 472.2 483.8 L 469.4 484.7 L 469.1 483.8 L 472.5 482.2 L 473.7 482.4 L 473.7 492.3 L 475.9 492.3 L 475.9 493.6 L 469.7 493.6 L 469.7 492.3 \" fill=\"#000000\"/>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 540.7,366.4 L 565.6,352.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 565.6,352.9 L 589.8,367.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 589.8,367.8 L 600.0,362.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 600.0,362.3 L 610.2,356.8\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 619.5,357.2 L 629.2,363.2\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 629.2,363.2 L 639.0,369.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 639.0,369.2 L 664.0,355.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 664.0,355.7 L 673.8,361.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 673.8,361.7 L 683.6,367.7\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 692.8,368.1 L 703.0,362.6\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 703.0,362.6 L 713.2,357.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 564.4,353.6 L 565.6,352.9 L 566.9,353.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 588.6,367.1 L 589.8,367.8 L 590.3,367.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 638.5,368.9 L 639.0,369.2 L 640.3,368.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path d=\"M 662.8,356.4 L 664.0,355.7 L 664.5,356.0\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-3\" d=\"M 611.1 354.3 Q 611.1 352.4, 612.1 351.3 Q 613.0 350.2, 614.8 350.2 Q 616.6 350.2, 617.6 351.3 Q 618.5 352.4, 618.5 354.3 Q 618.5 356.3, 617.5 357.4 Q 616.6 358.5, 614.8 358.5 Q 613.0 358.5, 612.1 357.4 Q 611.1 356.3, 611.1 354.3 M 614.8 357.6 Q 616.0 357.6, 616.7 356.8 Q 617.4 355.9, 617.4 354.3 Q 617.4 352.8, 616.7 352.0 Q 616.0 351.2, 614.8 351.2 Q 613.6 351.2, 612.9 351.9 Q 612.3 352.7, 612.3 354.3 Q 612.3 356.0, 612.9 356.8 Q 613.6 357.6, 614.8 357.6 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-6\" d=\"M 684.5 370.6 Q 684.5 368.7, 685.5 367.6 Q 686.4 366.5, 688.2 366.5 Q 690.0 366.5, 690.9 367.6 Q 691.9 368.7, 691.9 370.6 Q 691.9 372.5, 690.9 373.7 Q 690.0 374.8, 688.2 374.8 Q 686.4 374.8, 685.5 373.7 Q 684.5 372.6, 684.5 370.6 M 688.2 373.8 Q 689.4 373.8, 690.1 373.0 Q 690.8 372.2, 690.8 370.6 Q 690.8 369.0, 690.1 368.2 Q 689.4 367.4, 688.2 367.4 Q 687.0 367.4, 686.3 368.2 Q 685.6 369.0, 685.6 370.6 Q 685.6 372.2, 686.3 373.0 Q 687.0 373.8, 688.2 373.8 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-0\" d=\"M 537.8,367.6 L 537.8,367.6 L 537.8,367.7 L 537.8,367.7 L 537.8,367.8 L 537.8,367.8 L 537.7,367.9 L 537.7,367.9 L 537.7,367.9 L 537.7,368.0 L 537.6,368.0 L 537.6,368.0 L 537.5,368.1 L 537.5,368.1 L 537.4,368.1 L 537.4,368.1 L 537.4,368.1 L 537.3,368.1 L 537.3,368.2 L 537.2,368.2 L 537.2,368.1 L 537.1,368.1 L 537.1,368.1 L 537.0,368.1 L 537.0,368.1 L 536.9,368.1 L 536.9,368.0 L 536.9,368.0 L 536.8,368.0 L 536.8,367.9 L 536.8,367.9 L 536.7,367.8 L 536.7,367.8 L 536.7,367.8 L 536.7,367.7 L 536.7,367.7 L 536.7,367.6 L 536.7,367.6 L 536.7,367.5 L 536.7,367.5 L 536.7,367.4 L 536.7,367.4 L 536.7,367.3 L 536.8,367.3 L 536.8,367.2 L 536.8,367.2 L 536.9,367.2 L 536.9,367.1 L 536.9,367.1 L 537.0,367.1 L 537.0,367.1 L 537.1,367.0 L 537.1,367.0 L 537.2,367.0 L 537.2,367.0 L 537.3,367.0 L 537.3,367.0 L 537.4,367.0 L 537.4,367.0 L 537.4,367.1 L 537.5,367.1 L 537.5,367.1 L 537.6,367.1 L 537.6,367.2 L 537.7,367.2 L 537.7,367.2 L 537.7,367.3 L 537.7,367.3 L 537.8,367.3 L 537.8,367.4 L 537.8,367.4 L 537.8,367.5 L 537.8,367.5 L 537.8,367.6 L 537.2,367.6 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-0\" d=\"M 537.8,365.3 L 537.8,365.4 L 537.8,365.4 L 537.8,365.5 L 537.8,365.5 L 537.8,365.5 L 537.7,365.6 L 537.7,365.6 L 537.7,365.7 L 537.7,365.7 L 537.6,365.7 L 537.6,365.8 L 537.5,365.8 L 537.5,365.8 L 537.4,365.8 L 537.4,365.9 L 537.4,365.9 L 537.3,365.9 L 537.3,365.9 L 537.2,365.9 L 537.2,365.9 L 537.1,365.9 L 537.1,365.8 L 537.0,365.8 L 537.0,365.8 L 536.9,365.8 L 536.9,365.8 L 536.9,365.7 L 536.8,365.7 L 536.8,365.7 L 536.8,365.6 L 536.7,365.6 L 536.7,365.5 L 536.7,365.5 L 536.7,365.4 L 536.7,365.4 L 536.7,365.3 L 536.7,365.3 L 536.7,365.2 L 536.7,365.2 L 536.7,365.1 L 536.7,365.1 L 536.7,365.1 L 536.8,365.0 L 536.8,365.0 L 536.8,364.9 L 536.9,364.9 L 536.9,364.9 L 536.9,364.8 L 537.0,364.8 L 537.0,364.8 L 537.1,364.8 L 537.1,364.8 L 537.2,364.7 L 537.2,364.7 L 537.3,364.7 L 537.3,364.7 L 537.4,364.8 L 537.4,364.8 L 537.4,364.8 L 537.5,364.8 L 537.5,364.8 L 537.6,364.8 L 537.6,364.9 L 537.7,364.9 L 537.7,364.9 L 537.7,365.0 L 537.7,365.0 L 537.8,365.1 L 537.8,365.1 L 537.8,365.2 L 537.8,365.2 L 537.8,365.3 L 537.8,365.3 L 537.2,365.3 Z\" style=\"fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:0.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;\"/>\n",
       "<path class=\"legend\" d=\"M 529.8 483.5 L 526.3 483.5 L 526.3 482.3 L 534.7 482.3 L 534.7 483.5 L 531.4 483.5 L 531.4 493.6 L 529.8 493.6 L 529.8 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 536.4 485.4 L 536.6 486.5 Q 537.5 485.2, 538.9 485.2 Q 539.3 485.2, 539.9 485.4 L 539.7 486.7 Q 539.0 486.6, 538.6 486.6 Q 537.9 486.6, 537.5 486.8 Q 537.1 487.1, 536.7 487.7 L 536.7 493.6 L 535.2 493.6 L 535.2 485.4 L 536.4 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 547.7 485.4 L 547.7 493.6 L 546.5 493.6 L 546.3 492.5 Q 545.2 493.7, 543.5 493.7 Q 542.1 493.7, 541.4 493.0 Q 540.7 492.2, 540.7 490.8 L 540.7 485.4 L 542.2 485.4 L 542.2 490.7 Q 542.2 491.7, 542.6 492.1 Q 543.0 492.6, 543.8 492.6 Q 544.5 492.6, 545.2 492.2 Q 545.8 491.9, 546.2 491.3 L 546.2 485.4 L 547.7 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 549.5 489.5 Q 549.5 487.4, 550.5 486.3 Q 551.6 485.2, 553.4 485.2 Q 555.2 485.2, 556.0 486.3 Q 556.8 487.4, 556.8 489.4 L 556.8 489.7 L 551.1 489.7 Q 551.1 491.1, 551.7 491.8 Q 552.4 492.5, 553.5 492.5 Q 554.2 492.5, 554.8 492.4 Q 555.3 492.2, 556.1 491.9 L 556.5 492.9 Q 555.7 493.4, 554.9 493.5 Q 554.2 493.7, 553.4 493.7 Q 551.6 493.7, 550.6 492.6 Q 549.5 491.5, 549.5 489.5 M 553.4 486.4 Q 552.4 486.4, 551.9 487.0 Q 551.3 487.5, 551.1 488.6 L 555.2 488.6 Q 555.1 487.4, 554.7 486.9 Q 554.2 486.4, 553.4 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 558.0 491.7 L 559.6 491.7 L 559.6 493.3 L 558.0 493.3 L 558.0 491.7 M 558.0 486.2 L 559.6 486.2 L 559.6 487.8 L 558.0 487.8 L 558.0 486.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 572.6 487.6 Q 573.7 487.9, 574.2 488.7 Q 574.8 489.4, 574.8 490.5 Q 574.8 491.4, 574.3 492.2 Q 573.8 492.9, 572.9 493.4 Q 572.0 493.8, 570.9 493.8 Q 569.7 493.8, 568.8 493.3 Q 567.9 492.9, 567.1 492.0 L 568.1 491.1 Q 568.8 491.9, 569.4 492.2 Q 569.9 492.5, 570.9 492.5 Q 571.9 492.5, 572.5 491.9 Q 573.2 491.4, 573.2 490.5 Q 573.2 489.3, 572.5 488.8 Q 571.9 488.3, 570.5 488.3 L 569.7 488.3 L 569.7 487.1 L 570.4 487.1 Q 571.6 487.1, 572.3 486.6 Q 572.9 486.0, 572.9 485.0 Q 572.9 484.3, 572.4 483.9 Q 571.8 483.4, 570.9 483.4 Q 570.0 483.4, 569.4 483.8 Q 568.8 484.1, 568.3 484.9 L 567.2 484.3 Q 567.6 483.4, 568.6 482.8 Q 569.6 482.1, 570.9 482.1 Q 572.6 482.1, 573.5 482.9 Q 574.5 483.7, 574.5 485.0 Q 574.5 485.9, 574.0 486.6 Q 573.5 487.3, 572.6 487.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 576.2 492.0 L 577.8 492.0 L 577.8 493.6 L 576.2 493.6 L 576.2 492.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 585.3 483.5 L 579.4 483.5 L 579.4 482.3 L 586.9 482.3 L 586.9 483.4 L 582.4 493.6 L 580.8 493.6 L 585.3 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 593.9 483.5 L 587.9 483.5 L 587.9 482.3 L 595.4 482.3 L 595.4 483.4 L 590.9 493.6 L 589.3 493.6 L 593.9 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 597.1 492.3 L 599.5 492.3 L 599.5 483.8 L 596.8 484.7 L 596.4 483.8 L 599.9 482.2 L 601.0 482.4 L 601.0 492.3 L 603.3 492.3 L 603.3 493.6 L 597.1 493.6 L 597.1 492.3 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 613.7 482.3 Q 615.6 482.3, 616.6 483.1 Q 617.6 484.0, 617.6 485.6 Q 617.6 487.2, 616.6 488.1 Q 615.6 488.9, 613.7 488.9 L 611.9 488.9 L 611.9 493.6 L 610.3 493.6 L 610.3 482.3 L 613.7 482.3 M 613.7 487.7 Q 614.8 487.7, 615.4 487.1 Q 616.0 486.6, 616.0 485.6 Q 616.0 484.6, 615.4 484.1 Q 614.8 483.5, 613.7 483.5 L 611.9 483.5 L 611.9 487.7 L 613.7 487.7 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 620.1 485.4 L 620.2 486.5 Q 621.1 485.2, 622.5 485.2 Q 623.0 485.2, 623.6 485.4 L 623.3 486.7 Q 622.6 486.6, 622.3 486.6 Q 621.6 486.6, 621.1 486.8 Q 620.7 487.1, 620.4 487.7 L 620.4 493.6 L 618.8 493.6 L 618.8 485.4 L 620.1 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 624.3 489.5 Q 624.3 487.4, 625.3 486.3 Q 626.4 485.2, 628.2 485.2 Q 630.0 485.2, 630.8 486.3 Q 631.6 487.4, 631.6 489.4 L 631.6 489.7 L 625.9 489.7 Q 625.9 491.1, 626.5 491.8 Q 627.2 492.5, 628.3 492.5 Q 629.0 492.5, 629.6 492.4 Q 630.1 492.2, 630.9 491.9 L 631.3 492.9 Q 630.5 493.4, 629.7 493.5 Q 629.0 493.7, 628.2 493.7 Q 626.4 493.7, 625.4 492.6 Q 624.3 491.5, 624.3 489.5 M 628.2 486.4 Q 627.3 486.4, 626.7 487.0 Q 626.1 487.5, 625.9 488.6 L 630.0 488.6 Q 629.9 487.4, 629.5 486.9 Q 629.0 486.4, 628.2 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 640.2 481.4 L 640.2 493.6 L 639.0 493.6 L 638.8 492.6 Q 637.9 493.7, 636.4 493.7 Q 634.7 493.7, 633.7 492.7 Q 632.8 491.6, 632.8 489.6 Q 632.8 487.5, 633.9 486.4 Q 635.0 485.2, 637.0 485.2 Q 637.8 485.2, 638.7 485.4 L 638.7 481.4 L 640.2 481.4 M 636.5 492.5 Q 637.3 492.5, 637.9 492.1 Q 638.5 491.6, 638.7 490.8 L 638.7 486.6 Q 637.9 486.4, 637.0 486.4 Q 635.7 486.4, 635.0 487.3 Q 634.3 488.1, 634.3 489.6 Q 634.3 491.0, 634.9 491.8 Q 635.4 492.5, 636.5 492.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 642.0 482.3 L 643.5 482.3 L 643.5 483.7 L 642.0 483.7 L 642.0 482.3 M 642.0 485.4 L 643.5 485.4 L 643.5 493.6 L 642.0 493.6 L 642.0 485.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 645.4 489.5 Q 645.4 487.5, 646.4 486.4 Q 647.4 485.2, 649.4 485.2 Q 651.2 485.2, 652.2 486.6 L 651.2 487.3 Q 650.8 486.9, 650.4 486.6 Q 649.9 486.4, 649.4 486.4 Q 648.2 486.4, 647.6 487.2 Q 647.0 488.0, 647.0 489.5 Q 647.0 491.0, 647.6 491.8 Q 648.3 492.5, 649.5 492.5 Q 650.1 492.5, 650.6 492.4 Q 651.1 492.2, 651.6 492.0 L 652.0 493.0 Q 650.9 493.7, 649.3 493.7 Q 647.4 493.7, 646.4 492.6 Q 645.4 491.4, 645.4 489.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 653.1 486.5 L 653.1 485.4 L 654.7 485.4 L 654.9 483.0 L 656.1 483.0 L 656.1 485.4 L 658.6 485.4 L 658.6 486.5 L 656.1 486.5 L 656.1 491.1 Q 656.1 492.5, 657.3 492.5 Q 657.7 492.5, 658.4 492.3 L 658.7 493.3 Q 657.8 493.7, 657.0 493.7 Q 655.9 493.7, 655.2 493.0 Q 654.6 492.4, 654.6 491.1 L 654.6 486.5 L 653.1 486.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 659.6 489.5 Q 659.6 487.4, 660.6 486.3 Q 661.6 485.2, 663.5 485.2 Q 665.3 485.2, 666.1 486.3 Q 666.9 487.4, 666.9 489.4 L 666.9 489.7 L 661.2 489.7 Q 661.2 491.1, 661.8 491.8 Q 662.4 492.5, 663.6 492.5 Q 664.3 492.5, 664.8 492.4 Q 665.4 492.2, 666.2 491.9 L 666.6 492.9 Q 665.8 493.4, 665.0 493.5 Q 664.3 493.7, 663.5 493.7 Q 661.7 493.7, 660.7 492.6 Q 659.6 491.5, 659.6 489.5 M 663.5 486.4 Q 662.5 486.4, 662.0 487.0 Q 661.4 487.5, 661.2 488.6 L 665.3 488.6 Q 665.2 487.4, 664.8 486.9 Q 664.3 486.4, 663.5 486.4 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 675.5 481.4 L 675.5 493.6 L 674.3 493.6 L 674.1 492.6 Q 673.2 493.7, 671.7 493.7 Q 670.0 493.7, 669.0 492.7 Q 668.0 491.6, 668.0 489.6 Q 668.0 487.5, 669.2 486.4 Q 670.3 485.2, 672.3 485.2 Q 673.1 485.2, 674.0 485.4 L 674.0 481.4 L 675.5 481.4 M 671.8 492.5 Q 672.6 492.5, 673.2 492.1 Q 673.8 491.6, 674.0 490.8 L 674.0 486.6 Q 673.2 486.4, 672.3 486.4 Q 671.0 486.4, 670.3 487.3 Q 669.6 488.1, 669.6 489.6 Q 669.6 491.0, 670.1 491.8 Q 670.7 492.5, 671.8 492.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 677.3 491.7 L 678.9 491.7 L 678.9 493.3 L 677.3 493.3 L 677.3 491.7 M 677.3 486.2 L 678.9 486.2 L 678.9 487.8 L 677.3 487.8 L 677.3 486.2 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"\" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 692.5 483.5 L 686.5 483.5 L 686.5 482.3 L 694.0 482.3 L 694.0 483.4 L 689.5 493.6 L 687.9 493.6 L 692.5 483.5 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 695.0 492.0 L 696.6 492.0 L 696.6 493.6 L 695.0 493.6 L 695.0 492.0 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 704.0 487.6 Q 705.0 488.0, 705.6 488.7 Q 706.2 489.4, 706.2 490.5 Q 706.2 491.4, 705.7 492.2 Q 705.2 492.9, 704.3 493.4 Q 703.4 493.8, 702.3 493.8 Q 700.4 493.8, 699.3 492.9 Q 698.2 492.0, 698.2 490.5 Q 698.2 489.6, 698.7 488.9 Q 699.2 488.2, 700.2 487.6 Q 699.4 487.2, 699.0 486.6 Q 698.6 486.0, 698.6 485.0 Q 698.6 483.7, 699.6 482.9 Q 700.6 482.1, 702.2 482.1 Q 703.9 482.1, 704.8 482.9 Q 705.8 483.7, 705.8 485.0 Q 705.8 485.9, 705.3 486.5 Q 704.9 487.1, 704.0 487.6 M 702.2 483.3 Q 701.3 483.3, 700.7 483.8 Q 700.2 484.2, 700.2 485.0 Q 700.2 485.6, 700.6 486.0 Q 700.9 486.4, 701.4 486.6 Q 701.9 486.9, 702.9 487.2 Q 703.6 486.7, 703.9 486.2 Q 704.2 485.7, 704.2 485.0 Q 704.2 484.2, 703.7 483.8 Q 703.2 483.3, 702.2 483.3 M 702.3 492.6 Q 703.3 492.6, 704.0 492.0 Q 704.6 491.4, 704.6 490.5 Q 704.6 489.9, 704.3 489.5 Q 703.9 489.1, 703.4 488.9 Q 702.9 488.6, 702.0 488.4 L 701.3 488.1 Q 700.5 488.6, 700.2 489.2 Q 699.8 489.7, 699.8 490.5 Q 699.8 491.4, 700.5 492.0 Q 701.2 492.6, 702.3 492.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 713.2 487.6 Q 714.3 487.9, 714.8 488.7 Q 715.4 489.4, 715.4 490.5 Q 715.4 491.4, 714.9 492.2 Q 714.4 492.9, 713.5 493.4 Q 712.6 493.8, 711.5 493.8 Q 710.3 493.8, 709.4 493.3 Q 708.5 492.9, 707.7 492.0 L 708.7 491.1 Q 709.4 491.9, 710.0 492.2 Q 710.5 492.5, 711.5 492.5 Q 712.5 492.5, 713.1 491.9 Q 713.8 491.4, 713.8 490.5 Q 713.8 489.3, 713.1 488.8 Q 712.5 488.3, 711.1 488.3 L 710.3 488.3 L 710.3 487.1 L 711.0 487.1 Q 712.2 487.1, 712.9 486.6 Q 713.5 486.0, 713.5 485.0 Q 713.5 484.3, 713.0 483.9 Q 712.4 483.4, 711.5 483.4 Q 710.6 483.4, 710.0 483.8 Q 709.4 484.1, 708.9 484.9 L 707.8 484.3 Q 708.2 483.4, 709.2 482.8 Q 710.2 482.1, 711.5 482.1 Q 713.2 482.1, 714.1 482.9 Q 715.1 483.7, 715.1 485.0 Q 715.1 485.9, 714.6 486.6 Q 714.1 487.3, 713.2 487.6 \" fill=\"#000000\"/>\n",
       "<path class=\"legend\" d=\"M 717.5 492.3 L 719.9 492.3 L 719.9 483.8 L 717.2 484.7 L 716.8 483.8 L 720.3 482.2 L 721.4 482.4 L 721.4 492.3 L 723.7 492.3 L 723.7 493.6 L 717.5 493.6 L 717.5 492.3 \" fill=\"#000000\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# inference on the validation subset \n",
    "val_preds = []\n",
    "val_targets = []\n",
    "orig_ids= []               \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(valid_loader):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        pred = model(batch).cpu().numpy().flatten()\n",
    "        val_preds.append(pred)\n",
    "        val_targets.append(batch.y.view(-1).cpu().numpy())\n",
    "        first   = batch_idx * valid_loader.batch_size\n",
    "        count   = pred.shape[0]\n",
    "        orig_ids.extend(valid_ids[first:first+count])\n",
    "\n",
    "val_preds = np.concatenate(val_preds)\n",
    "val_targets = np.concatenate(val_targets)\n",
    "\n",
    "sm_data = PCQM4Mv2Dataset(root=\"C:/Users/mattg/Downloads/HOMO-LUMO/data/pcqm4mv2\", only_smiles=True)\n",
    "\n",
    "valid_smiles = [sm_data[i] for i in orig_ids]  \n",
    "\n",
    "errors  = np.abs(val_preds - val_targets)\n",
    "top_k   = errors.argsort()[-6:][::-1]\n",
    "\n",
    "smiles  = [valid_smiles[i][0] for i in top_k]\n",
    "y_true  = val_targets[top_k]\n",
    "y_pred  = val_preds[top_k]\n",
    "\n",
    "mols    = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "labels  = [f\"True: {t:.3f} Predicted: {p:.3f}\" for t, p in zip(y_true, y_pred)]\n",
    "\n",
    "img = Draw.MolsToGridImage(mols, legends=labels, molsPerRow=3, subImgSize=(250,250), useSVG=True)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76353bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg = dict(gnn_dim = 512,\n",
    "           hidden_dim = 256,\n",
    "           extra_atom_dim = 5,\n",
    "           rdkit_dim = 6,\n",
    "           dropout = 0.2142,\n",
    "           act = \"GELU\",\n",
    "           # optimiser / schedule\n",
    "           max_lr = 8e-5, # ⅓ of valley bottom\n",
    "           div_factor = 25, # init_lr 3.2e-6\n",
    "           final_div_factor = 5_000, # min_lr 1.6e-8\n",
    "           pct_start = 0.30,\n",
    "           weight_decay = 2e-5,\n",
    "           num_epochs = 80,\n",
    "           # misc\n",
    "           accum_steps = 1,\n",
    "           clip_norm = 2.0,\n",
    "           patience = 10)\n",
    "\n",
    "model = GNN_Transformer_Hybrid(gnn_dim = cfg[\"gnn_dim\"],\n",
    "                               rdkit_dim = cfg[\"rdkit_dim\"],\n",
    "                               hidden_dim = cfg[\"hidden_dim\"],\n",
    "                               extra_atom_dim = cfg[\"extra_atom_dim\"],\n",
    "                               dropout_rate = cfg[\"dropout\"],\n",
    "                               activation = cfg[\"act\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2_pyg.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2_pyg.py:103: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  split_dict = replace_numpy_with_torchtensor(torch.load(osp.join(self.root, 'split_dict.pt')))\n",
      "[00:19:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:19:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:19:32] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:19:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:19:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:20:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:20:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:20:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:20:16] Conflicting single bond directions around double bond at index 13.\n",
      "[00:20:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[00:20:37] Conflicting single bond directions around double bond at index 11.\n",
      "[00:20:37]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-D graphs loaded & RDKit features attached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:26:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:29:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:29:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:29:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:29:47] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:47] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:47] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:47] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:47] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:47] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:50] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:50] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:50] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:29:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:29:55] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:56] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:56] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:29:56] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:30:06] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:30:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:30:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:30:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:30:14] Conflicting single bond directions around double bond at index 4.\n",
      "[00:30:14]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[00:30:18] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:30:46] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:30:46] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:31:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:31:33] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:31:34] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:31:39] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:00] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:01] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:05] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:10] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:12] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:32:12] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[00:32:13] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:19] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:24] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[00:32:26] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable train conformers: 3,378,606\n",
      "LMDB already exists - set REBUILD=True to force rebuild\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_25204\\1840175667.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\"))\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  split_dict = torch.load(osp.join(self.folder, 'split_dict.pt'))\n",
      "predict: 100%|██████████| 1149/1149 [01:25<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved hybridgnn_testdev_predictions.csv(n=147,037)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from ogb.lsc import PCQM4Mv2Dataset\n",
    "import numpy as np, pandas as pd, torch\n",
    "from tqdm import tqdm\n",
    "from build_pcqm4m_lmdb import SAVE_DIR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\"))\n",
    "model.to(device).eval()\n",
    "\n",
    "smiles_ds = PCQM4Mv2Dataset(root=f\"{DATA_ROOT}/pcqm4mv2/pcqm4m-v2/\", only_smiles=True)\n",
    "split     = smiles_ds.get_idx_split()\n",
    "test_ids  = split['test-dev']            \n",
    "\n",
    "TEST_LMDB = os.path.join(SAVE_DIR, \"pcqm4m_test-dev3d_dist.lmdb\")\n",
    "test_loader = DataLoader(LMDBDataset(test_ids, TEST_LMDB), batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# inference \n",
    "all_preds, all_idx = [], []\n",
    "with torch.no_grad():\n",
    "    for first, batch in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"predict\"):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        pred  = model(batch).cpu().numpy().ravel()\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        # the slice of indices that produced this batch\n",
    "        start = first * test_loader.batch_size\n",
    "        all_idx.append(test_ids[start:start + len(pred)])\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_idx = np.concatenate(all_idx)\n",
    "assert len(all_preds) == len(all_idx)\n",
    "\n",
    "pd.DataFrame({\"mol_index\": all_idx, \"prediction\": all_preds}).to_csv(\"hybridgnn_testdev_predictions.csv\", index=False)\n",
    "\n",
    "print(\"saved hybridgnn_testdev_predictions.csv\" f\"(n={len(all_preds):,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f7e71",
   "metadata": {},
   "source": [
    "1 Find the missing validation graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac749b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  split_dict = torch.load(osp.join(self.folder, 'split_dict.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid molecules : 73,545\n",
      "Already in LMDB       : 0\n",
      "**Missing in LMDB**   : 73,545\n"
     ]
    }
   ],
   "source": [
    "import lmdb, os, tqdm, numpy as np\n",
    "from ogb.lsc import PCQM4Mv2Dataset\n",
    "from graphdata_lmdb import LMDBDataset          # your wrapper\n",
    "\n",
    "DATA_ROOT = r\"C:/Users/mattg/Downloads/HOMO-LUMO/data\"\n",
    "SAVE_DIR  = f\"{DATA_ROOT}/processed_chunks\"\n",
    "TRAIN_LMDB = os.path.join(SAVE_DIR, \"pcqm4m_train3d_dist.lmdb\")\n",
    "\n",
    "# authoritative split\n",
    "smiles_ds  = PCQM4Mv2Dataset(root=f\"{DATA_ROOT}/pcqm4mv2/pcqm4m-v2/\", only_smiles=True)\n",
    "valid_ids  = set(smiles_ds.get_idx_split()['valid'])\n",
    "\n",
    "# open existing LMDB in RO mode and collect every stored key\n",
    "env = lmdb.open(TRAIN_LMDB, readonly=True, lock=False)\n",
    "with env.begin() as txn:\n",
    "    present_ids = {int(k.decode()) for k,_ in txn.cursor()}\n",
    "\n",
    "missing_ids = sorted(valid_ids - present_ids)\n",
    "print(f\"Total valid molecules : {len(valid_ids):,}\")\n",
    "print(f\"Already in LMDB       : {len(present_ids & valid_ids):,}\")\n",
    "print(f\"**Missing in LMDB**   : {len(missing_ids):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f557471",
   "metadata": {},
   "source": [
    " Make a separate “valid-only” LMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3636e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2_pyg.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2_pyg.py:103: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  split_dict = replace_numpy_with_torchtensor(torch.load(osp.join(self.root, 'split_dict.pt')))\n",
      "[18:20:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:20:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:20:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:20:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:20:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:21:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:21:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:21:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:21:23] Conflicting single bond directions around double bond at index 13.\n",
      "[18:21:23]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[18:21:42] Conflicting single bond directions around double bond at index 11.\n",
      "[18:21:42]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-D graphs loaded & RDKit features attached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:26:57] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:30:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:22] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:25] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:25] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:25] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:30] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:30] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:30] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:30] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:41] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:30:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:30:48] Conflicting single bond directions around double bond at index 4.\n",
      "[18:30:48]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[18:30:53] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:31:20] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:31:20] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:31:56] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:32:07] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:08] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:32:13] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:34] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:39] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:43] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:46] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:32:46] WARNING: not removing hydrogen atom with neighbor that has non-tetrahedral stereochemistry\n",
      "[18:32:47] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:52] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:58] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "[18:32:59] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable train conformers: 3,378,606\n",
      "LMDB already exists - set REBUILD=True to force rebuild\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattg\\AppData\\Local\\Temp\\ipykernel_12736\\1626944190.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNN_Transformer_Hybrid(\n",
       "  (atom_encoder): ExtendedAtomEncoder(\n",
       "    (atom_encoder): AtomEncoder(\n",
       "      (atom_embedding_list): ModuleList(\n",
       "        (0): Embedding(119, 512)\n",
       "        (1): Embedding(5, 512)\n",
       "        (2-3): 2 x Embedding(12, 512)\n",
       "        (4): Embedding(10, 512)\n",
       "        (5-6): 2 x Embedding(6, 512)\n",
       "        (7-8): 2 x Embedding(2, 512)\n",
       "      )\n",
       "    )\n",
       "    (extra_proj): Linear(in_features=5, out_features=512, bias=True)\n",
       "    (output_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (bond_encoder): BondEncoderWithDist(\n",
       "    (cat_enc): BondEncoder(\n",
       "      (bond_embedding_list): ModuleList(\n",
       "        (0): Embedding(5, 512)\n",
       "        (1): Embedding(6, 512)\n",
       "        (2): Embedding(2, 512)\n",
       "      )\n",
       "    )\n",
       "    (dist_mlp): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=512, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1): GINEConv(nn=Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  ))\n",
       "  (edge_upd1): PairWiseUpdate(\n",
       "    (f): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): GINEConv(nn=Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  ))\n",
       "  (edge_upd2): PairWiseUpdate(\n",
       "    (f): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (triplet): TripletBlock(\n",
       "    (angle_mlp): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): CustomTransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayerWithBias(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2142, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2142, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2142, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=518, out_features=256, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2142, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Dropout(p=0.2142, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, torch, numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ogb.lsc import PCQM4Mv2Dataset, PCQM4Mv2Evaluator\n",
    "from graphdata_lmdb import LMDBDataset        \n",
    "from build_pcqm4m_lmdb import MAX_NODES        \n",
    "\n",
    "DATA_ROOT = r\"C:/Users/mattg/Downloads/HOMO-LUMO/data\"\n",
    "SAVE_DIR  = f\"{DATA_ROOT}/processed_chunks\"\n",
    "\n",
    "TRAIN_LMDB = os.path.join(SAVE_DIR, \"pcqm4m_train3d_dist.lmdb\")\n",
    "TEST_LMDB  = os.path.join(SAVE_DIR, \"pcqm4m_test-dev3d_dist.lmdb\")  \n",
    "VALID_LMDB = os.path.join(SAVE_DIR, \"pcqm4m_valid3d_dist.lmdb\")\n",
    "# — load model weights —\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GNN_Transformer_Hybrid(gnn_dim = 512,\n",
    "                               hidden_dim = 256,\n",
    "                               rdkit_dim = 6,\n",
    "                               extra_atom_dim = 5,\n",
    "                               dropout_rate = 0.2142,\n",
    "                               activation = \"GELU\").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_gnn_transformer_hybrid.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1135d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module                                     # params\n",
      "----------------------------------------------------\n",
      "atom_encoder                                616,960\n",
      "bond_encoder                                286,208\n",
      "conv1                                       525,312\n",
      "edge_upd1                                 1,049,600\n",
      "conv2                                       525,312\n",
      "edge_upd2                                 1,049,600\n",
      "triplet                                     263,680\n",
      "transformer                               6,305,792\n",
      "mlp                                         165,889\n",
      "----------------------------------------------------\n",
      "TOTAL                                    10,788,865\n"
     ]
    }
   ],
   "source": [
    "def pretty_param_count(m):\n",
    "    return f\"{sum(p.numel() for p in m.parameters()):,}\"\n",
    "\n",
    "print(\"{:<35s} {:>15s}\".format(\"module\", \"# params\"))\n",
    "print(\"-\"*52)\n",
    "for name, sub in model.named_children():\n",
    "    print(f\"{name:<35s} {pretty_param_count(sub):>15s}\")\n",
    "print(\"-\"*52)\n",
    "print(f\"{'TOTAL':<35s} {pretty_param_count(model):>15s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3648a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\ogb\\lsc\\pcqm4mv2.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  split_dict = torch.load(osp.join(self.folder, 'split_dict.pt'))\n"
     ]
    }
   ],
   "source": [
    "# split indices (authoritative) \n",
    "smiles_ds   = PCQM4Mv2Dataset(root=f\"{DATA_ROOT}/pcqm4mv2/pcqm4m-v2/\", only_smiles=True)\n",
    "split_idx   = smiles_ds.get_idx_split()\n",
    "valid_ids   = split_idx['valid']      \n",
    "testdev_ids = split_idx['test-dev']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77e59d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "C:/Users/mattg/Downloads/HOMO-LUMO/data/processed_chunks\\pcqm4m_valid3d_dist.lmdb: The system cannot find the path specified.\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m y_pred, y_true \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m valid_loader:\n\u001b[0;32m      8\u001b[0m         batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m         out   \u001b[38;5;241m=\u001b[39m model(batch)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\mattg\\anaconda3\\envs\\chemml_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\mattg\\Downloads\\HOMO-LUMO\\graphdata_lmdb.py:62\u001b[0m, in \u001b[0;36mLMDBDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,i):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m=\u001b[39m\u001b[43mlmdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mreadahead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbegin(buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m txn:\n\u001b[0;32m     64\u001b[0m         buf\u001b[38;5;241m=\u001b[39mtxn\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mids[i])\u001b[38;5;241m.\u001b[39mencode())\n",
      "\u001b[1;31mError\u001b[0m: C:/Users/mattg/Downloads/HOMO-LUMO/data/processed_chunks\\pcqm4m_valid3d_dist.lmdb: The system cannot find the path specified.\r\n"
     ]
    }
   ],
   "source": [
    "# DataLoader over validation indices \n",
    "valid_loader = DataLoader(LMDBDataset(valid_ids, VALID_LMDB), batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# inference \n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        out   = model(batch).view(-1).cpu()\n",
    "        y_pred.append(out)\n",
    "        y_true.append(batch.y.view(-1).cpu())\n",
    "\n",
    "y_pred = torch.cat(y_pred) # 1-D tensor (num_valid,)\n",
    "y_true = torch.cat(y_true)\n",
    "\n",
    "print(\"Shapes:\", y_pred.shape, y_true.shape)\n",
    "\n",
    "# official metric \n",
    "evaluator  = PCQM4Mv2Evaluator()\n",
    "mae = evaluator.eval({'y_pred': y_pred, 'y_true': y_true})['mae']\n",
    "print(f\"Official validation MAE: {mae:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599109d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved submission_dir/y_pred_pcqm4m-v2_test-dev.npz\n"
     ]
    }
   ],
   "source": [
    "# DataLoader over test-dev indices \n",
    "test_loader = DataLoader(LMDBDataset(testdev_ids, TEST_LMDB), batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        preds.append(model(batch).view(-1).cpu())\n",
    "\n",
    "y_pred_test = torch.cat(preds) # (num_test-dev,)\n",
    "assert y_pred_test.numel() == len(testdev_ids)\n",
    "\n",
    "#  save in the required .npz format \n",
    "evaluator.save_test_submission(\n",
    "        input_dict = {'y_pred': y_pred_test},\n",
    "        dir_path   = \"submission_dir\", # any empty / new folder\n",
    "        mode       = 'test-dev')\n",
    "\n",
    "print(\"saved submission_dir/y_pred_pcqm4m-v2_test-dev.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
